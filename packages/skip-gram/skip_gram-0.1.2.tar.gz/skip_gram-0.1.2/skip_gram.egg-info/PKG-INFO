Metadata-Version: 2.4
Name: skip_gram
Version: 0.1.2
Summary: Skip-Gram Word2Vec model with Hierarchical Softmax in PyTorch
Home-page: https://github.com/agentksimha/skip_gram
Author: Krishna Simha
Author-email: Krishna Simha <krishna2005simha@gmail.com>
License: MIT
Keywords: word2vec,skip-gram,hierarchical-softmax,NLP,PyTorch
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE.txt
Requires-Dist: torch>=2.0
Requires-Dist: nltk>=3.8
Requires-Dist: numpy>=1.24
Dynamic: author
Dynamic: home-page
Dynamic: license-file
Dynamic: requires-python

# SkipGram-HS ðŸ§ 

A PyTorch implementation of the Skip-Gram model with Hierarchical Softmax from scratch.

## Features

- Train skip-gram embeddings on your own corpus or NLTK's Brown corpus.
- Hierarchical softmax for efficient training on large vocabularies.
- Save trained embeddings and training loss history.
- Analogy evaluation (e.g., king - man + woman â‰ˆ queen).

## Installation

Install directly from GitHub:

```bash
pip install git+https://github.com/agentksimha/skip_gram.git
