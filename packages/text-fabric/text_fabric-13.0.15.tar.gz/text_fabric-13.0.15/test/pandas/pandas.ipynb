{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy and Pandas versus Python dictionary\n",
    "\n",
    "We measure the memory size and access times for features of Text-Fabric.\n",
    "\n",
    "How much space does a loaded feature occupy in RAM?\n",
    "\n",
    "How fast can we look up the value of a feature for a given node?\n",
    "\n",
    "It turns out that nothing beats the Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from timeit import timeit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tf.core.data import Data\n",
    "from tf.core.timestamp import Timestamp\n",
    "from tf.advanced.helpers import dm\n",
    "\n",
    "from pack import deepSize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "We load some features from the BHSA.\n",
    "\n",
    "They have different sparsity characteristics, as we shall see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also compile this data as Pandas data.\n",
    "\n",
    "The closest data structure is a\n",
    "[Pandas Series](https://pandas.pydata.org/docs/user_guide/dsintro.html).\n",
    "\n",
    "We also test it with a sparse array as data for the series.\n",
    "\n",
    "We start with a Series object based on the data of the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP = \"_temp\"\n",
    "FEATURES = \"\"\"\n",
    "    vs\n",
    "    g_word_utf8\n",
    "    rela\n",
    "\"\"\".strip().split()\n",
    "\n",
    "HEAD = f\"\"\"\\\n",
    "feature | length | start | end | NaN | %NaN | python dict | numpy | pandas | pandas-sparse\n",
    "---     | ---    | ---   | --- | --- | ---  | --- | ---  | --- | ---\n",
    "\"\"\"\n",
    "\n",
    "HEAD_TIME = f\"\"\"\\\n",
    "feature | python dict | numpy | pandas | pandas-sparse\n",
    "---     | ---  | ---   | --- | ---\n",
    "\"\"\"\n",
    "\n",
    "NONES = {None, \"NA\"}\n",
    "\n",
    "TIMES = 1\n",
    "KEYS = (100001, 1000001)\n",
    "\n",
    "T = Timestamp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a class of feature test objects where we store data in various representations.\n",
    "\n",
    "We measure memory usage and add methods to measure the access times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureTest:\n",
    "    def __init__(self, feat):\n",
    "        dataObj = Data(f\"{TEMP}/{feat}.tf\", T)\n",
    "        dataObj.load()\n",
    "        T.indent(level=0)\n",
    "        data  = dataObj.data\n",
    "        start = min(data)\n",
    "        end = max(data)\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.nan = sum(1 for n in range(start, end + 1) if data.get(n, None) in NONES)\n",
    "        self.feat = feat\n",
    "        self.data  = data\n",
    "        self.ln = len(data)\n",
    "        self.mem = deepSize(data) // (1024 * 1024)\n",
    "        \n",
    "    def adjust(self, totalMax):\n",
    "        self.totalMax = totalMax\n",
    "        self.nanPerc = self.nan * 100 / totalMax\n",
    "        \n",
    "    def numpy(self):\n",
    "        data = self.data\n",
    "        totalMax = self.totalMax\n",
    "        array = [data.get(i, \"\") for i in range(totalMax + 1)]\n",
    "        dataN = np.array(array, np.str)\n",
    "        self.dataN = dataN\n",
    "        self.memN = deepSize(dataN) // (1024 * 1024)\n",
    "        \n",
    "    def pandas(self):\n",
    "        data = self.data\n",
    "        dataP = pd.Series(data, dtype=\"string\")\n",
    "        self.dataP = dataP\n",
    "        self.memP = dataP.memory_usage(index=True, deep=True) // (1024 * 1024)\n",
    "\n",
    "        totalMax = self.totalMax\n",
    "        array = [data.get(i, \"NA\") or \"NA\" for i in range(totalMax + 1)]\n",
    "        dataSP = pd.Series(pd.arrays.SparseArray(array, fill_value=\"NA\", dtype=\"string\"))\n",
    "        self.dataSP = dataSP\n",
    "        self.memSP = dataSP.memory_usage(index=True, deep=False) // (1024 * 1024)\n",
    "        \n",
    "    def accessTime(self, times):\n",
    "        data = self.data\n",
    "        locs = locals()\n",
    "        self.access = sum(timeit(f\"data.get({key}, None)\", globals=locs, number=times) for key in KEYS)\n",
    "        \n",
    "    def accessTimeN(self, times):\n",
    "        data = self.dataN\n",
    "        locs = locals()\n",
    "        self.accessN = sum(\n",
    "            timeit(f\"data[{key}] if {key} < data.size else None\", globals=locs, number=times)\n",
    "            for key in KEYS\n",
    "        )\n",
    "        \n",
    "    def accessTimeP(self, times):\n",
    "        dataP = self.dataP\n",
    "        locs = locals()\n",
    "        self.accessP = sum(timeit(f\"dataP.get({key})\", globals=locs, number=times) for key in KEYS)\n",
    "        \n",
    "    def accessTimeSP(self, times):\n",
    "        dataSP = self.dataSP\n",
    "        locs = locals()\n",
    "        self.accessSP = sum(timeit(f\"dataSP.get({key})\", globals=locs, number=times) for key in KEYS)\n",
    "        \n",
    "    def report(self):\n",
    "        return (\n",
    "            f\"{self.feat} | \"\n",
    "            f\"{self.ln} | \"\n",
    "            f\"{self.start} | \"\n",
    "            f\"{self.end} | \"\n",
    "            f\"{self.nan} | \"\n",
    "            f\"{self.nanPerc} | \"\n",
    "            f\"{self.mem} MB | \"\n",
    "            f\"{self.memN} MB | \"\n",
    "            f\"{self.memP} MB | \"\n",
    "            f\"{self.memSP} MB\\n\"\n",
    "        )\n",
    "    \n",
    "    def reportTime(self):\n",
    "        return (\n",
    "            f\"{self.feat} | \"\n",
    "            f\"{self.access} s | \"\n",
    "            f\"{self.accessN} s | \"\n",
    "            f\"{self.accessP} s | \"\n",
    "            f\"{self.accessSP} s\\n\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We collect the feature test objects in a general test object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTest:\n",
    "    def __init__(self):\n",
    "        totalMax = 0\n",
    "        features = {}\n",
    "        T.indent(reset=True)\n",
    "        \n",
    "        for feat in FEATURES:\n",
    "            T.info(f\"stage1 {feat}\")\n",
    "            fObj = FeatureTest(feat)\n",
    "            if fObj.end > totalMax:\n",
    "                totalMax = fObj.end\n",
    "            features[feat] = fObj\n",
    "        T.info(\"done\")\n",
    "            \n",
    "        self.features = features\n",
    "        \n",
    "        for (feat, fObj) in features.items():\n",
    "            T.info(f\"stage2 {feat}\")\n",
    "            fObj.adjust(totalMax)\n",
    "            fObj.numpy()\n",
    "            fObj.pandas()\n",
    "        T.info(\"done\")\n",
    "            \n",
    "    def accessTime(self, times):\n",
    "        features = self.features\n",
    "        for (feat, fObj) in features.items():\n",
    "            T.info(f\"timing {feat}\")\n",
    "            fObj.accessTime(times)\n",
    "            fObj.accessTimeN(times)\n",
    "            fObj.accessTimeP(times)\n",
    "            fObj.accessTimeSP(times)\n",
    "        \n",
    "    def report(self):\n",
    "        features = self.features\n",
    "        \n",
    "        md = HEAD\n",
    "        \n",
    "        for fObj in features.values():\n",
    "            md += fObj.report()\n",
    "            \n",
    "        dm(md)\n",
    "\n",
    "    def reportTime(self):\n",
    "        features = self.features\n",
    "        \n",
    "        md = HEAD_TIME\n",
    "        \n",
    "        for fObj in features.values():\n",
    "            md += fObj.reportTime()\n",
    "            \n",
    "        dm(md)\n",
    "        \n",
    "    def test(self, feat, nodes):\n",
    "        dt = self.features[feat]\n",
    "\n",
    "        md = f\"\"\"\\\n",
    "tf | numpy | pandas | pandas-sparse\n",
    "---|---|---|---\n",
    "\"\"\"\n",
    "\n",
    "        for i in nodes:\n",
    "            md += f\"{dt.data[i]} | {dt.dataN[i]} | {dt.dataP[i]} | {dt.dataSP[i]}\\n\"\n",
    "\n",
    "        dm(md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the features and measure the sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s stage1 vs\n",
      "  0.74s stage1 g_word_utf8\n",
      "  1.63s stage1 rela\n",
      "  2.89s done\n",
      "  2.89s stage2 vs\n",
      "  3.46s stage2 g_word_utf8\n",
      "  4.13s stage2 rela\n",
      "  4.82s done\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "feature | length | start | end | NaN | %NaN | python dict | numpy | pandas | pandas-sparse\n",
       "---     | ---    | ---   | --- | --- | ---  | --- | ---  | --- | ---\n",
       "vs | 426584 | 1 | 426584 | 352874 | 24.949499877329067 | 31 MB | 21 MB | 27 MB | 0 MB\n",
       "g_word_utf8 | 426584 | 1 | 426584 | 0 | 0.0 | 39 MB | 140 MB | 41 MB | 4 MB\n",
       "rela | 722681 | 427553 | 1414353 | 894226 | 63.225093028402384 | 59 MB | 21 MB | 46 MB | 1 MB\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DT = DataTest()\n",
    "DT.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few checks whether the data representations give back the right data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "tf | numpy | pandas | pandas-sparse\n",
       "---|---|---|---\n",
       "NA | NA | NA | NA\n",
       "NA | NA | NA | NA\n",
       "qal | qal | qal | qal\n",
       "NA | NA | NA | NA\n",
       "NA | NA | NA | NA\n",
       "NA | NA | NA | NA\n",
       "NA | NA | NA | NA\n",
       "NA | NA | NA | NA\n",
       "NA | NA | NA | NA\n",
       "NA | NA | NA | NA\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DT.test(\"vs\", range(1, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "tf | numpy | pandas | pandas-sparse\n",
       "---|---|---|---\n",
       "בְּ | בְּ | בְּ | בְּ\n",
       "רֵאשִׁ֖ית | רֵאשִׁ֖ית | רֵאשִׁ֖ית | רֵאשִׁ֖ית\n",
       "בָּרָ֣א | בָּרָ֣א | בָּרָ֣א | בָּרָ֣א\n",
       "אֱלֹהִ֑ים | אֱלֹהִ֑ים | אֱלֹהִ֑ים | אֱלֹהִ֑ים\n",
       "אֵ֥ת | אֵ֥ת | אֵ֥ת | אֵ֥ת\n",
       "הַ | הַ | הַ | הַ\n",
       "שָּׁמַ֖יִם | שָּׁמַ֖יִם | שָּׁמַ֖יִם | שָּׁמַ֖יִם\n",
       "וְ | וְ | וְ | וְ\n",
       "אֵ֥ת | אֵ֥ת | אֵ֥ת | אֵ֥ת\n",
       "הָ | הָ | הָ | הָ\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DT.test(\"g_word_utf8\", range(1, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "tf | numpy | pandas | pandas-sparse\n",
       "---|---|---|---\n",
       "Adju | Adju | Adju | Adju\n",
       "NA | NA | NA | NA\n",
       "NA | NA | NA | NA\n",
       "NA | NA | NA | NA\n",
       "Adju | Adju | Adju | Adju\n",
       "Coor | Coor | Coor | Coor\n",
       "Coor | Coor | Coor | Coor\n",
       "NA | NA | NA | NA\n",
       "Objc | Objc | Objc | Objc\n",
       "NA | NA | NA | NA\n",
       "NA | NA | NA | NA\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DT.test(\"rela\", range(427608, 427619))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    10s timing vs\n",
      "    11s timing g_word_utf8\n",
      "    15s timing rela\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "feature | python dict | numpy | pandas | pandas-sparse\n",
       "---     | ---  | ---   | --- | ---\n",
       "vs | 0.0018969129999995005 s | 0.009688880000002342 s | 0.09362182199999936 s | 0.6480762519999956 s\n",
       "g_word_utf8 | 0.0013883559999996464 s | 0.00787365400000084 s | 0.07825148999999954 s | 4.277200847000003 s\n",
       "rela | 0.0013625329999982227 s | 0.008385869000001378 s | 0.08113798900000546 s | 0.723207390999999 s\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DT.accessTime(10000)\n",
    "DT.reportTime()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "Storage in NumPy is worse than in a Python dict.\n",
    "The access time is also worse, in the order of 5 times.\n",
    "\n",
    "Storage in a Pandas series is slightly better space-wise than in a Python dict.\n",
    "However, the access time is 50 times worse.\n",
    "\n",
    "In a Pandas sparse series, the storage is much smaller, but the access time is 300-3000 times worse.\n",
    "\n",
    "For Text-Fabric, no performance gains are to be expected when turning to Pandas or Numpy as workhorses\n",
    "for storing and accessing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
