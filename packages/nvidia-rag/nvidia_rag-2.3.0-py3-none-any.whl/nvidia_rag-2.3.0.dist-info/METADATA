Metadata-Version: 2.4
Name: nvidia_rag
Version: 2.3.0
Summary: This blueprint serves as a reference solution for a foundational Retrieval Augmented Generation (RAG) pipeline.
Author-email: NVIDIA RAG <foundational-rag-dev@exchange.nvidia.com>
License-Expression: Apache-2.0
Project-URL: Homepage, https://github.com/NVIDIA-AI-Blueprints/rag
Project-URL: Documentation, https://github.com/NVIDIA-AI-Blueprints/rag/blob/main/README.md
Requires-Python: >=3.12
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: bleach==6.2.0
Requires-Dist: dataclass-wizard==0.27.0
Requires-Dist: fastapi==0.115.5
Requires-Dist: langchain>=0.3.27
Requires-Dist: langchain-community>=0.3.27
Requires-Dist: langchain-milvus>=0.2.1
Requires-Dist: langchain-nvidia-ai-endpoints>=0.3.17
Requires-Dist: minio==7.2.15
Requires-Dist: pdfplumber>=0.6
Requires-Dist: pydantic>=2.11.7
Requires-Dist: pymilvus==2.5.8
Requires-Dist: pymilvus-model==0.3.2
Requires-Dist: python-multipart==0.0.18
Requires-Dist: pyyaml==6.0.2
Requires-Dist: uvicorn[standard]==0.32.0
Requires-Dist: langchain-core>=0.3.72
Requires-Dist: redis==5.2.1
Requires-Dist: protobuf>=5.29.5
Requires-Dist: langchain-elasticsearch==0.3.2
Requires-Dist: lark>=1.2.2
Requires-Dist: python-dateutil>=2.9.0.post0
Requires-Dist: nv-ingest-api==25.9.0
Requires-Dist: nv-ingest-client==25.9.0
Requires-Dist: tritonclient==2.57.0
Provides-Extra: rag
Requires-Dist: langchain-openai==0.2.8; extra == "rag"
Requires-Dist: opentelemetry-api==1.29.0; extra == "rag"
Requires-Dist: opentelemetry-exporter-otlp==1.29.0; extra == "rag"
Requires-Dist: opentelemetry-exporter-prometheus==0.50b0; extra == "rag"
Requires-Dist: opentelemetry-instrumentation==0.50b0; extra == "rag"
Requires-Dist: opentelemetry-instrumentation-fastapi==0.50b0; extra == "rag"
Requires-Dist: opentelemetry-instrumentation-milvus==0.36.0; extra == "rag"
Requires-Dist: opentelemetry-processor-baggage==0.50b0; extra == "rag"
Requires-Dist: opentelemetry-sdk==1.29.0; extra == "rag"
Requires-Dist: opentelemetry-sdk-extension-prometheus-multiprocess==1.0.0; extra == "rag"
Requires-Dist: prometheus-client==0.20.0; extra == "rag"
Requires-Dist: azure-core>=1.35.0; extra == "rag"
Requires-Dist: azure-storage-blob>=12.26.0; extra == "rag"
Requires-Dist: pyarrow>=21.0.0; extra == "rag"
Provides-Extra: ingest
Requires-Dist: overrides==7.7.0; extra == "ingest"
Requires-Dist: tqdm==4.67.1; extra == "ingest"
Requires-Dist: opentelemetry-api==1.29.0; extra == "ingest"
Requires-Dist: opentelemetry-exporter-otlp==1.29.0; extra == "ingest"
Requires-Dist: opentelemetry-exporter-prometheus==0.50b0; extra == "ingest"
Requires-Dist: opentelemetry-instrumentation==0.50b0; extra == "ingest"
Requires-Dist: opentelemetry-instrumentation-fastapi==0.50b0; extra == "ingest"
Requires-Dist: opentelemetry-instrumentation-milvus==0.36.0; extra == "ingest"
Requires-Dist: opentelemetry-processor-baggage==0.50b0; extra == "ingest"
Requires-Dist: opentelemetry-sdk==1.29.0; extra == "ingest"
Requires-Dist: azure-core>=1.35.0; extra == "ingest"
Requires-Dist: azure-storage-blob>=12.26.0; extra == "ingest"
Requires-Dist: pyarrow>=21.0.0; extra == "ingest"
Provides-Extra: all
Requires-Dist: langchain-openai==0.2.8; extra == "all"
Requires-Dist: overrides==7.7.0; extra == "all"
Requires-Dist: tqdm==4.67.1; extra == "all"
Requires-Dist: opentelemetry-api==1.29.0; extra == "all"
Requires-Dist: opentelemetry-exporter-otlp==1.29.0; extra == "all"
Requires-Dist: opentelemetry-exporter-prometheus==0.50b0; extra == "all"
Requires-Dist: opentelemetry-instrumentation==0.50b0; extra == "all"
Requires-Dist: opentelemetry-instrumentation-fastapi==0.50b0; extra == "all"
Requires-Dist: opentelemetry-instrumentation-milvus==0.36.0; extra == "all"
Requires-Dist: opentelemetry-processor-baggage==0.50b0; extra == "all"
Requires-Dist: opentelemetry-sdk==1.29.0; extra == "all"
Requires-Dist: azure-core>=1.35.0; extra == "all"
Requires-Dist: azure-storage-blob>=12.26.0; extra == "all"
Requires-Dist: pyarrow>=21.0.0; extra == "all"
Dynamic: license-file

<h1>NVIDIA RAG Blueprint</h1>

Retrieval-Augmented Generation (RAG) combines the reasoning power of large language models (LLMs)
with real-time retrieval from trusted data sources.
It grounds AI responses in enterprise knowledge,
reducing hallucinations and ensuring accuracy, compliance, and freshness.



## Overview

The NVIDIA RAG Blueprint is a reference solution and foundational starting point
for building Retrieval-Augmented Generation (RAG) pipelines with NVIDIA NIM microservices.
It enables enterprises to deliver natural language question answering grounded in their own data,
while meeting governance, latency, and scalability requirements.
Designed to be decomposable and configurable, the blueprint integrates GPU-accelerated components with NeMo Retriever models, Multimodal and Vision Language Models, and guardrailing services,
to provide an enterprise-ready framework.
With a pre-built reference UI, open-source code, and multiple deployment options — including local docker (with and without NVIDIA Hosted endpoints) and Kubernetes —
it serves as a flexible starting point that developers can adapt and extend to their specific needs.



## Key Features

<details>
    <summary>Data Ingestion</summary>
    <ul>
        <li>Multimodal content extraction - Documents with with text, tables, charts, infographics, and audio. For the full list of supported file types, see [NeMo Retriever Extraction Overview](https://docs.nvidia.com/nemo/retriever/latest/extraction/overview/).</li>
        <li>Custom metadata support</li>
    </ul>
</details>
<details>
    <summary>Search and Retrieval</summary>
    <ul>
        <li>Multi-collection searchability</li>
        <li>Hybrid search with dense and sparse search</li>
        <li>Reranking to further improve accuracy</li>
        <li>GPU-accelerated Index creation and search</li>
        <li>Pluggable vector database</li>
    </ul>
</details>
<details>
    <summary>Query Processing</summary>
    <ul>
        <li>Query decomposition</li>
        <li>Dynamic filter expression creation</li>
    </ul>
</details>
<details>
    <summary>Generation and Enrichment</summary>
    <ul>
        <li>Opt-in for Multimodal and Vision Language Model Support in the answer generation pipeline.</li>
        <li>Document summarization</li>
        <li>Improve accuracy with optional reflection</li>
        <li>Optional programmable guardrails for content safety</li>
    </ul>
</details>
<details>
    <summary>Evaluation</summary>
    <ul>
        <li>Evaluation scripts (RAGAS framework)</li>
    </ul>
</details>
<details>
    <summary>User Experience</summary>
    <ul>
        <li>Sample user interface</li>
        <li>Multi-turn conversations</li>
        <li>Multi-session support</li>
    </ul>
</details>
<details>
    <summary>Deployment and Operations</summary>
    <ul>
        <li>Telemetry and observability</li>
        <li>Decomposable and customizable</li>
        <li>NIM Operator support</li>
        <li>Python library mode support</li>
        <li>OpenAI-compatible APIs</li>
    </ul>
</details>



## Software Components

The RAG blueprint is built from the following complementary categories of software:


- **NVIDIA NIM microservices** – Deliver the core AI functionality. Large-scale inference (e.g.for example, Nemotron LLM models for response generation), retrieval and reranking models, and specialized extractors for text, tables, charts, and graphics. Optional NIMs extend these capabilities with OCR, content safety, topic control, and multimodal embeddings.

- **The integration and orchestration layer** – Acts as the glue that binds the system into a complete solution.

This modular design ensures efficient query processing, accurate retrieval of information, and easy customization.


### NVIDIA NIM Microservices


- Response Generation (Inference)

    - [NVIDIA NIM llama-3.3-nemotron-super-49b-v1.5](https://build.nvidia.com/nvidia/llama-3_3-nemotron-super-49b-v1_5)

- Retriever and Extraction Models

    - [NVIDIA NIM llama-3_2-nv-embedqa-1b-v2]( https://build.nvidia.com/nvidia/llama-3_2-nv-embedqa-1b-v2)
    - [NVIDIA NIM llama-3_2-nv-rerankqa-1b-v2](https://build.nvidia.com/nvidia/llama-3_2-nv-rerankqa-1b-v2)
    - [NeMo Retriever Page Elements NIM](https://build.nvidia.com/nvidia/nemoretriever-page-elements-v2)
    - [NeMo Retriever Table Structure NIM](https://build.nvidia.com/nvidia/nemoretriever-table-structure-v1)
    - [NeMo Retriever Graphic Elements NIM](https://build.nvidia.com/nvidia/nemoretriever-graphic-elements-v1)
    - [PaddleOCR NIM](https://build.nvidia.com/baidu/paddleocr)

- Optional NIMs

    - [Llama 3.1 NemoGuard 8B Content Safety NIM](https://build.nvidia.com/nvidia/llama-3_1-nemoguard-8b-content-safety)
    - [Llama 3.1 NemoGuard 8B Topic Control NIM](https://build.nvidia.com/nvidia/llama-3_1-nemoguard-8b-topic-control)
    - [Llama-3.1 Nemotron-nano-vl-8b-v1 NIM](https://build.nvidia.com/nvidia/llama-3.1-nemotron-nano-vl-8b-v1)
    - [NeMo Retriever Parse NIM](https://build.nvidia.com/nvidia/nemoretriever-parse)
    - [NeMo Retriever OCR NIM](https://build.nvidia.com/nvidia/nemoretriever-ocr) (Early Access)
    - [llama-3.2-nemoretriever-1b-vlm-embed-v1](https://build.nvidia.com/nvidia/llama-3_2-nemoretriever-1b-vlm-embed-v1) (Early Access)


 ### Integration and orchestration layer

- **RAG Orchestrator Server** – Coordinates interactions between the user, retrievers, vector database, and inference models, ensuring multi-turn and context-aware query handling. This is [LangChain](https://www.langchain.com/)-based.

- **Vector Database (accelerated with NVIDIA cuVS)** – Stores and searches embeddings at scale with GPU-accelerated indexing and retrieval for low-latency performance. You can use [Milvus Vector Database](https://milvus.io/) or [Elasticsearch](https://www.elastic.co/elasticsearch/vector-database).

- **NeMo Retriever Extraction** – A high-performance ingestion microservice for parsing multimodal content. For more information about the ingestion pipeline, see [NeMo Retriever Extraction Overview](https://docs.nvidia.com/nemo/retriever/latest/extraction/overview/)

- **RAG User Interface (rag-frontend)** – A lightweight user interface that demonstrates end-to-end query, retrieval, and response workflows for developers and end users.


## Source code
The source code for this python package is available [here.](https://github.com/NVIDIA-AI-Blueprints/rag)

## Getting started
Refer to [this notebook](https://github.com/NVIDIA-AI-Blueprints/rag/blob/main/notebooks/rag_library_usage.ipynb) to understand how to leverage this python package for building enterprise RAG usecases!

## Ethical Considerations
NVIDIA believes Trustworthy AI is a shared responsibility, and we have established policies and practices to enable development for a wide array of AI applications. When downloaded or used in accordance with our terms of service, developers should work with their supporting model team to ensure the models meet requirements for the relevant industry and use case and address unforeseen product misuse. For more detailed information on ethical considerations for the models, please see the Model Card++ Explainability, Bias, Safety & Security, and Privacy Subcards. Please report security vulnerabilities or NVIDIA AI concerns [here](https://www.nvidia.com/en-us/support/submit-security-vulnerability/).

## License

This NVIDIA AI BLUEPRINT is licensed under the [Apache License, Version 2.0](https://github.com/NVIDIA-AI-Blueprints/rag/blob/main/LICENSE). This project will download and install additional third-party open source software projects and containers. Review [the license terms of these open source projects](https://github.com/NVIDIA-AI-Blueprints/rag/blob/main/LICENSE-3rd-party.txt) before use.

Use of the models in this blueprint is governed by the [NVIDIA AI Foundation Models Community License](https://docs.nvidia.com/ai-foundation-models-community-license.pdf).


## Terms of Use
This blueprint is governed by the [NVIDIA Agreements | Enterprise Software | NVIDIA Software License Agreement](https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-software-license-agreement/) and the [NVIDIA Agreements | Enterprise Software | Product Specific Terms for AI Product](https://www.nvidia.com/en-us/agreements/enterprise-software/product-specific-terms-for-ai-products/). The models are governed by the [NVIDIA Agreements | Enterprise Software | NVIDIA Community Model License](https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-community-models-license/) and the [NVIDIA RAG dataset](https://github.com/NVIDIA-AI-Blueprints/rag/blob/main/data) which is governed by the [NVIDIA Asset License Agreement](https://github.com/NVIDIA-AI-Blueprints/rag/blob/main/data/LICENSE.DATA).
The following models that are built with Llama are governed by the Llama 3.2 Community License Agreement: nvidia/llama-3.2-nv-embedqa-1b-v2 and nvidia/llama-3.2-nv-rerankqa-1b-v2 and llama-3.2-nemoretriever-1b-vlm-embed-v1.

## Additional Information

The [Llama 3.1 Community License Agreement](https://www.llama.com/llama3_1/license/) for the llama-3.1-nemotron-nano-vl-8b-v1, llama-3.1-nemoguard-8b-content-safety and llama-3.1-nemoguard-8b-topic-control models. The [Llama 3.2 Community License Agreement](https://www.llama.com/llama3_2/license/) for the nvidia/llama-3.2-nv-embedqa-1b-v2, nvidia/llama-3.2-nv-rerankqa-1b-v2 and llama-3.2-nemoretriever-1b-vlm-embed-v1 models. The [Llama 3.3 Community License Agreement](https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/LICENSE) for the llama-3.3-nemotron-super-49b-v1.5 models. Built with Llama. Apache 2.0 for NVIDIA Ingest and for the nemoretriever-page-elements-v2, nemoretriever-table-structure-v1, nemoretriever-graphic-elements-v1, paddleocr and nemoretriever-ocr-v1 models.
