{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB Multi-Phase Training with Training Hub\n",
    "\n",
    "This notebook demonstrates how to perform LAB (Large-scale Alignment for chatBots) multi-phase training using the training_hub library. We'll walk through the two-phase LAB training process:\n",
    "\n",
    "1. **Phase 1 - Knowledge Tuning (Phase07)**: Training on knowledge-heavy data to build foundational understanding\n",
    "2. **Phase 2 - Skills + Replay Training (Phase10)**: Training on skills data with replay of both Phase07 knowledge data AND the base model's original instruction tuning data to maintain all capabilities\n",
    "\n",
    "This LAB multi-phase approach is specifically designed for instruction tuning where you first establish additional knowledge foundations, then add task-specific skills while preventing knowledge forgetting and preserving the base model's original instruction-following capabilities through comprehensive replay mechanisms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, let's import the necessary libraries and set up our training environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training_hub for SFT training\n",
    "from training_hub import sft\n",
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from contextlib import redirect_stdout, redirect_stderr\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging Configuration\n",
    "\n",
    "Set up logging to prevent notebook crashes from excessive output while still showing essential progress and error information.\n",
    "\n",
    "**Note:** While this notebook will walk you through a breakdown of all the steps and contains the end-to-end pipeline, we also provide an example script for any significantly long-running jobs for reproducibility, flexibility, and logging consistency in case of notebook disconnects. You can find the script at `scripts/lab_multiphase_training.py`.\n",
    "\n",
    "**Quick script usage:**\n",
    "```bash\n",
    "python scripts/lab_multiphase_training.py \\\n",
    "  --base-model-path /path/to/model \\\n",
    "  --phase07-data-path /path/to/knowledge.jsonl \\\n",
    "  --phase10-data-path /path/to/skills_replay.jsonl \\\n",
    "  --ckpt-output-base-dir /path/to/checkpoints\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging to prevent notebook crashes from excessive output\n",
    "# while still showing essential progress and error information\n",
    "\n",
    "def setup_training_logging():\n",
    "    \"\"\"Set up logging configuration optimized for notebook environments.\"\"\"\n",
    "    # Reduce logging level for common noisy loggers\n",
    "    logging.getLogger(\"transformers\").setLevel(logging.WARNING)\n",
    "    logging.getLogger(\"torch\").setLevel(logging.WARNING)\n",
    "    logging.getLogger(\"accelerate\").setLevel(logging.WARNING)\n",
    "    \n",
    "    # Set up a custom logger that shows progress without overwhelming the notebook\n",
    "    root_logger = logging.getLogger()\n",
    "    root_logger.setLevel(logging.INFO)\n",
    "    \n",
    "    print(\"‚úÖ Logging configured for notebook environment\")\n",
    "\n",
    "def run_training_with_managed_output(training_func, description=\"Training\"):\n",
    "    \"\"\"\n",
    "    Run training with balanced output showing progress without overwhelming the notebook.\n",
    "    Shows essential progress, errors, and key milestones while filtering excessive logs.\n",
    "    \"\"\"\n",
    "    print(f\"üöÄ Starting {description}...\")\n",
    "    print(\"üìù Showing essential progress and key training milestones\")\n",
    "    print(\"‚è≥ This may take a while. Training progress will appear below:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Run training with minimal output redirection to allow subprocess logs\n",
    "        # but reduce verbosity of the most chatty components\n",
    "        import os\n",
    "        \n",
    "        # Set environment variables to reduce some verbose output\n",
    "        old_env = {}\n",
    "        env_settings = {\n",
    "            'TRANSFORMERS_VERBOSITY': 'warning',\n",
    "            'TOKENIZERS_PARALLELISM': 'false',  # Reduces tokenizer warnings\n",
    "        }\n",
    "        \n",
    "        for key, value in env_settings.items():\n",
    "            old_env[key] = os.environ.get(key)\n",
    "            os.environ[key] = value\n",
    "        \n",
    "        try:\n",
    "            result = training_func()\n",
    "        finally:\n",
    "            # Restore environment\n",
    "            for key, old_value in old_env.items():\n",
    "                if old_value is None:\n",
    "                    os.environ.pop(key, None)\n",
    "                else:\n",
    "                    os.environ[key] = old_value\n",
    "        \n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "        print(f\"‚úÖ {description} completed successfully!\")\n",
    "        print(f\"‚è±Ô∏è  Duration: {duration/3600:.2f} hours\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "        print(f\"‚ùå {description} failed after {duration/60:.1f} minutes\")\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"\\nüí° The error occurred in the distributed training subprocess.\")\n",
    "        print(\"   Check the training logs above for more context about the failure.\")\n",
    "        print(\"   Common issues include: data path problems, memory issues, or model loading errors.\")\n",
    "        \n",
    "        raise\n",
    "\n",
    "# Set up logging\n",
    "setup_training_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Let's define our training configuration. You'll need to adjust these paths to match your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAB Multi-Phase Training Configuration\n",
    "experiment_prefix = \"lab_multiphase_training_demo\"\n",
    "ckpt_output_base_dir = \"/path/to/your/checkpoints\"  # Update this path\n",
    "\n",
    "# Model and data paths - Update these to your actual paths\n",
    "base_model_path = \"/path/to/your/base/model\"  # e.g., granite-3.1-8b-starter-v2.1\n",
    "phase07_data_path = \"/path/to/knowledge_data.jsonl\"  # Knowledge/facts data for Phase07\n",
    "phase10_data_path = \"/path/to/skills_plus_replay_data.jsonl\"  # Skills + replay data for Phase10\n",
    "# Note: Phase10 data should include:\n",
    "# - New skills/task data\n",
    "# - Replay of Phase07 knowledge data  \n",
    "# - Replay of base model's original instruction tuning data\n",
    "\n",
    "# Training hyperparameters\n",
    "max_tokens_per_gpu = 25_000  # Memory limit per GPU (reduce if hitting OOM errors)\n",
    "max_seq_len = 20_000         # Maximum sequence length\n",
    "\n",
    "# Distributed training setup (adjust for your hardware)\n",
    "nproc_per_node = 8  # Number of GPUs per node\n",
    "nnodes = 1          # Number of nodes\n",
    "node_rank = 0       # This node's rank\n",
    "rdzv_id = 47        # Rendezvous ID\n",
    "rdzv_endpoint = \"0.0.0.0:12345\"  # Master endpoint\n",
    "\n",
    "print(f\"LAB Multi-Phase Experiment: {experiment_prefix}\")\n",
    "print(f\"Output directory: {ckpt_output_base_dir}\")\n",
    "print(f\"GPUs per node: {nproc_per_node}\")\n",
    "print(f\"Max tokens per GPU: {max_tokens_per_gpu:,}\")\n",
    "print(f\"\\nData composition:\")\n",
    "print(f\"  Phase07: Knowledge data only\")\n",
    "print(f\"  Phase10: Skills + Phase07 replay + Base model instruction replay\")\n",
    "print(f\"\\nüí° Note: If you encounter OOM (Out of Memory) errors, reduce max_tokens_per_gpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Knowledge Tuning (Phase07)\n",
    "\n",
    "In Phase07, we train the model on knowledge-heavy data to establish foundational understanding. This phase focuses on factual information, domain knowledge, and core concepts that the model needs to master before learning specific skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase07 (Knowledge Tuning) configuration\n",
    "experiment_prefix_phase07 = experiment_prefix + \"_phase07\"\n",
    "experiment_name_phase07 = experiment_prefix_phase07 + \"_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "phase07_ckpt_output_dir = os.path.join(ckpt_output_base_dir, experiment_prefix_phase07)\n",
    "\n",
    "print(f\"Phase07 (Knowledge Tuning) Configuration:\")\n",
    "print(f\"  Experiment name: {experiment_name_phase07}\")\n",
    "print(f\"  Input model: {base_model_path}\")\n",
    "print(f\"  Data path: {phase07_data_path}\")\n",
    "print(f\"  Output directory: {phase07_ckpt_output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Phase07 training with managed output\n",
    "def phase07_training():\n",
    "    \"\"\"Execute Phase07 training with all parameters.\"\"\"\n",
    "    return sft(\n",
    "        # Required parameters\n",
    "        model_path=base_model_path,           # Path to the model to fine-tune\n",
    "        data_path=phase07_data_path,          # Path to the training data\n",
    "        ckpt_output_dir=phase07_ckpt_output_dir,  # Directory to save checkpoints\n",
    "        \n",
    "        # Core training parameters\n",
    "        num_epochs=7,                         # Number of training epochs\n",
    "        effective_batch_size=128,             # Effective batch size for training (smaller due to smaller knowledge dataset)\n",
    "        learning_rate=2e-5,                   # Learning rate for training\n",
    "        max_seq_len=max_seq_len,              # Maximum sequence length\n",
    "        max_tokens_per_gpu=max_tokens_per_gpu, # Maximum tokens per GPU in a mini-batch (hard-cap for memory to avoid OOMs)\n",
    "        \n",
    "        # Data and checkpointing parameters\n",
    "        data_output_dir=\"/dev/shm\",           # Directory to save processed data (using RAM for faster data processing)\n",
    "        warmup_steps=0,                       # Number of warmup steps\n",
    "        save_samples=0,                       # Number of samples to save after training (0 disables saving based on sample count)\n",
    "        checkpoint_at_epoch=True,             # Whether to checkpoint at each epoch (default value, shown for clarity)\n",
    "        accelerate_full_state_at_epoch=False, # Whether to save full state at epoch for automatic checkpoint resumption (override default to save space)\n",
    "        \n",
    "        # Distributed training parameters\n",
    "        nproc_per_node=nproc_per_node,        # Number of processes (GPUs) per node for distributed training\n",
    "        nnodes=nnodes,                        # Total number of nodes for distributed training\n",
    "        node_rank=node_rank,                  # Rank of this node (0 to nnodes-1) for distributed training\n",
    "        rdzv_id=rdzv_id,                      # Unique job ID for rendezvous in distributed training\n",
    "        rdzv_endpoint=rdzv_endpoint,          # Master node endpoint for multi-node training\n",
    "    )\n",
    "\n",
    "# Execute Phase07 training with managed output to prevent notebook crashes\n",
    "try:\n",
    "    result = run_training_with_managed_output(phase07_training, \"Phase07 (Knowledge Tuning)\")\n",
    "    print(\"üéØ Phase07 training completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"üí• Phase07 training failed: {e}\")\n",
    "    print(\"üîç Check the error details above for troubleshooting\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint Discovery\n",
    "\n",
    "After Phase07 completes, we need to find the most recent checkpoint to use as input for Phase10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most recent checkpoint from Phase07\n",
    "phase07_checkpoint_location = f\"{phase07_ckpt_output_dir}/hf_format\"\n",
    "\n",
    "print(f\"Looking for Phase07 checkpoints in: {phase07_checkpoint_location}\")\n",
    "\n",
    "if not os.path.exists(phase07_checkpoint_location):\n",
    "    print(f\"‚ùå Checkpoint directory not found: {phase07_checkpoint_location}\")\n",
    "    print(\"   Make sure Phase07 completed successfully\")\n",
    "else:\n",
    "    phase07_checkpoints = os.listdir(phase07_checkpoint_location)\n",
    "    \n",
    "    if not phase07_checkpoints:\n",
    "        print(f\"‚ùå No checkpoints found in {phase07_checkpoint_location}\")\n",
    "    else:\n",
    "        print(f\"Found {len(phase07_checkpoints)} checkpoint(s):\")\n",
    "        for ckpt in phase07_checkpoints:\n",
    "            print(f\"  - {ckpt}\")\n",
    "        \n",
    "        # Find the most recent checkpoint\n",
    "        most_recent_checkpoint, most_recent_time = None, 0\n",
    "        \n",
    "        for checkpoint in phase07_checkpoints:\n",
    "            full_ckpt_path = f\"{phase07_checkpoint_location}/{checkpoint}\"\n",
    "            if os.path.isdir(full_ckpt_path):\n",
    "                ckpt_time = os.stat(full_ckpt_path).st_ctime\n",
    "                if ckpt_time > most_recent_time:\n",
    "                    most_recent_checkpoint = full_ckpt_path\n",
    "                    most_recent_time = ckpt_time\n",
    "        \n",
    "        if most_recent_checkpoint:\n",
    "            print(f\"\\n‚úÖ Most recent Phase07 checkpoint: {most_recent_checkpoint}\")\n",
    "            print(f\"   Created: {datetime.fromtimestamp(most_recent_time)}\")\n",
    "        else:\n",
    "            print(\"‚ùå No valid checkpoint directories found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Skills + Replay Training (Phase10)\n",
    "\n",
    "In Phase10, we continue training from the Phase07 checkpoint using a comprehensive dataset that includes:\n",
    "\n",
    "1. **New Skills Data**: Task instructions, problem-solving examples, and specific capabilities\n",
    "2. **Phase07 Knowledge Replay**: Replay of the knowledge data from Phase07 to prevent knowledge forgetting  \n",
    "3. **Base Model Instruction Replay**: Replay of the base model's original instruction tuning data to preserve foundational instruction-following capabilities\n",
    "\n",
    "This comprehensive replay strategy ensures that the model maintains both its original instruction-following abilities and the newly acquired knowledge from Phase07, while learning new skills in Phase10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase10 (Skills + Replay Training) configuration\n",
    "if 'most_recent_checkpoint' not in locals() or most_recent_checkpoint is None:\n",
    "    print(\"‚ùå Cannot proceed with Phase10: No checkpoint from Phase07\")\n",
    "    print(\"   Please ensure Phase07 completed successfully\")\n",
    "else:\n",
    "    phase10_input_model = most_recent_checkpoint\n",
    "    experiment_prefix_phase10 = experiment_prefix + \"_phase10\"\n",
    "    experiment_name_phase10 = experiment_prefix_phase10 + \"_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    phase10_ckpt_output_dir = os.path.join(ckpt_output_base_dir, experiment_prefix_phase10)\n",
    "    \n",
    "    print(f\"Phase10 (Skills + Replay Training) Configuration:\")\n",
    "    print(f\"  Experiment name: {experiment_name_phase10}\")\n",
    "    print(f\"  Input model (from Phase07): {phase10_input_model}\")\n",
    "    print(f\"  Data path: {phase10_data_path}\")\n",
    "    print(f\"  Output directory: {phase10_ckpt_output_dir}\")\n",
    "    print(f\"  Training on skills + comprehensive replay data...\")\n",
    "    print(f\"  ‚Ü≥ Skills data + Phase07 knowledge replay + Base model instruction replay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Phase10 training with managed output\n",
    "if 'most_recent_checkpoint' not in locals() or most_recent_checkpoint is None:\n",
    "    print(\"‚ùå Cannot proceed with Phase10: No checkpoint from Phase07\")\n",
    "    print(\"   Please ensure Phase07 completed successfully\")\n",
    "else:\n",
    "    def phase10_training():\n",
    "        \"\"\"Execute Phase10 training with all parameters.\"\"\"\n",
    "        return sft(\n",
    "            # Required parameters\n",
    "            model_path=phase10_input_model,       # Path to the model to fine-tune (from Phase07 checkpoint)\n",
    "            data_path=phase10_data_path,          # Path to the training data (skills + replay data)\n",
    "            ckpt_output_dir=phase10_ckpt_output_dir,  # Directory to save checkpoints\n",
    "            \n",
    "            # Core training parameters\n",
    "            num_epochs=7,                         # Number of training epochs\n",
    "            effective_batch_size=3840,            # Effective batch size for training (larger due to larger skills + replay dataset)\n",
    "            learning_rate=2e-5,                   # Learning rate for training\n",
    "            max_seq_len=max_seq_len,              # Maximum sequence length\n",
    "            max_tokens_per_gpu=max_tokens_per_gpu, # Maximum tokens per GPU in a mini-batch (hard-cap for memory to avoid OOMs)\n",
    "            \n",
    "            # Data and checkpointing parameters\n",
    "            data_output_dir=\"/dev/shm\",           # Directory to save processed data (using RAM for faster data processing)\n",
    "            warmup_steps=0,                       # Number of warmup steps\n",
    "            save_samples=0,                       # Number of samples to save after training (0 disables saving based on sample count)\n",
    "            checkpoint_at_epoch=True,             # Whether to checkpoint at each epoch (default value, shown for clarity)\n",
    "            accelerate_full_state_at_epoch=True,  # Whether to save full state at epoch for automatic checkpoint resumption (default value, enable for final model)\n",
    "            \n",
    "            # Distributed training parameters\n",
    "            nproc_per_node=nproc_per_node,        # Number of processes (GPUs) per node for distributed training\n",
    "            nnodes=nnodes,                        # Total number of nodes for distributed training\n",
    "            node_rank=node_rank,                  # Rank of this node (0 to nnodes-1) for distributed training\n",
    "            rdzv_id=rdzv_id,                      # Unique job ID for rendezvous in distributed training\n",
    "            rdzv_endpoint=rdzv_endpoint,          # Master node endpoint for multi-node training\n",
    "        )\n",
    "\n",
    "    # Execute Phase10 training with managed output to prevent notebook crashes\n",
    "    try:\n",
    "        result = run_training_with_managed_output(phase10_training, \"Phase10 (Skills + Replay Training)\")\n",
    "        print(\"üéØ Phase10 training completed successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"üí• Phase10 training failed: {e}\")\n",
    "        print(\"üîç Check the error details above for troubleshooting\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Summary\n",
    "\n",
    "Let's summarize what we accomplished and where to find the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéâ LAB Multi-Phase Training Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if 'phase07_ckpt_output_dir' in locals():\n",
    "    print(f\"üìÅ Phase07 (Knowledge Tuning) Output: {phase07_ckpt_output_dir}\")\n",
    "    \n",
    "if 'phase10_ckpt_output_dir' in locals():\n",
    "    print(f\"üìÅ Phase10 (Skills + Replay) Output: {phase10_ckpt_output_dir}\")\n",
    "    print(f\"\\nüéØ Final trained model location:\")\n",
    "    print(f\"   {phase10_ckpt_output_dir}/hf_format/[latest_checkpoint]\")\n",
    "    \n",
    "    # List final checkpoints if available\n",
    "    final_ckpt_dir = f\"{phase10_ckpt_output_dir}/hf_format\"\n",
    "    if os.path.exists(final_ckpt_dir):\n",
    "        final_checkpoints = [d for d in os.listdir(final_ckpt_dir) if os.path.isdir(os.path.join(final_ckpt_dir, d))]\n",
    "        if final_checkpoints:\n",
    "            print(f\"\\nüìã Available final checkpoints:\")\n",
    "            for ckpt in sorted(final_checkpoints):\n",
    "                print(f\"   - {ckpt}\")\n",
    "\n",
    "print(f\"\\nüîß LAB Training Configuration Used:\")\n",
    "print(f\"   - Max tokens per GPU: {max_tokens_per_gpu:,}\")\n",
    "print(f\"   - Max sequence length: {max_seq_len:,}\")\n",
    "print(f\"   - GPUs per node: {nproc_per_node}\")\n",
    "print(f\"   - Phase07 batch size: 128 (smaller knowledge dataset)\")\n",
    "print(f\"   - Phase10 batch size: 3840 (larger skills + replay dataset)\")\n",
    "print(f\"   - Learning rate: 2e-5\")\n",
    "print(f\"   - Epochs per phase: 7\")\n",
    "\n",
    "print(f\"\\nüìä Data Composition:\")\n",
    "print(f\"   - Phase07: Knowledge data only\")\n",
    "print(f\"   - Phase10: Skills + Phase07 replay + Base model instruction replay\")\n",
    "\n",
    "print(f\"\\nüí° Next Steps:\")\n",
    "print(f\"   1. Evaluate your model on relevant benchmarks\")\n",
    "print(f\"   2. Test with sample prompts to verify training quality\")\n",
    "print(f\"   3. Check knowledge retention from Phase07\")\n",
    "print(f\"   4. Verify new skills acquisition from Phase10\")\n",
    "print(f\"   5. Confirm base model instruction-following capabilities are preserved\")\n",
    "print(f\"   6. Deploy for inference using your preferred serving framework\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Concepts Explained\n",
    "\n",
    "### LAB Multi-Phase Training Benefits:\n",
    "\n",
    "1. **Knowledge ‚Üí Skills + Comprehensive Replay**: Phase07 builds foundational knowledge, Phase10 adds task-specific capabilities while replaying both Phase07 knowledge AND base model instruction data\n",
    "2. **Comprehensive Replay Strategy**: Prevents both knowledge forgetting (Phase07) and capability regression (base model instruction-following)\n",
    "3. **Dataset-Appropriate Batch Sizes**: Smaller batch size for smaller knowledge datasets, larger batch size for larger skills + replay datasets\n",
    "4. **Checkpoint Continuity**: Seamlessly continue from Phase07 results into Phase10\n",
    "5. **Multi-Level Preservation**: Maintains original instruction capabilities, Phase07 knowledge, and adds new Phase10 skills\n",
    "\n",
    "### Training_Hub Advantages:\n",
    "\n",
    "1. **Simplified Interface**: Single `sft()` function instead of separate argument objects\n",
    "2. **Clear Parameter Organization**: Logical grouping of training, distributed, and advanced options\n",
    "3. **Backend Flexibility**: Easy to switch between different training backends\n",
    "4. **Better Documentation**: Clear parameter names like `max_tokens_per_gpu`\n",
    "\n",
    "### LAB Training Strategy:\n",
    "\n",
    "- **Phase07 Focus**: Knowledge acquisition on typically smaller, focused knowledge datasets\n",
    "- **Phase10 Focus**: Skills training with comprehensive replay on larger combined datasets\n",
    "- **Dual Replay Mechanism**: Prevents both knowledge drift and instruction capability loss\n",
    "- **Memory Management**: `max_tokens_per_gpu` prevents OOM while maintaining throughput\n",
    "- **Fast Data Loading**: Using `/dev/shm` for data processing\n",
    "- **Checkpointing Strategy**: Different strategies for intermediate vs final models\n",
    "\n",
    "### Data Composition Details:\n",
    "\n",
    "**Phase07**: Pure knowledge data for focused learning (typically smaller datasets)\n",
    "**Phase10**: Carefully balanced mixture of (typically much larger combined dataset):\n",
    "- New skills/task data (primary learning objective)\n",
    "- Phase07 knowledge replay (prevents knowledge forgetting)\n",
    "- Base model instruction replay (preserves original capabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### Common Issues:\n",
    "\n",
    "1. **Out of Memory (OOM)**:\n",
    "   - Reduce `max_tokens_per_gpu`\n",
    "   - Reduce `effective_batch_size`\n",
    "   - Check GPU memory usage\n",
    "\n",
    "2. **Checkpoint Not Found**:\n",
    "   - Verify Phase 1 completed successfully\n",
    "   - Check `ckpt_output_dir` permissions\n",
    "   - Look for error messages in training logs\n",
    "\n",
    "3. **Distributed Training Issues**:\n",
    "   - Verify network connectivity between nodes\n",
    "   - Check `rdzv_endpoint` accessibility\n",
    "   - Ensure consistent environment across nodes\n",
    "\n",
    "4. **Data Loading Errors**:\n",
    "   - Verify data file paths exist\n",
    "   - Check JSONL format validity\n",
    "   - Ensure sufficient disk space in `/dev/shm`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
