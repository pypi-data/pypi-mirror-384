{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37b2628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (C) [2025] [DingGuohua]\n",
    "#\n",
    "# This program is free software: you can redistribute it and/or modify\n",
    "# it under the terms of the GNU Affero General Public License as published\n",
    "# by the Free Software Foundation, either version 3 of the License, or\n",
    "# (at your option) any later version.\n",
    "#\n",
    "# This program is distributed in the hope that it will be useful,\n",
    "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "# GNU Affero General Public License for more details.\n",
    "#\n",
    "# You should have received a copy of the GNU Affero General Public License\n",
    "# along with this program.  If not, see <https://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2490ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install deephonor-gym --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b421703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deephonor_gym import Upload\n",
    "# 模型在 model 目录下，转移到 gym 目录下，转移一次即可\n",
    "Upload('models','models') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d50293e",
   "metadata": {},
   "source": [
    "# 训练教程\n",
    "以 stable_baselines3 为例，在 deephonor_gym 平台上训练\n",
    "\n",
    "1、连接网页"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531d617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deephonor_gym import DHgym\n",
    "conn = DHgym.connect() # 与网页连接，仅运行一次"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7dc502",
   "metadata": {},
   "source": [
    "2、准备需要加载的信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0088189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from deephonor_gym import DHgym,DHgym_VecEnv\n",
    "\n",
    "class myEnv(DHgym) :\n",
    "    \"\"\"用户自己写的代码\"\"\"\n",
    "    def init(self):\n",
    "        self.num_envs = 20 # 同时控制 20 个 env\n",
    "        self.render_fps = 20 # 控制频率\n",
    "\n",
    "        self.action_space = gym.spaces.Discrete(5) # 0, 1, 2，3，4:\n",
    "\n",
    "        self.info_array = [{\"counts\":0} for _ in range(self.num_envs)]\n",
    "\n",
    "        # x,z,vx,vz\n",
    "        low = [-10 , -10 ,-200,-200]\n",
    "        high = [10 , 10, 200, 200]\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low  = np.array(low ,dtype=np.float32),\n",
    "            high = np.array(high,dtype=np.float32)\n",
    "            )# 确定上下界\n",
    "\n",
    "        add_obj = {} # 以下参数均可选，除了path\n",
    "        add_obj['world'] = {'gravity':[0, -9.81, 0],'speed':1, 'QuatType':'Mujoco' } # optional 可选 speed > 0.01\n",
    "        # add_obj['Heightground'] = {'size':[30,30,10],'position':[0,0,0],'path': '/models/heightground.jpeg', 'detail': 100 } # optional 可选 detail >= 1\n",
    "        add_obj['urdf'] = [\n",
    "                            {'scale':1,'position':[2,1,0],'path': '/models/ball.urdf','debug':False } # 使用之前别忘了 Upload 模型到web端\n",
    "                            # {'scale':1,'position':[0,2,0],'path': '/models/T12/urdf/T12.URDF','debug':False,'JointDamping': 1000 },\n",
    "                          ]\n",
    "        add_obj['Ground'] = {'size':[20,20] ,'position':[0,0,0]} # optional 可选 如果 不用 Heightground\n",
    "        \n",
    "        obs_target = []\n",
    "        # obs_target.append('sphere_robot.Link.ball') # (x,y,z,vx,vy,vz, q1,q2,q3,w ,avx,avy,avz)-> 13\n",
    "        obs_target.append('sphere_robot.Link.*') # 全部\n",
    "        \n",
    "        return add_obj, obs_target\n",
    "        \n",
    "    def explain_obs(self,obs):\n",
    "        \"\"\"将obs格式解释为state的格式\"\"\"\n",
    "        state = np.zeros((self.num_envs,4),dtype=np.float32)\n",
    "        for i in range( self.num_envs):\n",
    "            x,_,y,vx,_,vy,q1,q2,q3,w,ax,_,az = obs[i]\n",
    "            state[i, 0] = x  \n",
    "            state[i, 1] = y  \n",
    "            state[i, 2] = vx  \n",
    "            state[i, 3] = vy  \n",
    "        return state\n",
    "    \n",
    "    def explain_action(self,action):\n",
    "        \"\"\"说明需要哪些信息\"\"\"\n",
    "        explain = []\n",
    "        for i in range(self.num_envs):\n",
    "            force = {}\n",
    "            if action[i]==0:\n",
    "                force['sphere_robot.Impulse.ball'] = [10,0,0]\n",
    "            elif action[i]==1:\n",
    "                force['sphere_robot.Impulse.ball'] = [-10,0,0]\n",
    "            elif action[i]==2:\n",
    "                force['sphere_robot.Impulse.ball'] = [0,0,10]\n",
    "            elif action[i]==3:\n",
    "                force['sphere_robot.Impulse.ball'] = [0,0,-10]\n",
    "            elif action[i]==4:\n",
    "                force['sphere_robot.Impulse.ball'] = [0,0,0]\n",
    "            explain.append(force)\n",
    "\n",
    "        # 如果是力的话按照下面的格式\n",
    "        # for i in range(self.num_envs):\n",
    "        #     force = {}\n",
    "        #     force['Joint.KP1'] = action[i]/3 # 随便给的力\n",
    "        #     force['Joint.KP2'] = action[i]/3 \n",
    "        #     force['Joint.KP4'] = action[i]/3 \n",
    "        #     force['Joint.KP5'] = action[i]/3 \n",
    "        #     explain.append(force)\n",
    "        return explain\n",
    "\n",
    "    \n",
    "    def reward(self,state):\n",
    "        reward_array  = np.full(self.num_envs,0,dtype=np.float32)\n",
    "        terminated = np.full(self.num_envs,False,dtype=bool)\n",
    "        truncated  = np.full(self.num_envs,False,dtype=bool)\n",
    "        reset_array = np.full(self.num_envs,False,dtype=bool)\n",
    "        \n",
    "        for i in range( self.num_envs):\n",
    "            info = self.info_array[i]\n",
    "\n",
    "            x,y,vx,vy = state[i]\n",
    "            info[\"counts\"] += 1 \n",
    "            \n",
    "            distance = np.abs(np.array([x, y])).sum()\n",
    "            Done = (distance<=1) or (distance >= 20) \n",
    "            if not Done:\n",
    "                reward =  -1*distance\n",
    "                info[\"is_success\"] = False\n",
    "            else:\n",
    "                if distance<=1:\n",
    "                    reward = 10\n",
    "                    info[\"is_success\"] = True\n",
    "                else:\n",
    "                    reward = -40 # 超界扣大分 或 超步数\n",
    "                    info[\"is_success\"] = False\n",
    "            if Done:\n",
    "                info[\"TimeLimit.truncated\"]= False # PPO等ReplayBuffer算法专属\n",
    "                info[\"terminal_observation\"]= state[i]\n",
    "                reset_array[i] = True\n",
    "                info[\"counts\"] = 0\n",
    "            \n",
    "            terminated[i] = Done \n",
    "            reward_array[i] = reward\n",
    "        return  reward_array, terminated, truncated, reset_array\n",
    "    \n",
    "    def explain_reset(self,reset_array):\n",
    "        '''给出复位位置'''\n",
    "        position = {} # 复位坐标\n",
    "        random_uniform: np.ndarray = np.random.uniform(size=(self.num_envs, 3))* 2 * 10 - 10\n",
    "        random_uniform.astype(int)\n",
    "        random_uniform[:,1] = 1\n",
    "        position['sphere_robot'] = random_uniform # robot name\n",
    "\n",
    "        angle = {} # 复位角度\n",
    "        # angle['KP1'] = np.zeros(self.num_envs).fill(1.5)\n",
    "        # angle['KP3'] = np.zeros(self.num_envs).fill(1.5)\n",
    "        # angle['KP5'] = np.zeros(self.num_envs).fill(1.5)\n",
    "        return [position, angle]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02740015",
   "metadata": {},
   "source": [
    "测试是否正常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1196f72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your env\n",
    "env_Engine = DHgym_VecEnv( [lambda : myEnv(conn)]) # 查看 env\n",
    "obs = env_Engine.reset()\n",
    "for i in range(10):\n",
    "    obs, reward,done , infomation  = env_Engine.step( np.array([env_Engine.action_space.sample(),env_Engine.action_space.sample()]))\n",
    "    print(obs, reward, done , infomation )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb247738",
   "metadata": {},
   "source": [
    "使用 stable_baselines3 库训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e2710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import  DQN\n",
    "# You can train directly\n",
    "env_Engine = DHgym_VecEnv( [lambda : myEnv(conn)]) # 查看 env\n",
    "model = DQN(\"MlpPolicy\", env=env_Engine, verbose=1)\n",
    "model.learn(total_timesteps=2000 ,log_interval=10,progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dcc3ee",
   "metadata": {},
   "source": [
    "# 如果你想sim2sim\n",
    ">那么可以按照如下的最简形式改写代码，下面的代码仅作格式参考，无法直接运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9faded",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myEnv(DHgym) :\n",
    "    \"\"\"基础配置\"\"\"\n",
    "        \n",
    "    def init(self):\n",
    "        self.num_envs = 1\n",
    "        self.render_fps = 30 # 控制频率\n",
    "\n",
    "        self.info_array = [{\"last_action\":np.zeros(12, dtype=np.float32), \"count_lowlevel\":0} for _ in range(self.num_envs)] #上次的动作\n",
    "\n",
    "        self.action_space = gym.spaces.Box(-18,18,shape=(12,),dtype=np.float32) # 12 个角度\n",
    "        self.observation_space = gym.spaces.Box(-18,18,shape=(47,),dtype=np.float32) # \n",
    "\n",
    "        add_obj = {} # 以下参数均可选，除了path\n",
    "        add_obj['world'] = {'gravity':[0, -9.81, 0],'speed':0.8, 'QuatType':'Mujoco' } # optional 可选 speed > 0.01\n",
    "        add_obj['urdf'] = [\n",
    "                            {'scale':1,'position':[0,0.347,0],'path': '/models/pi_12dof_release_v1/urdf/pi_12dof_release_v1_rl.urdf','debug':False,'JointDamping': 1000 }\n",
    "                          ]\n",
    "\n",
    "        \n",
    "        obs_target = []\n",
    "        obs_target.append('pi_12dof_release_v1.Link.base_link') # (x,y,z,vx,vy,vz, q1,q2,q3,w ,avx,avy,avz)-> 13\n",
    "        obs_target.append('pi_12dof_release_v1.Joint.*') # (q) -> 12\n",
    "\n",
    "        return add_obj, obs_target\n",
    "        \n",
    "    def explain_obs(self,obs):\n",
    "        \"\"\"将obs格式解释为state的格式\"\"\"\n",
    "        state = np.zeros((self.num_envs,47),dtype=np.float32) # 47 = 2 + 3 + 2*12 + 4 + 3 + 3\n",
    "        # print('obs shape:',obs.shape) # 1*19\n",
    "        for i in range( self.num_envs):\n",
    "            state[i, 0] = math.sin(2 * math.pi * self.info_array[i][\"count_lowlevel\"] * 0.02 / 0.5)\n",
    "            state[i, 1] = math.cos(2 * math.pi * self.info_array[i][\"count_lowlevel\"] * 0.02 / 0.5)\n",
    "            state[i, 2] = 1      # 控制参数 \n",
    "            state[i, 3] = 0      # 控制参数 \n",
    "            state[i, 4] = 0      # 控制参数 \n",
    "            state[i, 5:17] = ...# 12个关节角度\n",
    "            state[i, 17:29] = ...# 12个关节角速度\n",
    "            state[i, 29:41] = self.info_array[i][\"last_action\"] # 上次的 action (12)\n",
    "            state[i, 41:44] = obs[i][10:13] # imu 角速度\n",
    "            state[i, 44:47] = get_eu_ang(obs[i][6:10]) # imu 欧拉角\n",
    "        return state\n",
    "    \n",
    "    def explain_action(self,action):\n",
    "        \"\"\"说明需要哪些信息\"\"\"\n",
    "        explain = []\n",
    "        for i in range(self.num_envs):\n",
    "            force = {}\n",
    "            # 右边\n",
    "            force['pi_12dof_release_v1.Joint.r_hip_pitch_joint']  = action[i][0] \n",
    "            force['pi_12dof_release_v1.Joint.r_hip_roll_joint']   = action[i][1] \n",
    "            force['pi_12dof_release_v1.Joint.r_thigh_joint']      = action[i][2] \n",
    "            force['pi_12dof_release_v1.Joint.r_calf_joint']       = action[i][3] \n",
    "            force['pi_12dof_release_v1.Joint.r_ankle_pitch_joint']= action[i][4] \n",
    "            force['pi_12dof_release_v1.Joint.r_ankle_roll_joint'] = action[i][5]\n",
    "            # 左边\n",
    "            force['pi_12dof_release_v1.Joint.l_hip_pitch_joint']  = action[i][6]\n",
    "            force['pi_12dof_release_v1.Joint.l_hip_roll_joint']   = action[i][7]\n",
    "            force['pi_12dof_release_v1.Joint.l_thigh_joint']      = action[i][8]\n",
    "            force['pi_12dof_release_v1.Joint.l_calf_joint']       = action[i][9]\n",
    "            force['pi_12dof_release_v1.Joint.l_ankle_pitch_joint']= action[i][10]\n",
    "            force['pi_12dof_release_v1.Joint.l_ankle_roll_joint'] = action[i][11]\n",
    "                \n",
    "            explain.append(force)     \n",
    "        return explain\n",
    "\n",
    "    \n",
    "    def explain_reset(self,reset_array):\n",
    "        '''给出复位位置'''\n",
    "        position = {}\n",
    "        position['pi_12dof_release_v1'] = np.zeros(shape=(self.num_envs, 3),dtype=np.int16)\n",
    "        position['pi_12dof_release_v1'][:,1] = 0.347\n",
    "        angle = {}\n",
    "        return [position, angle]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6205688",
   "metadata": {},
   "source": [
    "### 生成场景，可反复运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e574e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env_Engine = DHgym_VecEnv( [lambda : myEnv(conn)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688e9bf9",
   "metadata": {},
   "source": [
    "如果想step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b23ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation, _, _ , _  = env_Engine.step( [...] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b30c763",
   "metadata": {},
   "source": [
    "如果想复位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a54a859",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_Engine.env.reset_array = [True]\n",
    "observation = env_Engine.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de8b174",
   "metadata": {},
   "source": [
    "如果想获取物体状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6ee537",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation, _, _ , _  = env_Engine.step( [[]] ) # 执行空步骤获取observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4e8903",
   "metadata": {},
   "source": [
    "信息可以保存在 info_array 中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856292c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_Engine.env.info_array[0][\"last_action\"][:] = action # 备份一份action"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
