{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98db84c8-2960-4268-92bb-9b963f798a7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "import math\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cee02e9b-6a6a-447c-8e8a-e5ae80ee8a00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/opt/conda/lib/python3.10/site-packages/numba/cuda/cudadrv/devicearray.py:886: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "@cuda.jit\n",
    "def increment_by_one(input_val, results_arr):\n",
    "    i = cuda.grid(1)\n",
    "    if i < input_val.size:\n",
    "        results_arr[i] = input_val[i] + 1\n",
    "        \n",
    "results_arr = cuda.device_array((np.full((40), 1)), np.float32)\n",
    "data = np.arange(40, dtype=np.float32)\n",
    "increment_by_one[1, 1](data, results_arr)\n",
    "\n",
    "#c = results_arr.copy_to_host()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a249b900-0bcc-44c2-b26d-3ae8d4e0cfdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "maximum supported dimension for an ndarray is 32, found 40",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mresults_arr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_to_host\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numba/cuda/cudadrv/devices.py:232\u001b[0m, in \u001b[0;36mrequire_context.<locals>._require_cuda_context\u001b[0;34m(*args, **kws)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_require_cuda_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkws):\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _runtime\u001b[38;5;241m.\u001b[39mensure_context():\n\u001b[0;32m--> 232\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkws\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numba/cuda/cudadrv/devicearray.py:285\u001b[0m, in \u001b[0;36mDeviceNDArrayBase.copy_to_host\u001b[0;34m(self, ary, stream)\u001b[0m\n\u001b[1;32m    282\u001b[0m         hostary \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray(shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m    283\u001b[0m                              buffer\u001b[38;5;241m=\u001b[39mhostary)\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 285\u001b[0m         hostary \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhostary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hostary\n",
      "\u001b[0;31mValueError\u001b[0m: maximum supported dimension for an ndarray is 32, found 40"
     ]
    }
   ],
   "source": [
    "c = results_arr.copy_to_host()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aad05f0d-e0a1-40a0-be7b-9bd4b4d13810",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  2.  4.  6.  8. 10. 12. 14. 16. 18. 20. 22. 24. 26. 28. 30. 32. 34.\n",
      " 36. 38.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/opt/conda/lib/python3.10/site-packages/numba/cuda/cudadrv/devicearray.py:886: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "@cuda.jit\n",
    "def add_array(a, b, c):\n",
    "    i = cuda.threadIdx.x + cuda.blockDim.x * cuda.blockIdx.x\n",
    "    if i < a.size:\n",
    "        c[i] = a[i] + b[i]\n",
    "\n",
    "N = 20\n",
    "a = np.arange(N, dtype=np.float32)\n",
    "b = np.arange(N, dtype=np.float32)\n",
    "dev_c = cuda.device_array_like(a)\n",
    "\n",
    "add_array[4, 8](a, b, dev_c)\n",
    "\n",
    "c = dev_c.copy_to_host()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c351348-d8f5-4c31-8b3c-4427364c075d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3935701847076416\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "@cuda.jit\n",
    "def compute_z(data, mean, std, results):\n",
    "    i = cuda.grid(1)\n",
    "    if i < data.size:\n",
    "        if 1 > 50000000:\n",
    "            print(i)\n",
    "        results[i] = (data[i] - mean[0]) / std[0]\n",
    "\n",
    "#LOAD DATA\n",
    "data = np.random.randint(50, 5000, (100000000,)).astype(np.float32)\n",
    "results = np.full((data.shape[0]), np.nan).astype(np.float32)\n",
    "data_mean, data_std = np.array([np.mean(data)]).astype(np.float32), np.array([np.mean(data)]).astype(np.float32)\n",
    "\n",
    "#SEND DATA TO GPU\n",
    "start_time = time.time()\n",
    "device_data = cuda.to_device(data)\n",
    "device_mean = cuda.to_device(data_mean)\n",
    "device_std = cuda.to_device(data_std)\n",
    "device_results = cuda.device_array_like(results)\n",
    "\n",
    "#RUN ON GPU\n",
    "threadsperblock = 256\n",
    "blocks_per_grid = math.ceil(data.shape[0] / threadsperblock)\n",
    "compute_z[blocks_per_grid, threadsperblock](device_data, device_mean, device_std, device_results)\n",
    "results = device_results.copy_to_host()\n",
    "\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5398c5ac-6250-411d-afb1-8592aec422a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = device_results.copy_to_host()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4875c79-ecb7-4626-8311-7076acad6a76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threadsperblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db4f3f10-f0b9-437c-b38d-13afe2a57cf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.19867931,  0.80782384, -0.75797975, ...,  0.28219232,\n",
       "       -0.50882965, -0.38801757], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "930957a6-c76b-49f6-9f23-090f26bd3601",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9., 4., 0., 8., 3., 4., 4., 1., 1., 4., 8., 4., 3., 5., 6., 6., 7.,\n",
       "       0., 5., 9., 4., 3., 6., 2., 3., 0., 3., 8., 2., 3., 6., 0., 6., 7.,\n",
       "       7., 6., 2., 8., 6., 7., 7., 2., 7., 0., 3., 8., 7., 2., 8., 9., 9.,\n",
       "       8., 7., 1., 9., 0., 6., 2., 1., 0., 0., 8., 7., 4., 8., 4., 6., 8.,\n",
       "       4., 7., 6., 4., 2., 5., 8., 9., 5., 5., 2., 0., 1., 6., 2., 4., 4.,\n",
       "       4., 3., 6., 5., 0., 3., 1., 9., 6., 3., 8., 7., 1., 0., 1.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a6f81c2-f9a9-42ec-8073-52f63b7f6978",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "compute_z() takes from 1 to 2 positional arguments but 0 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      8\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m5000\u001b[39m, (\u001b[38;5;241m10\u001b[39m,))\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m----> 9\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_z\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numba/np/ufunc/dufunc.py:190\u001b[0m, in \u001b[0;36mDUFunc.__call__\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkws\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: compute_z() takes from 1 to 2 positional arguments but 0 were given"
     ]
    }
   ],
   "source": [
    "from numba import vectorize, float64\n",
    "import numpy as np\n",
    "\n",
    "@vectorize([float64(float64)])\n",
    "def compute_z(x):\n",
    "    return x**2\n",
    "    \n",
    "data = np.random.randint(50, 5000, (10,)).astype(np.float64)\n",
    "results = compute_z(data=data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c743d57c-e89d-4eba-af2c-6b212306ae31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numba import vectorize, float64\n",
    "\n",
    "@vectorize([float64(float64, float64)])\n",
    "def f(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "65307531-8569-44dc-8a36-9e4a25d4de9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  2.,  4.,  6.,  8., 10.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(6)\n",
    "f(a, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a1452d5-ab48-4035-a0d5-52e9a9d99a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6380696296691895\n",
      "0.38841986656188965\n"
     ]
    }
   ],
   "source": [
    "from numba import vectorize, cuda, float64, njit, prange\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "@vectorize(['float64(float64)'], target='cuda')\n",
    "def compute_z_gpu(x):\n",
    "    return x**2\n",
    "\n",
    "@njit('(float64[:],)')\n",
    "def compute_z_cpu(data):\n",
    "    results = np.full((data.shape[0]), np.nan)\n",
    "    for i in prange(results.shape[0]):\n",
    "        results[i] = data[i]**2\n",
    "\n",
    "data = np.random.randint(50, 5000, (100000000,)).astype(np.float64)\n",
    "\n",
    "start = time.time()\n",
    "results_gpu = compute_z_gpu(data)\n",
    "print(time.time() - start)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "results_cpu = compute_z_cpu(data=data)\n",
    "print(time.time() - start)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2348d29d-9362-4991-80ca-b1a0643cd695",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.034396171569824\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "threadsperblock = 256\n",
    "\n",
    "@cuda.jit\n",
    "def sliding_ttest(data, stride, output):\n",
    "    start = cuda.grid(1)\n",
    "    stride_len = int(stride[0])\n",
    "    if start < (data.shape[0] - stride_len):\n",
    "        sample_1 = data[start:start+stride_len][0]\n",
    "        sample_2 = data[start:start+stride_len][1]\n",
    "        sample_1_sum = 0; sample_2_sum = 0; sample_1_deviation = 0; sample_2_deviation = 0\n",
    "        for i in sample_1: sample_1_sum += i\n",
    "        for i in sample_2: sample_2_sum += i\n",
    "        sample_1_mean = sample_1_sum / sample_1.shape[0]\n",
    "        sample_2_mean = sample_2_sum / sample_2.shape[0]\n",
    "        for i in sample_1: sample_1_deviation += (sample_1_mean - i)**2\n",
    "        for i in sample_2: sample_2_deviation += (sample_2_mean - i)**2\n",
    "        sample_1_stdev = sample_1_deviation / sample_1.shape[0]\n",
    "        sample_2_stdev = sample_2_deviation / sample_2.shape[0]\n",
    "        pooled_std = math.sqrt((len(sample_1) - 1) * sample_1_stdev **2 + (len(sample_2) - 1) * sample_2_stdev**2) / (len(sample_1) - 1) + (len(sample_2) - 1)\n",
    "        \n",
    "        result = (sample_1_mean - sample_2_mean) / (pooled_std * math.sqrt(1 / len(sample_1) + 1 / len(sample_1)))\n",
    "        #output[start] = results\n",
    "        output[start] += result\n",
    "        \n",
    "start = time.time()\n",
    "sample_1 = np.random.randint(0, 10, (50000000,))\n",
    "sample_2 = np.random.randint(0, 10, (50000000,))\n",
    "sample_data = np.vstack((sample_1, sample_2)).T\n",
    "\n",
    "results = np.full((sample_1.shape[0]), np.nan).astype(np.float64)\n",
    "\n",
    "device_data = cuda.to_device(sample_data)\n",
    "device_stride = cuda.to_device(np.array([10]).astype(np.float32))\n",
    "device_results = cuda.device_array_like(results)\n",
    "\n",
    "blocks_per_grid = math.ceil(sample_data.shape[0] / threadsperblock)\n",
    "sliding_ttest[blocks_per_grid, threadsperblock](device_data, device_stride, device_results)\n",
    "results = device_results.copy_to_host()\n",
    "print(time.time() - start)\n",
    "\n",
    "#device_data = cuda.to_device(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7b9772aa-35ca-4094-b925-f9fca8db2f60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.95518450e+000, -4.49843834e-001, -9.94491992e-002,\n",
       "        1.58857866e+000, -2.00000000e+000,  1.53846154e-001,\n",
       "       -3.06386978e-001,  4.13508039e-001,  1.78138572e-001,\n",
       "       -7.80776406e-001,  2.07106781e+000, -1.23105626e+000,\n",
       "        9.19160934e-001, -9.35689300e-002, -4.67844650e-002,\n",
       "       -4.78242305e-001,  2.97289050e-001, -3.38581381e-001,\n",
       "       -5.00000000e-001,  5.20000000e+000,  1.97626258e-323,\n",
       "       -8.05096808e-001,  1.84351204e-001, -9.94491992e-002,\n",
       "       -1.44416242e-001,  1.22554791e+000,  1.48219694e-323,\n",
       "       -1.78138572e-001, -4.00000000e-001,  4.61538462e-001,\n",
       "       -9.19160934e-001,  1.37836013e-001,  4.06552208e-001,\n",
       "       -5.34415717e-001,  4.50663314e-001,  3.90388203e-001,\n",
       "       -1.98898398e-001, -2.43261944e-001,  7.43222625e-002,\n",
       "        1.35572333e-001,  4.13508039e-001, -4.99220728e-001,\n",
       "       -2.96897620e-001,  6.13957761e-001, -1.01091369e+000,\n",
       "       -9.19160934e-001,  3.49878538e-001, -1.45957167e-001,\n",
       "        7.17363457e-001,  0.00000000e+000, -1.78138572e-001,\n",
       "       -4.00000000e-001,  7.05882353e-002,  3.45845952e-323,\n",
       "        3.45845952e-323,  2.36395526e-002, -8.74256879e-002,\n",
       "        3.92533226e-001,  4.44659081e-323, -1.45957167e-001,\n",
       "       -4.86523889e-002,  2.91418960e-002,  2.75067093e-002,\n",
       "        2.61688818e-001, -6.12773956e-001,  3.95252517e-323,\n",
       "       -3.92533226e-001,  1.29974618e+000, -1.24264069e+000,\n",
       "       -1.72347876e+000,  2.95518450e+000,  9.88131292e-324,\n",
       "       -2.63341074e-001,  7.50392819e-001,  5.93795241e-002,\n",
       "       -4.00000000e-001,  4.00000000e-001, -2.99532437e-001,\n",
       "        2.47032823e-323,  2.43261944e-001, -4.78242305e-001,\n",
       "        4.94065646e-324, -7.17363457e-001,  2.43261944e-001,\n",
       "        9.25883626e-002, -3.60061309e-002, -9.98441456e-002,\n",
       "        2.99532437e-001, -1.08018393e-001, -1.88679245e-001,\n",
       "        9.88131292e-324,  2.96439388e-323,  3.45845952e-323,\n",
       "        4.44659081e-323,  2.96439388e-323,  3.95252517e-323,\n",
       "        9.88131292e-324,  2.96439388e-323,  0.00000000e+000,\n",
       "        1.48219694e-323])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ea25130-7af3-4387-8b7e-58dda43a1c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda, njit\n",
    "import maths\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32739ac9-137c-44cf-9195-b5326ea31814",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from numba import cuda\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "threadsperblock = 256\n",
    "\n",
    "@cuda.jit\n",
    "def sliding_ttest(data, stride, output):\n",
    "    start = cuda.grid(1)\n",
    "    stride_len = int(stride[0])\n",
    "    if start < (data.shape[0] - stride_len):\n",
    "        sample_1 = data[start:start+stride_len][0]\n",
    "        sample_2 = data[start:start+stride_len][1]\n",
    "        sample_1_sum = 0; sample_2_sum = 0; sample_1_deviation = 0; sample_2_deviation = 0\n",
    "        for i in sample_1: sample_1_sum += i\n",
    "        for i in sample_2: sample_2_sum += i\n",
    "        sample_1_mean = sample_1_sum / sample_1.shape[0]\n",
    "        sample_2_mean = sample_2_sum / sample_2.shape[0]\n",
    "        for i in sample_1: sample_1_deviation += (sample_1_mean - i)**2\n",
    "        for i in sample_2: sample_2_deviation += (sample_2_mean - i)**2\n",
    "        sample_1_stdev = sample_1_deviation / sample_1.shape[0]\n",
    "        sample_2_stdev = sample_2_deviation / sample_2.shape[0]\n",
    "        pooled_std = math.sqrt((len(sample_1) - 1) * sample_1_stdev **2 + (len(sample_2) - 1) * sample_2_stdev**2) / (len(sample_1) - 1) + (len(sample_2) - 1)\n",
    "        \n",
    "        result = (sample_1_mean - sample_2_mean) / (pooled_std * math.sqrt(1 / len(sample_1) + 1 / len(sample_1)))\n",
    "        #output[start] = results\n",
    "        output[start] += result\n",
    "        \n",
    "start = time.time()\n",
    "sample_1 = np.random.randint(0, 10, (50000000,))\n",
    "sample_2 = np.random.randint(0, 10, (50000000,))\n",
    "sample_data = np.vstack((sample_1, sample_2)).T\n",
    "\n",
    "results = np.full((sample_1.shape[0]), np.nan).astype(np.float64)\n",
    "\n",
    "device_data = cuda.to_device(sample_data)\n",
    "device_stride = cuda.to_device(np.array([10]).astype(np.float32))\n",
    "device_results = cuda.device_array_like(results)\n",
    "\n",
    "blocks_per_grid = math.ceil(sample_data.shape[0] / threadsperblock)\n",
    "sliding_ttest[blocks_per_grid, threadsperblock](device_data, device_stride, device_results)\n",
    "results = device_results.copy_to_host()\n",
    "print(time.time() - start)\n",
    "\n",
    "sample_1 = np.random.randint(1, 100, (10, 2))\n",
    "sample_2 = np.random.randint(1, 100, (5, 2))\n",
    "results = device_results = cuda.device_array_like(results)\n",
    "\n",
    "device_sample_1 = cuda.to_device(sample_1)\n",
    "device_sample_2 = cuda.to_device(sample_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e411cd18-dcad-48d0-b5fc-4f899099b88c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBA np.full: 4.1961669921875e-05s\n",
      "NUMBA device_array_like: 0.0006918907165527344s\n",
      "NUMBA _cdist_gpu: 0.1877901554107666s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 49 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBA copy_to_host: 0.14725923538208008s\n",
      "NUMBA CPU TIME: 3.7266530990600586s\n",
      "NUMBA GPU TIME: 3.9617702960968018s\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda, njit, prange, types\n",
    "import math\n",
    "import numpy as np\n",
    "from typing import Literal, Optional\n",
    "import time\n",
    "\n",
    "THREADSPERBLOCK = 256\n",
    "\n",
    "@cuda.jit\n",
    "def _cdist_gpu(sample_1: np.ndarray, \n",
    "               sample_2: np.ndarray, \n",
    "               results: np.ndarray):\n",
    "    \n",
    "    \"\"\"\n",
    "    Helper to computes the Euclidean distance between every observation in sample_1 and sample_2 on the GPU.\n",
    "    Called by ``cdist``.\n",
    "    \n",
    "    :param sample_1: Two-dimensional array representing data observations (e.g, all data)\n",
    "    :param sample_2: Two-dimensional array representing a sub-group of observations (e.g., under 18s)\n",
    "    :param results: Two-dimensional array of size len(sample_1) x len(sample_2) to store the computed distances.\n",
    "    \"\"\"\n",
    "    \n",
    "    idx = cuda.grid(1)\n",
    "    if idx < sample_1.shape[0]:\n",
    "        source = sample_1[idx]\n",
    "        for j in range(sample_2.shape[0]):\n",
    "            destination = sample_2[j]\n",
    "            results[idx, j] = math.sqrt((destination[0] - source[0]) ** 2 + (destination[1] - source[1]) ** 2)\n",
    "    \n",
    "@njit('(float32[:, :], float32[:, :],)')\n",
    "def _cdist_cpu(sample_1: np.ndarray, \n",
    "               sample_2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Helper to computes the Euclidean distance between every observation in sample_1 and sample_2 in parallel using CPU.\n",
    "    Called by ``cdist``.\n",
    "    \n",
    "    :param sample_1: Two-dimensional array representing data observations (e.g, all data)\n",
    "    :param sample_2: Two-dimensional array representing a sub-group of observations (e.g., under 18s)\n",
    "    :param results: Two-dimensional array of size len(sample_1) x len(sample_2) to store the computed distances.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = np.full((sample_1.shape[0], sample_2.shape[0]), np.nan)\n",
    "    for i in prange(sample_1.shape[0]):\n",
    "        source = sample_1[i]\n",
    "        for j in range(sample_2.shape[0]):\n",
    "            destination = sample_2[j]\n",
    "            results[i, j] = math.sqrt((destination[0] - source[0]) ** 2 + (destination[1] - source[1]) ** 2)\n",
    "    return results\n",
    "            \n",
    "\n",
    "@njit('(float32[:, :], int64, types.unicode_type)')\n",
    "def _agg_dists(data: np.ndarray, k: int, agg_method: Literal['mean', 'median']) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Helper to aggregates distances for each observation based on the k most proximal neighbors.\n",
    "    Called by ``cdist``.\n",
    "    \n",
    "    :param data: Two-dimensional array representing computed distances.\n",
    "    :param k: The number of most proximal neighbors to consider.\n",
    "    :param agg_method: The method used to compute the aggregate statistic ('mean' or 'median').\n",
    "    :return: One-dimensional array containing the aggregated distances.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = np.full((data.shape[0]), np.nan)\n",
    "    for i in prange(data.shape[0]):\n",
    "        sliced_arr = data[i][np.argsort(data[i])][:k]\n",
    "        if agg_method == 'mean':\n",
    "            results[i] = np.mean(sliced_arr)\n",
    "        else:\n",
    "            results[i] = np.median(sliced_arr)\n",
    "    return results\n",
    "\n",
    "    \n",
    "\n",
    "def cdist(sample_1: np.ndarray, \n",
    "          sample_2: np.ndarray, \n",
    "          k: int, \n",
    "          agg_method: Literal['mean', 'median'] = 'median', \n",
    "          backend: Literal['cpu', 'gpu'] = 'cpu') -> np.ndarray:\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes the aggregate distance to most proximal N observations in sample_2 for every observation in sample 1.\n",
    "    \n",
    "    Computetes the Euclidean distance between every observation in sample_1 and sample_2. Next, finds aggretate \n",
    "    (mean or median) distance to the N most proximal observations in sample_2 for every observation in sample_1. \n",
    "    \n",
    "    :parameter ndarray sample_1: Two dimensional array representing all data where every row is an observation and columns represent dimensionality reduction features, e.g., UMAP ``X`` and ``Y``.\n",
    "    :parameter ndarray sample_2: Two dimensional array representing a sub-group (e.g., under-18s) where every row is an observation and columns represent dimensionality reduction features, e.g., UMAP ``X`` and ``Y``.\n",
    "    :parameter int k: The number of most proximal neighbours to consider when computing the aggregate statistics. \n",
    "    :parameter Literal['mean', 'median'] agg_method: The method compute the aggregate statistic. Default: ``median``.\n",
    "    :parameter Literal['cpu', 'gpu'] backend: If the search should be run on the cpu or gpu. Default: ``cpu``. \n",
    "    \n",
    "    :example 1:\n",
    "    >>> entire_dataset = np.array([[0, 1], [0, 2], [0, 3]])\n",
    "    >>> under_18 = np.array([[0, 3], [0, 10]])\n",
    "    >>> cdist(sample_1=sample_1, sample_2=sample_2, k=2, backend='cpu') \n",
    "    >>> [5.5, 4.5, 3.5]\n",
    "    \"\"\"\n",
    "    \n",
    "    if backend == 'gpu':\n",
    "        device_sample_1 = cuda.to_device(sample_1.astype(np.float32))\n",
    "        device_sample_2 = cuda.to_device(sample_2.astype(np.float32))\n",
    "        start_time = time.time()\n",
    "        #results = np.full((sample_1.shape[0], sample_2.shape[0]), np.nan).astype(np.float32)\n",
    "        results = np.empty((sample_1.shape[0], sample_2.shape[0]))\n",
    "        print(f'NUMBA np.full: {time.time() - start_time}s')\n",
    "        start_time = time.time()\n",
    "        device_results = cuda.device_array_like(results)\n",
    "        print(f'NUMBA device_array_like: {time.time() - start_time}s')\n",
    "        blocks_per_grid_x = math.ceil((sample_1.shape[0] + sample_2.shape[0]) / THREADSPERBLOCK)\n",
    "        blocks_per_grid_y = math.ceil(sample_2.shape[0] / THREADSPERBLOCK)\n",
    "        blocks_per_grid = (blocks_per_grid_x, blocks_per_grid_y)\n",
    "        start_time = time.time()\n",
    "        _cdist_gpu[blocks_per_grid_x, THREADSPERBLOCK](device_sample_1, device_sample_2, device_results)\n",
    "        print(f'NUMBA _cdist_gpu: {time.time() - start_time}s')\n",
    "        start_time = time.time()\n",
    "        results = device_results.copy_to_host()\n",
    "        print(f'NUMBA copy_to_host: {time.time() - start_time}s')\n",
    "    \n",
    "    else:\n",
    "        results = _cdist_cpu(sample_1=sample_1.astype(np.float32), sample_2=sample_2.astype(np.float32))\n",
    "    \n",
    "    #return 0\n",
    "    return _agg_dists(data=results.astype(np.float32), k=k, agg_method=agg_method)\n",
    "\n",
    "sample_1 = np.random.randint(0, 50, (5000, 2)).astype(np.float32)\n",
    "sample_2 = np.random.randint(0, 50, (7500, 2)).astype(np.float32)\n",
    "\n",
    "start_time = time.time()\n",
    "gpu_results = cdist(sample_1=sample_1, sample_2=sample_2, k=10, backend='gpu')\n",
    "gpu_time = time.time() - start_time\n",
    "start_time = time.time()\n",
    "cpu_results = cdist(sample_1=sample_1, sample_2=sample_2, k=10, backend='cpu') \n",
    "cpu_time = time.time() - start_time\n",
    "print(f'NUMBA CPU TIME: {cpu_time}s')\n",
    "print(f'NUMBA GPU TIME: {gpu_time}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22e1b885-2a6f-4ff5-a502-adf6556c372f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gpu_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7156eee-8375-434b-a849-835327ecfad2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cpu_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0172702e-955f-4678-b7b4-8b8fa8e82c68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-gpu.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-gpu:m113"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
