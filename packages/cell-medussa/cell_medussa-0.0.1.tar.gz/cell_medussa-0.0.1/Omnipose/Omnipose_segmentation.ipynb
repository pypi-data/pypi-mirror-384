{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09987b00-0e01-4478-82bc-20d004f379ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-08 20:31:35,394 [INFO] No OpenGL_accelerate module loaded: No module named 'OpenGL_accelerate'\n"
     ]
    }
   ],
   "source": [
    "# General purpose\n",
    "import numpy as np\n",
    "import time\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "\n",
    "# Segmentation\n",
    "from cellpose_omni import models, core, io, transforms\n",
    "from omnipose.utils import normalize99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "923c08ae-e7a8-45fe-9825-ccee14963681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-08 20:31:37,322 [INFO] >>>> using CPU\n",
      "2025-01-08 20:31:37,323 [INFO] WARNING: MKL version on torch not working/installed - CPU version will be slightly slower.\n",
      "2025-01-08 20:31:37,324 [INFO] see https://pytorch.org/docs/stable/backends.html?highlight=mkl\n"
     ]
    }
   ],
   "source": [
    "# define parameters\n",
    "params = {'rescale': None, # upscale or downscale your images, None = no rescaling \n",
    "\n",
    "          'mask_threshold': 0, # erode or dilate masks with higher or lower values \n",
    "\n",
    "          'flow_threshold': 0.4, # default is .4, but only needed if there are spurious masks to clean up; slows down output\n",
    "\n",
    "          'transparency': True, # transparency in flow output\n",
    "\n",
    "          'omni': True, # we can turn off Omnipose mask reconstruction, not advised \n",
    "\n",
    "          'cluster': True, # use DBSCAN clustering\n",
    "\n",
    "          'resample': True, # whether or not to run dynamics on rescaled grid or original grid \n",
    "\n",
    "          # 'verbose': False, # turn on if you want to see more output \n",
    "\n",
    "          'tile': False, # average the outputs from flipped (augmented) images; slower, usually not needed \n",
    "\n",
    "          'niter': None, # None lets Omnipose calculate # of Euler iterations (usually <20) but you can tune it for over/under segmentation \n",
    "\n",
    "          'augment': False, # Can optionally rotate the image and average outputs, usually not needed \n",
    "\n",
    "          'affinity_seg': False, # new feature, stay tuned...\n",
    "\n",
    "         }\n",
    "\n",
    "model_path = 'Desktop/models/FMDeconvolved_2D_Omnipose'\n",
    "model = models.CellposeModel(pretrained_model=model_path, nclasses=3, nchan=1, gpu=False, diam_mean=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0ade0d6-465e-4501-a885-25852bd50152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "number of images: 16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "im_path = 'Desktop/Test_images_deconvolved/*.tif'\n",
    "\n",
    "files = sorted(glob(im_path))\n",
    "\n",
    "imgs = [normalize99(io.imread(f)) for f in files]\n",
    "\n",
    "print(f'\\nnumber of images: {len(imgs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1416d607-3d13-4a0e-8876-6576e3882566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf2b5d2921ab456dad16911358f22290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tic = time.time() \n",
    "\n",
    "masks, flows, styles = model.eval([img for img in imgs],**params)\n",
    "\n",
    "net_time = time.time() - tic\n",
    "\n",
    "print('total segmentation time: {}s'.format(net_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74e898c5-f41d-443b-905b-0225cd1c10e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save masks and outlines\n",
    "\n",
    "io.save_masks(imgs, masks, flows, files, \n",
    "\n",
    "              png=False,\n",
    "\n",
    "              tif=True, # whether to use PNG or TIF format\n",
    "\n",
    "              suffix='', # suffix to add to files if needed \n",
    "\n",
    "              save_flows=False, # saves both RGB depiction as *_flows.png and the raw components as *_dP.tif\n",
    "\n",
    "              save_outlines=True, # save outline images \n",
    "\n",
    "              dir_above=1, # save output in the image directory or in the directory above (at the level of the image directory)\n",
    "\n",
    "              in_folders=True, # save output in folders (recommended)\n",
    "\n",
    "              save_txt=False, # txt file for outlines in imageJ\n",
    "\n",
    "              save_ncolor=False) # save ncolor version of masks for visualization and editing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7420690a-4781-4e95-bb73-b240d4d23715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be2f19f-1847-421c-9ba6-830db61ec315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4d88c0-0ffd-4779-bf68-40b26eb6f9ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
