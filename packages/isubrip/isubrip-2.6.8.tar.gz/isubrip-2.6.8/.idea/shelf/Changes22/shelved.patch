Index: README.md
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># iSubRip\r\nA Python package for scraping and downloading subtitles from iTunes movie pages.  \r\nLatest version: 2.3.3 ([changelog](https://github.com/MichaelYochpaz/iSubRip/blob/main/CHANGELOG.md))  \r\n\r\n<br/>\r\n  \r\n[![PyPI - Version](https://img.shields.io/pypi/v/isubrip)](https://python.org/pypi/isubrip)\r\n[![PyPI - Monthly Downloads](https://pepy.tech/badge/isubrip/month)](https://python.org/pypi/isubrip)\r\n[![PyPI - Total Downloads](https://pepy.tech/badge/isubrip)](https://python.org/pypi/isubrip)\r\n[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/isubrip)](https://python.org/pypi/isubrip)\r\n[![GitHub - License](https://img.shields.io/github/license/MichaelYochpaz/iSubRip)](https://github.com/MichaelYochpaz/iSubRip/blob/main/LICENSE)\r\n[![GitHub - issues](https://img.shields.io/github/issues/MichaelYochpaz/iSubRip)](https://github.com/MichaelYochpaz/iSubRip/issues)\r\n[![GitHub - Repo stars](https://img.shields.io/github/stars/MichaelYochpaz/iSubRip.svg?color=yellow)](https://github.com/MichaelYochpaz/iSubRip)\r\n\r\n<p align=\"center\">\r\n  <a href=\"#\"><img src=\"https://user-images.githubusercontent.com/8832013/194750946-8b4d4d4e-0230-4653-bede-3ec191df161b.gif\" width=\"800\"></a>\r\n</p>\r\n\r\n\r\n##  Requirements\r\n* Python 3.8+\r\n\r\n##  Installation\r\n### PyPI (Recommended)\r\n```\r\npython3 -m pip install isubrip\r\n```\r\n\r\n### Git Source Code\r\n```\r\npython3 -m pip install -e git+https://github.com/MichaelYochpaz/iSubRip.git#egg=isubrip\r\n```\r\n\r\n## Usage\r\n```\r\nisubrip <iTunes movie URL> [iTunes movie URL...]\r\n```  \r\n\r\n## Configuration\r\nIt's possible to configure different options and enable / disable different features using a [TOML](https://toml.io) config file.   \r\nA config file will be looked for in one of the following paths according to OS: \r\n\r\n**Windows**: `%USERPROFILE%\\.isubrip\\config.toml`  \r\n**Linux / macOS**: `$HOME/.isubrip/config.toml`  \r\n\r\n### Examples:\r\n**Windows**: `C:\\Users\\Michael\\.isubrip\\config.toml`  \r\n**Linux**: `/home/Michael/.isubrip/config.toml`  \r\n**macOS**: `/Users/Michael/.isubrip/config.toml`  \r\n\r\n---\r\n\r\n### Example Config:\r\n```toml\r\n[downloads]\r\nfolder = \"C:\\\\iTunes-Subtitles\"\r\nformat = \"srt\"\r\nlanguages = [\"en-US\"]\r\nzip = false\r\n\r\n[subtitles]\r\nfix-rtl = true\r\n```\r\n\r\nA complete config with all the available options and explanations for each configuration can be found [here](https://github.com/MichaelYochpaz/iSubRip/blob/main/config.toml)\r\n\r\n### Notes\r\n* All settings are optional. Not specifying a setting will result in using the default value.\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/README.md b/README.md
--- a/README.md	(revision 92bad88b64f1dabfedd5ae9f1a8a40b483a2bea8)
+++ b/README.md	(date 1682806213256)
@@ -1,5 +1,5 @@
 # iSubRip
-A Python package for scraping and downloading subtitles from iTunes movie pages.  
+A Python package for scraping and downloading subtitles from AppleTV / iTunes movie pages.  
 Latest version: 2.3.3 ([changelog](https://github.com/MichaelYochpaz/iSubRip/blob/main/CHANGELOG.md))  
 
 <br/>
Index: isubrip/scrapers/appletv_scraper.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nfrom isubrip.data_structures import MovieData\r\nfrom isubrip.scrapers.itunes_scraper import iTunesScraper\r\nfrom isubrip.scrapers.scraper import M3U8Scraper, MediaSourceData, MovieScraper, ScraperException, \\\r\n    SeriesScraper, ScraperFactory\r\nfrom isubrip.subtitle_formats.webvtt import WebVTTSubtitles\r\n\r\n\r\nclass AppleTVPlusScraper(M3U8Scraper, MovieScraper, SeriesScraper):\r\n    \"\"\"\r\n    An Apple TV+ movie data scraper.\r\n    Also works for Apple TV items that include iTunes links (by redirecting to the iTunes scraper).\r\n    \"\"\"\r\n    url_regex = r\"(https?://tv\\.apple\\.com/([a-z]{2})/(movie|show)/(?:[\\w\\-%]+/)?(umc\\.cmc\\.[a-z\\d]{24,25}))(?:\\?.*)?\"\r\n    service_data = MediaSourceData(id=\"appletvplus\", name=\"Apple TV+\", abbreviation=\"ATVP\")\r\n    subtitles_class = WebVTTSubtitles\r\n    is_movie_scraper = True\r\n    is_series_scraper = True\r\n    uses_scrapers = [iTunesScraper]\r\n\r\n    _api_url = \"https://tv.apple.com/api/uts/v3/movies/\"\r\n    _api_request_params = {\r\n        \"utscf\": \"OjAAAAAAAAA~\",\r\n        \"utsk\": \"6e3013c6d6fae3c2::::::235656c069bb0efb\",\r\n        \"caller\": \"web\",\r\n        \"v\": \"58\",\r\n        \"pfm\": \"web\",\r\n        \"locale\": \"en-US\"\r\n    }\r\n    _storefronts_mapping = {\r\n        \"AF\": \"143610\", \"AO\": \"143564\", \"AI\": \"143538\", \"AL\": \"143575\", \"AD\": \"143611\", \"AE\": \"143481\", \"AR\": \"143505\",\r\n        \"AM\": \"143524\", \"AG\": \"143540\", \"AU\": \"143460\", \"AT\": \"143445\", \"AZ\": \"143568\", \"BE\": \"143446\", \"BJ\": \"143576\",\r\n        \"BF\": \"143578\", \"BD\": \"143490\", \"BG\": \"143526\", \"BH\": \"143559\", \"BS\": \"143539\", \"BA\": \"143612\", \"BY\": \"143565\",\r\n        \"BZ\": \"143555\", \"BM\": \"143542\", \"BO\": \"143556\", \"BR\": \"143503\", \"BB\": \"143541\", \"BN\": \"143560\", \"BT\": \"143577\",\r\n        \"BW\": \"143525\", \"CF\": \"143623\", \"CA\": \"143455\", \"CH\": \"143459\", \"CL\": \"143483\", \"CN\": \"143465\", \"CI\": \"143527\",\r\n        \"CM\": \"143574\", \"CD\": \"143613\", \"CG\": \"143582\", \"CO\": \"143501\", \"CV\": \"143580\", \"CR\": \"143495\", \"KY\": \"143544\",\r\n        \"CY\": \"143557\", \"CZ\": \"143489\", \"DE\": \"143443\", \"DM\": \"143545\", \"DK\": \"143458\", \"DO\": \"143508\", \"DZ\": \"143563\",\r\n        \"EC\": \"143509\", \"EG\": \"143516\", \"ES\": \"143454\", \"EE\": \"143518\", \"ET\": \"143569\", \"FI\": \"143447\", \"FJ\": \"143583\",\r\n        \"FR\": \"143442\", \"FM\": \"143591\", \"GA\": \"143614\", \"GB\": \"143444\", \"GE\": \"143615\", \"GH\": \"143573\", \"GN\": \"143616\",\r\n        \"GM\": \"143584\", \"GW\": \"143585\", \"GR\": \"143448\", \"GD\": \"143546\", \"GT\": \"143504\", \"GY\": \"143553\", \"HK\": \"143463\",\r\n        \"HN\": \"143510\", \"HR\": \"143494\", \"HU\": \"143482\", \"ID\": \"143476\", \"IN\": \"143467\", \"IE\": \"143449\", \"IQ\": \"143617\",\r\n        \"IS\": \"143558\", \"IL\": \"143491\", \"IT\": \"143450\", \"JM\": \"143511\", \"JO\": \"143528\", \"JP\": \"143462\", \"KZ\": \"143517\",\r\n        \"KE\": \"143529\", \"KG\": \"143586\", \"KH\": \"143579\", \"KN\": \"143548\", \"KR\": \"143466\", \"KW\": \"143493\", \"LA\": \"143587\",\r\n        \"LB\": \"143497\", \"LR\": \"143588\", \"LY\": \"143567\", \"LC\": \"143549\", \"LI\": \"143522\", \"LK\": \"143486\", \"LT\": \"143520\",\r\n        \"LU\": \"143451\", \"LV\": \"143519\", \"MO\": \"143515\", \"MA\": \"143620\", \"MC\": \"143618\", \"MD\": \"143523\", \"MG\": \"143531\",\r\n        \"MV\": \"143488\", \"MX\": \"143468\", \"MK\": \"143530\", \"ML\": \"143532\", \"MT\": \"143521\", \"MM\": \"143570\", \"ME\": \"143619\",\r\n        \"MN\": \"143592\", \"MZ\": \"143593\", \"MR\": \"143590\", \"MS\": \"143547\", \"MU\": \"143533\", \"MW\": \"143589\", \"MY\": \"143473\",\r\n        \"NA\": \"143594\", \"NE\": \"143534\", \"NG\": \"143561\", \"NI\": \"143512\", \"NL\": \"143452\", \"NO\": \"143457\", \"NP\": \"143484\",\r\n        \"NR\": \"143606\", \"NZ\": \"143461\", \"OM\": \"143562\", \"PK\": \"143477\", \"PA\": \"143485\", \"PE\": \"143507\", \"PH\": \"143474\",\r\n        \"PW\": \"143595\", \"PG\": \"143597\", \"PL\": \"143478\", \"PT\": \"143453\", \"PY\": \"143513\", \"PS\": \"143596\", \"QA\": \"143498\",\r\n        \"RO\": \"143487\", \"RU\": \"143469\", \"RW\": \"143621\", \"SA\": \"143479\", \"SN\": \"143535\", \"SG\": \"143464\", \"SB\": \"143601\",\r\n        \"SL\": \"143600\", \"SV\": \"143506\", \"RS\": \"143500\", \"ST\": \"143598\", \"SR\": \"143554\", \"SK\": \"143496\", \"SI\": \"143499\",\r\n        \"SE\": \"143456\", \"SZ\": \"143602\", \"SC\": \"143599\", \"TC\": \"143552\", \"TD\": \"143581\", \"TH\": \"143475\", \"TJ\": \"143603\",\r\n        \"TM\": \"143604\", \"TO\": \"143608\", \"TT\": \"143551\", \"TN\": \"143536\", \"TR\": \"143480\", \"TW\": \"143470\", \"TZ\": \"143572\",\r\n        \"UG\": \"143537\", \"UA\": \"143492\", \"UY\": \"143514\", \"US\": \"143441\", \"UZ\": \"143566\", \"VC\": \"143550\", \"VE\": \"143502\",\r\n        \"VG\": \"143543\", \"VN\": \"143471\", \"VU\": \"143609\", \"WS\": \"143607\", \"XK\": \"143624\", \"YE\": \"143571\", \"ZA\": \"143472\",\r\n        \"ZM\": \"143622\", \"ZW\": \"143605\",\r\n    }\r\n\r\n    def __init__(self, config_data: dict | None = None):\r\n        super().__init__(config_data=config_data)\r\n        self.itunes_scraper = ScraperFactory().get_scraper_instance_by_scraper(\r\n            scraper_class=iTunesScraper,\r\n            scrapers_config_data=config_data,\r\n        )\r\n\r\n    def fetch_api_data(self, url: str) -> dict:\r\n        \"\"\"\r\n        Send a request to AppleTV's API and return the JSON response.\r\n\r\n        Args:\r\n            url: The URL to send the request to.\r\n\r\n        Returns:\r\n            dict: The JSON response.\r\n\r\n        Raises:\r\n            HttpError: If an HTTP error response is received.\r\n        \"\"\"\r\n        regex_match = self.match_url(url, raise_error=True)\r\n\r\n        # Add storefront ID to params\r\n        request_params = self._api_request_params.copy()\r\n\r\n        if regex_match.group(2).upper() in self._storefronts_mapping:\r\n            request_params[\"sf\"] = self._storefronts_mapping[regex_match.group(2).upper()]\r\n\r\n        else:\r\n            raise ScraperException(f\"ID mapping for storefront '{regex_match.group(2).upper()}' could not be found.\")\r\n\r\n        response = self._session.get(self._api_url + regex_match.group(4), params=request_params)\r\n        response.raise_for_status()\r\n        response_json = response.json()\r\n\r\n        return response_json.get(\"data\", {})\r\n\r\n    def get_data(self, url: str) -> MovieData | list[MovieData] | None:\r\n        json_data = self.fetch_api_data(url)\r\n        itunes_channel: str | None = None\r\n        appletvplus_channel: str | None = None\r\n\r\n        for channel in json_data[\"channels\"].values():\r\n            if channel.get(\"isAppleTvPlus\", False):\r\n                appletvplus_channel = channel[\"id\"]\r\n\r\n            elif channel.get(\"isItunes\", False):\r\n                itunes_channel = channel[\"id\"]\r\n        \r\n        if appletvplus_channel:\r\n            media_type = json_data.get(\"content\", {}).get(\"type\")\r\n\r\n            if media_type in (\"Movie\", \"Show\"):\r\n                for playable in json_data[\"playables\"].values():\r\n                    if playable.get(\"channelId\") == appletvplus_channel:\r\n                        raise NotImplementedError(\"AppleTV+ content scraping is not currently supported.\")\r\n\r\n            else:\r\n                raise ScraperException(f\"Unsupported media type: '{media_type}'.\")\r\n\r\n        elif itunes_channel:\r\n            itunes_playables = []\r\n\r\n            for playable in json_data[\"playables\"].values():\r\n                if playable.get(\"channelId\", '') == itunes_channel:\r\n                    itunes_playables.append(playable)\r\n\r\n            return self._get_data_itunes(playables_data=itunes_playables)\r\n\r\n        return None\r\n\r\n    def _get_data_itunes(self, playables_data: list[dict]) -> MovieData | list[MovieData]:\r\n        results = []\r\n\r\n        for playable_data in playables_data:\r\n            itunes_url = playable_data[\"punchoutUrls\"][\"open\"].replace(\"itmss://\", \"https://\")\r\n            results.append(self.itunes_scraper.get_data(itunes_url))\r\n\r\n        if len(results) == 1:\r\n            return results[0]\r\n\r\n        return results\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/scrapers/appletv_scraper.py b/isubrip/scrapers/appletv_scraper.py
--- a/isubrip/scrapers/appletv_scraper.py	(revision 92bad88b64f1dabfedd5ae9f1a8a40b483a2bea8)
+++ b/isubrip/scrapers/appletv_scraper.py	(date 1683844916411)
@@ -1,32 +1,34 @@
 from __future__ import annotations
 
-from isubrip.data_structures import MovieData
+import datetime as dt
+from enum import Enum
+import fnmatch
+from typing import List, Union
+
+from isubrip.config import ConfigSetting
+from isubrip.data_structures import EpisodeData, MovieData, SeasonData, SeriesData, SubtitlesData
 from isubrip.scrapers.itunes_scraper import iTunesScraper
 from isubrip.scrapers.scraper import M3U8Scraper, MediaSourceData, MovieScraper, ScraperException, \
     SeriesScraper, ScraperFactory
 from isubrip.subtitle_formats.webvtt import WebVTTSubtitles
+from isubrip.utils import convert_epoch_to_datetime, parse_url_params
 
 
-class AppleTVPlusScraper(M3U8Scraper, MovieScraper, SeriesScraper):
-    """
-    An Apple TV+ movie data scraper.
-    Also works for Apple TV items that include iTunes links (by redirecting to the iTunes scraper).
-    """
-    url_regex = r"(https?://tv\.apple\.com/([a-z]{2})/(movie|show)/(?:[\w\-%]+/)?(umc\.cmc\.[a-z\d]{24,25}))(?:\?.*)?"
-    service_data = MediaSourceData(id="appletvplus", name="Apple TV+", abbreviation="ATVP")
+class AppleTVScraper(M3U8Scraper, MovieScraper, SeriesScraper):
+    """An Apple TV scraper."""
+    url_regex = r"(?P<base_url>https?://tv\.apple\.com/(?P<country_code>[a-z]{2})/(?P<media_type>movie|episode|season|show)/(?:(?P<media_name>[\w\-%]+)/)?(?P<media_id>umc\.cmc\.[a-z\d]{24,25}))(?:\?(?P<url_params>(?:).*))?"  # noqa: E501
+    service_data = MediaSourceData(id="appletv", name="Apple TV", abbreviation="ATV")  # TODO: Add support for lists? Need to add AppleTV+ (and consider replacing ATV with iT)
     subtitles_class = WebVTTSubtitles
     is_movie_scraper = True
     is_series_scraper = True
     uses_scrapers = [iTunesScraper]
 
-    _api_url = "https://tv.apple.com/api/uts/v3/movies/"
-    _api_request_params = {
+    _api_url = "https://tv.apple.com/api/uts/v3"
+    _api_const_params = {
         "utscf": "OjAAAAAAAAA~",
-        "utsk": "6e3013c6d6fae3c2::::::235656c069bb0efb",
         "caller": "web",
-        "v": "58",
+        "v": "64",
         "pfm": "web",
-        "locale": "en-US"
     }
     _storefronts_mapping = {
         "AF": "143610", "AO": "143564", "AI": "143538", "AL": "143575", "AD": "143611", "AE": "143481", "AR": "143505",
@@ -58,19 +60,66 @@
         "ZM": "143622", "ZW": "143605",
     }
 
+    class Channel(Enum):
+        """
+        An Enum representing AppleTV channels.
+        Value represents the channel ID as used by the API.
+        """
+        APPLE_TV_PLUS = "tvs.sbd.4000"
+        DISNEY_PLUS = "tvs.sbd.1000216"
+        ITUNES = "tvs.sbd.9001"
+        HULU = "tvs.sbd.10000"
+        MAX = "tvs.sbd.9050"
+        NETFLIX = "tvs.sbd.9000"
+        PRIME_VIDEO = "tvs.sbd.12962"
+        STARZ = "tvs.sbd.1000308"
+
     def __init__(self, config_data: dict | None = None):
         super().__init__(config_data=config_data)
+
+        self.config.add_settings([
+            ConfigSetting(  # TODO: Add in default_config, docs, and release notes
+                key="preferred_locale",
+                type=Union[str, List[str]],
+                required=False,
+            )])
+
         self.itunes_scraper = ScraperFactory().get_scraper_instance_by_scraper(
             scraper_class=iTunesScraper,
             scrapers_config_data=config_data,
         )
 
-    def fetch_api_data(self, url: str) -> dict:
+    def _decide_locale(self, preferred_locales: str | list[str], default_locale: str, locales: list[str]) -> str:
+        """
+        Decide which locale to use.
+
+        Args:
+            preferred_locales (str | list[str]): The preferred locales to use.
+            default_locale (str): The default locale to use if there is no match.
+            locales (list[str]): The locales to search in.
+
+        Returns:
+            str: The locale to use.
+        """
+        if isinstance(preferred_locales, str):
+            preferred_locales = [preferred_locales]
+
+        for locale in preferred_locales:
+            if locale in locales:
+                return locale.replace("_", "-")
+
+        if result := fnmatch.filter(locales, "en_*"):
+            return result[0].replace("_", "-")
+
+        return default_locale
+
+    def _fetch_api_data(self, storefront_id: str, endpoint: str, additional_params: dict | None = None) -> dict:
         """
         Send a request to AppleTV's API and return the JSON response.
 
         Args:
-            url: The URL to send the request to.
+            endpoint (str): The endpoint to send the request to.
+            additional_params (dict[str, str]): Additional parameters to send with the request.
 
         Returns:
             dict: The JSON response.
@@ -78,65 +127,185 @@
         Raises:
             HttpError: If an HTTP error response is received.
         """
-        regex_match = self.match_url(url, raise_error=True)
+        storefront_data = self._get_configuration_data(storefront_id=storefront_id)["applicationProps"]["storefront"]
 
-        # Add storefront ID to params
-        request_params = self._api_request_params.copy()
+        locale = self._decide_locale(
+            preferred_locales=["en_US", "en_GB"],  # TODO: Make this configurable
+            default_locale=storefront_data["defaultLocale"],
+            locales=storefront_data["localesSupported"],
+        )
 
-        if regex_match.group(2).upper() in self._storefronts_mapping:
-            request_params["sf"] = self._storefronts_mapping[regex_match.group(2).upper()]
+        request_params = self._generate_api_request_params(storefront_id=storefront_id, locale=locale)
 
-        else:
-            raise ScraperException(f"ID mapping for storefront '{regex_match.group(2).upper()}' could not be found.")
+        if additional_params:
+            request_params.update(additional_params)
 
-        response = self._session.get(self._api_url + regex_match.group(4), params=request_params)
+        # Send request to fetch media data
+        response = self._session.get(url=f"{self._api_url}{endpoint}", params=request_params)
         response.raise_for_status()
         response_json = response.json()
 
         return response_json.get("data", {})
 
-    def get_data(self, url: str) -> MovieData | list[MovieData] | None:
-        json_data = self.fetch_api_data(url)
-        itunes_channel: str | None = None
-        appletvplus_channel: str | None = None
+    def _generate_api_request_params(self, storefront_id: str,
+                                     locale: str | None = None, utsk: str | None = None) -> dict:
+        """
+        Generate request params for the AppleTV's API.
+
+        Args:
+            storefront_id (str): ID of the storefront to use.
+            locale (str | None, optional): ID of the locale to use. Defaults to None.
+            utsk (str | None, optional): utsk data. Defaults to None.
+
+        Returns:
+            dict: The request params, generated from the given arguments.
+        """
+        params = self._api_const_params.copy()
+        params["sf"] = storefront_id
+
+        if utsk:
+            params["utsk"] = utsk
+
+        if locale:
+            params["locale"] = locale
+
+        return params
+
+    def _get_configuration_data(self, storefront_id: str) -> dict:
+        """
+        Get configuration data for the given storefront ID.
+
+        Args:
+            storefront_id (str): The ID of the storefront to get the configuration data for.
+
+        Returns:
+            dict: The configuration data.
+        """
+        url = f"{self._api_url}/configurations"
+        params = self._generate_api_request_params(storefront_id=storefront_id, locale="en-US")
+        response = self._session.get(url=url, params=params)
+        response.raise_for_status()
+
+        return response.json()["data"]
+
+    def _map_playables_by_channel(self, playables: list[dict]) -> dict[str, dict]:
+        """
+        Map playables by channel name.
+        Args:
+            playables (list[dict]): Playables data to map.
 
-        for channel in json_data["channels"].values():
-            if channel.get("isAppleTvPlus", False):
-                appletvplus_channel = channel["id"]
+        Returns:
+            dict: The mapped playables (in a `channel_name (str): [playables]` format).
+        """
+        mapped_playables = {}
 
-            elif channel.get("isItunes", False):
-                itunes_channel = channel["id"]
-        
-        if appletvplus_channel:
-            media_type = json_data.get("content", {}).get("type")
+        for playable in playables:
+            channel_id = playable.get("channelId", "")
+            mapped_playables.setdefault(channel_id, []).append(playable)
+
+        return mapped_playables
 
-            if media_type in ("Movie", "Show"):
-                for playable in json_data["playables"].values():
-                    if playable.get("channelId") == appletvplus_channel:
-                        raise NotImplementedError("AppleTV+ content scraping is not currently supported.")
+    def get_movie_data(self, storefront_id: str, movie_id: str) -> MovieData | list[MovieData]:
+        data = self._fetch_api_data(
+            storefront_id=storefront_id,
+            endpoint=f"/movies/{movie_id}",
+        )
 
+        mapped_playables = self._map_playables_by_channel(playables=data["playables"].values())
+
+        if self.Channel.ITUNES.value not in mapped_playables:
+            if self.Channel.APPLE_TV_PLUS.value in mapped_playables:
+                raise ScraperException("Scraping AppleTV+ content is not currently supported.")
+
             else:
-                raise ScraperException(f"Unsupported media type: '{media_type}'.")
+                raise ScraperException("Movie is not available on iTunes.")
+
+        return_data = []
+        for playable_data in mapped_playables[self.Channel.ITUNES.value]:
+            movie_id = playable_data["itunesMediaApiData"]["id"]  # iTunes ID
+            movie_alt_id = playable_data["canonicalId"]  # AppleTV ID
+            movie_title = playable_data["canonicalMetadata"]["movieTitle"]
+            movie_release_date = convert_epoch_to_datetime(playable_data["canonicalMetadata"]["releaseDate"] // 1000)
+
+            movie_playlist = None
+
+            if offers := playable_data["itunesMediaApiData"].get("offers"):
+                movie_playlist = offers[0].get("hlsUrl")
+
+            if movie_expected_release_date := playable_data["itunesMediaApiData"].get("expectedReleaseDate"):
+                dt.datetime.strptime(movie_expected_release_date, "%Y-%m-%d")
+
+            return_data.append(
+                MovieData(
+                    id=movie_id,
+                    alt_id=movie_alt_id,
+                    name=movie_title,
+                    release_date=movie_release_date,
+                    playlist=movie_playlist,
+                    source=self.service_data,
+                    scraper=self.itunes_scraper,
+                    original_data=playable_data,
+                    preorder_availability_date=movie_expected_release_date
+                ))
+
+        if len(return_data) == 1:
+            return return_data[0]
+
+        return return_data
+
+    def get_episode_data(self, storefront_id: str, episode_id: str) -> EpisodeData:
+        raise NotImplementedError("AppleTV series scraping is not currently supported.")
+
+    def get_season_data(self, storefront_id: str, season_id: str, show_id: str) -> SeasonData:
+        raise NotImplementedError("AppleTV series scraping is not currently supported.")
+
+    def get_show_data(self, storefront_id: str, show_id: str) -> SeriesData:
+        raise NotImplementedError("AppleTV series scraping is not currently supported.")
+        # data = self._fetch_api_data(
+        #     storefront_id=storefront_id,
+        #     endpoint=f"/shows/{show_id}/episodes",
+        #     additional_params={
+        #         "includeSeasonSummary": "true",
+        #         "nextToken": "0:1",  # f"{page}:{episodes_per_page}"
+        #     },
+        # )  # TODO: Utilize "seasonSummaries" and "totalEpisodeCount" for pagination
 
-        elif itunes_channel:
-            itunes_playables = []
+    def get_data(self, url: str) -> MovieData | list[MovieData] | EpisodeData | SeasonData | SeriesData:
+        regex_match = self.match_url(url, raise_error=True)
+        url_data = regex_match.groupdict()
 
-            for playable in json_data["playables"].values():
-                if playable.get("channelId", '') == itunes_channel:
-                    itunes_playables.append(playable)
+        media_type = url_data["media_type"]
+        stroefront_code = url_data["country_code"].upper()
+        media_id = url_data["media_id"]
 
-            return self._get_data_itunes(playables_data=itunes_playables)
+        if stroefront_code not in self._storefronts_mapping:
+            raise ScraperException(f"ID mapping for storefront '{stroefront_code}' could not be found.")
 
-        return None
+        storefront_id = self._storefronts_mapping[stroefront_code]
 
-    def _get_data_itunes(self, playables_data: list[dict]) -> MovieData | list[MovieData]:
-        results = []
+        if media_type == "movie":
+            return self.get_movie_data(storefront_id=storefront_id, movie_id=media_id)
 
-        for playable_data in playables_data:
-            itunes_url = playable_data["punchoutUrls"]["open"].replace("itmss://", "https://")
-            results.append(self.itunes_scraper.get_data(itunes_url))
+        elif media_type == "episode":
+            return self.get_episode_data(storefront_id=storefront_id, episode_id=media_id)
 
-        if len(results) == 1:
-            return results[0]
+        elif media_type == "season":
+            if url_params := url_data.get("url_params"):
+                if show_id := parse_url_params(url_params).get("showId"):
+                    return self.get_season_data(storefront_id=storefront_id, season_id=media_id, show_id=show_id)
 
-        return results
+            raise ScraperException("Invalid AppleTV URL: Missing 'showId' parameter.")
+
+        elif media_type == "show":
+            return self.get_show_data(storefront_id=storefront_id, show_id=media_id)
+
+        else:
+            raise ScraperException(f"Invalid media type '{media_type}'.")
+
+
+    # TODO: Find the best way to resolve this issue (relationship between iTunes and AppleTV scrapers)
+    # def get_subtitles(self, main_playlist: M3U8, language_filter: list[str] | str | None = None,
+    #                   subrip_conversion: bool = False) -> Iterator[SubtitlesData]:
+    #     # Use the iTunes scraper to get the subtitles to assure the configuration of iTunes is used
+    #     return self.itunes_scraper.get_subtitles(main_playlist=main_playlist, language_filter=language_filter,
+    #                                                 subrip_conversion=subrip_conversion)
\ No newline at end of file
Index: isubrip/scrapers/scraper.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nimport asyncio\r\nimport importlib\r\nimport inspect\r\nimport os\r\nimport re\r\nimport sys\r\nfrom abc import abstractmethod, ABC\r\nfrom enum import Enum\r\nfrom glob import glob\r\nfrom pathlib import Path\r\nfrom typing import ClassVar, Iterator, Literal, overload, Union, List, TypeVar\r\n\r\nimport aiohttp\r\nimport m3u8\r\nimport requests\r\nfrom m3u8 import M3U8, Media, Segment, SegmentList\r\n\r\nfrom isubrip.config import Config, ConfigSetting\r\nfrom isubrip.constants import PACKAGE_NAME, SCRAPER_MODULES_SUFFIX\r\nfrom isubrip.data_structures import MediaSourceData, SubtitlesData, SubtitlesFormat, SubtitlesType\r\nfrom isubrip.subtitle_formats.subtitles import Subtitles\r\nfrom isubrip.utils import merge_dict_values, SingletonMeta\r\n\r\n\r\nScraperT = TypeVar(\"ScraperT\", bound=\"Scraper\")\r\n\r\n\r\nclass Scraper(ABC, metaclass=SingletonMeta):\r\n    \"\"\"\r\n    A base class for scrapers.\r\n\r\n    Attributes:\r\n        default_user_agent (str): [Class Attribute]\r\n            Default user agent to use if no other user agent is specified when making requests.\r\n        url_regex: [Class Attribute] A RegEx pattern to find URLs matching the service.\r\n        service_data: [Class Attribute] A MediaSourceData object containing the service's name and abbreviation.\r\n        subtitles_class: [Class Attribute] Class of the subtitles format returned by the scraper.\r\n        is_movie_scraper: [Class Attribute] Whether the scraper is for movies.\r\n        is_series_scraper: [Class Attribute] Whether the scraper is for series.\r\n        uses_scrapers: [Class Attribute] A list of other scraper classes that this scraper uses.\r\n            This assures that the config data for the other scrapers is passed as well.\r\n        _session (requests.Session): A requests session to use for making requests.\r\n        config (Config): A Config object containing the scraper's configuration.\r\n    \"\"\"\r\n    default_user_agent: ClassVar[str]\r\n    subtitles_fix_rtl: ClassVar[bool]\r\n    subtitles_fix_rtl_languages: ClassVar[list | None]\r\n    subtitles_remove_duplicates: ClassVar[bool]\r\n\r\n    url_regex: ClassVar[str | list[str]]\r\n    service_data: ClassVar[MediaSourceData]\r\n    subtitles_class: ClassVar[type[Subtitles]]\r\n    is_movie_scraper: ClassVar[bool] = False\r\n    is_series_scraper: ClassVar[bool] = False\r\n    uses_scrapers: ClassVar[list[type[Scraper]]] = []\r\n\r\n    def __init__(self, config_data: dict | None = None):\r\n        \"\"\"\r\n        Initialize a Scraper object.\r\n\r\n        Args:\r\n            config_data (dict | None, optional): A dictionary containing scraper's configuration data. Defaults to None.\r\n        \"\"\"\r\n        self._session = requests.Session()\r\n        self.config = Config(config_data=config_data.get(self.service_data.id) if config_data else None)\r\n\r\n        self.config.add_settings([\r\n            ConfigSetting(\r\n                key=\"user-agent\",\r\n                type=str,\r\n                required=False,\r\n            )],\r\n            check_config=False)\r\n\r\n        self._session.headers.update({\"User-Agent\": self.config.get(\"user-agent\") or self.default_user_agent})\r\n\r\n    @classmethod\r\n    @overload\r\n    def match_url(cls, url: str, raise_error: Literal[True] = ...) -> re.Match:\r\n        ...\r\n\r\n    @classmethod\r\n    @overload\r\n    def match_url(cls, url: str, raise_error: Literal[False] = ...) -> re.Match | None:\r\n        ...\r\n\r\n    @classmethod\r\n    def match_url(cls, url: str, raise_error: bool = False) -> re.Match | None:\r\n        \"\"\"\r\n        Checks if a URL matches scraper's url regex.\r\n\r\n        Args:\r\n            url (str): A URL to check against the regex.\r\n            raise_error (bool, optional): Whether to raise an error instead of returning None if the URL doesn't match.\r\n\r\n        Returns:\r\n            re.Match | None: A Match object if the URL matches the regex, None otherwise (if raise_error is False).\r\n\r\n        Raises:\r\n            ValueError: If the URL doesn't match the regex and raise_error is True.\r\n        \"\"\"\r\n        if isinstance(cls.url_regex, str):\r\n            return re.fullmatch(cls.url_regex, url)\r\n\r\n        else:  # isinstance(cls.url_regex, (list, tuple)):\r\n            for regex in cls.url_regex:\r\n                if result := re.fullmatch(regex, url):\r\n                    return result\r\n\r\n        if raise_error:\r\n            raise ValueError(f\"URL '{url}' doesn't match the URL regex of {cls.service_data.name}.\")\r\n\r\n        return None\r\n\r\n    def __enter__(self):\r\n        return self\r\n\r\n    def __exit__(self, exc_type, exc_val, exc_tb):\r\n        self.close()\r\n\r\n    def close(self):\r\n        self._session.close()\r\n\r\n    @abstractmethod\r\n    def get_data(self, url: str):\r\n        \"\"\"\r\n        Scrape media information about the media on a URL.\r\n\r\n        Args:\r\n            url (str): A URL to get media information about.\r\n        \"\"\"\r\n        pass\r\n\r\n    @abstractmethod\r\n    def get_subtitles(self, main_playlist: M3U8, language_filter: list[str] | None = None,\r\n                      subrip_conversion: bool = False) -> Iterator[SubtitlesData]:\r\n        \"\"\"\r\n        Find and yield subtitles data from a main_playlist.\r\n\r\n        Args:\r\n            main_playlist (M3U8): Main playlist of the media to search for subtitles in.\r\n            language_filter (list[str], optional): A list of languages to filter for.\r\n            subrip_conversion (bool, optional): Whether to convert the subtitles to SubRip format. Defaults to False.\r\n\r\n        Yields:\r\n            SubtitlesData: A SubtitlesData object for each subtitle found\r\n                in the main playlist (matching the filters, if given).\r\n        \"\"\"\r\n        pass\r\n\r\n\r\nclass MovieScraper(Scraper, ABC):\r\n    \"\"\"A base class for movie scrapers.\"\"\"\r\n    is_movie_scraper = True\r\n\r\n\r\nclass SeriesScraper(Scraper, ABC):\r\n    \"\"\"A base class for series scrapers.\"\"\"\r\n    is_series_scraper = True\r\n\r\n\r\nclass AsyncScraper(Scraper, ABC):\r\n    \"\"\"A base class for scrapers that utilize async requests.\"\"\"\r\n    def __init__(self, config_data: dict | None = None):\r\n        super().__init__(config_data)\r\n        self.async_session = aiohttp.ClientSession()\r\n        self.async_session.headers.update(self._session.headers)\r\n\r\n    def close(self):\r\n        asyncio.get_event_loop().run_until_complete(self._async_close())\r\n        super().close()\r\n\r\n    async def _async_close(self):\r\n        await self.async_session.close()\r\n\r\n\r\nclass M3U8Scraper(AsyncScraper, ABC):\r\n    \"\"\"A base class for M3U8 scrapers.\"\"\"\r\n    playlist_filters_config_category = \"playlist-filters\"\r\n\r\n    class M3U8Attribute(Enum):\r\n        \"\"\"\r\n        An enum representing all possible M3U8 attributes.\r\n        Names / Keys represent M3U8 Media object attributes (should be converted to lowercase),\r\n        and values represent the name of the key for config usage.\r\n        \"\"\"\r\n        ASSOC_LANGUAGE = \"assoc-language\"\r\n        AUTOSELECT = \"autoselect\"\r\n        CHARACTERISTICS = \"characteristics\"\r\n        CHANNELS = \"channels\"\r\n        DEFAULT = \"default\"\r\n        FORCED = \"forced\"\r\n        GROUP_ID = \"group-id\"\r\n        INSTREAM_ID = \"instream-id\"\r\n        LANGUAGE = \"language\"\r\n        NAME = \"name\"\r\n        STABLE_RENDITION_ID = \"stable-rendition-id\"\r\n        TYPE = \"type\"\r\n\r\n    def __init__(self, config_data: dict | None = None):\r\n        super().__init__(config_data)\r\n\r\n        if self.config is None:\r\n            self.config = Config()\r\n\r\n        # Add M3U8 filters settings\r\n        self.config.add_settings([\r\n            ConfigSetting(\r\n                category=self.playlist_filters_config_category,\r\n                key=m3u8_attribute.value,\r\n                type=Union[str, List[str]],\r\n                required=False,\r\n            ) for m3u8_attribute in self.M3U8Attribute],\r\n            check_config=False)\r\n\r\n    def _download_segments_async(self, segments: SegmentList[Segment]) -> list[bytes]:\r\n        \"\"\"\r\n        Download M3U8 segments asynchronously.\r\n\r\n        Args:\r\n            segments (m3u8.SegmentList[m3u8.Segment]): List of segments to download.\r\n\r\n        Returns:\r\n            list[bytes]: List of downloaded segments.\r\n        \"\"\"\r\n        loop = asyncio.get_event_loop()\r\n        async_tasks = [loop.create_task(self._download_segment_async(segment.absolute_uri)) for segment in segments]\r\n        segments_bytes = loop.run_until_complete(asyncio.gather(*async_tasks))\r\n\r\n        return list(segments_bytes)\r\n\r\n    async def _download_segment_async(self, url: str) -> bytes:\r\n        \"\"\"\r\n        Download an M3U8 segment asynchronously.\r\n\r\n        Args:\r\n            url (str): URL of the segment to download.\r\n\r\n        Returns:\r\n            bytes: Downloaded segment.\r\n        \"\"\"\r\n        async with self.async_session.get(url) as response:\r\n            return await response.read()\r\n\r\n    @staticmethod\r\n    def detect_subtitles_type(subtitles_media: Media) -> SubtitlesType | None:\r\n        \"\"\"\r\n        Detect the subtitles type (Closed Captions, Forced, etc.) from an M3U8 Media object.\r\n\r\n        Args:\r\n            subtitles_media (m3u8.Media): Subtitles Media object to detect the type of.\r\n\r\n        Returns:\r\n            SubtitlesType | None: The type of the subtitles, None for regular subtitles.\r\n        \"\"\"\r\n        if subtitles_media.forced == \"YES\":\r\n            return SubtitlesType.FORCED\r\n\r\n        elif subtitles_media.characteristics is not None and \"public.accessibility\" in subtitles_media.characteristics:\r\n            return SubtitlesType.CC\r\n\r\n        return None\r\n\r\n    def get_media_playlists(self, main_playlist: M3U8,\r\n                            playlist_filters: dict[str, str | list[str]] | None = None,\r\n                            include_default_filters: bool = True) -> Iterator[Media]:\r\n        \"\"\"\r\n        Find and yield playlists of media within an M3U8 main_playlist using optional filters.\r\n\r\n        Args:\r\n            main_playlist (m3u8.M3U8): an M3U8 object of the main main_playlist.\r\n            playlist_filters (dict[str, str | list[str], optional):\r\n                A dictionary of filters to use when searching for subtitles.\r\n                Will be added to filters set by the config (unless `include_default_filters` is set to false).\r\n                Defaults to None.\r\n            include_default_filters (bool, optional): Whether to include the default filters set by the config or not.\r\n                Defaults to True.\r\n\r\n        Yields:\r\n            SubtitlesData: A NamedTuple with a matching main_playlist, and it's metadata:\r\n                Language Code, Language Name, SubtitlesType, Playlist URL.\r\n        \"\"\"\r\n        default_filters: dict | None = self.config.get(M3U8Scraper.playlist_filters_config_category)\r\n\r\n        if include_default_filters and default_filters:\r\n            if not playlist_filters:\r\n                playlist_filters = default_filters\r\n\r\n            else:\r\n                playlist_filters = merge_dict_values(default_filters, playlist_filters)\r\n\r\n        for media in main_playlist.media:\r\n            if not playlist_filters:\r\n                yield media\r\n\r\n            else:\r\n                is_valid = True\r\n\r\n                for filter_name, filter_value in playlist_filters.items():\r\n                    try:\r\n                        filter_name_enum = M3U8Scraper.M3U8Attribute(filter_name)\r\n                        attribute_value = getattr(media, filter_name_enum.name.lower(), None)\r\n\r\n                        if attribute_value is None:\r\n                            is_valid = False\r\n                            break\r\n\r\n                        elif isinstance(filter_value, list) and \\\r\n                                attribute_value.casefold() not in (x.casefold() for x in filter_value):\r\n                            is_valid = False\r\n                            break\r\n\r\n                        elif isinstance(filter_value, str) and filter_value.casefold() != attribute_value.casefold():\r\n                            is_valid = False\r\n                            break\r\n\r\n                    except Exception:\r\n                        continue\r\n\r\n                if is_valid:\r\n                    yield media\r\n\r\n    def get_subtitles(self, main_playlist: M3U8, language_filter: list[str] | str | None = None,\r\n                      subrip_conversion: bool = False) -> Iterator[SubtitlesData]:\r\n        \"\"\"\r\n        Find and yield subtitles for a movie using optional filters.\r\n\r\n        Args:\r\n            main_playlist (m3u8.M3U8): an M3U8 object of the main playlist.\r\n            language_filter (list[str] | str | None, optional):\r\n                A language or a list of languages to filter for. Defaults to None.\r\n            subrip_conversion (bool, optional): Whether to convert and return the subtitles as an SRT file or not.\r\n                Defaults to False.\r\n\r\n        Yields:\r\n            SubtitlesData: A SubtitlesData NamedTuple with a matching playlist, and it's metadata.\r\n        \"\"\"\r\n        playlist_filters = {self.M3U8Attribute.LANGUAGE.value: language_filter} if language_filter else None\r\n\r\n        for matched_media in self.get_media_playlists(main_playlist=main_playlist, playlist_filters=playlist_filters):\r\n            try:\r\n                matched_media_playlist = m3u8.load(matched_media.absolute_uri)\r\n                subtitles = self.subtitles_class(language_code=matched_media.language)\r\n                for segment in self._download_segments_async(matched_media_playlist.segments):\r\n                    subtitles.append_subtitles(subtitles.loads(segment.decode(\"utf-8\")))\r\n\r\n                subtitles.polish(\r\n                    fix_rtl=self.subtitles_fix_rtl,\r\n                    rtl_languages=self.subtitles_fix_rtl_languages,\r\n                    remove_duplicates=self.subtitles_remove_duplicates,\r\n                )\r\n\r\n                yield SubtitlesData(\r\n                    language_code=matched_media.language,\r\n                    language_name=matched_media.name,\r\n                    subtitles_format=SubtitlesFormat.SUBRIP if subrip_conversion else SubtitlesFormat.WEBVTT,\r\n                    content=subtitles.to_srt().dump() if subrip_conversion else subtitles.dump(),\r\n                    special_type=self.detect_subtitles_type(matched_media),\r\n                )\r\n\r\n            except Exception:\r\n                continue\r\n\r\n\r\nclass ScraperFactory(metaclass=SingletonMeta):\r\n    def __init__(self):\r\n        self._scraper_classes_cache: list[type[Scraper]] | None = None\r\n        self._scraper_instances_cache: dict[type[Scraper], Scraper] = {}\r\n\r\n    def get_initialized_scrapers(self) -> list[Scraper]:\r\n        \"\"\"\r\n        Get a list of all previously initialized scrapers.\r\n\r\n        Returns:\r\n            list[Scraper]: A list of initialized scrapers.\r\n        \"\"\"\r\n        return list(self._scraper_instances_cache.values())\r\n\r\n    def get_scraper_classes(self) -> list[type[Scraper]]:\r\n        \"\"\"\r\n        Get a list of all scraper classes.\r\n\r\n        Returns:\r\n            list[type[Scraper]]: A list of scraper classes.\r\n        \"\"\"\r\n        if self._scraper_classes_cache is not None:\r\n            return self._scraper_classes_cache\r\n\r\n        else:\r\n            scrapers_list: list[type[Scraper]] = []\r\n\r\n            scraper_modules_paths = glob(os.path.dirname(__file__) + f\"/*{SCRAPER_MODULES_SUFFIX}.py\")\r\n\r\n            for scraper_module_path in scraper_modules_paths:\r\n                sys.path.append(scraper_module_path)\r\n\r\n                module = importlib.import_module(f\"{PACKAGE_NAME}.scrapers.{Path(scraper_module_path).stem}\")\r\n\r\n                # find Scraper subclasses\r\n                for name, obj in inspect.getmembers(module,\r\n                                                    predicate=lambda x: inspect.isclass(x) and issubclass(x, Scraper)):\r\n                    # Skip object if it's an abstract or imported from another module\r\n                    if not inspect.isabstract(obj) and obj.__module__ == module.__name__:\r\n                        if any((obj.is_movie_scraper, obj.is_series_scraper)):\r\n                            scrapers_list.append(obj)\r\n\r\n            return scrapers_list\r\n\r\n    @overload\r\n    def get_scraper_instance_by_url(self, url: str, scrapers_config_data: dict | None = ...,\r\n                                    raise_error: Literal[True] = ...) -> Scraper:\r\n        ...\r\n\r\n    @overload\r\n    def get_scraper_instance_by_url(self, url: str, scrapers_config_data: dict | None = ...,\r\n                                    raise_error: Literal[False] = ...) -> Scraper | None:\r\n        ...\r\n\r\n    def get_scraper_instance_by_url(self, url: str, scrapers_config_data: dict | None = None,\r\n                                    raise_error: bool = False) -> Scraper | None:\r\n        \"\"\"\r\n        Find, initialize and return a scraper that matches the given URL.\r\n\r\n        Args:\r\n            url (str): A URL to match a scraper for.\r\n            scrapers_config_data (dict, optional): A dictionary containing scrapers config data to use\r\n                when creating a new scraper. Defaults to None.\r\n            raise_error (bool, optional): Whether to raise an error if no scraper was found. Defaults to False.\r\n\r\n        Returns:\r\n            Scraper | None: An instance of a scraper that matches the given URL,\r\n                None otherwise (if raise_error is False).\r\n\r\n        Raises:\r\n            ValueError: If no scraper was found and raise_error is True.\r\n        \"\"\"\r\n        for scraper in self.get_scraper_classes():\r\n            if url and scraper.match_url(url) is not None:\r\n                return self.get_scraper_instance_by_scraper(scraper_class=scraper,\r\n                                                            scrapers_config_data=scrapers_config_data)\r\n\r\n        if raise_error:\r\n            raise ValueError(f\"No matching scraper was found for {url}\")\r\n\r\n        return None\r\n\r\n    def get_scraper_instance_by_scraper(self, scraper_class: type[ScraperT],\r\n                                        scrapers_config_data: dict | None = None) -> ScraperT:\r\n        \"\"\"\r\n        Initialize and return a scraper instance.\r\n\r\n        Args:\r\n            scraper_class (type[ScraperT]): A scraper class to initialize.\r\n            scrapers_config_data (dict, optional): A dictionary containing scrapers config data to use\r\n                when creating a new scraper. Defaults to None.\r\n\r\n        Returns:\r\n            Scraper: An instance of the given scraper class.\r\n        \"\"\"\r\n        if scraper_class not in self._scraper_instances_cache:\r\n            if not scrapers_config_data:\r\n                config_data = None\r\n\r\n            else:\r\n                required_scrapers_ids = [scraper_class.service_data.id] + \\\r\n                                        [s.service_data.id for s in scraper_class.uses_scrapers]\r\n                config_data = \\\r\n                    {scraper_id: scrapers_config_data[scraper_id] for scraper_id in required_scrapers_ids\r\n                     if scrapers_config_data.get(scraper_id)}\r\n\r\n            self._scraper_instances_cache[scraper_class] = scraper_class(config_data=config_data)\r\n\r\n        return self._scraper_instances_cache[scraper_class]  # type: ignore[return-value]\r\n\r\n\r\nclass ScraperException(Exception):\r\n    pass\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/scrapers/scraper.py b/isubrip/scrapers/scraper.py
--- a/isubrip/scrapers/scraper.py	(revision 92bad88b64f1dabfedd5ae9f1a8a40b483a2bea8)
+++ b/isubrip/scrapers/scraper.py	(date 1683491339854)
@@ -50,7 +50,7 @@
     subtitles_remove_duplicates: ClassVar[bool]
 
     url_regex: ClassVar[str | list[str]]
-    service_data: ClassVar[MediaSourceData]
+    service_data: ClassVar[MediaSourceData | list[MediaSourceData]]
     subtitles_class: ClassVar[type[Subtitles]]
     is_movie_scraper: ClassVar[bool] = False
     is_series_scraper: ClassVar[bool] = False
@@ -102,11 +102,11 @@
             ValueError: If the URL doesn't match the regex and raise_error is True.
         """
         if isinstance(cls.url_regex, str):
-            return re.fullmatch(cls.url_regex, url)
+            return re.fullmatch(pattern=cls.url_regex, string=url, flags=re.IGNORECASE)
 
         else:  # isinstance(cls.url_regex, (list, tuple)):
-            for regex in cls.url_regex:
-                if result := re.fullmatch(regex, url):
+            for url_regex_item in cls.url_regex:
+                if result := re.fullmatch(pattern=url_regex_item, string=url, flags=re.IGNORECASE):
                     return result
 
         if raise_error:
Index: setup.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nimport re\r\nfrom pathlib import Path\r\nfrom setuptools import setup\r\n\r\nCURRENT_PATH = Path(__file__).parent.absolute()\r\nPACKAGE_NAME = \"isubrip\"\r\nREADME_PATH = CURRENT_PATH / \"README.md\"\r\n\r\n\r\ndef get_version() -> str:\r\n    init_file_path = CURRENT_PATH / PACKAGE_NAME / \"__init__.py\"\r\n    version_regex = r\"^__version__ = ['\\\"](\\d+(?:\\.\\d+){2,3})['\\\"]\"\r\n\r\n    if not init_file_path.exists():\r\n        raise FileNotFoundError(f\"{init_file_path} file is missing.\")\r\n\r\n    with open(init_file_path, 'r') as fp:\r\n        file_data = fp.read()\r\n\r\n    for line in file_data.splitlines():\r\n        if line.startswith(\"__version__\"):\r\n            if result := re.match(version_regex, line).group(1):\r\n                return result\r\n\r\n            else:\r\n                raise RuntimeError('__version__ assignment does not match expected regex.')\r\n\r\n    raise RuntimeError('Unable to find version string.')\r\n\r\n\r\ndef get_long_description() -> str:\r\n    readme_path = CURRENT_PATH / \"README.md\"\r\n\r\n    if not readme_path.exists():\r\n        raise FileNotFoundError(f\"{readme_path} file is missing.\")\r\n\r\n    with open(readme_path, \"r\") as file:\r\n        return file.read()\r\n\r\n\r\nsetup(\r\n    name=PACKAGE_NAME,\r\n    version=get_version(),\r\n    author=\"Michael Yochpaz\",\r\n    license=\"MIT\",\r\n    license_files=('LICENSE',),\r\n    description=\"A Python package for scraping and downloading subtitles from iTunes movie pages.\",\r\n    long_description=get_long_description(),\r\n    long_description_content_type=\"text/markdown\",\r\n    url=\"https://github.com/MichaelYochpaz/iSubRip\",\r\n\r\n    project_urls={\r\n        \"Bug Reports\": \"https://github.com/MichaelYochpaz/iSubRip/issues\",\r\n        \"Source\": \"https://github.com/MichaelYochpaz/iSubRip\"\r\n    },\r\n\r\n    classifiers=[\r\n        \"Development Status :: 5 - Production/Stable\",\r\n        \"Intended Audience :: End Users/Desktop\",\r\n        \"Intended Audience :: Developers\",\r\n        \"Topic :: Utilities\",\r\n        \"License :: OSI Approved :: MIT License\",\r\n        \"Programming Language :: Python :: 3.8\",\r\n        \"Programming Language :: Python :: 3.9\",\r\n        \"Programming Language :: Python :: 3.10\"\r\n    ],\r\n\r\n    keywords=[\"iTunes\", \"movies\", \"subtitles\", \"scrape\", \"scraper\", \"download\", \"m3u8\"],\r\n    packages=[PACKAGE_NAME],\r\n    install_requires=[\"aiohttp\", \"beautifulsoup4\", \"lxml\", \"m3u8\", \"mergedeep\", \"requests\", \"tomli\"],\r\n    package_data={PACKAGE_NAME: [\"resources/*\"]},\r\n    python_requires=\">=3.8\",\r\n    entry_points={\r\n        \"console_scripts\":\r\n            [f\"{PACKAGE_NAME} = {PACKAGE_NAME}.__main__:main\"]\r\n    },\r\n)\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/setup.py b/setup.py
--- a/setup.py	(revision 92bad88b64f1dabfedd5ae9f1a8a40b483a2bea8)
+++ b/setup.py	(date 1682806213264)
@@ -69,7 +69,7 @@
 
     keywords=["iTunes", "movies", "subtitles", "scrape", "scraper", "download", "m3u8"],
     packages=[PACKAGE_NAME],
-    install_requires=["aiohttp", "beautifulsoup4", "lxml", "m3u8", "mergedeep", "requests", "tomli"],
+    install_requires=["aiohttp", "m3u8", "mergedeep", "requests", "tomli"],
     package_data={PACKAGE_NAME: ["resources/*"]},
     python_requires=">=3.8",
     entry_points={
Index: isubrip/__main__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nimport atexit\r\nimport shutil\r\nimport sys\r\nfrom pathlib import Path\r\n\r\nimport m3u8\r\nimport requests\r\nfrom requests.utils import default_user_agent\r\n\r\nfrom isubrip.config import Config, ConfigException\r\nfrom isubrip.constants import ARCHIVE_FORMAT, DATA_FOLDER_PATH, DEFAULT_CONFIG_PATH, DEFAULT_CONFIG_SETTINGS, \\\r\n    PACKAGE_NAME, TEMP_FOLDER_PATH, USER_CONFIG_FILE\r\nfrom isubrip.data_structures import EpisodeData,  MediaData, MovieData, SubtitlesDownloadResults, SubtitlesData\r\nfrom isubrip.scrapers.scraper import Scraper, ScraperFactory\r\nfrom isubrip.utils import download_subtitles_to_file, generate_non_conflicting_path, generate_release_name, \\\r\n    single_to_list\r\n\r\n\r\ndef main():\r\n    scraper_factory = None\r\n\r\n    try:\r\n        # Assure at least one argument was passed\r\n        if len(sys.argv) < 2:\r\n            print_usage()\r\n            exit(1)\r\n\r\n        config = generate_config()\r\n        update_settings(config)\r\n\r\n        if config.general.get(\"check-for-updates\", True):\r\n            check_for_updates()\r\n\r\n        scraper_factory = ScraperFactory()\r\n\r\n        multiple_urls = len(sys.argv) > 2\r\n\r\n        for idx, url in enumerate(sys.argv[1:]):\r\n            if idx > 0:\r\n                print(\"\\n--------------------------------------------------\\n\")  # Print between different movies\r\n\r\n            print(f\"Scraping {url}\")\r\n\r\n            try:\r\n                scraper = scraper_factory.get_scraper_instance_by_url(url=url,\r\n                                                                      scrapers_config_data=config.data.get(\"scrapers\"),\r\n                                                                      raise_error=True)\r\n\r\n                atexit.register(scraper.close)\r\n                scraper.config.check()\r\n\r\n                media_data = scraper.get_data(url=url)\r\n\r\n                if not media_data:\r\n                    print(f\"Error: No supported media data was found for {url}.\")\r\n                    continue\r\n\r\n                download_media_subtitles_args = {\r\n                    \"download_path\": Path(config.downloads[\"folder\"]),\r\n                    \"language_filter\": config.downloads.get(\"languages\"),\r\n                    \"convert_to_srt\": config.subtitles.get(\"convert-to-srt\", False),\r\n                    \"overwrite_existing\": config.downloads.get(\"overwrite-existing\", False),\r\n                    \"zip_files\": config.downloads.get(\"zip\", False),\r\n                }\r\n\r\n                media_items: list[MediaData] = single_to_list(media_data)\r\n                multiple_media_items = len(media_items) > 1\r\n                if multiple_media_items:\r\n                    print(f\"{len(media_items)} media items were found.\")\r\n\r\n                for media_item in media_items:\r\n                    try:\r\n                        if multiple_media_items:\r\n                            print(f\"{media_item.id if media_item.id else media_item.name}:\")\r\n\r\n                        if not media_item.playlist:\r\n                            print(\"Error: No valid playlist were found.\")\r\n                            continue\r\n\r\n                        results = download_subtitles(media_data=media_item,\r\n                                                     **download_media_subtitles_args)\r\n\r\n                        success_count = len(results.successful_subtitles)\r\n\r\n                        if not success_count:\r\n                            print(\"No matching subtitles were found.\")\r\n                            continue\r\n\r\n                        else:\r\n                            failed_count = len(results.failed_subtitles)\r\n                            print(f\"\\n{success_count}/{success_count + failed_count} matching subtitles \"\r\n                                  f\"have been successfully downloaded.\", sep='')\r\n\r\n                    except Exception as e:\r\n                        if multiple_media_items:\r\n                            print(f\"Error: Encountered an error while scraping playlist \"\r\n                                  f\"{media_item.id if media_item.id else media_item.name}: {e}\")\r\n                            continue\r\n\r\n                        else:\r\n                            raise e\r\n\r\n            except Exception as e:\r\n                if multiple_urls:\r\n                    print(f\"Error: Encountered an error while scraping {url}: {e}\")\r\n                    continue\r\n\r\n                else:\r\n                    raise e\r\n\r\n    except Exception as e:\r\n        print(f\"Error: {e}\")\r\n        exit(1)\r\n\r\n    finally:\r\n        # Note: This will only close scrapers that were initialized using the ScraperFactory.\r\n        if scraper_factory:\r\n            for scraper in scraper_factory.get_initialized_scrapers():\r\n                scraper.close()\r\n\r\n\r\ndef check_for_updates() -> None:\r\n    \"\"\"Check and print if a newer version of the package is available.\"\"\"\r\n    api_url = f\"https://pypi.org/pypi/{PACKAGE_NAME}/json\"  # Used for checking updates\r\n\r\n    try:\r\n        current_version = sys.modules[PACKAGE_NAME].__version__\r\n\r\n        response = requests.get(\r\n            url=api_url,\r\n            headers={\"Accept\": \"application/json\"},\r\n            timeout=10,\r\n        )\r\n        response.raise_for_status()\r\n        response_data = response.json()\r\n\r\n        if latest_version := response_data[\"info\"][\"version\"]:\r\n            if latest_version != current_version:\r\n                print(f\"Note: You are currently using version {current_version} of {PACKAGE_NAME}, \"\r\n                      f\"however version {latest_version} is available.\",\r\n                      f\"\\nConsider upgrading by running \\\"python3 -m pip install --upgrade {PACKAGE_NAME}\\\"\\n\")\r\n\r\n    except Exception:\r\n        return\r\n\r\n\r\ndef download_subtitles(media_data: MovieData | EpisodeData, download_path: Path,\r\n                       language_filter: list[str] | None = None, convert_to_srt: bool = False,\r\n                       overwrite_existing: bool = True, zip_files: bool = False) -> SubtitlesDownloadResults:\r\n    \"\"\"\r\n    Download subtitles for the given media data.\r\n\r\n    Args:\r\n        media_data (MovieData | EpisodeData): A MovieData or an EpisodeData object of the media.\r\n        download_path (Path): Path to a folder where the subtitles will be downloaded to.\r\n        language_filter (list[str] | None): List of specific languages to download subtitles for.\r\n            None for all languages (no filter). Defaults to None.\r\n        convert_to_srt (bool, optional): Whether to convert the subtitles to SRT format. Defaults to False.\r\n        overwrite_existing (bool, optional): Whether to overwrite existing subtitles. Defaults to True.\r\n        zip_files (bool, optional): Whether to unite the subtitles into a single zip file\r\n            (only if there are multiple subtitles).\r\n\r\n    Returns:\r\n        Path: Path to the parent folder of the downloaded subtitles files / zip file.\r\n    \"\"\"\r\n    temp_download_path = generate_media_path(base_path=TEMP_FOLDER_PATH, media_data=media_data)\r\n    atexit.register(shutil.rmtree, TEMP_FOLDER_PATH, ignore_errors=False, onerror=None)\r\n\r\n    if media_data.playlist is None:\r\n        raise ValueError(\"No playlist data was found for the given media data.\")\r\n\r\n    successful_downloads: list[SubtitlesData] = []\r\n    failed_downloads: list[SubtitlesData] = []\r\n    temp_downloads: list[Path] = []\r\n\r\n    m3u8_playlist = m3u8.load(media_data.playlist)\r\n\r\n    for subtitles_data in media_data.scraper.get_subtitles(main_playlist=m3u8_playlist,\r\n                                                           language_filter=language_filter,\r\n                                                           subrip_conversion=convert_to_srt):\r\n        try:\r\n            temp_downloads.append(download_subtitles_to_file(\r\n                media_data=media_data,\r\n                subtitles_data=subtitles_data,\r\n                output_path=temp_download_path,\r\n                overwrite=overwrite_existing,\r\n            ))\r\n\r\n            successful_downloads.append(subtitles_data)\r\n            language_data = f\"{subtitles_data.language_name} ({subtitles_data.language_code})\"\r\n\r\n            if subtitles_data.special_type:\r\n                language_data += f\" [{subtitles_data.special_type.value}]\"\r\n\r\n            print(f\"{language_data} subtitles were successfully downloaded.\")\r\n\r\n        except Exception:\r\n            failed_downloads.append(subtitles_data)\r\n            continue\r\n\r\n    if not zip_files or len(temp_downloads) == 1:\r\n        for file_path in temp_downloads:\r\n            if overwrite_existing:\r\n                file_path.replace(download_path / file_path.name)\r\n\r\n            else:\r\n                file_path.replace(generate_non_conflicting_path(download_path / file_path.name))\r\n\r\n    else:\r\n        archive_path = Path(shutil.make_archive(\r\n            base_name=str(temp_download_path.parent / temp_download_path.name),\r\n            format=ARCHIVE_FORMAT,\r\n            root_dir=temp_download_path,\r\n        ))\r\n\r\n        file_name = generate_media_folder_name(media_data=media_data) + f\".{ARCHIVE_FORMAT}\"\r\n\r\n        if overwrite_existing:\r\n            destination_path = download_path / file_name\r\n\r\n        else:\r\n            destination_path = generate_non_conflicting_path(download_path / file_name)\r\n\r\n        archive_path.replace(destination_path)\r\n\r\n    shutil.rmtree(temp_download_path)\r\n    atexit.unregister(shutil.rmtree)\r\n\r\n    return SubtitlesDownloadResults(\r\n        media_data=media_data,\r\n        successful_subtitles=successful_downloads,\r\n        failed_subtitles=failed_downloads,\r\n        is_zip=zip_files,\r\n    )\r\n\r\n\r\ndef generate_config() -> Config:\r\n    \"\"\"\r\n    Generate a config object using config files, and validate it.\r\n\r\n    Returns:\r\n        Config: A config object.\r\n\r\n    Raises:\r\n        ConfigException: If there is a general config error.\r\n        MissingConfigValue: If a required config value is missing.\r\n        InvalidConfigValue: If a config value is invalid.\r\n    \"\"\"\r\n    config_files = [DEFAULT_CONFIG_PATH]\r\n\r\n    if not DEFAULT_CONFIG_PATH.is_file():\r\n        raise ConfigException(\"Default config file could not be found.\")\r\n\r\n    # If data folder doesn't exist, create it\r\n    if not DATA_FOLDER_PATH.is_dir():\r\n        DATA_FOLDER_PATH.mkdir(parents=True, exist_ok=True)\r\n\r\n    else:\r\n        # If a user config file exists, add it to config_files\r\n        if USER_CONFIG_FILE.is_file():\r\n            config_files.append(USER_CONFIG_FILE)\r\n\r\n    config = Config(config_settings=DEFAULT_CONFIG_SETTINGS)\r\n\r\n    for file_path in config_files:\r\n        with open(file_path, 'r') as data:\r\n            config.loads(config_data=data.read(), check_config=True)\r\n\r\n    config.check()\r\n    return config\r\n\r\n\r\ndef generate_media_folder_name(media_data: MediaData) -> str:\r\n    \"\"\"\r\n    Generate a folder name for media data.\r\n\r\n    Args:\r\n        media_data (MediaData): A media data object.\r\n\r\n    Returns:\r\n        str: A folder name for the media data.\r\n    \"\"\"\r\n    return generate_release_name(\r\n        title=media_data.name,\r\n        release_year=media_data.release_year,\r\n        media_source=media_data.source.abbreviation,\r\n    )\r\n\r\n\r\ndef generate_media_path(base_path: Path, media_data: MediaData) -> Path:\r\n    \"\"\"\r\n    Generate a temporary folder for downloading media data.\r\n\r\n    Args:\r\n        base_path (Path): A base path to generate the folder in.\r\n        media_data (MediaData): A media data object.\r\n\r\n    Returns:\r\n        Path: A path to the temporary folder.\r\n    \"\"\"\r\n    temp_folder_name = generate_media_folder_name(media_data=media_data)\r\n    path = generate_non_conflicting_path(base_path / temp_folder_name, has_extension=False)\r\n    path.mkdir(parents=True, exist_ok=True)\r\n\r\n    return path\r\n\r\n\r\ndef update_settings(config: Config) -> None:\r\n    \"\"\"\r\n    Update settings according to config.\r\n\r\n    Args:\r\n        config (Config): An instance of a config to set settings according to.\r\n    \"\"\"\r\n    Scraper.subtitles_fix_rtl = config.subtitles[\"fix-rtl\"]\r\n    Scraper.subtitles_fix_rtl_languages = config.subtitles.get(\"rtl-languages\")\r\n    Scraper.subtitles_remove_duplicates = config.subtitles[\"remove-duplicates\"]\r\n    Scraper.default_user_agent = config.scrapers.get(\"user-agent\", default_user_agent())\r\n\r\n\r\ndef print_usage() -> None:\r\n    \"\"\"Print usage information.\"\"\"\r\n    print(f\"Usage: {PACKAGE_NAME} <iTunes movie URL> [iTunes movie URL...]\")\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/__main__.py b/isubrip/__main__.py
--- a/isubrip/__main__.py	(revision 92bad88b64f1dabfedd5ae9f1a8a40b483a2bea8)
+++ b/isubrip/__main__.py	(date 1683837454708)
@@ -71,9 +71,11 @@
                     print(f"{len(media_items)} media items were found.")
 
                 for media_item in media_items:
+                    media_id = media_item.id or media_item.alt_id or media_item.name
+
                     try:
                         if multiple_media_items:
-                            print(f"{media_item.id if media_item.id else media_item.name}:")
+                            print(f"{media_id}:")
 
                         if not media_item.playlist:
                             print("Error: No valid playlist were found.")
@@ -94,15 +96,17 @@
                                   f"have been successfully downloaded.", sep='')
 
                     except Exception as e:
+                        raise e
                         if multiple_media_items:
-                            print(f"Error: Encountered an error while scraping playlist "
-                                  f"{media_item.id if media_item.id else media_item.name}: {e}")
+                            print(f"Error: Encountered an error while scraping playlist for "
+                                  f"{media_id}: {e}")
                             continue
 
                         else:
                             raise e
 
             except Exception as e:
+                raise e
                 if multiple_urls:
                     print(f"Error: Encountered an error while scraping {url}: {e}")
                     continue
@@ -111,6 +115,7 @@
                     raise e
 
     except Exception as e:
+        raise e
         print(f"Error: {e}")
         exit(1)
 
@@ -284,7 +289,7 @@
     """
     return generate_release_name(
         title=media_data.name,
-        release_year=media_data.release_year,
+        release_year=media_data.release_date.year,
         media_source=media_data.source.abbreviation,
     )
 
Index: requirements.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>aiohttp==3.8.1\r\nbeautifulsoup4==4.11.1\r\nlxml==4.9.1\r\nm3u8==3.2.0\r\nmergedeep==1.3.4\r\nrequests==2.28.1\r\ntomli==2.0.1\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/requirements.txt b/requirements.txt
--- a/requirements.txt	(revision 92bad88b64f1dabfedd5ae9f1a8a40b483a2bea8)
+++ b/requirements.txt	(date 1682806213260)
@@ -1,6 +1,4 @@
 aiohttp==3.8.1
-beautifulsoup4==4.11.1
-lxml==4.9.1
 m3u8==3.2.0
 mergedeep==1.3.4
 requests==2.28.1
Index: isubrip/scrapers/itunes_scraper.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nimport json\r\nfrom datetime import datetime\r\n\r\nimport m3u8\r\nfrom bs4 import BeautifulSoup, Tag, NavigableString\r\nfrom requests import HTTPError\r\n\r\nfrom isubrip.data_structures import MediaSourceData, MovieData\r\nfrom isubrip.scrapers.scraper import M3U8Scraper, MovieScraper, ScraperException\r\nfrom isubrip.subtitle_formats.webvtt import WebVTTSubtitles\r\n\r\n\r\nclass iTunesScraper(M3U8Scraper, MovieScraper):\r\n    \"\"\"An iTunes movie data scraper.\"\"\"\r\n    url_regex = r\"(https?://itunes\\.apple\\.com/[a-z]{2}/movie/(?:[\\w\\-%]+/)?(id\\d{9,10}))(?:\\?.*)?\"\r\n    service_data = MediaSourceData(id=\"itunes\", name=\"iTunes\", abbreviation=\"iT\")\r\n    subtitles_class = WebVTTSubtitles\r\n    is_movie_scraper = True\r\n\r\n    def get_data(self, url: str) -> MovieData:\r\n        \"\"\"\r\n        Scrape iTunes to find info about a movie, and it's M3U8 main_playlist.\r\n\r\n        Args:\r\n            url (str): An iTunes store movie URL.\r\n\r\n        Raises:\r\n            InvalidURL: `itunes_url` is not a valid iTunes store movie URL.\r\n            PageLoadError: HTML page did not load properly.\r\n            HTTPError: HTTP request failed.\r\n\r\n        Returns:\r\n            MovieData: A MovieData (NamedTuple) object with movie's name, and an M3U8 object of the main_playlist\r\n            if the main_playlist is found. None otherwise.\r\n        \"\"\"\r\n        regex_match = self.match_url(url, raise_error=True)\r\n\r\n        url = regex_match.group(1)\r\n        response = self._session.get(url)\r\n        response.raise_for_status()\r\n\r\n        # Response is JSON formatted\r\n        if \"application/json\" in response.headers['content-type']:\r\n            try:\r\n                json_data = json.loads(response.content)\r\n\r\n            except json.JSONDecodeError:\r\n                raise ScraperException(\"Received an invalid JSON response.\")\r\n\r\n            return self._find_playlist_data_json(json_data)\r\n\r\n        # Response is HTML formatted\r\n        elif \"text/html\" in response.headers['content-type'] and response.status_code != 404:\r\n            html_data = BeautifulSoup(response.content, \"lxml\")\r\n            return self._find_playlist_data_html(html_data)\r\n\r\n        raise ScraperException(\"Received an unexpected response.\")\r\n\r\n    def _find_playlist_data_json(self, json_data: dict) -> MovieData:\r\n        \"\"\"\r\n        Scrape an iTunes JSON response to get movie info.\r\n\r\n        Args:\r\n            json_data (dict): A dictionary with iTunes data loaded from a JSON response.\r\n\r\n        Returns:\r\n            MovieData: A MovieData (NamedTuple) object with movie's name, and an M3U8 object of the main_playlist\r\n            if the main_playlist is found. None otherwise.\r\n        \"\"\"\r\n        itunes_id = json_data[\"pageData\"][\"id\"]\r\n        movie_data = json_data[\"storePlatformData\"][\"product-dv\"][\"results\"][itunes_id]\r\n\r\n        movie_title = movie_data[\"nameRaw\"]\r\n        movie_release_year = datetime.strptime(movie_data[\"releaseDate\"], '%Y-%m-%d').year\r\n\r\n        # Loop safely to find a matching main_playlist\r\n        for offer in movie_data[\"offers\"]:\r\n            if isinstance(offer.get(\"type\"), str) and offer[\"type\"] in [\"buy\", \"rent\"]:\r\n                if isinstance(offer.get(\"assets\"), list) and len(offer[\"assets\"]) > 0:\r\n                    for asset in offer[\"assets\"]:\r\n                        playlist_url: str = asset[\"hlsUrl\"]\r\n\r\n                        # Assure main_playlist is valid\r\n                        try:\r\n                            m3u8.load(playlist_url)\r\n\r\n                        # If m3u8 main_playlist is invalid, skip it\r\n                        except (ValueError, HTTPError):\r\n                            continue\r\n\r\n                        return MovieData(\r\n                            id=itunes_id,\r\n                            name=movie_title,\r\n                            release_year=movie_release_year,\r\n                            playlist=playlist_url,\r\n                            source=self.service_data,\r\n                            scraper=self,\r\n                        )\r\n\r\n        return MovieData(\r\n            id=itunes_id,\r\n            name=movie_title,\r\n            release_year=movie_release_year,\r\n            playlist=None,\r\n            source=self.service_data,\r\n            scraper=self,\r\n        )\r\n\r\n    def _find_playlist_data_html(self, html_data: BeautifulSoup) -> MovieData:\r\n        \"\"\"\r\n        Scrape an iTunes HTML page to get movie info.\r\n\r\n        Note:\r\n            This function uses web-scraping and because of that,\r\n            it's a lot less reliable than `_find_playlist_data_itunes_json_`.\r\n\r\n        Args:\r\n            html_data (BeautifulSoup): A BeautifulSoup object of the page.\r\n\r\n        Raises:\r\n            PageLoadError: HTML page did not load properly.\r\n\r\n        Returns:\r\n            MovieData: A MovieData (NamedTuple) object with movie's name, and an M3U8 object of the main_playlist\r\n            if the main_playlist is found. None otherwise.\r\n        \"\"\"\r\n        itunes_id_tag: Tag | NavigableString | None = html_data.find(\"meta\", attrs={\"name\": \"apple:content_id\"})\r\n        if not isinstance(itunes_id_tag, Tag):\r\n            raise ScraperException(\"HTML page did not load properly.\")\r\n\r\n        itunes_id: str = itunes_id_tag.attrs[\"content\"]\r\n\r\n        # Scrape a dictionary on the webpage that has playlists data\r\n        shoebox_data_tag: Tag | NavigableString | None = \\\r\n            html_data.find(\"script\", attrs={\"id\": \"shoebox-ember-data-store\", \"type\": \"fastboot/shoebox\"})\r\n\r\n        # fastboot/shoebox data could not be found\r\n        if not isinstance(shoebox_data_tag, Tag):\r\n            raise ScraperException(\"fastboot/shoebox data could not be found.\")\r\n\r\n        # Convert to dictionary structure\r\n        shoebox_data: dict = json.loads(str(shoebox_data_tag.contents[0]).strip())\r\n\r\n        # Loop safely to find a matching main_playlist\r\n        if isinstance(shoebox_data[itunes_id].get(\"included\"), list):\r\n            movie_data: dict = shoebox_data[itunes_id]\r\n            movie_title: str = movie_data[\"data\"][\"attributes\"][\"name\"]\r\n            movie_release_year = datetime.strptime(movie_data[\"data\"][\"attributes\"][\"releaseDate\"], '%Y-%m-%d').year\r\n\r\n            for item in movie_data[\"included\"]:\r\n                if isinstance(item.get(\"type\"), str) and item[\"type\"] == \"offer\":\r\n                    if isinstance(item.get(\"attributes\"), dict) and \\\r\n                        isinstance(item[\"attributes\"].get(\"assets\"), list) and \\\r\n                            len(item[\"attributes\"][\"assets\"]) > 0:\r\n\r\n                        for asset in item[\"attributes\"][\"assets\"]:\r\n                            if isinstance(asset, dict) and isinstance(asset.get(\"hlsUrl\"), str):\r\n                                playlist_url: str = item[\"attributes\"][\"assets\"][0][\"hlsUrl\"]\r\n\r\n                                # Try loading the main_playlist to assure it's working\r\n                                try:\r\n                                    m3u8.load(playlist_url)\r\n\r\n                                # If m3u8 main_playlist is invalid, skip it\r\n                                except (ValueError, HTTPError):\r\n                                    continue\r\n\r\n                                return MovieData(\r\n                                    id=itunes_id,\r\n                                    name=movie_title,\r\n                                    release_year=movie_release_year,\r\n                                    playlist=playlist_url,\r\n                                    source=self.service_data,\r\n                                    scraper=self,\r\n                                )\r\n        else:\r\n            raise ScraperException(\"Invalid shoebox data.\")\r\n\r\n        return MovieData(\r\n            id=itunes_id,\r\n            name=movie_title,\r\n            release_year=movie_release_year,\r\n            playlist=None,\r\n            source=self.service_data,\r\n            scraper=self,\r\n        )\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/scrapers/itunes_scraper.py b/isubrip/scrapers/itunes_scraper.py
--- a/isubrip/scrapers/itunes_scraper.py	(revision 92bad88b64f1dabfedd5ae9f1a8a40b483a2bea8)
+++ b/isubrip/scrapers/itunes_scraper.py	(date 1683838262992)
@@ -1,10 +1,9 @@
 from __future__ import annotations
 
 import json
-from datetime import datetime
+import datetime as dt
 
 import m3u8
-from bs4 import BeautifulSoup, Tag, NavigableString
 from requests import HTTPError
 
 from isubrip.data_structures import MediaSourceData, MovieData
@@ -51,11 +50,6 @@
 
             return self._find_playlist_data_json(json_data)
 
-        # Response is HTML formatted
-        elif "text/html" in response.headers['content-type'] and response.status_code != 404:
-            html_data = BeautifulSoup(response.content, "lxml")
-            return self._find_playlist_data_html(html_data)
-
         raise ScraperException("Received an unexpected response.")
 
     def _find_playlist_data_json(self, json_data: dict) -> MovieData:
@@ -73,7 +67,7 @@
         movie_data = json_data["storePlatformData"]["product-dv"]["results"][itunes_id]
 
         movie_title = movie_data["nameRaw"]
-        movie_release_year = datetime.strptime(movie_data["releaseDate"], '%Y-%m-%d').year
+        movie_release_date = dt.datetime.strptime(movie_data["releaseDate"], "%Y-%m-%d")
 
         # Loop safely to find a matching main_playlist
         for offer in movie_data["offers"]:
@@ -93,7 +87,7 @@
                         return MovieData(
                             id=itunes_id,
                             name=movie_title,
-                            release_year=movie_release_year,
+                            release_date=movie_release_date,
                             playlist=playlist_url,
                             source=self.service_data,
                             scraper=self,
@@ -102,86 +96,7 @@
         return MovieData(
             id=itunes_id,
             name=movie_title,
-            release_year=movie_release_year,
-            playlist=None,
-            source=self.service_data,
-            scraper=self,
-        )
-
-    def _find_playlist_data_html(self, html_data: BeautifulSoup) -> MovieData:
-        """
-        Scrape an iTunes HTML page to get movie info.
-
-        Note:
-            This function uses web-scraping and because of that,
-            it's a lot less reliable than `_find_playlist_data_itunes_json_`.
-
-        Args:
-            html_data (BeautifulSoup): A BeautifulSoup object of the page.
-
-        Raises:
-            PageLoadError: HTML page did not load properly.
-
-        Returns:
-            MovieData: A MovieData (NamedTuple) object with movie's name, and an M3U8 object of the main_playlist
-            if the main_playlist is found. None otherwise.
-        """
-        itunes_id_tag: Tag | NavigableString | None = html_data.find("meta", attrs={"name": "apple:content_id"})
-        if not isinstance(itunes_id_tag, Tag):
-            raise ScraperException("HTML page did not load properly.")
-
-        itunes_id: str = itunes_id_tag.attrs["content"]
-
-        # Scrape a dictionary on the webpage that has playlists data
-        shoebox_data_tag: Tag | NavigableString | None = \
-            html_data.find("script", attrs={"id": "shoebox-ember-data-store", "type": "fastboot/shoebox"})
-
-        # fastboot/shoebox data could not be found
-        if not isinstance(shoebox_data_tag, Tag):
-            raise ScraperException("fastboot/shoebox data could not be found.")
-
-        # Convert to dictionary structure
-        shoebox_data: dict = json.loads(str(shoebox_data_tag.contents[0]).strip())
-
-        # Loop safely to find a matching main_playlist
-        if isinstance(shoebox_data[itunes_id].get("included"), list):
-            movie_data: dict = shoebox_data[itunes_id]
-            movie_title: str = movie_data["data"]["attributes"]["name"]
-            movie_release_year = datetime.strptime(movie_data["data"]["attributes"]["releaseDate"], '%Y-%m-%d').year
-
-            for item in movie_data["included"]:
-                if isinstance(item.get("type"), str) and item["type"] == "offer":
-                    if isinstance(item.get("attributes"), dict) and \
-                        isinstance(item["attributes"].get("assets"), list) and \
-                            len(item["attributes"]["assets"]) > 0:
-
-                        for asset in item["attributes"]["assets"]:
-                            if isinstance(asset, dict) and isinstance(asset.get("hlsUrl"), str):
-                                playlist_url: str = item["attributes"]["assets"][0]["hlsUrl"]
-
-                                # Try loading the main_playlist to assure it's working
-                                try:
-                                    m3u8.load(playlist_url)
-
-                                # If m3u8 main_playlist is invalid, skip it
-                                except (ValueError, HTTPError):
-                                    continue
-
-                                return MovieData(
-                                    id=itunes_id,
-                                    name=movie_title,
-                                    release_year=movie_release_year,
-                                    playlist=playlist_url,
-                                    source=self.service_data,
-                                    scraper=self,
-                                )
-        else:
-            raise ScraperException("Invalid shoebox data.")
-
-        return MovieData(
-            id=itunes_id,
-            name=movie_title,
-            release_year=movie_release_year,
+            release_date=movie_release_date,
             playlist=None,
             source=self.service_data,
             scraper=self,
Index: isubrip/config.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nimport os.path\r\nimport typing\r\nfrom copy import deepcopy\r\nfrom enum import Enum\r\nfrom typing import Any, NamedTuple, Type\r\n\r\nimport tomli\r\nfrom mergedeep import merge\r\n\r\nfrom isubrip.utils import check_type, single_to_list\r\n\r\n\r\nclass DuplicateBehavior(Enum):\r\n    \"\"\"\r\n    An Enum representing optional behaviors for when a duplicate config key is found.\r\n\r\n    Attributes:\r\n        OVERWRITE: Overwrite the existing value with the new value.\r\n        IGNORE: Ignore the new value and keep the existing value.\r\n        RAISE_ERROR: Raise an error.\r\n    \"\"\"\r\n    OVERWRITE = 1\r\n    IGNORE = 2\r\n    RAISE_ERROR = 3\r\n\r\n\r\nclass SpecialConfigType(Enum):\r\n    \"\"\"\r\n    An Enum representing special config value properties to validate.\r\n\r\n    Attributes:\r\n        EXISTING_FILE_PATH: The value must be of a path to an existing file.\r\n        EXISTING_FOLDER_PATH: The value must be of a path to an existing folder.\r\n    \"\"\"\r\n    EXISTING_FILE_PATH = 1\r\n    EXISTING_FOLDER_PATH = 2\r\n\r\n\r\nclass ConfigSetting(NamedTuple):\r\n    \"\"\"\r\n    A NamedTuple representing a config setting.\r\n\r\n    Attributes:\r\n        key (str): Dictionary key used to access the setting.\r\n        type (type): Variable type of the value of the setting. Used for validation.\r\n        category (str | list[str], optional): A category that the setting is under.\r\n            Categories are used to group related settings' keys together in a sub-dictionary.\r\n            A list can be used to nest categories (first item is the top-level category). Defaults to None.\r\n        required (bool, optional): Whether the setting is required. Defaults to False.\r\n        enum_type (type[Enum], optional): An Enum that the settings values will be converted to. Defaults to None.\r\n        special_type (SpecialConfigType | list[SpecialConfigType], optional): A special property of the setting's value\r\n            to validate, represented by a SpecialConfigType value. Defaults to None.\r\n    \"\"\"\r\n    key: str\r\n    # Using typing._UnionGenericAlias as a replacement for types.UnionType, which is available only on  Python 3.10+\r\n    type: type | typing._UnionGenericAlias  # type: ignore[name-defined]\r\n    category: str | list[str] | None = None\r\n    required: bool = False\r\n    enum_type: Type[Enum] | None = None\r\n    special_type: SpecialConfigType | list[SpecialConfigType] | None = None\r\n\r\n    def __eq__(self, other: Any) -> bool:\r\n        if isinstance(other, ConfigSetting):\r\n            return self.key == other.key and self.category == other.category\r\n        return False\r\n\r\n\r\nclass Config:\r\n    \"\"\"A class for managing iSubRip config files.\"\"\"\r\n    def __init__(self, config_settings: list[ConfigSetting] | None = None, config_data: dict | None = None):\r\n        \"\"\"\r\n        Create a new Config instance.\r\n\r\n        Args:\r\n            config_settings (list[ConfigSetting], optional): A list of ConfigSettings objects\r\n                that will be used for validations. Defaults to None.\r\n            config_data (dict, optional): A dict of config data to add to the config. Defaults to None.\r\n        \"\"\"\r\n        self._config_settings: list = []\r\n        self._config_data: dict = {}\r\n\r\n        if config_settings:\r\n            self.add_settings(config_settings, check_config=False)\r\n\r\n        if config_data:\r\n            self._config_data = deepcopy(config_data)\r\n\r\n    def __getattr__(self, key: str) -> Any:\r\n        \"\"\"\r\n        Allow access to config settings using attributes.\r\n\r\n        Args:\r\n            key (str): Config key to get.\r\n\r\n        Returns:\r\n            Any: The corresponding value for the key in the config.\r\n        \"\"\"\r\n        if self._config_data and key in self._config_data:\r\n            return self._config_data[key]\r\n\r\n        else:\r\n            raise AttributeError(f\"Attribute \\'{key}\\' does not exist.\")\r\n\r\n    def __getitem__(self, key: str) -> Any:\r\n        \"\"\"\r\n        Allow access to config settings using dict-like syntax.\r\n\r\n        Args:\r\n            key (str): Config key to get.\r\n\r\n        Returns:\r\n            Any: The corresponding value for the key in the config.\r\n        \"\"\"\r\n        return self._config_data[key]\r\n\r\n    def get(self, key: str, default: Any = None) -> Any:\r\n        \"\"\"\r\n        Get a config value.\r\n\r\n        Args:\r\n            key (str): Config key to get.\r\n            default (Any, optional): Default value to return if the key does not exist. Defaults to None.\r\n\r\n        Returns:\r\n            Any: The corresponding value for the key in the config or the default value if the key does not exist.\r\n        \"\"\"\r\n        return self._config_data.get(key, default)\r\n\r\n    @property\r\n    def data(self):\r\n        return self._config_data\r\n\r\n    def add_settings(self, config_settings: list[ConfigSetting],\r\n                     duplicate_behavior: DuplicateBehavior = DuplicateBehavior.OVERWRITE,\r\n                     check_config: bool = True) -> None:\r\n        \"\"\"\r\n        Add new config settings to the config.\r\n\r\n        Args:\r\n            config_settings (list[ConfigSetting]): A list of ConfigSettings objects to add to the config.\r\n            duplicate_behavior (DuplicateBehavior, optional): Behaviour to apply if a duplicate is found.\r\n                Defaults to DuplicateBehavior.OVERWRITE.\r\n            check_config (bool, optional): Whether to check the config after loading it. Defaults to True.\r\n        \"\"\"\r\n        config_settings_copy = deepcopy(config_settings)\r\n\r\n        for config_setting in config_settings_copy:\r\n            if config_setting in self._config_settings:\r\n                if duplicate_behavior == DuplicateBehavior.OVERWRITE:\r\n                    self._config_settings.remove(config_setting)\r\n                    self._config_settings.append(config_setting)\r\n\r\n                elif duplicate_behavior == DuplicateBehavior.RAISE_ERROR:\r\n                    raise ValueError(f\"Duplicate config setting: {config_setting}\")\r\n\r\n            else:\r\n                self._config_settings.append(config_setting)\r\n\r\n        if check_config:\r\n            self.check()\r\n\r\n    def loads(self, config_data: str, check_config: bool = True) -> None:\r\n        \"\"\"\r\n        Parse a tomli config from a string.\r\n\r\n        Args:\r\n            config_data (str): Config file data as a string.\r\n            check_config (bool, optional): Whether to check the config after loading it. Defaults to True.\r\n\r\n        Raises:\r\n            FileNotFoundError: Config file could not be found in the specified path.\r\n            TOMLDecodeError: Config file is not a valid TOML file.\r\n            ConfigValueMissing: A required config value is missing.\r\n            InvalidConfigValue: An invalid value was used in the config file.\r\n        \"\"\"\r\n        # Load settings from default config file\r\n        loaded_data: dict = tomli.loads(config_data)\r\n\r\n        if self._config_data:\r\n            temp_config = dict(merge(self._config_data, loaded_data))\r\n\r\n        else:\r\n            temp_config = loaded_data\r\n\r\n        self._config_data = temp_config\r\n\r\n        if check_config and self._config_settings:\r\n            self.check()\r\n\r\n    @staticmethod\r\n    def _map_config_settings(settings: list[ConfigSetting], data: dict) -> dict[ConfigSetting, Any]:\r\n        \"\"\"\r\n        Map config settings to their values.\r\n        This function wil also unflatten data.\r\n\r\n        Args:\r\n            settings (list[ConfigSetting]): A list or tuple of ConfigSettings objects.\r\n            data (dict): A dictionary containing the config data.\r\n\r\n        Returns:\r\n            dict[ConfigSetting, Any]: A dictionary mapping config settings to their values.\r\n        \"\"\"\r\n        mapped_settings: dict = {}\r\n\r\n        for setting in settings:\r\n            if setting.category:\r\n                setting_categories = single_to_list(setting.category)\r\n                config_dict_iter: dict = data\r\n\r\n                for setting_category in setting_categories:\r\n                    if setting_category not in config_dict_iter:\r\n                        mapped_settings[setting] = None\r\n                        break\r\n\r\n                    config_dict_iter = config_dict_iter[setting_category]\r\n\r\n            else:\r\n                config_dict_iter = data\r\n\r\n            if setting.key not in config_dict_iter:\r\n                mapped_settings[setting] = None\r\n\r\n            else:\r\n                value = config_dict_iter[setting.key]\r\n                enum_type = setting.enum_type\r\n\r\n                if enum_type is not None:\r\n                    try:\r\n                        value = enum_type(value)\r\n\r\n                    except ValueError:\r\n                        setting_path = '.'.join(single_to_list(setting.category))\r\n                        enum_options = ', '.join([f\"\\'{option.name}\\'\" for option in enum_type])\r\n\r\n                        raise InvalidConfigValue(\r\n                            f\"Invalid config value for {setting_path}.{setting.key}: \\'{value}\\'.\\n\"\r\n                            f\"Expected one of: {enum_options}.\")\r\n\r\n                if type(value) in (list, tuple) and len(value) == 0:\r\n                    value = None\r\n\r\n                special_types = single_to_list(setting.special_type)\r\n\r\n                if SpecialConfigType.EXISTING_FILE_PATH in special_types:\r\n                    value = value.rstrip(r\"\\/\")\r\n\r\n                mapped_settings[setting] = value\r\n\r\n        return mapped_settings\r\n\r\n    def check(self) -> None:\r\n        \"\"\"\r\n            Check whether the config is valid by comparing config's data to the config settings.\r\n            Raises an error if an invalid value is found.\r\n\r\n        Raises:\r\n            MissingConfigValue: A required config value is missing.\r\n            InvalidConfigValue: An invalid value was used in the config file.\r\n        \"\"\"\r\n        if self._config_data is None or not self._config_settings:\r\n            return\r\n\r\n        mapped_config = Config._map_config_settings(self._config_settings, self._config_data)\r\n\r\n        for setting, value in mapped_config.items():\r\n            if isinstance(setting.category, (list, tuple)):\r\n                setting_path = '.'.join(setting.category) + f\".{setting.key}\"\r\n\r\n            elif isinstance(setting.category, str):\r\n                setting_path = setting.category + f\".{setting.key}\"\r\n\r\n            else:\r\n                setting_path = setting.key\r\n\r\n            if value is None:\r\n                if setting.required:\r\n                    raise MissingConfigValue(f\"Missing required config value: '{setting_path}'\")\r\n\r\n                else:\r\n                    continue\r\n\r\n            if setting.enum_type is None and not check_type(value, setting.type):\r\n                raise InvalidConfigValue(\r\n                    f\"Invalid config value type for '{setting_path}': '{value}'.\\n\"\r\n                    f\"Expected {setting.type}, received: {type(value)}.\")\r\n\r\n            special_types = single_to_list(setting.special_type)\r\n\r\n            if SpecialConfigType.EXISTING_FILE_PATH in special_types:\r\n                if not os.path.isfile(value):\r\n                    raise InvalidConfigValue(f\"Invalid config value type for '{setting_path}'.\\n\"\r\n                                             f\"File '{value}' not found.\")\r\n\r\n            elif SpecialConfigType.EXISTING_FOLDER_PATH in special_types:\r\n                if not os.path.isdir(value):\r\n                    raise InvalidConfigValue(f\"Invalid config value type for '{setting_path}'.\\n\"\r\n                                             f\"Folder '{value}' not found.\")\r\n\r\n\r\nclass ConfigException(Exception):\r\n    pass\r\n\r\n\r\nclass MissingConfigValue(ConfigException):\r\n    \"\"\"A required config value is missing.\"\"\"\r\n    pass\r\n\r\n\r\nclass InvalidConfigValue(ConfigException):\r\n    \"\"\"An invalid value has been used.\"\"\"\r\n    pass\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/config.py b/isubrip/config.py
--- a/isubrip/config.py	(revision 92bad88b64f1dabfedd5ae9f1a8a40b483a2bea8)
+++ b/isubrip/config.py	(date 1683838379249)
@@ -54,7 +54,7 @@
             to validate, represented by a SpecialConfigType value. Defaults to None.
     """
     key: str
-    # Using typing._UnionGenericAlias as a replacement for types.UnionType, which is available only on  Python 3.10+
+    # TODO: Use `types.UnionType` instead of `typing._UnionGenericAlias`, once minimum Python version >= 3.10
     type: type | typing._UnionGenericAlias  # type: ignore[name-defined]
     category: str | list[str] | None = None
     required: bool = False
Index: isubrip/data_structures.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nfrom abc import ABC\r\nfrom dataclasses import dataclass\r\nfrom enum import Enum\r\nfrom typing import NamedTuple, TYPE_CHECKING\r\n\r\nif TYPE_CHECKING:\r\n    from isubrip.scrapers.scraper import Scraper\r\n\r\n\r\nclass SubtitlesDownloadResults(NamedTuple):\r\n    \"\"\"\r\n    A named tuple containing download results.\r\n\r\n    Attributes:\r\n        media_data (MediaData): Media data.\r\n        successful_subtitles (list[SubtitlesData]): List of subtitles that were successfully downloaded.\r\n        failed_subtitles (list[SubtitlesData]): List of subtitles that failed to download.\r\n        is_zip (bool): Whether the subtitles were saved in a zip file.\r\n    \"\"\"\r\n    media_data: MediaData\r\n    successful_subtitles: list[SubtitlesData]\r\n    failed_subtitles: list[SubtitlesData]\r\n    is_zip: bool\r\n\r\n\r\nclass SubtitlesFormatData(NamedTuple):\r\n    \"\"\"\r\n    A named tuple for containing metadata about subtitles formats.\r\n\r\n    Attributes:\r\n        name (str): Name of the format.\r\n        file_extension (str): File extension of the format.\r\n    \"\"\"\r\n    name: str\r\n    file_extension: str\r\n\r\n\r\nclass SubtitlesFormat(Enum):\r\n    \"\"\"\r\n    An Enum representing subtitles formats.\r\n\r\n    Attributes:\r\n        SUBRIP (SubtitlesFormatData): SubRip format.\r\n        WEBVTT (SubtitlesFormatData): WebVTT format.\r\n    \"\"\"\r\n    SUBRIP = SubtitlesFormatData(\"SubRip\", \"srt\")\r\n    WEBVTT = SubtitlesFormatData(\"WebVTT\", \"vtt\")\r\n\r\n\r\nclass SubtitlesType(Enum):\r\n    \"\"\"\r\n    Subtitles special type.\r\n\r\n    Attributes:\r\n        CC (SubtitlesType): Closed captions.\r\n        FORCED (SubtitlesType): Forced subtitles.\r\n    \"\"\"\r\n    CC = \"CC\"\r\n    FORCED = \"Forced\"\r\n\r\n\r\nclass MediaSourceData(NamedTuple):\r\n    \"\"\"\r\n    A named tuple containing media source data.\r\n\r\n    Attributes:\r\n        id (str): Internal ID of the source.\r\n        name (str): Name of the source.\r\n        abbreviation (str): Abbreviation of the source.\r\n    \"\"\"\r\n    id: str\r\n    name: str\r\n    abbreviation: str\r\n\r\n\r\n@dataclass\r\nclass SubtitlesData:\r\n    \"\"\"\r\n    A named tuple containing subtitles metadata.\r\n\r\n    Attributes:\r\n        language_code (str): Language code of the language the subtitles are in.\r\n        language_name (str): Name of the language the subtitles are in.\r\n        subtitles_format (SubtitlesFormat): Format of the subtitles.\r\n        content (bytes): Content of the subtitles in binary format.\r\n        special_type (SubtitlesType | None): Type of the subtitles, if they're not regular. Defaults to None.\r\n    \"\"\"\r\n    language_code: str\r\n    language_name: str\r\n    subtitles_format: SubtitlesFormat\r\n    content: bytes\r\n    special_type: SubtitlesType | None = None\r\n\r\n    def __post_init__(self):\r\n        self.language_name = self.language_name.strip()\r\n\r\n\r\n@dataclass\r\nclass MediaData(ABC):\r\n    \"\"\"\r\n    A base class for media data.\r\n\r\n    Attributes:\r\n        id (str | None): ID of the media.\r\n        name (str): Name of the media. (movie or series name)\r\n        release_year (int): Release year of the media.\r\n        playlist (str | None): URL to the playlist.\r\n        source (MediaSourceData): Source of the media.\r\n        scraper (Scraper): A reference to the scraper that was used to get the data.\r\n    \"\"\"\r\n    id: str | None\r\n    name: str\r\n    release_year: int\r\n    playlist: str | None\r\n    source: MediaSourceData\r\n    scraper: Scraper\r\n\r\n\r\n@dataclass\r\nclass MovieData(MediaData):\r\n    \"\"\"A named tuple containing movie metadata.\r\n\r\n    Attributes:\r\n        id (str | None): ID of the movie.\r\n        name (str): Name of the movie.\r\n        release_year (int): Release year of the movie.\r\n        playlist (str | None): URL to the playlist.\r\n        source (MediaSourceData): Source of the media.\r\n    \"\"\"\r\n    pass\r\n\r\n\r\n@dataclass\r\nclass EpisodeData(MediaData):\r\n    \"\"\"\r\n    A named tuple containing episode metadata.\r\n\r\n    Attributes:\r\n        id (str | None): ID of the episode.\r\n        name (str): Name of the movie.\r\n        release_year (int): Release year of the series.\r\n        playlist (str | None): URL to the playlist.\r\n        source (MediaSourceData): Source of the media.\r\n        episode_number (int): Episode number.\r\n        season_number (int): Season number.\r\n        episode_name (str | None, optional): Episode name. Defaults to None.\r\n        season_name (str | None, optional): Season name. Defaults to None.\r\n    \"\"\"\r\n    episode_number: int\r\n    season_number: int\r\n    episode_name: str | None = None\r\n    season_name: str | None = None\r\n\r\n\r\n@dataclass\r\nclass SeasonData(MediaData):\r\n    \"\"\"\r\n    A named tuple containing season metadata.\r\n\r\n    Attributes:\r\n        id (str | None): ID of the season.\r\n        name (str): Name of the series.\r\n        release_year (int): Release year of the series.\r\n        playlist (str | None): URL to the playlist.\r\n        source (MediaSourceData): Source of the media.\r\n        season_number (int): Season number.\r\n        season_episodes (list[EpisodeData]): Episodes that belong to the season.\r\n        season_name (str | None, optional): Season name. Defaults to None.\r\n    \"\"\"\r\n    season_number: int\r\n    season_episodes: list[EpisodeData]\r\n    season_name: str | None = None\r\n\r\n\r\n@dataclass\r\nclass SeriesData(MediaData):\r\n    \"\"\"\r\n    A named tuple containing series metadata.\r\n\r\n    Attributes:\r\n        id (str | None): ID of the series.\r\n        name (str): Name of the series.\r\n        release_year (int): Release year of the series.\r\n        playlist (str | None): URL to the playlist.\r\n        source (MediaSourceData): Source of the media.\r\n        series_seasons (list[SeasonData]): Seasons that belong to the series.\r\n    \"\"\"\r\n    series_seasons: list[SeasonData]\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/data_structures.py b/isubrip/data_structures.py
--- a/isubrip/data_structures.py	(revision 92bad88b64f1dabfedd5ae9f1a8a40b483a2bea8)
+++ b/isubrip/data_structures.py	(date 1683837990998)
@@ -1,5 +1,6 @@
 from __future__ import annotations
 
+import datetime as dt
 from abc import ABC
 from dataclasses import dataclass
 from enum import Enum
@@ -97,6 +98,7 @@
         self.language_name = self.language_name.strip()
 
 
+# TODO: Use `kw_only` on dataclasses, and set default values of None for optional arguments once min version => 3.10
 @dataclass
 class MediaData(ABC):
     """
@@ -104,18 +106,22 @@
 
     Attributes:
         id (str | None): ID of the media.
+        alt_id (str | None): Alternative ID of the media.
         name (str): Name of the media. (movie or series name)
-        release_year (int): Release year of the media.
+        release_date (datetime): Release date of the media.
         playlist (str | None): URL to the playlist.
         source (MediaSourceData): Source of the media.
         scraper (Scraper): A reference to the scraper that was used to get the data.
+        original_data (dict): Original data that was used to create the object.
     """
     id: str | None
+    alt_id: str | None
     name: str
-    release_year: int
+    release_date: dt.datetime
     playlist: str | None
     source: MediaSourceData
     scraper: Scraper
+    original_data: dict
 
 
 @dataclass
@@ -123,13 +129,20 @@
     """A named tuple containing movie metadata.
 
     Attributes:
-        id (str | None): ID of the movie.
+        id (str | None): ID of the movie. Defaults to None.
+        alt_id (str | None): Alternative ID of the media. Defaults to None.
         name (str): Name of the movie.
-        release_year (int): Release year of the movie.
-        playlist (str | None): URL to the playlist.
+        release_date (datetime): Release date of the movie.
+        playlist (str | None): URL to the playlist. Defaults to None.
         source (MediaSourceData): Source of the media.
+        scraper (Scraper): A reference to the scraper that was used to get the data.
+        preorder_availability_date (datetime | None, optional): Date when the movie will be available for preorder.
+            None if not a preorder. Defaults to None.
     """
-    pass
+    id = None
+    alt_id = None
+    playlist = None
+    preorder_availability_date: dt.datetime | None = None
 
 
 @dataclass
@@ -138,19 +151,26 @@
     A named tuple containing episode metadata.
 
     Attributes:
-        id (str | None): ID of the episode.
+        id (str | None): ID of the episode. Defaults to None.
+        alt_id (str | None): Alternative ID of the media. Defaults to None.
         name (str): Name of the movie.
-        release_year (int): Release year of the series.
-        playlist (str | None): URL to the playlist.
+        release_date (datetime): Release date of the series.
+        playlist (str | None): URL to the playlist. Defaults to None.
         source (MediaSourceData): Source of the media.
+        scraper (Scraper): A reference to the scraper that was used to get the data.
         episode_number (int): Episode number.
         season_number (int): Season number.
         episode_name (str | None, optional): Episode name. Defaults to None.
         season_name (str | None, optional): Season name. Defaults to None.
+        episode_release_date (datetime | None): Release date of the episode. Defaults to None.
     """
+    id = None
+    alt_id = None
+    playlist = None
     episode_number: int
+    episode_name: str
     season_number: int
-    episode_name: str | None = None
+    episode_release_date: dt.datetime | None = None
     season_name: str | None = None
 
 
@@ -160,17 +180,24 @@
     A named tuple containing season metadata.
 
     Attributes:
-        id (str | None): ID of the season.
+        id (str | None): ID of the season. Defaults to None.
+        alt_id (str | None): Alternative ID of the media. Defaults to None.
         name (str): Name of the series.
-        release_year (int): Release year of the series.
-        playlist (str | None): URL to the playlist.
+        release_date (datetime): Release date of the series.
+        playlist (str | None): URL to the playlist. Defaults to None.
         source (MediaSourceData): Source of the media.
+        scraper (Scraper): A reference to the scraper that was used to get the data.
         season_number (int): Season number.
+        season_name (str | None, optional): Season name. Defaults to None.
         season_episodes (list[EpisodeData]): Episodes that belong to the season.
-        season_name (str | None, optional): Season name. Defaults to None.
+        season_release_date (datetime | None, optional): Release date of the season. Defaults to None.
     """
+    id = None
+    alt_id = None
+    playlist = None
     season_number: int
     season_episodes: list[EpisodeData]
+    season_release_date: dt.datetime | None = None
     season_name: str | None = None
 
 
@@ -180,11 +207,13 @@
     A named tuple containing series metadata.
 
     Attributes:
-        id (str | None): ID of the series.
+        id (str | None): ID of the series. Defaults to None.
+        alt_id (str | None): Alternative ID of the media. Defaults to None.
         name (str): Name of the series.
-        release_year (int): Release year of the series.
-        playlist (str | None): URL to the playlist.
+        release_date (datetime): Release date of the series.
+        playlist (str | None): URL to the playlist. Defaults to None.
         source (MediaSourceData): Source of the media.
+        scraper (Scraper): A reference to the scraper that was used to get the data.
         series_seasons (list[SeasonData]): Seasons that belong to the series.
     """
     series_seasons: list[SeasonData]
Index: isubrip/utils.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nimport os\r\nimport re\r\nimport sys\r\nfrom abc import ABCMeta\r\n\r\nfrom datetime import time\r\nfrom os import PathLike\r\nfrom pathlib import Path\r\nfrom typing import Any, Iterable, Union, get_args, get_origin\r\n\r\nfrom isubrip.data_structures import EpisodeData, MovieData, SubtitlesData, SubtitlesFormat, SubtitlesType\r\n\r\n\r\nclass SingletonMeta(ABCMeta):\r\n    \"\"\"\r\n    A metaclass that implements the Singleton pattern.\r\n    When a class using this metaclass is initialized, it will return the same instance every time.\r\n    \"\"\"\r\n    _instances: dict[object, object] = {}\r\n\r\n    def __call__(cls, *args, **kwargs) -> object:\r\n        if cls._instances.get(cls) is None:\r\n            cls._instances[cls] = super().__call__(*args, **kwargs)\r\n\r\n        return cls._instances[cls]\r\n\r\n\r\ndef check_type(value: Any, type_) -> bool:\r\n    \"\"\"\r\n    Check if a value is of a certain type.\r\n    Works with parameterized generics.\r\n\r\n    Args:\r\n        value: Value to check.\r\n        type_: Type to check against.\r\n\r\n    Returns:\r\n        bool: True if the value is of the specified type, False otherwise.\r\n    \"\"\"\r\n    origin = get_origin(type_)\r\n    args = get_args(type_)\r\n\r\n    if origin is Union:\r\n        return any(check_type(value, union_sub_type) for union_sub_type in args)\r\n\r\n    elif origin is tuple:\r\n        if args[-1] is Ellipsis:\r\n            # Example: (int, str, ...)\r\n            args_len = len(args)\r\n\r\n            return check_type(value[:args_len - 1], tuple(args[:-1])) and \\\r\n                all(check_type(item, args[-2]) for item in value[args_len - 1:])\r\n\r\n        else:\r\n            return isinstance(value, tuple) and \\\r\n                len(value) == len(args) and \\\r\n                all(check_type(item, item_type) for item, item_type in zip(value, args))\r\n\r\n    elif origin is list:\r\n        return isinstance(value, list) and \\\r\n            all(check_type(item, args[0]) for item in value)\r\n\r\n    elif origin is dict:\r\n        return isinstance(value, dict) and \\\r\n            all(check_type(k, args[0]) and check_type(v, args[1]) for k, v in value.items())\r\n\r\n    return isinstance(value, type_)\r\n\r\n\r\ndef download_subtitles_to_file(media_data: MovieData | EpisodeData, subtitles_data: SubtitlesData,\r\n                               output_path: str | PathLike, overwrite: bool = False) -> Path:\r\n    \"\"\"\r\n    Download subtitles to a file.\r\n\r\n    Args:\r\n        media_data (MovieData | EpisodeData): An object containing media data.\r\n        subtitles_data (SubtitlesData): A SubtitlesData object containing subtitles data.\r\n        output_path (str | PathLike): Path to the output folder.\r\n        overwrite (bool, optional): Whether to overwrite files if they already exist. Defaults to True.\r\n\r\n    Returns:\r\n        Path: Path to the downloaded subtitles file.\r\n\r\n    Raises:\r\n        ValueError: If the path in `output_path` does not exist.\r\n    \"\"\"\r\n    if not os.path.isdir(output_path):\r\n        raise ValueError(f'Invalid path: {output_path}')\r\n\r\n    if isinstance(media_data, MovieData):\r\n        file_name = generate_release_name(title=media_data.name,\r\n                                          release_year=media_data.release_year,\r\n                                          media_source=media_data.source.abbreviation,\r\n                                          language_code=subtitles_data.language_code,\r\n                                          subtitles_type=subtitles_data.special_type,\r\n                                          file_format=subtitles_data.subtitles_format)\r\n    elif isinstance(media_data, EpisodeData):\r\n        file_name = generate_release_name(title=media_data.name,\r\n                                          release_year=media_data.release_year,\r\n                                          season_number=media_data.season_number,\r\n                                          episode_number=media_data.episode_number,\r\n                                          episode_name=media_data.episode_name,\r\n                                          media_source=media_data.source.abbreviation,\r\n                                          language_code=subtitles_data.language_code,\r\n                                          subtitles_type=subtitles_data.special_type,\r\n                                          file_format=subtitles_data.subtitles_format)\r\n\r\n    else:\r\n        raise TypeError(f'This function only supports MovieData and EpisodeData objects. Got {type(media_data)}.')\r\n\r\n    file_path = Path(output_path) / file_name\r\n\r\n    if file_path.exists() and not overwrite:\r\n        file_path = generate_non_conflicting_path(file_path)\r\n\r\n    with open(file_path, 'wb') as f:\r\n        f.write(subtitles_data.content)\r\n\r\n    return file_path\r\n\r\n\r\ndef generate_non_conflicting_path(file_path: str | Path, has_extension: bool = True) -> Path:\r\n    \"\"\"\r\n    Generate a non-conflicting path for a file.\r\n    If the file already exists, a number will be added to the end of the file name.\r\n\r\n    Args:\r\n        file_path (str | Path): Path to a file.\r\n        has_extension (bool, optional): Whether the name of the file includes file extension. Defaults to True.\r\n\r\n    Returns:\r\n        Path: A non-conflicting file path.\r\n    \"\"\"\r\n    if isinstance(file_path, str):\r\n        file_path = Path(file_path)\r\n\r\n    if not file_path.exists():\r\n        return file_path\r\n\r\n    i = 1\r\n    while True:\r\n        if has_extension:\r\n            new_file_path = file_path.parent / f'{file_path.stem}-{i}{file_path.suffix}'\r\n\r\n        else:\r\n            new_file_path = file_path.parent / f'{file_path}-{i}'\r\n\r\n        if not new_file_path.exists():\r\n            return new_file_path\r\n\r\n        i += 1\r\n\r\n\r\ndef generate_release_name(title: str,\r\n                          release_year: int | None = None,\r\n                          season_number: int | None = None,\r\n                          episode_number: int | None = None,\r\n                          episode_name: str | None = None,\r\n                          media_source: str | None = None,\r\n                          source_type: str | None = \"WEB\",\r\n                          additional_info: str | list[str] | None = None,\r\n                          language_code: str | None = None,\r\n                          subtitles_type: SubtitlesType | None = None,\r\n                          file_format: str | SubtitlesFormat | None = None) -> str:\r\n    \"\"\"\r\n    Generate a release name.\r\n\r\n    Args:\r\n        title (str): Media title.\r\n        release_year (int | None, optional): Release year. Defaults to None.\r\n        season_number (int | None, optional): Season number. Defaults to None.\r\n        episode_number (int | None, optional): Episode number. Defaults to None.\r\n        episode_name (str | None, optional): Episode name. Defaults to None.\r\n        media_source (str | None, optional): Media source name (full or abbreviation). Defaults to None.\r\n        source_type(str | None, optional): General source type (WEB, BluRay, etc.). Defaults to None.\r\n        additional_info (list[str] | str | None, optional): Additional info to add to the file name. Defaults to None.\r\n        language_code (str | None, optional): Language code. Defaults to None.\r\n        subtitles_type (SubtitlesType | None, optional): Subtitles type. Defaults to None.\r\n        file_format (SubtitlesFormat | str | None, optional): File format to use.  Defaults to None.\r\n\r\n    Returns:\r\n        str: Generated file name.\r\n    \"\"\"\r\n    file_name = standardize_title(title)\r\n\r\n    if release_year is not None and str(release_year) not in file_name:\r\n        file_name += f'.{release_year}'\r\n\r\n    if season_number is not None:\r\n        file_name += f'.S{season_number:02}'\r\n\r\n    if episode_number is not None:\r\n        file_name += f'.E{episode_number:02}'\r\n\r\n    if episode_name is not None:\r\n        file_name += f'.{standardize_title(episode_name)}'\r\n\r\n    if media_source is not None:\r\n        file_name += f'.{media_source}'\r\n\r\n    if source_type is not None:\r\n        file_name += f'.{source_type}'\r\n\r\n    if additional_info is not None:\r\n        if isinstance(additional_info, (list, tuple)):\r\n            additional_info = '.'.join(additional_info)\r\n\r\n        file_name += f'.{additional_info}'\r\n\r\n    if language_code is not None:\r\n        file_name += f'.{language_code}'\r\n\r\n    if subtitles_type is not None:\r\n        file_name += f'.{subtitles_type.value.lower()}'\r\n\r\n    if file_format is not None:\r\n        if isinstance(file_format, SubtitlesFormat):\r\n            file_format = file_format.value.file_extension\r\n\r\n        file_name += f'.{file_format}'\r\n\r\n    return file_name\r\n\r\n\r\ndef merge_dict_values(*dictionaries: dict) -> dict:\r\n    \"\"\"\r\n    A function for merging the values of multiple dictionaries using the same keys.\r\n    If a key already exists, the value will be added to a list of values mapped to that key.\r\n\r\n    Args:\r\n        *dictionaries (dict): Dictionaries to merge.\r\n\r\n    Returns:\r\n        dict: A merged dictionary.\r\n    \"\"\"\r\n    result: dict = {}\r\n\r\n    for dict_ in dictionaries:\r\n        for key, value in dict_.items():\r\n            if key in result:\r\n                if isinstance(result[key], list) and value not in result[key]:\r\n                    result[key].append(value)\r\n\r\n                elif isinstance(result[key], tuple) and value not in result[key]:\r\n                    result[key] = result[key] + (value,)\r\n\r\n                elif value != result[key]:\r\n                    result[key] = [result[key], value]\r\n            else:\r\n                result[key] = value\r\n\r\n    return result\r\n\r\n\r\ndef single_to_list(obj) -> list:\r\n    \"\"\"\r\n    Convert a single non-iterable object to a list.\r\n    If None is passed, an empty list will be returned.\r\n\r\n    Args:\r\n        obj: Object to convert.\r\n\r\n    Returns:\r\n        list: A list containing the object.\r\n            If the object is already an iterable, it will be converted to a list.\r\n    \"\"\"\r\n    if isinstance(obj, Iterable) and not isinstance(obj, str):\r\n        return list(obj)\r\n\r\n    elif obj is None:\r\n        return []\r\n\r\n    return [obj]\r\n\r\n\r\ndef split_subtitles_timestamp(timestamp: str) -> tuple[time, time]:\r\n    \"\"\"\r\n    Split a subtitles timestamp into start and end.\r\n\r\n    Args:\r\n        timestamp (str): A subtitles timestamp. For example: \"00:00:00.000 --> 00:00:00.000\"\r\n\r\n    Returns:\r\n        tuple(time, time): A tuple containing start and end times as a datetime object.\r\n    \"\"\"\r\n    # Support ',' character in timestamp's milliseconds (used in SubRip format).\r\n    timestamp = timestamp.replace(',', '.')\r\n\r\n    start_time, end_time = timestamp.split(\" --> \")\r\n    return time.fromisoformat(start_time), time.fromisoformat(end_time)\r\n\r\n\r\ndef standardize_title(title: str) -> str:\r\n    \"\"\"\r\n    Format movie title to a standardized title that can be used as a file name.\r\n\r\n    Args:\r\n        title (str): A movie title.\r\n\r\n    Returns:\r\n        str: The movie title, in a file-name-friendly format.\r\n    \"\"\"\r\n    windows_reserved_file_names = (\"CON\", \"PRN\", \"AUX\", \"NUL\", \"COM1\", \"COM2\", \"COM3\", \"COM4\",\r\n                                   \"COM5\", \"COM6\", \"COM7\", \"COM8\", \"COM9\", \"LPT1\", \"LPT2\",\r\n                                   \"LPT3\", \"LPT4\", \"LPT5\", \"LPT6\", \"LPT7\", \"LPT8\", \"LPT9\")\r\n\r\n    title = title.strip()\r\n\r\n    # Replacements will be done in the same order of this list\r\n    replacement_pairs = [\r\n        (': ', '.'),\r\n        (':', '.'),\r\n        (' - ', '-'),\r\n        (', ', '.'),\r\n        ('. ', '.'),\r\n        (' ', '.'),\r\n        ('|', '.'),\r\n        ('/', '.'),\r\n        ('<', ''),\r\n        ('>', ''),\r\n        ('(', ''),\r\n        (')', ''),\r\n        ('\"', ''),\r\n        ('?', ''),\r\n        ('*', ''),\r\n    ]\r\n\r\n    for pair in replacement_pairs:\r\n        title = title.replace(pair[0], pair[1])\r\n\r\n    title = re.sub(r\"\\.+\", \".\", title)  # Replace multiple dots with a single dot\r\n\r\n    # If running on Windows, rename Windows reserved names to allow file creation\r\n    if sys.platform == 'win32':\r\n        split_title = title.split('.')\r\n\r\n        if split_title[0].upper() in windows_reserved_file_names:\r\n            if len(split_title) > 1:\r\n                return split_title[0] + split_title[1] + '.'.join(split_title[2:])\r\n\r\n            elif len(split_title) == 1:\r\n                return \"_\" + title\r\n\r\n    return title\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/utils.py b/isubrip/utils.py
--- a/isubrip/utils.py	(revision 92bad88b64f1dabfedd5ae9f1a8a40b483a2bea8)
+++ b/isubrip/utils.py	(date 1683837454712)
@@ -1,11 +1,11 @@
 from __future__ import annotations
 
+import datetime as dt
 import os
 import re
 import sys
+
 from abc import ABCMeta
-
-from datetime import time
 from os import PathLike
 from pathlib import Path
 from typing import Any, Iterable, Union, get_args, get_origin
@@ -69,6 +69,23 @@
     return isinstance(value, type_)
 
 
+def convert_epoch_to_datetime(epoch_timestamp: int) -> dt.datetime:
+    """
+    Convert an epoch timestamp to a datetime object.
+
+    Args:
+        epoch_timestamp (int): Epoch timestamp.
+
+    Returns:
+        datetime: A datetime object representing the timestamp.
+    """
+    if epoch_timestamp >= 0:
+        return dt.datetime.fromtimestamp(epoch_timestamp)
+
+    else:
+        return dt.datetime(1970, 1, 1) + dt.timedelta(seconds=epoch_timestamp)
+
+
 def download_subtitles_to_file(media_data: MovieData | EpisodeData, subtitles_data: SubtitlesData,
                                output_path: str | PathLike, overwrite: bool = False) -> Path:
     """
@@ -91,14 +108,14 @@
 
     if isinstance(media_data, MovieData):
         file_name = generate_release_name(title=media_data.name,
-                                          release_year=media_data.release_year,
+                                          release_year=media_data.release_date.year,
                                           media_source=media_data.source.abbreviation,
                                           language_code=subtitles_data.language_code,
                                           subtitles_type=subtitles_data.special_type,
                                           file_format=subtitles_data.subtitles_format)
     elif isinstance(media_data, EpisodeData):
         file_name = generate_release_name(title=media_data.name,
-                                          release_year=media_data.release_year,
+                                          release_year=media_data.release_date.year,
                                           season_number=media_data.season_number,
                                           episode_number=media_data.episode_number,
                                           episode_name=media_data.episode_name,
@@ -185,7 +202,7 @@
     """
     file_name = standardize_title(title)
 
-    if release_year is not None and str(release_year) not in file_name:
+    if release_year is not None:
         file_name += f'.{release_year}'
 
     if season_number is not None:
@@ -254,6 +271,26 @@
     return result
 
 
+def parse_url_params(url_params: str) -> dict:
+    """
+    Parse GET parameters from a URL to a dictionary.
+
+    Args:
+        url_params (str): URL parameters. (e.g. 'param1=value1&param2=value2')
+
+    Returns:
+        dict: A dictionary containing the URL parameters.
+    """
+    url_params = url_params.strip('?').rstrip('&')
+    params_list = url_params.split('&')
+
+    if len(params_list) == 0 or \
+            (len(params_list) == 1 and '=' not in params_list[0]):
+        return {}
+
+    return {key: value for key, value in (param.split('=') for param in params_list)}
+
+
 def single_to_list(obj) -> list:
     """
     Convert a single non-iterable object to a list.
@@ -275,7 +312,7 @@
     return [obj]
 
 
-def split_subtitles_timestamp(timestamp: str) -> tuple[time, time]:
+def split_subtitles_timestamp(timestamp: str) -> tuple[dt.time, dt.time]:
     """
     Split a subtitles timestamp into start and end.
 
@@ -289,7 +326,7 @@
     timestamp = timestamp.replace(',', '.')
 
     start_time, end_time = timestamp.split(" --> ")
-    return time.fromisoformat(start_time), time.fromisoformat(end_time)
+    return dt.time.fromisoformat(start_time), dt.time.fromisoformat(end_time)
 
 
 def standardize_title(title: str) -> str:
