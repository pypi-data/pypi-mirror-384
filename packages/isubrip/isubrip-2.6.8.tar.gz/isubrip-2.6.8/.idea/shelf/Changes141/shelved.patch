Index: isubrip/__main__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nimport asyncio\r\nimport logging\r\nfrom pathlib import Path\r\nimport shutil\r\nimport sys\r\n\r\nimport httpx\r\nfrom pydantic_core._pydantic_core import ValidationError\r\n\r\nfrom isubrip.config import Config\r\nfrom isubrip.constants import (\r\n    ARCHIVE_FORMAT,\r\n    DATA_FOLDER_PATH,\r\n    EVENT_LOOP,\r\n    LOG_FILE_NAME,\r\n    LOG_FILES_PATH,\r\n    PACKAGE_NAME,\r\n    PACKAGE_VERSION,\r\n    PREORDER_MESSAGE,\r\n    TEMP_FOLDER_PATH,\r\n)\r\nfrom isubrip.data_structures import (\r\n    Episode,\r\n    MediaData,\r\n    Movie,\r\n    ScrapedMediaResponse,\r\n    Season,\r\n    Series,\r\n    SubtitlesData,\r\n    SubtitlesDownloadResults,\r\n)\r\nfrom isubrip.logger import CustomLogFileFormatter, CustomStdoutFormatter, logger\r\nfrom isubrip.scrapers.scraper import PlaylistLoadError, Scraper, ScraperError, ScraperFactory, SubtitlesDownloadError\r\nfrom isubrip.subtitle_formats.webvtt import WebVTTCaptionBlock\r\nfrom isubrip.utils import (\r\n    TempDirGenerator,\r\n    download_subtitles_to_file,\r\n    format_config_validation_error,\r\n    format_media_description,\r\n    format_release_name,\r\n    format_subtitles_description,\r\n    generate_non_conflicting_path,\r\n    get_model_field,\r\n    raise_for_status,\r\n    single_string_to_list,\r\n)\r\n\r\nLOG_ROTATION_SIZE: int | None = None\r\n\r\n\r\n\r\ndef main() -> None:\r\n    try:\r\n        # Assure at least one argument was passed\r\n        if len(sys.argv) < 2:\r\n            print_usage()\r\n            exit(0)\r\n\r\n        if not DATA_FOLDER_PATH.is_dir():\r\n            DATA_FOLDER_PATH.mkdir(parents=True)\r\n\r\n        setup_loggers(stdout_loglevel=logging.INFO,\r\n                      file_loglevel=logging.DEBUG)\r\n\r\n        cli_args = \" \".join(sys.argv[1:])\r\n        logger.debug(f\"CLI Command: {PACKAGE_NAME} {cli_args}\")\r\n        logger.debug(f\"Python version: {sys.version}\")\r\n        logger.debug(f\"Package version: {PACKAGE_VERSION}\")\r\n        logger.debug(f\"OS: {sys.platform}\")\r\n\r\n        try:\r\n            config = Config()\r\n\r\n        except ValidationError as e:\r\n            logger.error(\"Invalid configuration - the following errors were found in the configuration file:\\n\"\r\n                         \"---\\n\" +\r\n                         format_config_validation_error(exc=e) +\r\n                         \"---\\n\"\r\n                         \"Please update your configuration to resolve the issue.\")\r\n            logger.debug(\"Debug information:\", exc_info=True)\r\n            exit(1)\r\n\r\n        update_settings(config=config)\r\n\r\n        if config.general.check_for_updates:\r\n            check_for_updates(current_package_version=PACKAGE_VERSION)\r\n\r\n        EVENT_LOOP.run_until_complete(download(urls=single_string_to_list(item=sys.argv[1:]),\r\n                                               config=config))\r\n\r\n    except Exception as ex:\r\n        logger.error(f\"Error: {ex}\")\r\n        logger.debug(\"Debug information:\", exc_info=True)\r\n        exit(1)\r\n\r\n    finally:\r\n        if log_rotation_size := LOG_ROTATION_SIZE:\r\n            handle_log_rotation(log_rotation_size=log_rotation_size)\r\n\r\n        # NOTE: This will only close scrapers that were initialized using the ScraperFactory.\r\n        async_cleanup_coroutines = []\r\n        for scraper in ScraperFactory.get_initialized_scrapers():\r\n            logger.debug(f\"Requests count for '{scraper.name}' scraper: {scraper.requests_count}\")\r\n            scraper.close()\r\n            async_cleanup_coroutines.append(scraper.async_close())\r\n\r\n        EVENT_LOOP.run_until_complete(asyncio.gather(*async_cleanup_coroutines))\r\n        TempDirGenerator.cleanup()\r\n\r\n\r\nasync def download(urls: list[str], config: Config) -> None:\r\n    \"\"\"\r\n    Download subtitles from a given URL.\r\n\r\n    Args:\r\n        urls (list[str]): A list of URLs to download subtitles from.\r\n        config (Config): A config to use for downloading subtitles.\r\n    \"\"\"\r\n    scrapers_configs = {\r\n        scraper_id: get_model_field(config.scrapers, scraper_id) for scraper_id in config.scrapers.model_fields\r\n    }\r\n\r\n    for url in urls:\r\n        try:\r\n            logger.info(f\"Scraping '{url}'...\")\r\n\r\n            scraper = ScraperFactory.get_scraper_instance(url=url, scrapers_configs=scrapers_configs)\r\n\r\n            try:\r\n                logger.debug(f\"Fetching '{url}'...\")\r\n                scraper_response: ScrapedMediaResponse = await scraper.get_data(url=url)\r\n\r\n            except ScraperError as e:\r\n                logger.error(f\"Error: {e}\")\r\n                logger.debug(\"Debug information:\", exc_info=True)\r\n                continue\r\n\r\n            media_data = scraper_response.media_data\r\n            playlist_scraper = ScraperFactory.get_scraper_instance(scraper_id=scraper_response.playlist_scraper,\r\n                                                                   scrapers_configs=scrapers_configs)\r\n\r\n            if not media_data:\r\n                logger.error(f\"Error: No supported media was found for {url}.\")\r\n                continue\r\n\r\n            for media_item in media_data:\r\n                try:\r\n                    logger.info(f\"Found {media_item.media_type}: {format_media_description(media_data=media_item)}\")\r\n                    await download_media(scraper=playlist_scraper,\r\n                                         media_item=media_item,\r\n                                         download_path=config.downloads.folder,\r\n                                         language_filter=config.downloads.languages,\r\n                                         convert_to_srt=config.subtitles.convert_to_srt,\r\n                                         overwrite_existing=config.downloads.overwrite_existing,\r\n                                         archive=config.downloads.zip)\r\n\r\n                except Exception as e:\r\n                    if len(media_data) > 1:\r\n                        logger.warning(f\"Error scraping media item \"\r\n                                       f\"'{format_media_description(media_data=media_item)}': {e}\\n\"\r\n                                       f\"Skipping to next media item...\")\r\n                        logger.debug(\"Debug information:\", exc_info=True)\r\n                        continue\r\n\r\n                    raise\r\n\r\n        except Exception as e:\r\n            logger.error(f\"Error while scraping '{url}': {e}\")\r\n            logger.debug(\"Debug information:\", exc_info=True)\r\n            continue\r\n\r\n\r\nasync def download_media(scraper: Scraper, media_item: MediaData, download_path: Path,\r\n                              language_filter: list[str] | None = None, convert_to_srt: bool = False,\r\n                              overwrite_existing: bool = True, archive: bool = False) -> None:\r\n    \"\"\"\r\n    Download a media item.\r\n\r\n    Args:\r\n        scraper (Scraper): A Scraper object to use for downloading subtitles.\r\n        media_item (MediaData): A media data item to download subtitles for.\r\n        download_path (Path): Path to a folder where the subtitles will be downloaded to.\r\n        language_filter (list[str] | None): List of specific languages to download subtitles for.\r\n            None for all languages (no filter). Defaults to None.\r\n        convert_to_srt (bool, optional): Whether to convert the subtitles to SRT format. Defaults to False.\r\n        overwrite_existing (bool, optional): Whether to overwrite existing subtitles. Defaults to True.\r\n        archive (bool, optional): Whether to archive the subtitles into a single zip file\r\n            (only if there are multiple subtitles).\r\n    \"\"\"\r\n    if isinstance(media_item, Series):\r\n        for season in media_item.seasons:\r\n            await download_media(media_item=season, scraper=scraper, download_path=download_path,\r\n                                 language_filter=language_filter, convert_to_srt=convert_to_srt,\r\n                                 overwrite_existing=overwrite_existing, archive=archive)\r\n\r\n    elif isinstance(media_item, Season):\r\n        for episode in media_item.episodes:\r\n            logger.info(f\"{format_media_description(media_data=episode, shortened=True)}:\")\r\n            await download_media_item(media_item=episode, scraper=scraper, download_path=download_path,\r\n                                 language_filter=language_filter, convert_to_srt=convert_to_srt,\r\n                                 overwrite_existing=overwrite_existing, archive=archive)\r\n\r\n    elif isinstance(media_item, (Movie, Episode)):\r\n        await download_media_item(media_item=media_item, scraper=scraper, download_path=download_path,\r\n                                 language_filter=language_filter, convert_to_srt=convert_to_srt,\r\n                                 overwrite_existing=overwrite_existing, archive=archive)\r\n\r\n\r\nasync def download_media_item(scraper: Scraper, media_item: Movie | Episode, download_path: Path,\r\n                              language_filter: list[str] | None = None, convert_to_srt: bool = False,\r\n                              overwrite_existing: bool = True, archive: bool = False) -> None:\r\n    \"\"\"\r\n    Download subtitles for a single media item.\r\n\r\n    Args:\r\n        scraper (Scraper): A Scraper object to use for downloading subtitles.\r\n        media_item (Movie | Episode): A movie or episode data object.\r\n        download_path (Path): Path to a folder where the subtitles will be downloaded to.\r\n        language_filter (list[str] | None): List of specific languages to download subtitles for.\r\n            None for all languages (no filter). Defaults to None.\r\n        convert_to_srt (bool, optional): Whether to convert the subtitles to SRT format. Defaults to False.\r\n        overwrite_existing (bool, optional): Whether to overwrite existing subtitles. Defaults to True.\r\n        archive (bool, optional): Whether to archive the subtitles into a single zip file\r\n            (only if there are multiple subtitles).\r\n    \"\"\"\r\n    ex: Exception | None = None\r\n\r\n    if media_item.playlist:\r\n        try:\r\n            results = await download_subtitles(\r\n                scraper=scraper,\r\n                media_data=media_item,\r\n                download_path=download_path,\r\n                language_filter=language_filter,\r\n                convert_to_srt=convert_to_srt,\r\n                overwrite_existing=overwrite_existing,\r\n                archive=archive,\r\n            )\r\n\r\n            success_count = len(results.successful_subtitles)\r\n            failed_count = len(results.failed_subtitles)\r\n\r\n            if success_count or failed_count:\r\n                logger.info(f\"{success_count}/{success_count + failed_count} matching subtitles \"\r\n                            f\"were successfully downloaded.\")\r\n\r\n            else:\r\n                logger.info(\"No matching subtitles were found.\")\r\n\r\n            return  # noqa: TRY300\r\n\r\n        except PlaylistLoadError as e:\r\n            ex = e\r\n\r\n    # We get here if there is no playlist, or there is one, but it failed to load\r\n    if isinstance(media_item, Movie) and media_item.preorder_availability_date:\r\n        preorder_date_str = media_item.preorder_availability_date.strftime(\"%Y-%m-%d\")\r\n        logger.info(PREORDER_MESSAGE.format(movie_name=media_item.name, scraper_name=scraper.name,\r\n                                            preorder_date=preorder_date_str))\r\n\r\n    else:\r\n        if ex:\r\n            logger.error(f\"Error: {ex}\")\r\n\r\n        else:\r\n            logger.error(\"Error: No valid playlist was found.\")\r\n\r\n\r\ndef check_for_updates(current_package_version: str) -> None:\r\n    \"\"\"\r\n    Check and print if a newer version of the package is available, and log accordingly.\r\n\r\n    Args:\r\n        current_package_version (str): The current version of the package.\r\n    \"\"\"\r\n    api_url = f\"https://pypi.org/pypi/{PACKAGE_NAME}/json\"\r\n    logger.debug(\"Checking for package updates on PyPI...\")\r\n    try:\r\n        response = httpx.get(\r\n            url=api_url,\r\n            headers={\"Accept\": \"application/json\"},\r\n            timeout=5,\r\n        )\r\n        raise_for_status(response)\r\n        response_data = response.json()\r\n\r\n        pypi_latest_version = response_data[\"info\"][\"version\"]\r\n\r\n        if pypi_latest_version != current_package_version:\r\n            logger.warning(f\"You are currently using version '{current_package_version}' of '{PACKAGE_NAME}', \"\r\n                           f\"however version '{pypi_latest_version}' is available.\"\r\n                           f'\\nConsider upgrading by running \"pip install --upgrade {PACKAGE_NAME}\"\\n')\r\n\r\n        else:\r\n            logger.debug(f\"Latest version of '{PACKAGE_NAME}' ({current_package_version}) is currently installed.\")\r\n\r\n    except Exception as e:\r\n        logger.warning(f\"Update check failed: {e}\")\r\n        logger.debug(\"Debug information:\", exc_info=True)\r\n        return\r\n\r\n\r\nasync def download_subtitles(scraper: Scraper, media_data: Movie | Episode, download_path: Path,\r\n                             language_filter: list[str] | None = None, convert_to_srt: bool = False,\r\n                             overwrite_existing: bool = True, archive: bool = False) -> SubtitlesDownloadResults:\r\n    \"\"\"\r\n    Download subtitles for the given media data.\r\n\r\n    Args:\r\n        scraper (Scraper): A Scraper object to use for downloading subtitles.\r\n        media_data (Movie | Episode): A movie or episode data object.\r\n        download_path (Path): Path to a folder where the subtitles will be downloaded to.\r\n        language_filter (list[str] | None): List of specific languages to download subtitles for.\r\n            None for all languages (no filter). Defaults to None.\r\n        convert_to_srt (bool, optional): Whether to convert the subtitles to SRT format. Defaults to False.\r\n        overwrite_existing (bool, optional): Whether to overwrite existing subtitles. Defaults to True.\r\n        archive (bool, optional): Whether to archive the subtitles into a single zip file\r\n            (only if there are multiple subtitles).\r\n\r\n    Returns:\r\n        SubtitlesDownloadResults: A SubtitlesDownloadResults object containing the results of the download.\r\n    \"\"\"\r\n    temp_dir_name = generate_media_folder_name(media_data=media_data, source=scraper.abbreviation)\r\n    temp_download_path = TempDirGenerator.generate(directory_name=temp_dir_name)\r\n\r\n    successful_downloads: list[SubtitlesData] = []\r\n    failed_downloads: list[SubtitlesDownloadError] = []\r\n    temp_downloads: list[Path] = []\r\n\r\n    if not media_data.playlist:\r\n        raise PlaylistLoadError(\"No playlist was found for provided media data.\")\r\n\r\n    main_playlist = await scraper.load_playlist(url=media_data.playlist)  # type: ignore[func-returns-value]\r\n\r\n    if not main_playlist:\r\n        raise PlaylistLoadError(\"Failed to load the main playlist.\")\r\n\r\n    matching_subtitles = scraper.find_matching_subtitles(main_playlist=main_playlist,  # type: ignore[var-annotated]\r\n                                                         language_filter=language_filter)\r\n\r\n    logger.debug(f\"{len(matching_subtitles)} matching subtitles were found.\")\r\n\r\n    for matching_subtitles_item in matching_subtitles:\r\n        subtitles_data = await scraper.download_subtitles(media_data=matching_subtitles_item,\r\n                                                          subrip_conversion=convert_to_srt)\r\n        language_info = format_subtitles_description(language_code=subtitles_data.language_code,\r\n                                                     language_name=subtitles_data.language_name,\r\n                                                     special_type=subtitles_data.special_type)\r\n\r\n        if isinstance(subtitles_data, SubtitlesDownloadError):\r\n            logger.warning(f\"Failed to download '{language_info}' subtitles. Skipping...\")\r\n            logger.debug(\"Debug information:\", exc_info=subtitles_data.original_exc)\r\n            failed_downloads.append(subtitles_data)\r\n            continue\r\n\r\n        try:\r\n            temp_downloads.append(download_subtitles_to_file(\r\n                media_data=media_data,\r\n                subtitles_data=subtitles_data,\r\n                output_path=temp_download_path,\r\n                source_abbreviation=scraper.abbreviation,\r\n                overwrite=overwrite_existing,\r\n            ))\r\n\r\n            logger.info(f\"'{language_info}' subtitles were successfully downloaded.\")\r\n            successful_downloads.append(subtitles_data)\r\n\r\n        except Exception as e:\r\n            logger.error(f\"Error: Failed to save '{language_info}' subtitles: {e}\")\r\n            logger.debug(\"Debug information:\", exc_info=True)\r\n            failed_downloads.append(\r\n                SubtitlesDownloadError(\r\n                    language_code=subtitles_data.language_code,\r\n                    language_name=subtitles_data.language_name,\r\n                    special_type=subtitles_data.special_type,\r\n                    original_exc=e,\r\n                ),\r\n            )\r\n\r\n    if not archive or len(temp_downloads) == 1:\r\n        for file_path in temp_downloads:\r\n            if overwrite_existing:\r\n                new_path = download_path / file_path.name\r\n\r\n            else:\r\n                new_path = generate_non_conflicting_path(file_path=download_path / file_path.name)\r\n\r\n            # str conversion needed only for Python <= 3.8 - https://github.com/python/cpython/issues/76870\r\n            shutil.move(src=str(file_path), dst=new_path)\r\n\r\n    elif len(temp_downloads) > 0:\r\n        archive_path = Path(shutil.make_archive(\r\n            base_name=str(temp_download_path.parent / temp_download_path.name),\r\n            format=ARCHIVE_FORMAT,\r\n            root_dir=temp_download_path,\r\n        ))\r\n\r\n        file_name = generate_media_folder_name(media_data=media_data,\r\n                                               source=scraper.abbreviation) + f\".{ARCHIVE_FORMAT}\"\r\n\r\n        if overwrite_existing:\r\n            destination_path = download_path / file_name\r\n\r\n        else:\r\n            destination_path = generate_non_conflicting_path(file_path=download_path / file_name)\r\n\r\n        shutil.move(src=str(archive_path), dst=destination_path)\r\n\r\n    return SubtitlesDownloadResults(\r\n        media_data=media_data,\r\n        successful_subtitles=successful_downloads,\r\n        failed_subtitles=failed_downloads,\r\n        is_archive=archive,\r\n    )\r\n\r\n\r\ndef handle_log_rotation(log_rotation_size: int) -> None:\r\n    \"\"\"\r\n    Handle log rotation and remove old log files if needed.\r\n\r\n    Args:\r\n        log_rotation_size (int): Maximum amount of log files to keep.\r\n    \"\"\"\r\n    sorted_log_files = sorted(LOG_FILES_PATH.glob(\"*.log\"), key=lambda file: file.stat().st_mtime, reverse=True)\r\n\r\n    if len(sorted_log_files) > log_rotation_size:\r\n        for log_file in sorted_log_files[log_rotation_size:]:\r\n            log_file.unlink()\r\n\r\n\r\ndef generate_media_folder_name(media_data: Movie | Episode, source: str | None = None) -> str:\r\n    \"\"\"\r\n    Generate a folder name for media data.\r\n\r\n    Args:\r\n        media_data (Movie | Episode): A movie or episode data object.\r\n        source (str | None, optional): Abbreviation of the source to use for file names. Defaults to None.\r\n\r\n    Returns:\r\n        str: A folder name for the media data.\r\n    \"\"\"\r\n    if isinstance(media_data, Movie):\r\n        return format_release_name(\r\n            title=media_data.name,\r\n            release_date=media_data.release_date,\r\n            media_source=source,\r\n        )\r\n\r\n    # elif isinstance(media_data, Episode):\r\n    return format_release_name(\r\n        title=media_data.series_name,\r\n        season_number=media_data.season_number,\r\n        episode_number=media_data.episode_number,\r\n        media_source=source,\r\n    )\r\n\r\n\r\ndef generate_temp_media_path(media_data: Movie | Episode, source: str | None = None) -> Path:\r\n    \"\"\"\r\n    Generate a temporary directory for downloading media data.\r\n\r\n    Args:\r\n        media_data (Movie | Episode): A movie or episode data object.\r\n        source (str | None, optional): Abbreviation of the source to use for file names. Defaults to None.\r\n\r\n    Returns:\r\n        Path: A path to the temporary folder.\r\n    \"\"\"\r\n    temp_folder_name = generate_media_folder_name(media_data=media_data, source=source)\r\n    path = generate_non_conflicting_path(file_path=TEMP_FOLDER_PATH / temp_folder_name, has_extension=False)\r\n\r\n    return TempDirGenerator.generate(directory_name=path.name)\r\n\r\n\r\ndef update_settings(config: Config) -> None:\r\n    \"\"\"\r\n    Update settings according to config.\r\n\r\n    Args:\r\n        config (Config): An instance of a config to set settings according to.\r\n    \"\"\"\r\n    Scraper.subtitles_fix_rtl = config.subtitles.fix_rtl\r\n    Scraper.subtitles_remove_duplicates = config.subtitles.remove_duplicates\r\n    Scraper.default_timeout = config.scrapers.default.timeout\r\n    Scraper.default_user_agent = config.scrapers.default.user_agent\r\n    Scraper.default_proxy = config.scrapers.default.proxy\r\n    Scraper.default_verify_ssl = config.scrapers.default.verify_ssl\r\n\r\n    WebVTTCaptionBlock.subrip_alignment_conversion = (\r\n        config.subtitles.webvtt.subrip_alignment_conversion\r\n    )\r\n\r\n    if log_rotation := config.general.log_rotation_size:\r\n        global LOG_ROTATION_SIZE\r\n        LOG_ROTATION_SIZE = log_rotation\r\n\r\n\r\ndef print_usage() -> None:\r\n    \"\"\"Print usage information.\"\"\"\r\n    logger.info(f\"Usage: {PACKAGE_NAME} <iTunes movie URL> [iTunes movie URL...]\")\r\n\r\n\r\ndef setup_loggers(stdout_loglevel: int, file_loglevel: int) -> None:\r\n    \"\"\"\r\n    Configure loggers.\r\n\r\n    Args:\r\n        stdout_loglevel (int): Log level for STDOUT logger.\r\n        file_loglevel (int): Log level for logfile logger.\r\n    \"\"\"\r\n    logger.setLevel(logging.DEBUG)\r\n\r\n    # Setup STDOUT logger\r\n    stdout_handler = logging.StreamHandler(sys.stdout)\r\n    stdout_handler.setLevel(stdout_loglevel)\r\n    stdout_handler.setFormatter(CustomStdoutFormatter())\r\n    logger.addHandler(stdout_handler)\r\n\r\n    # Setup logfile logger\r\n    if not LOG_FILES_PATH.is_dir():\r\n        logger.debug(\"Logs directory could not be found and will be created.\")\r\n        LOG_FILES_PATH.mkdir()\r\n\r\n    logfile_path = generate_non_conflicting_path(file_path=LOG_FILES_PATH / LOG_FILE_NAME)\r\n    logfile_handler = logging.FileHandler(filename=logfile_path, encoding=\"utf-8\")\r\n    logfile_handler.setLevel(file_loglevel)\r\n    logfile_handler.setFormatter(CustomLogFileFormatter())\r\n    logger.debug(f\"Log file location: '{logfile_path}'\")\r\n    logger.addHandler(logfile_handler)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/__main__.py b/isubrip/__main__.py
--- a/isubrip/__main__.py	(revision e867c18c611a905d9dffebbb90f312b95abcef7b)
+++ b/isubrip/__main__.py	(date 1725475231282)
@@ -61,7 +61,7 @@
         if not DATA_FOLDER_PATH.is_dir():
             DATA_FOLDER_PATH.mkdir(parents=True)
 
-        setup_loggers(stdout_loglevel=logging.INFO,
+        setup_loggers(stdout_loglevel=logging.DEBUG,
                       file_loglevel=logging.DEBUG)
 
         cli_args = " ".join(sys.argv[1:])
@@ -96,6 +96,7 @@
         exit(1)
 
     finally:
+        # TODO: Change from const. Perhaps utilize `setup_loggers` or `update_settings` to set log rotation size.
         if log_rotation_size := LOG_ROTATION_SIZE:
             handle_log_rotation(log_rotation_size=log_rotation_size)
 
Index: isubrip/config.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nfrom abc import ABC\r\nfrom pathlib import Path\r\nfrom typing import TYPE_CHECKING, List, Tuple, Type\r\n\r\nfrom pydantic import BaseModel, ConfigDict, Field, create_model, field_validator\r\nfrom pydantic_core._pydantic_core import PydanticCustomError\r\nfrom pydantic_settings import BaseSettings, PydanticBaseSettingsSource, SettingsConfigDict, TomlConfigSettingsSource\r\n\r\nfrom isubrip.constants import USER_CONFIG_FILE_PATH\r\nfrom isubrip.scrapers.scraper import DefaultScraperConfig, ScraperFactory\r\nfrom isubrip.utils import normalize_config_name\r\n\r\n\r\nclass ConfigCategory(BaseModel, ABC):\r\n    \"\"\"A base class for settings categories.\"\"\"\r\n    model_config = ConfigDict(\r\n        extra='allow',\r\n        alias_generator=normalize_config_name,\r\n    )\r\n\r\n\r\nclass GeneralCategory(ConfigCategory):\r\n    check_for_updates: bool = Field(default=True)\r\n    log_rotation_size: int = Field(default=15)\r\n\r\n\r\nclass DownloadsCategory(ConfigCategory):\r\n    folder: Path = Field(default=Path.cwd().resolve())\r\n    languages: List[str] = Field(default=[])\r\n    overwrite_existing: bool = Field(default=False)\r\n    zip: bool = Field(default=False)\r\n\r\n    @field_validator('folder')\r\n    @classmethod\r\n    def assure_path_exists(cls, value: Path) -> Path:\r\n        if value.exists():\r\n            if not value.is_dir():\r\n                raise PydanticCustomError(\r\n                    \"invalid_path\",\r\n                    \"Path is not a directory.\",\r\n                )\r\n\r\n        else:\r\n            raise PydanticCustomError(\r\n                \"invalid_path\",\r\n                \"Path does not exist.\")\r\n\r\n        return value\r\n\r\n\r\nclass WebVTTSubcategory(ConfigCategory):\r\n    subrip_alignment_conversion: bool = Field(default=False)\r\n\r\n\r\nclass SubtitlesCategory(ConfigCategory):\r\n    fix_rtl: bool = Field(default=False)\r\n    remove_duplicates: bool = Field(default=True)\r\n    convert_to_srt: bool = Field(default=False)\r\n    webvtt: WebVTTSubcategory = WebVTTSubcategory()\r\n\r\n\r\nclass ScrapersCategory(ConfigCategory):\r\n    default: DefaultScraperConfig = Field(default_factory=DefaultScraperConfig)\r\n\r\n\r\n# Resolve mypy errors as mypy doesn't support dynamic models.\r\nif TYPE_CHECKING:\r\n    DynamicScrapersCategory = ScrapersCategory\r\n\r\nelse:\r\n    # A config model that's dynamically created based on the available scrapers and their configurations.\r\n    DynamicScrapersCategory = create_model(\r\n        'DynamicScrapersCategory',\r\n        __base__=ScrapersCategory,\r\n        **{\r\n            scraper.id: (scraper.ScraperConfig, Field(default_factory=scraper.ScraperConfig))\r\n            for scraper in ScraperFactory.get_scraper_classes()\r\n        },  # type: ignore[call-overload]\r\n    )\r\n\r\n\r\nclass Config(BaseSettings):\r\n    model_config = SettingsConfigDict(\r\n        extra='forbid',\r\n        alias_generator=normalize_config_name,\r\n        toml_file=USER_CONFIG_FILE_PATH,\r\n    )\r\n\r\n    general: GeneralCategory = Field(default_factory=GeneralCategory)\r\n    downloads: DownloadsCategory = Field(default_factory=DownloadsCategory)\r\n    subtitles: SubtitlesCategory = Field(default_factory=SubtitlesCategory)\r\n    scrapers: DynamicScrapersCategory = Field(default_factory=DynamicScrapersCategory)\r\n\r\n    @classmethod\r\n    def settings_customise_sources(\r\n        cls,\r\n        settings_cls: Type[BaseSettings],\r\n        init_settings: PydanticBaseSettingsSource,\r\n        env_settings: PydanticBaseSettingsSource,\r\n        dotenv_settings: PydanticBaseSettingsSource,\r\n        file_secret_settings: PydanticBaseSettingsSource,\r\n    ) -> Tuple[PydanticBaseSettingsSource, ...]:\r\n        return (\r\n            init_settings,\r\n            TomlConfigSettingsSource(settings_cls),\r\n            env_settings,\r\n            dotenv_settings,\r\n            file_secret_settings,\r\n        )\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/config.py b/isubrip/config.py
--- a/isubrip/config.py	(revision ea78d7310b108e0a7e0392d467d7b2aef5731fea)
+++ b/isubrip/config.py	(date 1725475231288)
@@ -28,7 +28,7 @@
 
 class DownloadsCategory(ConfigCategory):
     folder: Path = Field(default=Path.cwd().resolve())
-    languages: List[str] = Field(default=[])
+    languages: List[str] = Field(default=[])  # TODO: Use Pydantic's Language type.
     overwrite_existing: bool = Field(default=False)
     zip: bool = Field(default=False)
 
Index: pyproject.toml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>[tool.poetry]\r\nname = \"isubrip\"\r\nversion = \"2.5.6\"\r\ndescription = \"A Python package for scraping and downloading subtitles from AppleTV / iTunes movie pages.\"\r\nlicense = \"MIT\"\r\nauthors = [\"Michael Yochpaz\"]\r\nreadme = \"README.md\"\r\nhomepage = \"https://github.com/MichaelYochpaz/iSubRip\"\r\nrepository = \"https://github.com/MichaelYochpaz/iSubRip\"\r\nkeywords = [\r\n    \"iTunes\",\r\n    \"AppleTV\",\r\n    \"movies\",\r\n    \"subtitles\",\r\n    \"scrape\",\r\n    \"scraper\",\r\n    \"download\",\r\n    \"m3u8\"\r\n]\r\nclassifiers = [\r\n    \"Development Status :: 5 - Production/Stable\",\r\n    \"Intended Audience :: End Users/Desktop\",\r\n    \"Intended Audience :: Developers\",\r\n    \"Operating System :: Microsoft :: Windows\",\r\n    \"Operating System :: MacOS\",\r\n    \"Operating System :: POSIX :: Linux\",\r\n    \"Topic :: Utilities\",\r\n    \"License :: OSI Approved :: MIT License\",\r\n    \"Programming Language :: Python :: 3.8\",\r\n    \"Programming Language :: Python :: 3.9\",\r\n    \"Programming Language :: Python :: 3.10\",\r\n    \"Programming Language :: Python :: 3.11\",\r\n    \"Programming Language :: Python :: 3.12\",\r\n]\r\npackages = [\r\n    { include = \"isubrip\" },\r\n]\r\ninclude = [\r\n    \"isubrip/resources\", \"README.md\", \"LICENSE\"\r\n]\r\n\r\n[tool.mypy]\r\ncheck_untyped_defs = true\r\ndisallow_untyped_defs = true\r\nexplicit_package_bases = true\r\nignore_missing_imports = true\r\npython_version = \"3.8\"\r\nwarn_return_any = true\r\nplugins = [\r\n    \"pydantic.mypy\"\r\n]\r\n\r\n[tool.poetry.scripts]\r\nisubrip = \"isubrip.__main__:main\"\r\n\r\n[tool.poetry.urls]\r\n\"Bug Reports\" = \"https://github.com/MichaelYochpaz/iSubRip/issues\"\r\n\r\n[tool.poetry.dependencies]\r\npython = \"^3.8\"\r\nhttpx = {extras = [\"http2\"], version = \"^0.27.0\"}\r\nm3u8 = \"^4.1.0\"\r\npydantic = \"^2.7.0\"\r\ntomli = \"^2.0.1\"\r\n\r\n\r\n[tool.poetry.group.dev.dependencies]\r\nmypy = \"^1.10.0\"\r\nruff = \"^0.4.2\"\r\n\r\n[build-system]\r\nrequires = [\"poetry-core\"]\r\nbuild-backend = \"poetry.core.masonry.api\"\r\n\r\n[tool.poetry_bumpversion.file.\"isubrip/constants.py\"]\r\nsearch = 'PACKAGE_VERSION = \"{current_version}\"'\r\nreplace = 'PACKAGE_VERSION = \"{new_version}\"'\r\n\r\n\r\n[tool.ruff]\r\nline-length = 120\r\ntarget-version = \"py38\"\r\n\r\n[tool.ruff.lint]\r\nselect = [\r\n    \"ARG\",\r\n    \"ASYNC\",\r\n    \"B\",\r\n    \"C4\",\r\n    \"COM\",\r\n    \"E\",\r\n    \"F\",\r\n    \"FA\",\r\n    \"I\",\r\n    \"INP\",\r\n    \"ISC\",\r\n    \"N\",\r\n    \"PIE\",\r\n    \"PGH\",\r\n    \"PT\",\r\n    \"PTH\",\r\n    \"Q\",\r\n    \"RSE\",\r\n    \"RET\",\r\n    \"RUF\",\r\n    \"S\",\r\n    \"SIM\",\r\n    \"SLF\",\r\n    \"T20\",\r\n    \"TCH\",\r\n    \"TID\",\r\n    \"TRY\",\r\n    \"UP\",\r\n]\r\nignore = [\r\n    \"C416\",\r\n    \"Q000\",\r\n    \"RUF010\",\r\n    \"RUF012\",\r\n    \"SIM108\",\r\n    \"TD002\",\r\n    \"TD003\",\r\n    \"TRY003\",\r\n]\r\nunfixable = [\"ARG\"]\r\n\r\n[tool.ruff.lint.flake8-tidy-imports]\r\nban-relative-imports = \"all\"\r\n\r\n[tool.ruff.lint.flake8-quotes]\r\ndocstring-quotes = \"double\"\r\n\r\n[tool.ruff.lint.isort]\r\nforce-sort-within-sections = true\r\n\r\n[tool.ruff.lint.pyupgrade]\r\nkeep-runtime-typing = true
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/pyproject.toml b/pyproject.toml
--- a/pyproject.toml	(revision ea78d7310b108e0a7e0392d467d7b2aef5731fea)
+++ b/pyproject.toml	(date 1725475231302)
@@ -57,7 +57,7 @@
 "Bug Reports" = "https://github.com/MichaelYochpaz/iSubRip/issues"
 
 [tool.poetry.dependencies]
-python = "^3.8"
+python = "^3.8"  # TODO: Update to 3.9
 httpx = {extras = ["http2"], version = "^0.27.0"}
 m3u8 = "^4.1.0"
 pydantic = "^2.7.0"
