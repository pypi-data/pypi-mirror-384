Index: isubrip/__main__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nimport asyncio\r\nimport logging\r\nfrom pathlib import Path\r\nimport shutil\r\nimport sys\r\nfrom typing import List, Union\r\n\r\nimport httpx\r\n\r\nfrom isubrip.config import Config, ConfigError, ConfigSetting, SpecialConfigType\r\nfrom isubrip.constants import (\r\n    ARCHIVE_FORMAT,\r\n    DATA_FOLDER_PATH,\r\n    DEFAULT_CONFIG_PATH,\r\n    EVENT_LOOP,\r\n    LOG_FILE_NAME,\r\n    LOG_FILES_PATH,\r\n    PACKAGE_NAME,\r\n    PACKAGE_VERSION,\r\n    PREORDER_MESSAGE,\r\n    TEMP_FOLDER_PATH,\r\n    USER_CONFIG_FILE,\r\n)\r\nfrom isubrip.data_structures import (\r\n    Episode,\r\n    MediaData,\r\n    Movie,\r\n    ScrapedMediaResponse,\r\n    Season,\r\n    Series,\r\n    SubtitlesData,\r\n    SubtitlesDownloadResults,\r\n)\r\nfrom isubrip.logger import CustomLogFileFormatter, CustomStdoutFormatter, logger\r\nfrom isubrip.scrapers.scraper import PlaylistLoadError, Scraper, ScraperError, ScraperFactory, SubtitlesDownloadError\r\nfrom isubrip.subtitle_formats.webvtt import WebVTTCaptionBlock\r\nfrom isubrip.utils import (\r\n    TempDirGenerator,\r\n    download_subtitles_to_file,\r\n    format_media_description,\r\n    format_release_name,\r\n    format_subtitles_description,\r\n    generate_non_conflicting_path,\r\n    raise_for_status,\r\n    single_to_list,\r\n)\r\n\r\nLOG_ROTATION_SIZE: int | None = None\r\n\r\nBASE_CONFIG_SETTINGS = [\r\n    ConfigSetting(\r\n        key=\"check-for-updates\",\r\n        value_type=bool,\r\n        category=\"general\",\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"log_rotation_size\",\r\n        value_type=str,\r\n        category=\"general\",\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"add-release-year-to-series\",\r\n        value_type=bool,\r\n        category=\"downloads\",\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"folder\",\r\n        value_type=str,\r\n        category=\"downloads\",\r\n        required=True,\r\n        special_type=SpecialConfigType.EXISTING_FOLDER_PATH,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"languages\",\r\n        value_type=List[str],\r\n        category=\"downloads\",\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"overwrite-existing\",\r\n        value_type=bool,\r\n        category=\"downloads\",\r\n        required=True,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"zip\",\r\n        value_type=bool,\r\n        category=\"downloads\",\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"fix-rtl\",\r\n        value_type=bool,\r\n        category=\"subtitles\",\r\n        required=True,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"rtl-languages\",\r\n        value_type=List[str],\r\n        category=\"subtitles\",\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"remove-duplicates\",\r\n        value_type=bool,\r\n        category=\"subtitles\",\r\n        required=True,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"convert-to-srt\",\r\n        value_type=bool,\r\n        category=\"subtitles\",\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"subrip-alignment-conversion\",\r\n        value_type=bool,\r\n        category=(\"subtitles\", \"webvtt\"),\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"timeout\",\r\n        value_type=Union[int, float],\r\n        category=\"scrapers\",\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"user-agent\",\r\n        value_type=str,\r\n        category=\"scrapers\",\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"proxy\",\r\n        value_type=str,\r\n        category=\"scrapers\",\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"verify-ssl\",\r\n        value_type=bool,\r\n        category=\"scrapers\",\r\n        required=False,\r\n    ),\r\n]\r\n\r\n\r\ndef main() -> None:\r\n    try:\r\n        # Assure at least one argument was passed\r\n        if len(sys.argv) < 2:\r\n            print_usage()\r\n            exit(0)\r\n\r\n        if not DATA_FOLDER_PATH.is_dir():\r\n            DATA_FOLDER_PATH.mkdir(parents=True)\r\n\r\n        setup_loggers(stdout_loglevel=logging.INFO,\r\n                      file_loglevel=logging.DEBUG)\r\n\r\n        cli_args = \" \".join(sys.argv[1:])\r\n        logger.debug(f\"CLI Command: {PACKAGE_NAME} {cli_args}\")\r\n        logger.debug(f\"Python version: {sys.version}\")\r\n        logger.debug(f\"Package version: {PACKAGE_VERSION}\")\r\n        logger.debug(f\"OS: {sys.platform}\")\r\n\r\n        config = generate_config()\r\n        update_settings(config)\r\n\r\n        if config.general.get(\"check-for-updates\", True):\r\n            check_for_updates(current_package_version=PACKAGE_VERSION)\r\n\r\n        urls = single_to_list(sys.argv[1:])\r\n        EVENT_LOOP.run_until_complete(download(urls=urls, config=config))\r\n\r\n    except Exception as ex:\r\n        logger.error(f\"Error: {ex}\")\r\n        logger.debug(\"Debug information:\", exc_info=True)\r\n        exit(1)\r\n\r\n    finally:\r\n        if log_rotation_size := LOG_ROTATION_SIZE:\r\n            handle_log_rotation(log_rotation_size=log_rotation_size)\r\n\r\n        # NOTE: This will only close scrapers that were initialized using the ScraperFactory.\r\n        async_cleanup_coroutines = []\r\n        for scraper in ScraperFactory.get_initialized_scrapers():\r\n            # Log scraper.requests_count\r\n            logger.debug(f\"Requests count for '{scraper.name}' scraper: {scraper.requests_count}\")\r\n            scraper.close()\r\n            async_cleanup_coroutines.append(scraper.async_close())\r\n\r\n        EVENT_LOOP.run_until_complete(asyncio.gather(*async_cleanup_coroutines))\r\n        TempDirGenerator.cleanup()\r\n\r\n\r\nasync def download(urls: list[str], config: Config) -> None:\r\n    \"\"\"\r\n    Download subtitles from a given URL.\r\n\r\n    Args:\r\n        urls (list[str]): A list of URLs to download subtitles from.\r\n        config (Config): A config to use for downloading subtitles.\r\n    \"\"\"\r\n    for url in urls:\r\n        try:\r\n            logger.info(f\"Scraping '{url}'...\")\r\n\r\n            scraper = ScraperFactory.get_scraper_instance(url=url,\r\n                                                          kwargs={\"config_data\": config.data.get(\"scrapers\")},\r\n                                                          extract_scraper_config=True)\r\n            scraper.config.check()  # Recheck config after scraper settings were loaded\r\n\r\n            try:\r\n                logger.debug(f\"Fetching '{url}'...\")\r\n                scraper_response: ScrapedMediaResponse = await scraper.get_data(url=url)\r\n\r\n            except ScraperError as e:\r\n                logger.error(f\"Error: {e}\")\r\n                logger.debug(\"Debug information:\", exc_info=True)\r\n                continue\r\n\r\n            media_data = scraper_response.media_data\r\n            playlist_scraper = ScraperFactory.get_scraper_instance(scraper_id=scraper_response.playlist_scraper,\r\n                                                                   kwargs={\"config_data\": config.data.get(\"scrapers\")},\r\n                                                                   extract_scraper_config=True)\r\n\r\n            if not media_data:\r\n                logger.error(f\"Error: No supported media was found for {url}.\")\r\n                continue\r\n\r\n            for media_item in media_data:\r\n                try:\r\n                    logger.info(f\"Found {media_item.media_type}: {format_media_description(media_data=media_item)}\")\r\n                    await download_media(scraper=playlist_scraper, media_item=media_item, config=config)\r\n\r\n                except Exception as e:\r\n                    if len(media_data) > 1:\r\n                        logger.warning(f\"Error scraping media item \"\r\n                                       f\"'{format_media_description(media_data=media_item)}': {e}\\n\"\r\n                                       f\"Skipping to next media item...\")\r\n                        logger.debug(\"Debug information:\", exc_info=True)\r\n                        continue\r\n\r\n                    raise\r\n\r\n        except Exception as e:\r\n            logger.error(f\"Error while scraping '{url}': {e}\")\r\n            logger.debug(\"Debug information:\", exc_info=True)\r\n            continue\r\n\r\n\r\nasync def download_media(scraper: Scraper, media_item: MediaData, config: Config) -> None:\r\n    \"\"\"\r\n    Download a media item.\r\n\r\n    Args:\r\n        scraper (Scraper): A Scraper object to use for downloading subtitles.\r\n        media_item (MediaData): A media data item to download subtitles for.\r\n        config (Config): A config to use for downloading subtitles.\r\n    \"\"\"\r\n    if isinstance(media_item, Series):\r\n        for season in media_item.seasons:\r\n            await download_media(scraper=scraper, media_item=season, config=config)\r\n\r\n    elif isinstance(media_item, Season):\r\n        for episode in media_item.episodes:\r\n            logger.info(f\"{format_media_description(media_data=episode, shortened=True)}:\")\r\n            await download_media_item(scraper=scraper, media_item=episode, config=config)\r\n\r\n    elif isinstance(media_item, (Movie, Episode)):\r\n        await download_media_item(scraper=scraper, media_item=media_item, config=config)\r\n\r\n\r\nasync def download_media_item(scraper: Scraper, media_item: Movie | Episode, config: Config) -> None:\r\n    if media_item.playlist:\r\n        download_subtitles_kwargs = {\r\n            \"download_path\": Path(config.downloads[\"folder\"]),\r\n            \"language_filter\": config.downloads.get(\"languages\"),\r\n            \"convert_to_srt\": config.subtitles.get(\"convert-to-srt\", False),\r\n            \"overwrite_existing\": config.downloads.get(\"overwrite-existing\", False),\r\n            \"zip_files\": config.downloads.get(\"zip\", False),\r\n        }\r\n\r\n        try:\r\n            results = await download_subtitles(scraper=scraper,\r\n                                               media_data=media_item,\r\n                                               **download_subtitles_kwargs)\r\n\r\n            success_count = len(results.successful_subtitles)\r\n            failed_count = len(results.failed_subtitles)\r\n\r\n            if success_count or failed_count:\r\n                logger.info(f\"{success_count}/{success_count + failed_count} matching subtitles \"\r\n                            f\"were successfully downloaded.\")\r\n\r\n            else:\r\n                logger.info(\"No matching subtitles were found.\")\r\n\r\n            return  # noqa: TRY300\r\n\r\n        except PlaylistLoadError:\r\n            pass\r\n\r\n    # We get here if there is no playlist, or there is one, but it failed to load\r\n    if isinstance(media_item, Movie) and media_item.preorder_availability_date:\r\n        preorder_date_str = media_item.preorder_availability_date.strftime(\"%Y-%m-%d\")\r\n        logger.info(PREORDER_MESSAGE.format(movie_name=media_item.name, scraper_name=scraper.name,\r\n                                            preorder_date=preorder_date_str))\r\n\r\n    else:\r\n        logger.error(\"No valid playlist was found.\")\r\n\r\n\r\ndef check_for_updates(current_package_version: str) -> None:\r\n    \"\"\"\r\n    Check and print if a newer version of the package is available, and log accordingly.\r\n\r\n    Args:\r\n        current_package_version (str): The current version of the package.\r\n    \"\"\"\r\n    api_url = f\"https://pypi.org/pypi/{PACKAGE_NAME}/json\"\r\n    logger.debug(\"Checking for package updates on PyPI...\")\r\n    try:\r\n        response = httpx.get(\r\n            url=api_url,\r\n            headers={\"Accept\": \"application/json\"},\r\n            timeout=5,\r\n        )\r\n        raise_for_status(response)\r\n        response_data = response.json()\r\n\r\n        pypi_latest_version = response_data[\"info\"][\"version\"]\r\n\r\n        if pypi_latest_version != current_package_version:\r\n            logger.warning(f\"You are currently using version '{current_package_version}' of '{PACKAGE_NAME}', \"\r\n                           f\"however version '{pypi_latest_version}' is available.\"\r\n                           f'\\nConsider upgrading by running \"pip install --upgrade {PACKAGE_NAME}\"\\n')\r\n\r\n        else:\r\n            logger.debug(f\"Latest version of '{PACKAGE_NAME}' ({current_package_version}) is currently installed.\")\r\n\r\n    except Exception as e:\r\n        logger.warning(f\"Update check failed: {e}\")\r\n        logger.debug(\"Debug information:\", exc_info=True)\r\n        return\r\n\r\n\r\nasync def download_subtitles(scraper: Scraper, media_data: Movie | Episode, download_path: Path,\r\n                             language_filter: list[str] | None = None, convert_to_srt: bool = False,\r\n                             overwrite_existing: bool = True, zip_files: bool = False) -> SubtitlesDownloadResults:\r\n    \"\"\"\r\n    Download subtitles for the given media data.\r\n\r\n    Args:\r\n        scraper (Scraper): A Scraper object to use for downloading subtitles.\r\n        media_data (Movie | Episode): A movie or episode data object.\r\n        download_path (Path): Path to a folder where the subtitles will be downloaded to.\r\n        language_filter (list[str] | None): List of specific languages to download subtitles for.\r\n            None for all languages (no filter). Defaults to None.\r\n        convert_to_srt (bool, optional): Whether to convert the subtitles to SRT format. Defaults to False.\r\n        overwrite_existing (bool, optional): Whether to overwrite existing subtitles. Defaults to True.\r\n        zip_files (bool, optional): Whether to unite the subtitles into a single zip file\r\n            (only if there are multiple subtitles).\r\n\r\n    Returns:\r\n        SubtitlesDownloadResults: A SubtitlesDownloadResults object containing the results of the download.\r\n    \"\"\"\r\n    temp_dir_name = generate_media_folder_name(media_data=media_data, source=scraper.abbreviation)\r\n    temp_download_path = TempDirGenerator.generate(directory_name=temp_dir_name)\r\n\r\n    successful_downloads: list[SubtitlesData] = []\r\n    failed_downloads: list[SubtitlesDownloadError] = []\r\n    temp_downloads: list[Path] = []\r\n\r\n    if not media_data.playlist:\r\n        raise PlaylistLoadError(\"No playlist was found for provided media data.\")\r\n\r\n    main_playlist = await scraper.load_playlist(url=media_data.playlist)\r\n    matching_subtitles = scraper.find_matching_subtitles(main_playlist=main_playlist,  # type: ignore[var-annotated]\r\n                                                         language_filter=language_filter)\r\n\r\n    logger.debug(f\"{len(matching_subtitles)} matching subtitles were found.\")\r\n\r\n    for matching_subtitles_item in matching_subtitles:\r\n        subtitles_data = await scraper.download_subtitles(media_data=matching_subtitles_item,\r\n                                                          subrip_conversion=convert_to_srt)\r\n        language_info = format_subtitles_description(language_code=subtitles_data.language_code,\r\n                                                     language_name=subtitles_data.language_name,\r\n                                                     special_type=subtitles_data.special_type)\r\n\r\n        if isinstance(subtitles_data, SubtitlesDownloadError):\r\n            logger.warning(f\"Failed to download '{language_info}' subtitles. Skipping...\")\r\n            logger.debug(\"Debug information:\", exc_info=subtitles_data.original_exc)\r\n            failed_downloads.append(subtitles_data)\r\n            continue\r\n\r\n        try:\r\n            temp_downloads.append(download_subtitles_to_file(\r\n                media_data=media_data,\r\n                subtitles_data=subtitles_data,\r\n                output_path=temp_download_path,\r\n                source_abbreviation=scraper.abbreviation,\r\n                overwrite=overwrite_existing,\r\n            ))\r\n\r\n            logger.info(f\"'{language_info}' subtitles were successfully downloaded.\")\r\n            successful_downloads.append(subtitles_data)\r\n\r\n        except Exception as e:\r\n            logger.error(f\"Error: Failed to save '{language_info}' subtitles: {e}\")\r\n            logger.debug(\"Debug information:\", exc_info=True)\r\n            failed_downloads.append(\r\n                SubtitlesDownloadError(\r\n                    language_code=subtitles_data.language_code,\r\n                    language_name=subtitles_data.language_name,\r\n                    special_type=subtitles_data.special_type,\r\n                    original_exc=e,\r\n                ),\r\n            )\r\n\r\n    if not zip_files or len(temp_downloads) == 1:\r\n        for file_path in temp_downloads:\r\n            if overwrite_existing:\r\n                new_path = download_path / file_path.name\r\n\r\n            else:\r\n                new_path = generate_non_conflicting_path(file_path=download_path / file_path.name)\r\n\r\n            # str conversion needed only for Python <= 3.8 - https://github.com/python/cpython/issues/76870\r\n            shutil.move(src=str(file_path), dst=new_path)\r\n\r\n    elif len(temp_downloads) > 0:\r\n        archive_path = Path(shutil.make_archive(\r\n            base_name=str(temp_download_path.parent / temp_download_path.name),\r\n            format=ARCHIVE_FORMAT,\r\n            root_dir=temp_download_path,\r\n        ))\r\n\r\n        file_name = generate_media_folder_name(media_data=media_data,\r\n                                               source=scraper.abbreviation) + f\".{ARCHIVE_FORMAT}\"\r\n\r\n        if overwrite_existing:\r\n            destination_path = download_path / file_name\r\n\r\n        else:\r\n            destination_path = generate_non_conflicting_path(file_path=download_path / file_name)\r\n\r\n        shutil.move(src=str(archive_path), dst=destination_path)\r\n\r\n    return SubtitlesDownloadResults(\r\n        media_data=media_data,\r\n        successful_subtitles=successful_downloads,\r\n        failed_subtitles=failed_downloads,\r\n        is_zip=zip_files,\r\n    )\r\n\r\n\r\ndef handle_log_rotation(log_rotation_size: int) -> None:\r\n    \"\"\"\r\n    Handle log rotation and remove old log files if needed.\r\n\r\n    Args:\r\n        log_rotation_size (int): Maximum amount of log files to keep.\r\n    \"\"\"\r\n    sorted_log_files = sorted(LOG_FILES_PATH.glob(\"*.log\"), key=lambda file: file.stat().st_mtime, reverse=True)\r\n\r\n    if len(sorted_log_files) > log_rotation_size:\r\n        for log_file in sorted_log_files[log_rotation_size:]:\r\n            log_file.unlink()\r\n\r\n\r\ndef generate_config() -> Config:\r\n    \"\"\"\r\n    Generate a config object using config files, and validate it.\r\n\r\n    Returns:\r\n        Config: A config object.\r\n\r\n    Raises:\r\n        ConfigException: If there is a general config error.\r\n        MissingConfigValue: If a required config value is missing.\r\n        InvalidConfigValue: If a config value is invalid.\r\n    \"\"\"\r\n    if not DEFAULT_CONFIG_PATH.is_file():\r\n        raise ConfigError(\"Default config file could not be found.\")\r\n\r\n    config = Config(config_settings=BASE_CONFIG_SETTINGS)\r\n\r\n    logger.debug(\"Loading default config data...\")\r\n\r\n    with DEFAULT_CONFIG_PATH.open('r') as data:\r\n        config.loads(config_data=data.read(), check_config=True)\r\n\r\n    logger.debug(\"Default config data loaded and validated successfully.\")\r\n\r\n    # If logs folder doesn't exist, create it (also handles data folder)\r\n    if not DATA_FOLDER_PATH.is_dir():\r\n        logger.debug(f\"'{DATA_FOLDER_PATH}' directory could not be found and will be created.\")\r\n        DATA_FOLDER_PATH.mkdir(parents=True, exist_ok=True)\r\n        LOG_FILES_PATH.mkdir()\r\n\r\n    else:\r\n        if not LOG_FILES_PATH.is_dir():\r\n            logger.debug(f\"'{LOG_FILES_PATH}' directory could not be found and will be created.\")\r\n            LOG_FILES_PATH.mkdir()\r\n\r\n        # If a user config file exists, add it to config_files\r\n        if USER_CONFIG_FILE.is_file():\r\n            logger.info(f\"User config file detected at '{USER_CONFIG_FILE}' and will be used.\")\r\n\r\n            with USER_CONFIG_FILE.open('r') as data:\r\n                config.loads(config_data=data.read(), check_config=True)\r\n\r\n            logger.debug(\"User config file loaded and validated successfully.\")\r\n\r\n    return config\r\n\r\n\r\ndef generate_media_folder_name(media_data: Movie | Episode, source: str | None = None) -> str:\r\n    \"\"\"\r\n    Generate a folder name for media data.\r\n\r\n    Args:\r\n        media_data (Movie | Episode): A movie or episode data object.\r\n        source (str | None, optional): Abbreviation of the source to use for file names. Defaults to None.\r\n\r\n    Returns:\r\n        str: A folder name for the media data.\r\n    \"\"\"\r\n    if isinstance(media_data, Movie):\r\n        return format_release_name(\r\n            title=media_data.name,\r\n            release_date=media_data.release_date,\r\n            media_source=source,\r\n        )\r\n\r\n    # elif isinstance(media_data, Episode):\r\n    return format_release_name(\r\n        title=media_data.series_name,\r\n        season_number=media_data.season_number,\r\n        episode_number=media_data.episode_number,\r\n        media_source=source,\r\n    )\r\n\r\n\r\ndef generate_temp_media_path(media_data: Movie | Episode, source: str | None = None) -> Path:\r\n    \"\"\"\r\n    Generate a temporary directory for downloading media data.\r\n\r\n    Args:\r\n        media_data (Movie | Episode): A movie or episode data object.\r\n        source (str | None, optional): Abbreviation of the source to use for file names. Defaults to None.\r\n\r\n    Returns:\r\n        Path: A path to the temporary folder.\r\n    \"\"\"\r\n    temp_folder_name = generate_media_folder_name(media_data=media_data, source=source)\r\n    path = generate_non_conflicting_path(file_path=TEMP_FOLDER_PATH / temp_folder_name, has_extension=False)\r\n\r\n    return TempDirGenerator.generate(directory_name=path.name)\r\n\r\n\r\ndef update_settings(config: Config) -> None:\r\n    \"\"\"\r\n    Update settings according to config.\r\n\r\n    Args:\r\n        config (Config): An instance of a config to set settings according to.\r\n    \"\"\"\r\n    Scraper.subtitles_fix_rtl = config.subtitles[\"fix-rtl\"]\r\n    Scraper.subtitles_remove_duplicates = config.subtitles[\"remove-duplicates\"]\r\n    Scraper.default_timeout = config.scrapers.get(\"timeout\", 10)\r\n    Scraper.default_user_agent = config.scrapers.get(\"user-agent\", httpx._client.USER_AGENT)  # noqa: SLF001\r\n    Scraper.default_proxy = config.scrapers.get(\"proxy\")\r\n    Scraper.default_verify_ssl = config.scrapers.get(\"verify-ssl\", True)\r\n\r\n    if not Scraper.default_verify_ssl:\r\n        import urllib3\r\n        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\r\n\r\n    WebVTTCaptionBlock.subrip_alignment_conversion = (\r\n        config.subtitles.get(\"webvtt\", {}).get(\"subrip-alignment-conversion\", False)\r\n    )\r\n\r\n    if log_rotation := config.general.get(\"log-rotation-size\"):\r\n        global LOG_ROTATION_SIZE\r\n        LOG_ROTATION_SIZE = log_rotation\r\n\r\n\r\ndef print_usage() -> None:\r\n    \"\"\"Print usage information.\"\"\"\r\n    logger.info(f\"Usage: {PACKAGE_NAME} <iTunes movie URL> [iTunes movie URL...]\")\r\n\r\n\r\ndef setup_loggers(stdout_loglevel: int, file_loglevel: int) -> None:\r\n    \"\"\"\r\n    Configure loggers.\r\n\r\n    Args:\r\n        stdout_loglevel (int): Log level for STDOUT logger.\r\n        file_loglevel (int): Log level for logfile logger.\r\n    \"\"\"\r\n    logger.setLevel(logging.DEBUG)\r\n\r\n    # Setup STDOUT logger\r\n    stdout_handler = logging.StreamHandler(sys.stdout)\r\n    stdout_handler.setLevel(stdout_loglevel)\r\n    stdout_handler.setFormatter(CustomStdoutFormatter())\r\n    logger.addHandler(stdout_handler)\r\n\r\n    # Setup logfile logger\r\n    if not LOG_FILES_PATH.is_dir():\r\n        logger.debug(\"Logs directory could not be found and will be created.\")\r\n        LOG_FILES_PATH.mkdir()\r\n\r\n    logfile_path = generate_non_conflicting_path(file_path=LOG_FILES_PATH / LOG_FILE_NAME)\r\n    logfile_handler = logging.FileHandler(filename=logfile_path, encoding=\"utf-8\")\r\n    logfile_handler.setLevel(file_loglevel)\r\n    logfile_handler.setFormatter(CustomLogFileFormatter())\r\n    logger.debug(f\"Log file location: '{logfile_path}'\")\r\n    logger.addHandler(logfile_handler)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/__main__.py b/isubrip/__main__.py
--- a/isubrip/__main__.py	(revision f040b9612ca4349900c8d4bb1178838dc8a97be1)
+++ b/isubrip/__main__.py	(date 1723577783348)
@@ -8,6 +8,7 @@
 from typing import List, Union
 
 import httpx
+import typer
 
 from isubrip.config import Config, ConfigError, ConfigSetting, SpecialConfigType
 from isubrip.constants import (
@@ -149,6 +150,7 @@
     ),
 ]
 
+app = typer.Typer()
 
 def main() -> None:
     try:
@@ -198,6 +200,22 @@
         EVENT_LOOP.run_until_complete(asyncio.gather(*async_cleanup_coroutines))
         TempDirGenerator.cleanup()
 
+@app.command(name="download")
+def download_command(urls: List[str]) -> None:
+    """
+    Download subtitles from a given URL.
+
+    Args:
+        urls (List[str]): A list of URLs to download subtitles from.
+    """
+    try:
+        EVENT_LOOP.run_until_complete(download(urls=urls, config=config))
+
+    except Exception as ex:
+        logger.error(f"Error: {ex}")
+        logger.debug("Debug information:", exc_info=True)
+        exit(1)
+
 
 async def download(urls: list[str], config: Config) -> None:
     """
@@ -628,4 +646,5 @@
 
 
 if __name__ == "__main__":
-    main()
+    # TODO: when installed, `main` is ran by default.
+    app()
Index: isubrip/config.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nfrom copy import deepcopy\r\nfrom enum import Enum\r\nfrom pathlib import Path\r\nimport typing\r\nfrom typing import Any, NamedTuple, Type\r\n\r\nfrom mergedeep import merge\r\nimport tomli\r\n\r\nfrom isubrip.utils import check_type, single_to_list\r\n\r\n\r\nclass DuplicateBehavior(Enum):\r\n    \"\"\"\r\n    An Enum representing optional behaviors for when a duplicate config key is found.\r\n\r\n    Attributes:\r\n        OVERWRITE: Overwrite the existing value with the new value.\r\n        IGNORE: Ignore the new value and keep the existing value.\r\n        RAISE_ERROR: Raise an error.\r\n    \"\"\"\r\n    OVERWRITE = 1\r\n    IGNORE = 2\r\n    RAISE_ERROR = 3\r\n\r\n\r\nclass SpecialConfigType(Enum):\r\n    \"\"\"\r\n    An Enum representing special config value properties to validate.\r\n\r\n    Attributes:\r\n        EXISTING_FILE_PATH: The value must be of a path to an existing file.\r\n        EXISTING_FOLDER_PATH: The value must be of a path to an existing folder.\r\n    \"\"\"\r\n    EXISTING_FILE_PATH = 1\r\n    EXISTING_FOLDER_PATH = 2\r\n\r\n\r\nclass ConfigSetting(NamedTuple):\r\n    \"\"\"\r\n    A NamedTuple representing a config setting.\r\n\r\n    Attributes:\r\n        key (str): Dictionary key used to access the setting.\r\n        value_type (type): Variable type of the value of the setting. Used for validation.\r\n        category (str | tuple[str, ...], optional): A category that the setting is under.\r\n            Categories are used to group related settings' keys together in a sub-dictionary.\r\n            A tuple can be used to nest categories (first item is the top-level category). Defaults to None.\r\n        required (bool, optional): Whether the setting is required. Defaults to False.\r\n        enum_type (type[Enum], optional): An Enum that the settings values will be converted to. Defaults to None.\r\n        special_type (SpecialConfigType | list[SpecialConfigType], optional): A special property of the setting's value\r\n            to validate, represented by a SpecialConfigType value. Defaults to None.\r\n    \"\"\"\r\n    key: str\r\n    # TODO: Use `types.UnionType` instead of `typing._UnionGenericAlias`, once minimum Python version >= 3.10.\r\n    # TODO: Update 'InvalidConfigType' exception as well.\r\n    value_type: type | typing._UnionGenericAlias  # type: ignore[name-defined]\r\n    category: str | tuple[str, ...] | None = None\r\n    required: bool = False\r\n    enum_type: Type[Enum] | None = None\r\n    special_type: SpecialConfigType | list[SpecialConfigType] | None = None\r\n\r\n    def __eq__(self, other: Any) -> bool:\r\n        if isinstance(other, ConfigSetting):\r\n            return self.key == other.key and self.category == other.category\r\n        return False\r\n\r\n\r\nclass Config:\r\n    \"\"\"A class for managing iSubRip config files.\"\"\"\r\n    def __init__(self, config_settings: list[ConfigSetting] | None = None, config_data: dict | None = None):\r\n        \"\"\"\r\n        Create a new Config instance.\r\n\r\n        Args:\r\n            config_settings (list[ConfigSetting], optional): A list of ConfigSettings objects\r\n                that will be used for validations. Defaults to None.\r\n            config_data (dict, optional): A dict of config data to add to the config. Defaults to None.\r\n        \"\"\"\r\n        self._config_settings: list = []\r\n        self._config_data: dict = {}\r\n\r\n        if config_settings:\r\n            self.add_settings(config_settings, check_config=False)\r\n\r\n        if config_data:\r\n            self._config_data = deepcopy(config_data)\r\n\r\n    def __contains__(self, item: Any) -> bool:\r\n        \"\"\"\r\n        Allow checking if a key exists in the config using the 'in' operator.\r\n\r\n        Args:\r\n            item (Any): The key to check for.\r\n\r\n        Returns:\r\n            bool: True if the key exists in the config, False otherwise.\r\n        \"\"\"\r\n        return item in self._config_data\r\n\r\n    def __getattr__(self, key: str) -> Any:\r\n        \"\"\"\r\n        Allow access to config settings using attributes.\r\n\r\n        Args:\r\n            key (str): Config key to get.\r\n\r\n        Returns:\r\n            Any: The corresponding value for the key in the config.\r\n        \"\"\"\r\n        if self._config_data and key in self._config_data:\r\n            return self._config_data[key]\r\n\r\n        raise AttributeError(f\"Attribute '{key}' does not exist.\")\r\n\r\n    def __getitem__(self, key: str) -> Any:\r\n        \"\"\"\r\n        Allow access to config settings using dict-like syntax.\r\n\r\n        Args:\r\n            key (str): Config key to get.\r\n\r\n        Returns:\r\n            Any: The corresponding value for the key in the config.\r\n        \"\"\"\r\n        return self._config_data[key]\r\n\r\n    def get(self, key: str, default: Any = None) -> Any:\r\n        \"\"\"\r\n        Get a config value.\r\n\r\n        Args:\r\n            key (str): Config key to get.\r\n            default (Any, optional): Default value to return if the key does not exist. Defaults to None.\r\n\r\n        Returns:\r\n            Any: The corresponding value for the key in the config or the default value if the key does not exist.\r\n        \"\"\"\r\n        return self._config_data.get(key, default)\r\n\r\n    @property\r\n    def data(self) -> dict:\r\n        return self._config_data\r\n\r\n    def add_settings(self, config_settings: ConfigSetting | list[ConfigSetting],\r\n                     duplicate_behavior: DuplicateBehavior = DuplicateBehavior.OVERWRITE,\r\n                     check_config: bool = True) -> None:\r\n        \"\"\"\r\n        Add new config settings to the config.\r\n\r\n        Args:\r\n            config_settings (ConfigSetting | list[ConfigSetting]): A ConfigSetting object or a list of ConfigSetting\r\n                objects to add to the config.\r\n            duplicate_behavior (DuplicateBehavior, optional): Behaviour to apply if a duplicate is found.\r\n                Defaults to DuplicateBehavior.OVERWRITE.\r\n            check_config (bool, optional): Whether to check the config after loading it. Defaults to True.\r\n        \"\"\"\r\n        config_settings_copy = deepcopy(single_to_list(config_settings))\r\n\r\n        for config_setting in config_settings_copy:\r\n            if config_setting in self._config_settings:\r\n                if duplicate_behavior == DuplicateBehavior.OVERWRITE:\r\n                    self._config_settings.remove(config_setting)\r\n                    self._config_settings.append(config_setting)\r\n\r\n                elif duplicate_behavior == DuplicateBehavior.RAISE_ERROR:\r\n                    raise ValueError(f\"Duplicate config setting: {config_setting}\")\r\n\r\n            else:\r\n                self._config_settings.append(config_setting)\r\n\r\n        if check_config:\r\n            self.check()\r\n\r\n    def loads(self, config_data: str, check_config: bool = True) -> None:\r\n        \"\"\"\r\n        Parse a tomli config from a string.\r\n\r\n        Args:\r\n            config_data (str): Config file data as a string.\r\n            check_config (bool, optional): Whether to check the config after loading it. Defaults to True.\r\n\r\n        Raises:\r\n            FileNotFoundError: Config file could not be found in the specified path.\r\n            TOMLDecodeError: Config file is not a valid TOML file.\r\n            ConfigValueMissing: A required config value is missing.\r\n            InvalidConfigValue: An invalid value was used in the config file.\r\n        \"\"\"\r\n        # Load settings from default config file\r\n        loaded_data: dict = tomli.loads(config_data)\r\n\r\n        if self._config_data:\r\n            temp_config = dict(merge(self._config_data, loaded_data))\r\n\r\n        else:\r\n            temp_config = loaded_data\r\n\r\n        self._config_data = temp_config\r\n\r\n        if check_config and self._config_settings:\r\n            self.check()\r\n\r\n    def _map_config_settings(self, settings: list[ConfigSetting], data: dict) -> dict[ConfigSetting, Any]:\r\n        \"\"\"\r\n        Map config settings to their values.\r\n        This function wil also unflatten data.\r\n\r\n        Args:\r\n            settings (list[ConfigSetting]): A list or tuple of ConfigSettings objects.\r\n            data (dict): A dictionary containing the config data.\r\n\r\n        Returns:\r\n            dict[ConfigSetting, Any]: A dictionary mapping config settings to their values.\r\n        \"\"\"\r\n        mapped_settings: dict = {}\r\n\r\n        for setting in settings:\r\n            if setting.category:\r\n                setting_categories = single_to_list(setting.category)\r\n                config_dict_iter: dict = data\r\n\r\n                for setting_category in setting_categories:\r\n                    if setting_category not in config_dict_iter:\r\n                        mapped_settings[setting] = None\r\n                        break\r\n\r\n                    config_dict_iter = config_dict_iter[setting_category]\r\n\r\n            else:\r\n                config_dict_iter = data\r\n\r\n            if setting.key not in config_dict_iter:\r\n                mapped_settings[setting] = None\r\n\r\n            else:\r\n                value = config_dict_iter[setting.key]\r\n                enum_type = setting.enum_type\r\n\r\n                if enum_type is not None:\r\n                    try:\r\n                        value = enum_type(value)\r\n\r\n                    except ValueError as e:\r\n                        setting_path = '.'.join(single_to_list(setting.category))\r\n                        raise InvalidEnumConfigValueError(setting_path=setting_path,\r\n                                                          value=value, enum_type=enum_type) from e\r\n\r\n                if type(value) in (list, tuple) and len(value) == 0:\r\n                    value = None\r\n\r\n                special_types = single_to_list(setting.special_type)\r\n\r\n                if SpecialConfigType.EXISTING_FILE_PATH in special_types:\r\n                    value = value.rstrip(r\"\\/\")\r\n\r\n                mapped_settings[setting] = value\r\n\r\n        return mapped_settings\r\n\r\n    def check(self) -> None:\r\n        \"\"\"\r\n        Check whether the config is valid by comparing config's data to the config settings.\r\n        Raises an error if an invalid value is found.\r\n\r\n        Raises:\r\n            MissingConfigValue: A required config value is missing.\r\n            InvalidConfigValue: An invalid value was used in the config file.\r\n        \"\"\"\r\n        if not (self._config_data and self._config_settings):\r\n            return\r\n\r\n        mapped_config = self._map_config_settings(self._config_settings, self._config_data)\r\n\r\n        for setting, value in mapped_config.items():\r\n            if isinstance(setting.category, (list, tuple)):\r\n                setting_path = '.'.join(setting.category) + f\".{setting.key}\"\r\n\r\n            elif isinstance(setting.category, str):\r\n                setting_path = setting.category + f\".{setting.key}\"\r\n\r\n            else:\r\n                setting_path = setting.key\r\n\r\n            if value is None:\r\n                if setting.required:\r\n                    raise MissingRequiredConfigSettingError(setting_path=setting_path)\r\n\r\n                continue\r\n\r\n            if setting.enum_type is None and not check_type(value, setting.value_type):\r\n                raise InvalidConfigTypeError(setting_path=setting_path, value=value, expected_type=setting.value_type)\r\n\r\n            special_types = single_to_list(setting.special_type)\r\n\r\n            if SpecialConfigType.EXISTING_FILE_PATH in special_types and not Path(value).is_file():\r\n                raise InvalidConfigFilePathError(setting_path=setting_path, value=value)\r\n\r\n            if SpecialConfigType.EXISTING_FOLDER_PATH in special_types and not Path(value).is_dir():\r\n                raise InvalidConfigFolderPathError(setting_path=setting_path, value=value)\r\n\r\n\r\nclass ConfigError(Exception):\r\n    pass\r\n\r\n\r\nclass MissingRequiredConfigSettingError(ConfigError):\r\n    \"\"\"A required config value is missing.\"\"\"\r\n    def __init__(self, setting_path: str):\r\n        super().__init__(f\"Missing required config value: '{setting_path}'.\")\r\n\r\n\r\nclass InvalidConfigValueError(ConfigError):\r\n    \"\"\"An invalid config setting has been set.\"\"\"\r\n    def __init__(self, setting_path: str, value: Any, additional_note: str | None = None):\r\n        message = f\"Invalid config value for '{setting_path}': '{value}'.\"\r\n\r\n        if additional_note:\r\n            message += f\"\\n{additional_note}\"\r\n\r\n        super().__init__(message)\r\n\r\n\r\nclass InvalidEnumConfigValueError(InvalidConfigValueError):\r\n    \"\"\"An invalid config value of an enum type setting has been set.\"\"\"\r\n    def __init__(self, setting_path: str, value: Any, enum_type: type[Enum]):\r\n        enum_options = ', '.join([f\"'{option.name}'\" for option in enum_type])\r\n\r\n        super().__init__(\r\n            setting_path=setting_path,\r\n            value=value,\r\n            additional_note=f\"Value can only be one of: {enum_options}.\",\r\n        )\r\n\r\n\r\nclass InvalidConfigTypeError(InvalidConfigValueError):\r\n    \"\"\"An invalid config value type has been set.\"\"\"\r\n    def __init__(self, setting_path: str,\r\n                 expected_type: type | typing._UnionGenericAlias,  # type: ignore[name-defined]\r\n                 value: Any):\r\n        expected_type_str = expected_type.__name__ if hasattr(expected_type, '__name__') else str(expected_type)\r\n        value_type_str = type(value).__name__ if hasattr(type(value), '__name__') else str(type(value))\r\n\r\n        super().__init__(\r\n            setting_path=setting_path,\r\n            value=value,\r\n            additional_note=f\"Expected type: '{expected_type_str}'. Received: '{value_type_str}'.\",\r\n        )\r\n\r\n\r\nclass InvalidConfigFilePathError(InvalidConfigValueError):\r\n    \"\"\"An invalid config value of a file path has been set.\"\"\"\r\n    def __init__(self, setting_path: str, value: str):\r\n        super().__init__(\r\n            setting_path=setting_path,\r\n            value=value,\r\n            additional_note=f\"File '{value}' not found.\",\r\n        )\r\n\r\n\r\nclass InvalidConfigFolderPathError(InvalidConfigValueError):\r\n    \"\"\"An invalid config value of a folder path has been set.\"\"\"\r\n    def __init__(self, setting_path: str, value: str):\r\n        super().__init__(\r\n            setting_path=setting_path,\r\n            value=value,\r\n            additional_note=f\"Folder '{value}' not found.\",\r\n        )\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/config.py b/isubrip/config.py
--- a/isubrip/config.py	(revision f040b9612ca4349900c8d4bb1178838dc8a97be1)
+++ b/isubrip/config.py	(date 1723577371503)
@@ -7,6 +7,7 @@
 from typing import Any, NamedTuple, Type
 
 from mergedeep import merge
+from pydantic_settings import BaseSettings
 import tomli
 
 from isubrip.utils import check_type, single_to_list
Index: poetry.lock
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># This file is automatically @generated by Poetry 1.7.1 and should not be changed by hand.\r\n\r\n[[package]]\r\nname = \"annotated-types\"\r\nversion = \"0.7.0\"\r\ndescription = \"Reusable constraint types to use with typing.Annotated\"\r\noptional = false\r\npython-versions = \">=3.8\"\r\nfiles = [\r\n    {file = \"annotated_types-0.7.0-py3-none-any.whl\", hash = \"sha256:1f02e8b43a8fbbc3f3e0d4f0f4bfc8131bcb4eebe8849b8e5c773f3a1c582a53\"},\r\n    {file = \"annotated_types-0.7.0.tar.gz\", hash = \"sha256:aff07c09a53a08bc8cfccb9c85b05f1aa9a2a6f23728d790723543408344ce89\"},\r\n]\r\n\r\n[package.dependencies]\r\ntyping-extensions = {version = \">=4.0.0\", markers = \"python_version < \\\"3.9\\\"\"}\r\n\r\n[[package]]\r\nname = \"anyio\"\r\nversion = \"4.4.0\"\r\ndescription = \"High level compatibility layer for multiple asynchronous event loop implementations\"\r\noptional = false\r\npython-versions = \">=3.8\"\r\nfiles = [\r\n    {file = \"anyio-4.4.0-py3-none-any.whl\", hash = \"sha256:c1b2d8f46a8a812513012e1107cb0e68c17159a7a594208005a57dc776e1bdc7\"},\r\n    {file = \"anyio-4.4.0.tar.gz\", hash = \"sha256:5aadc6a1bbb7cdb0bede386cac5e2940f5e2ff3aa20277e991cf028e0585ce94\"},\r\n]\r\n\r\n[package.dependencies]\r\nexceptiongroup = {version = \">=1.0.2\", markers = \"python_version < \\\"3.11\\\"\"}\r\nidna = \">=2.8\"\r\nsniffio = \">=1.1\"\r\ntyping-extensions = {version = \">=4.1\", markers = \"python_version < \\\"3.11\\\"\"}\r\n\r\n[package.extras]\r\ndoc = [\"Sphinx (>=7)\", \"packaging\", \"sphinx-autodoc-typehints (>=1.2.0)\", \"sphinx-rtd-theme\"]\r\ntest = [\"anyio[trio]\", \"coverage[toml] (>=7)\", \"exceptiongroup (>=1.2.0)\", \"hypothesis (>=4.0)\", \"psutil (>=5.9)\", \"pytest (>=7.0)\", \"pytest-mock (>=3.6.1)\", \"trustme\", \"uvloop (>=0.17)\"]\r\ntrio = [\"trio (>=0.23)\"]\r\n\r\n[[package]]\r\nname = \"backports-datetime-fromisoformat\"\r\nversion = \"2.0.1\"\r\ndescription = \"Backport of Python 3.11's datetime.fromisoformat\"\r\noptional = false\r\npython-versions = \">3\"\r\nfiles = [\r\n    {file = \"backports-datetime-fromisoformat-2.0.1.tar.gz\", hash = \"sha256:1b6afca7f47019c22df43062cde73c1af65fbdebc66520f352c690d52fd27127\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-cp310-cp310-macosx_10_9_universal2.whl\", hash = \"sha256:b739ccd3f36244f618f1fbc21d89894d9dc9d1d75a68762fcf917d433df38ae3\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-cp310-cp310-macosx_10_9_x86_64.whl\", hash = \"sha256:afd072ca32f2ca4e838e0f7b61a56168d98837ee9a182c567a49a834e07c2b98\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-cp310-cp310-macosx_11_0_arm64.whl\", hash = \"sha256:1a136d85f8b1db4747aa9e56a8caa0ba77c5c25b761b18e2169ea7b1b516f012\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:5d3a0579958ade7db62c8238163e05d46a4de61c99cebb40031ed7409a44d5f6\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-cp310-cp310-musllinux_1_1_i686.whl\", hash = \"sha256:199df62af8feff5da0f4953fdc4a6994bcd7dbfe1db95901d8b93d05feda2ab5\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-cp310-cp310-musllinux_1_1_x86_64.whl\", hash = \"sha256:afe32e60a471831058ede14fc226d9f14120e6dc67d66fbbd36e1724826ad70b\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-cp310-cp310-win_amd64.whl\", hash = \"sha256:a1ba7e226a9694b20b713867f71b5ed2f662603c39875f14f968608d331fc96a\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-cp37-cp37m-macosx_10_9_x86_64.whl\", hash = \"sha256:403f155deecbe94d43d0679a74abb5c9ac441422a9ececcfde030fb133865659\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:b4d2ee049997d3aa2e714489cb3c34864fb0f25786e7a4ff04ac9d82af58b453\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-cp37-cp37m-musllinux_1_1_i686.whl\", hash = \"sha256:20aa422769af9f72ca41d83238d4a3a008d6cd74bcff0a08befb11b0018d6aa5\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-cp37-cp37m-musllinux_1_1_x86_64.whl\", hash = \"sha256:8ea8d85c3c9afa4ad51b6644d26516d43493f44c2131c12a2ba959433f4417f6\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-cp37-cp37m-win_amd64.whl\", hash = \"sha256:812b8c34e88a7d9615c604f1a0473a4e6d664aba94086bffb0c55627f9e3fb68\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-cp38-cp38-macosx_10_9_universal2.whl\", hash = \"sha256:df5365930320b7a9d404cd6f7bc13988e28355e812aa42e21aa5c93443dcdd2e\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-cp38-cp38-macosx_10_9_x86_64.whl\", hash = \"sha256:fe3e3968c8dce4a44da2da81a6031e992a4ee62d130c2536696d215a4db2ce3c\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-cp38-cp38-macosx_11_0_arm64.whl\", hash = \"sha256:36a4abb678ab0d6a1965d70e21e424bcf7a52086a7afb1c5f13243a3d44fa2dd\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:96b7e806ade09a91d8ce195c197fc799d8fbe6b8ea9cde21f8a01f1090e51e33\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-cp38-cp38-musllinux_1_1_i686.whl\", hash = \"sha256:002a77bd4f549ff5e80f1ef4a9b69982746dd6190786b90abe3d9c69c9883ce4\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-cp38-cp38-musllinux_1_1_x86_64.whl\", hash = \"sha256:7b4ad0013a96b656ebf85079921ffb211623a1e28ff4981b3927690a2ed6df54\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-cp38-cp38-win_amd64.whl\", hash = \"sha256:065421723e735ce8f68dbb4486f07562ce8556ed543ceaa012189b9aa209f303\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-cp39-cp39-macosx_10_9_universal2.whl\", hash = \"sha256:a4bf1bec08bc84095ee379202466c948fe12cff1442f58ee1a91fac4c5164c97\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-cp39-cp39-macosx_10_9_x86_64.whl\", hash = \"sha256:1836aff09b8317e179cc7288856b61a450515d4b411f0ab723dc9692dfa5362e\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-cp39-cp39-macosx_11_0_arm64.whl\", hash = \"sha256:815f85a581b142bcf34632c3ce26f7e21003f101ce88b5649631330e334bbe35\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:6a6986cfd3bc40b41465a6c54c18a30ca8110333d0b71f6062af136db11c8ff0\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-cp39-cp39-musllinux_1_1_i686.whl\", hash = \"sha256:82741e732d71f78b44a8c3b95f33b3630e7bfbdb02e3fede3938cdf15d5b6a83\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-cp39-cp39-musllinux_1_1_x86_64.whl\", hash = \"sha256:4eac27abb51ee84e08d1dd1e908c16cae2078c217ff5b54092e6cb92107b4c6c\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-cp39-cp39-win_amd64.whl\", hash = \"sha256:3b730d72061523be9600bcd281ef353f7f73b1df095adbbdc364aac8f430c44c\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-pp310-pypy310_pp73-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:f6e8f28f4a68539192473f427ed86794931502d186e2fffa1926250550c1335a\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-pp37-pypy37_pp73-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:0cef151f1df77e413dc179607edb5bee11949ca5890e81c0bb742d96fec753fe\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-pp38-pypy38_pp73-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:c28c95d6df2a44fa3540e18e484596c03e8ff7112e2f93b664f482fe3a88720b\"},\r\n    {file = \"backports_datetime_fromisoformat-2.0.1-pp39-pypy39_pp73-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:91042b53de903e3725209ad6d69b6994ae4819614c0decd62d05dfea23f35e2b\"},\r\n]\r\n\r\n[[package]]\r\nname = \"certifi\"\r\nversion = \"2024.6.2\"\r\ndescription = \"Python package for providing Mozilla's CA Bundle.\"\r\noptional = false\r\npython-versions = \">=3.6\"\r\nfiles = [\r\n    {file = \"certifi-2024.6.2-py3-none-any.whl\", hash = \"sha256:ddc6c8ce995e6987e7faf5e3f1b02b302836a0e5d98ece18392cb1a36c72ad56\"},\r\n    {file = \"certifi-2024.6.2.tar.gz\", hash = \"sha256:3cd43f1c6fa7dedc5899d69d3ad0398fd018ad1a17fba83ddaf78aa46c747516\"},\r\n]\r\n\r\n[[package]]\r\nname = \"exceptiongroup\"\r\nversion = \"1.2.1\"\r\ndescription = \"Backport of PEP 654 (exception groups)\"\r\noptional = false\r\npython-versions = \">=3.7\"\r\nfiles = [\r\n    {file = \"exceptiongroup-1.2.1-py3-none-any.whl\", hash = \"sha256:5258b9ed329c5bbdd31a309f53cbfb0b155341807f6ff7606a1e801a891b29ad\"},\r\n    {file = \"exceptiongroup-1.2.1.tar.gz\", hash = \"sha256:a4785e48b045528f5bfe627b6ad554ff32def154f42372786903b7abcfe1aa16\"},\r\n]\r\n\r\n[package.extras]\r\ntest = [\"pytest (>=6)\"]\r\n\r\n[[package]]\r\nname = \"h11\"\r\nversion = \"0.14.0\"\r\ndescription = \"A pure-Python, bring-your-own-I/O implementation of HTTP/1.1\"\r\noptional = false\r\npython-versions = \">=3.7\"\r\nfiles = [\r\n    {file = \"h11-0.14.0-py3-none-any.whl\", hash = \"sha256:e3fe4ac4b851c468cc8363d500db52c2ead036020723024a109d37346efaa761\"},\r\n    {file = \"h11-0.14.0.tar.gz\", hash = \"sha256:8f19fbbe99e72420ff35c00b27a34cb9937e902a8b810e2c88300c6f0a3b699d\"},\r\n]\r\n\r\n[[package]]\r\nname = \"h2\"\r\nversion = \"4.1.0\"\r\ndescription = \"HTTP/2 State-Machine based protocol implementation\"\r\noptional = false\r\npython-versions = \">=3.6.1\"\r\nfiles = [\r\n    {file = \"h2-4.1.0-py3-none-any.whl\", hash = \"sha256:03a46bcf682256c95b5fd9e9a99c1323584c3eec6440d379b9903d709476bc6d\"},\r\n    {file = \"h2-4.1.0.tar.gz\", hash = \"sha256:a83aca08fbe7aacb79fec788c9c0bac936343560ed9ec18b82a13a12c28d2abb\"},\r\n]\r\n\r\n[package.dependencies]\r\nhpack = \">=4.0,<5\"\r\nhyperframe = \">=6.0,<7\"\r\n\r\n[[package]]\r\nname = \"hpack\"\r\nversion = \"4.0.0\"\r\ndescription = \"Pure-Python HPACK header compression\"\r\noptional = false\r\npython-versions = \">=3.6.1\"\r\nfiles = [\r\n    {file = \"hpack-4.0.0-py3-none-any.whl\", hash = \"sha256:84a076fad3dc9a9f8063ccb8041ef100867b1878b25ef0ee63847a5d53818a6c\"},\r\n    {file = \"hpack-4.0.0.tar.gz\", hash = \"sha256:fc41de0c63e687ebffde81187a948221294896f6bdc0ae2312708df339430095\"},\r\n]\r\n\r\n[[package]]\r\nname = \"httpcore\"\r\nversion = \"1.0.5\"\r\ndescription = \"A minimal low-level HTTP client.\"\r\noptional = false\r\npython-versions = \">=3.8\"\r\nfiles = [\r\n    {file = \"httpcore-1.0.5-py3-none-any.whl\", hash = \"sha256:421f18bac248b25d310f3cacd198d55b8e6125c107797b609ff9b7a6ba7991b5\"},\r\n    {file = \"httpcore-1.0.5.tar.gz\", hash = \"sha256:34a38e2f9291467ee3b44e89dd52615370e152954ba21721378a87b2960f7a61\"},\r\n]\r\n\r\n[package.dependencies]\r\ncertifi = \"*\"\r\nh11 = \">=0.13,<0.15\"\r\n\r\n[package.extras]\r\nasyncio = [\"anyio (>=4.0,<5.0)\"]\r\nhttp2 = [\"h2 (>=3,<5)\"]\r\nsocks = [\"socksio (==1.*)\"]\r\ntrio = [\"trio (>=0.22.0,<0.26.0)\"]\r\n\r\n[[package]]\r\nname = \"httpx\"\r\nversion = \"0.27.0\"\r\ndescription = \"The next generation HTTP client.\"\r\noptional = false\r\npython-versions = \">=3.8\"\r\nfiles = [\r\n    {file = \"httpx-0.27.0-py3-none-any.whl\", hash = \"sha256:71d5465162c13681bff01ad59b2cc68dd838ea1f10e51574bac27103f00c91a5\"},\r\n    {file = \"httpx-0.27.0.tar.gz\", hash = \"sha256:a0cb88a46f32dc874e04ee956e4c2764aba2aa228f650b06788ba6bda2962ab5\"},\r\n]\r\n\r\n[package.dependencies]\r\nanyio = \"*\"\r\ncertifi = \"*\"\r\nh2 = {version = \">=3,<5\", optional = true, markers = \"extra == \\\"http2\\\"\"}\r\nhttpcore = \"==1.*\"\r\nidna = \"*\"\r\nsniffio = \"*\"\r\n\r\n[package.extras]\r\nbrotli = [\"brotli\", \"brotlicffi\"]\r\ncli = [\"click (==8.*)\", \"pygments (==2.*)\", \"rich (>=10,<14)\"]\r\nhttp2 = [\"h2 (>=3,<5)\"]\r\nsocks = [\"socksio (==1.*)\"]\r\n\r\n[[package]]\r\nname = \"hyperframe\"\r\nversion = \"6.0.1\"\r\ndescription = \"HTTP/2 framing layer for Python\"\r\noptional = false\r\npython-versions = \">=3.6.1\"\r\nfiles = [\r\n    {file = \"hyperframe-6.0.1-py3-none-any.whl\", hash = \"sha256:0ec6bafd80d8ad2195c4f03aacba3a8265e57bc4cff261e802bf39970ed02a15\"},\r\n    {file = \"hyperframe-6.0.1.tar.gz\", hash = \"sha256:ae510046231dc8e9ecb1a6586f63d2347bf4c8905914aa84ba585ae85f28a914\"},\r\n]\r\n\r\n[[package]]\r\nname = \"idna\"\r\nversion = \"3.7\"\r\ndescription = \"Internationalized Domain Names in Applications (IDNA)\"\r\noptional = false\r\npython-versions = \">=3.5\"\r\nfiles = [\r\n    {file = \"idna-3.7-py3-none-any.whl\", hash = \"sha256:82fee1fc78add43492d3a1898bfa6d8a904cc97d8427f683ed8e798d07761aa0\"},\r\n    {file = \"idna-3.7.tar.gz\", hash = \"sha256:028ff3aadf0609c1fd278d8ea3089299412a7a8b9bd005dd08b9f8285bcb5cfc\"},\r\n]\r\n\r\n[[package]]\r\nname = \"m3u8\"\r\nversion = \"4.1.0\"\r\ndescription = \"Python m3u8 parser\"\r\noptional = false\r\npython-versions = \">=3.7\"\r\nfiles = [\r\n    {file = \"m3u8-4.1.0-py3-none-any.whl\", hash = \"sha256:981daed09f57b7590721b6437278e49f2c36c1bceaa8fbe48f585e1745571d17\"},\r\n    {file = \"m3u8-4.1.0.tar.gz\", hash = \"sha256:3b9d7e5bafbaae89f2464cb16f397887d8decf6b1b48d8de58711414dc1c7b45\"},\r\n]\r\n\r\n[package.dependencies]\r\nbackports-datetime-fromisoformat = {version = \"*\", markers = \"python_version < \\\"3.11\\\"\"}\r\n\r\n[[package]]\r\nname = \"mergedeep\"\r\nversion = \"1.3.4\"\r\ndescription = \"A deep merge function for \uD83D\uDC0D.\"\r\noptional = false\r\npython-versions = \">=3.6\"\r\nfiles = [\r\n    {file = \"mergedeep-1.3.4-py3-none-any.whl\", hash = \"sha256:70775750742b25c0d8f36c55aed03d24c3384d17c951b3175d898bd778ef0307\"},\r\n    {file = \"mergedeep-1.3.4.tar.gz\", hash = \"sha256:0096d52e9dad9939c3d975a774666af186eda617e6ca84df4c94dec30004f2a8\"},\r\n]\r\n\r\n[[package]]\r\nname = \"mypy\"\r\nversion = \"1.10.1\"\r\ndescription = \"Optional static typing for Python\"\r\noptional = false\r\npython-versions = \">=3.8\"\r\nfiles = [\r\n    {file = \"mypy-1.10.1-cp310-cp310-macosx_10_9_x86_64.whl\", hash = \"sha256:e36f229acfe250dc660790840916eb49726c928e8ce10fbdf90715090fe4ae02\"},\r\n    {file = \"mypy-1.10.1-cp310-cp310-macosx_11_0_arm64.whl\", hash = \"sha256:51a46974340baaa4145363b9e051812a2446cf583dfaeba124af966fa44593f7\"},\r\n    {file = \"mypy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:901c89c2d67bba57aaaca91ccdb659aa3a312de67f23b9dfb059727cce2e2e0a\"},\r\n    {file = \"mypy-1.10.1-cp310-cp310-musllinux_1_1_x86_64.whl\", hash = \"sha256:0cd62192a4a32b77ceb31272d9e74d23cd88c8060c34d1d3622db3267679a5d9\"},\r\n    {file = \"mypy-1.10.1-cp310-cp310-win_amd64.whl\", hash = \"sha256:a2cbc68cb9e943ac0814c13e2452d2046c2f2b23ff0278e26599224cf164e78d\"},\r\n    {file = \"mypy-1.10.1-cp311-cp311-macosx_10_9_x86_64.whl\", hash = \"sha256:bd6f629b67bb43dc0d9211ee98b96d8dabc97b1ad38b9b25f5e4c4d7569a0c6a\"},\r\n    {file = \"mypy-1.10.1-cp311-cp311-macosx_11_0_arm64.whl\", hash = \"sha256:a1bbb3a6f5ff319d2b9d40b4080d46cd639abe3516d5a62c070cf0114a457d84\"},\r\n    {file = \"mypy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:b8edd4e9bbbc9d7b79502eb9592cab808585516ae1bcc1446eb9122656c6066f\"},\r\n    {file = \"mypy-1.10.1-cp311-cp311-musllinux_1_1_x86_64.whl\", hash = \"sha256:6166a88b15f1759f94a46fa474c7b1b05d134b1b61fca627dd7335454cc9aa6b\"},\r\n    {file = \"mypy-1.10.1-cp311-cp311-win_amd64.whl\", hash = \"sha256:5bb9cd11c01c8606a9d0b83ffa91d0b236a0e91bc4126d9ba9ce62906ada868e\"},\r\n    {file = \"mypy-1.10.1-cp312-cp312-macosx_10_9_x86_64.whl\", hash = \"sha256:d8681909f7b44d0b7b86e653ca152d6dff0eb5eb41694e163c6092124f8246d7\"},\r\n    {file = \"mypy-1.10.1-cp312-cp312-macosx_11_0_arm64.whl\", hash = \"sha256:378c03f53f10bbdd55ca94e46ec3ba255279706a6aacaecac52ad248f98205d3\"},\r\n    {file = \"mypy-1.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:6bacf8f3a3d7d849f40ca6caea5c055122efe70e81480c8328ad29c55c69e93e\"},\r\n    {file = \"mypy-1.10.1-cp312-cp312-musllinux_1_1_x86_64.whl\", hash = \"sha256:701b5f71413f1e9855566a34d6e9d12624e9e0a8818a5704d74d6b0402e66c04\"},\r\n    {file = \"mypy-1.10.1-cp312-cp312-win_amd64.whl\", hash = \"sha256:3c4c2992f6ea46ff7fce0072642cfb62af7a2484efe69017ed8b095f7b39ef31\"},\r\n    {file = \"mypy-1.10.1-cp38-cp38-macosx_10_9_x86_64.whl\", hash = \"sha256:604282c886497645ffb87b8f35a57ec773a4a2721161e709a4422c1636ddde5c\"},\r\n    {file = \"mypy-1.10.1-cp38-cp38-macosx_11_0_arm64.whl\", hash = \"sha256:37fd87cab83f09842653f08de066ee68f1182b9b5282e4634cdb4b407266bade\"},\r\n    {file = \"mypy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:8addf6313777dbb92e9564c5d32ec122bf2c6c39d683ea64de6a1fd98b90fe37\"},\r\n    {file = \"mypy-1.10.1-cp38-cp38-musllinux_1_1_x86_64.whl\", hash = \"sha256:5cc3ca0a244eb9a5249c7c583ad9a7e881aa5d7b73c35652296ddcdb33b2b9c7\"},\r\n    {file = \"mypy-1.10.1-cp38-cp38-win_amd64.whl\", hash = \"sha256:1b3a2ffce52cc4dbaeee4df762f20a2905aa171ef157b82192f2e2f368eec05d\"},\r\n    {file = \"mypy-1.10.1-cp39-cp39-macosx_10_9_x86_64.whl\", hash = \"sha256:fe85ed6836165d52ae8b88f99527d3d1b2362e0cb90b005409b8bed90e9059b3\"},\r\n    {file = \"mypy-1.10.1-cp39-cp39-macosx_11_0_arm64.whl\", hash = \"sha256:c2ae450d60d7d020d67ab440c6e3fae375809988119817214440033f26ddf7bf\"},\r\n    {file = \"mypy-1.10.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:6be84c06e6abd72f960ba9a71561c14137a583093ffcf9bbfaf5e613d63fa531\"},\r\n    {file = \"mypy-1.10.1-cp39-cp39-musllinux_1_1_x86_64.whl\", hash = \"sha256:2189ff1e39db399f08205e22a797383613ce1cb0cb3b13d8bcf0170e45b96cc3\"},\r\n    {file = \"mypy-1.10.1-cp39-cp39-win_amd64.whl\", hash = \"sha256:97a131ee36ac37ce9581f4220311247ab6cba896b4395b9c87af0675a13a755f\"},\r\n    {file = \"mypy-1.10.1-py3-none-any.whl\", hash = \"sha256:71d8ac0b906354ebda8ef1673e5fde785936ac1f29ff6987c7483cfbd5a4235a\"},\r\n    {file = \"mypy-1.10.1.tar.gz\", hash = \"sha256:1f8f492d7db9e3593ef42d4f115f04e556130f2819ad33ab84551403e97dd4c0\"},\r\n]\r\n\r\n[package.dependencies]\r\nmypy-extensions = \">=1.0.0\"\r\ntomli = {version = \">=1.1.0\", markers = \"python_version < \\\"3.11\\\"\"}\r\ntyping-extensions = \">=4.1.0\"\r\n\r\n[package.extras]\r\ndmypy = [\"psutil (>=4.0)\"]\r\ninstall-types = [\"pip\"]\r\nmypyc = [\"setuptools (>=50)\"]\r\nreports = [\"lxml\"]\r\n\r\n[[package]]\r\nname = \"mypy-extensions\"\r\nversion = \"1.0.0\"\r\ndescription = \"Type system extensions for programs checked with the mypy type checker.\"\r\noptional = false\r\npython-versions = \">=3.5\"\r\nfiles = [\r\n    {file = \"mypy_extensions-1.0.0-py3-none-any.whl\", hash = \"sha256:4392f6c0eb8a5668a69e23d168ffa70f0be9ccfd32b5cc2d26a34ae5b844552d\"},\r\n    {file = \"mypy_extensions-1.0.0.tar.gz\", hash = \"sha256:75dbf8955dc00442a438fc4d0666508a9a97b6bd41aa2f0ffe9d2f2725af0782\"},\r\n]\r\n\r\n[[package]]\r\nname = \"pydantic\"\r\nversion = \"2.8.0\"\r\ndescription = \"Data validation using Python type hints\"\r\noptional = false\r\npython-versions = \">=3.8\"\r\nfiles = [\r\n    {file = \"pydantic-2.8.0-py3-none-any.whl\", hash = \"sha256:ead4f3a1e92386a734ca1411cb25d94147cf8778ed5be6b56749047676d6364e\"},\r\n    {file = \"pydantic-2.8.0.tar.gz\", hash = \"sha256:d970ffb9d030b710795878940bd0489842c638e7252fc4a19c3ae2f7da4d6141\"},\r\n]\r\n\r\n[package.dependencies]\r\nannotated-types = \">=0.4.0\"\r\npydantic-core = \"2.20.0\"\r\ntyping-extensions = [\r\n    {version = \">=4.12.2\", markers = \"python_version >= \\\"3.13\\\"\"},\r\n    {version = \">=4.6.1\", markers = \"python_version < \\\"3.13\\\"\"},\r\n]\r\n\r\n[package.extras]\r\nemail = [\"email-validator (>=2.0.0)\"]\r\n\r\n[[package]]\r\nname = \"pydantic-core\"\r\nversion = \"2.20.0\"\r\ndescription = \"Core functionality for Pydantic validation and serialization\"\r\noptional = false\r\npython-versions = \">=3.8\"\r\nfiles = [\r\n    {file = \"pydantic_core-2.20.0-cp310-cp310-macosx_10_12_x86_64.whl\", hash = \"sha256:e9dcd7fb34f7bfb239b5fa420033642fff0ad676b765559c3737b91f664d4fa9\"},\r\n    {file = \"pydantic_core-2.20.0-cp310-cp310-macosx_11_0_arm64.whl\", hash = \"sha256:649a764d9b0da29816889424697b2a3746963ad36d3e0968784ceed6e40c6355\"},\r\n    {file = \"pydantic_core-2.20.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:7701df088d0b05f3460f7ba15aec81ac8b0fb5690367dfd072a6c38cf5b7fdb5\"},\r\n    {file = \"pydantic_core-2.20.0-cp310-cp310-manylinux_2_17_armv7l.manylinux2014_armv7l.whl\", hash = \"sha256:ab760f17c3e792225cdaef31ca23c0aea45c14ce80d8eff62503f86a5ab76bff\"},\r\n    {file = \"pydantic_core-2.20.0-cp310-cp310-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl\", hash = \"sha256:cb1ad5b4d73cde784cf64580166568074f5ccd2548d765e690546cff3d80937d\"},\r\n    {file = \"pydantic_core-2.20.0-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl\", hash = \"sha256:b81ec2efc04fc1dbf400647d4357d64fb25543bae38d2d19787d69360aad21c9\"},\r\n    {file = \"pydantic_core-2.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:c4a9732a5cad764ba37f3aa873dccb41b584f69c347a57323eda0930deec8e10\"},\r\n    {file = \"pydantic_core-2.20.0-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.whl\", hash = \"sha256:6dc85b9e10cc21d9c1055f15684f76fa4facadddcb6cd63abab702eb93c98943\"},\r\n    {file = \"pydantic_core-2.20.0-cp310-cp310-musllinux_1_1_aarch64.whl\", hash = \"sha256:21d9f7e24f63fdc7118e6cc49defaab8c1d27570782f7e5256169d77498cf7c7\"},\r\n    {file = \"pydantic_core-2.20.0-cp310-cp310-musllinux_1_1_x86_64.whl\", hash = \"sha256:8b315685832ab9287e6124b5d74fc12dda31e6421d7f6b08525791452844bc2d\"},\r\n    {file = \"pydantic_core-2.20.0-cp310-none-win32.whl\", hash = \"sha256:c3dc8ec8b87c7ad534c75b8855168a08a7036fdb9deeeed5705ba9410721c84d\"},\r\n    {file = \"pydantic_core-2.20.0-cp310-none-win_amd64.whl\", hash = \"sha256:85770b4b37bb36ef93a6122601795231225641003e0318d23c6233c59b424279\"},\r\n    {file = \"pydantic_core-2.20.0-cp311-cp311-macosx_10_12_x86_64.whl\", hash = \"sha256:58e251bb5a5998f7226dc90b0b753eeffa720bd66664eba51927c2a7a2d5f32c\"},\r\n    {file = \"pydantic_core-2.20.0-cp311-cp311-macosx_11_0_arm64.whl\", hash = \"sha256:78d584caac52c24240ef9ecd75de64c760bbd0e20dbf6973631815e3ef16ef8b\"},\r\n    {file = \"pydantic_core-2.20.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:5084ec9721f82bef5ff7c4d1ee65e1626783abb585f8c0993833490b63fe1792\"},\r\n    {file = \"pydantic_core-2.20.0-cp311-cp311-manylinux_2_17_armv7l.manylinux2014_armv7l.whl\", hash = \"sha256:6d0f52684868db7c218437d260e14d37948b094493f2646f22d3dda7229bbe3f\"},\r\n    {file = \"pydantic_core-2.20.0-cp311-cp311-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl\", hash = \"sha256:1def125d59a87fe451212a72ab9ed34c118ff771e5473fef4f2f95d8ede26d75\"},\r\n    {file = \"pydantic_core-2.20.0-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl\", hash = \"sha256:b34480fd6778ab356abf1e9086a4ced95002a1e195e8d2fd182b0def9d944d11\"},\r\n    {file = \"pydantic_core-2.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:d42669d319db366cb567c3b444f43caa7ffb779bf9530692c6f244fc635a41eb\"},\r\n    {file = \"pydantic_core-2.20.0-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.whl\", hash = \"sha256:53b06aea7a48919a254b32107647be9128c066aaa6ee6d5d08222325f25ef175\"},\r\n    {file = \"pydantic_core-2.20.0-cp311-cp311-musllinux_1_1_aarch64.whl\", hash = \"sha256:1f038156b696a1c39d763b2080aeefa87ddb4162c10aa9fabfefffc3dd8180fa\"},\r\n    {file = \"pydantic_core-2.20.0-cp311-cp311-musllinux_1_1_x86_64.whl\", hash = \"sha256:3f0f3a4a23717280a5ee3ac4fb1f81d6fde604c9ec5100f7f6f987716bb8c137\"},\r\n    {file = \"pydantic_core-2.20.0-cp311-none-win32.whl\", hash = \"sha256:316fe7c3fec017affd916a0c83d6f1ec697cbbbdf1124769fa73328e7907cc2e\"},\r\n    {file = \"pydantic_core-2.20.0-cp311-none-win_amd64.whl\", hash = \"sha256:2d06a7fa437f93782e3f32d739c3ec189f82fca74336c08255f9e20cea1ed378\"},\r\n    {file = \"pydantic_core-2.20.0-cp312-cp312-macosx_10_12_x86_64.whl\", hash = \"sha256:d6f8c49657f3eb7720ed4c9b26624063da14937fc94d1812f1e04a2204db3e17\"},\r\n    {file = \"pydantic_core-2.20.0-cp312-cp312-macosx_11_0_arm64.whl\", hash = \"sha256:ad1bd2f377f56fec11d5cfd0977c30061cd19f4fa199bf138b200ec0d5e27eeb\"},\r\n    {file = \"pydantic_core-2.20.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:ed741183719a5271f97d93bbcc45ed64619fa38068aaa6e90027d1d17e30dc8d\"},\r\n    {file = \"pydantic_core-2.20.0-cp312-cp312-manylinux_2_17_armv7l.manylinux2014_armv7l.whl\", hash = \"sha256:d82e5ed3a05f2dcb89c6ead2fd0dbff7ac09bc02c1b4028ece2d3a3854d049ce\"},\r\n    {file = \"pydantic_core-2.20.0-cp312-cp312-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl\", hash = \"sha256:b2ba34a099576234671f2e4274e5bc6813b22e28778c216d680eabd0db3f7dad\"},\r\n    {file = \"pydantic_core-2.20.0-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl\", hash = \"sha256:879ae6bb08a063b3e1b7ac8c860096d8fd6b48dd9b2690b7f2738b8c835e744b\"},\r\n    {file = \"pydantic_core-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:0b0eefc7633a04c0694340aad91fbfd1986fe1a1e0c63a22793ba40a18fcbdc8\"},\r\n    {file = \"pydantic_core-2.20.0-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.whl\", hash = \"sha256:73deadd6fd8a23e2f40b412b3ac617a112143c8989a4fe265050fd91ba5c0608\"},\r\n    {file = \"pydantic_core-2.20.0-cp312-cp312-musllinux_1_1_aarch64.whl\", hash = \"sha256:35681445dc85446fb105943d81ae7569aa7e89de80d1ca4ac3229e05c311bdb1\"},\r\n    {file = \"pydantic_core-2.20.0-cp312-cp312-musllinux_1_1_x86_64.whl\", hash = \"sha256:0f6dd3612a3b9f91f2e63924ea18a4476656c6d01843ca20a4c09e00422195af\"},\r\n    {file = \"pydantic_core-2.20.0-cp312-none-win32.whl\", hash = \"sha256:7e37b6bb6e90c2b8412b06373c6978d9d81e7199a40e24a6ef480e8acdeaf918\"},\r\n    {file = \"pydantic_core-2.20.0-cp312-none-win_amd64.whl\", hash = \"sha256:7d4df13d1c55e84351fab51383520b84f490740a9f1fec905362aa64590b7a5d\"},\r\n    {file = \"pydantic_core-2.20.0-cp313-cp313-macosx_10_12_x86_64.whl\", hash = \"sha256:d43e7ab3b65e4dc35a7612cfff7b0fd62dce5bc11a7cd198310b57f39847fd6c\"},\r\n    {file = \"pydantic_core-2.20.0-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:7b6a24d7b5893392f2b8e3b7a0031ae3b14c6c1942a4615f0d8794fdeeefb08b\"},\r\n    {file = \"pydantic_core-2.20.0-cp313-cp313-manylinux_2_17_armv7l.manylinux2014_armv7l.whl\", hash = \"sha256:b2f13c3e955a087c3ec86f97661d9f72a76e221281b2262956af381224cfc243\"},\r\n    {file = \"pydantic_core-2.20.0-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl\", hash = \"sha256:72432fd6e868c8d0a6849869e004b8bcae233a3c56383954c228316694920b38\"},\r\n    {file = \"pydantic_core-2.20.0-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl\", hash = \"sha256:d70a8ff2d4953afb4cbe6211f17268ad29c0b47e73d3372f40e7775904bc28fc\"},\r\n    {file = \"pydantic_core-2.20.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:8e49524917b8d3c2f42cd0d2df61178e08e50f5f029f9af1f402b3ee64574392\"},\r\n    {file = \"pydantic_core-2.20.0-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.whl\", hash = \"sha256:a4f0f71653b1c1bad0350bc0b4cc057ab87b438ff18fa6392533811ebd01439c\"},\r\n    {file = \"pydantic_core-2.20.0-cp313-cp313-musllinux_1_1_aarch64.whl\", hash = \"sha256:16197e6f4fdecb9892ed2436e507e44f0a1aa2cff3b9306d1c879ea2f9200997\"},\r\n    {file = \"pydantic_core-2.20.0-cp313-cp313-musllinux_1_1_x86_64.whl\", hash = \"sha256:763602504bf640b3ded3bba3f8ed8a1cc2fc6a87b8d55c1c5689f428c49c947e\"},\r\n    {file = \"pydantic_core-2.20.0-cp313-none-win32.whl\", hash = \"sha256:a3f243f318bd9523277fa123b3163f4c005a3e8619d4b867064de02f287a564d\"},\r\n    {file = \"pydantic_core-2.20.0-cp313-none-win_amd64.whl\", hash = \"sha256:03aceaf6a5adaad3bec2233edc5a7905026553916615888e53154807e404545c\"},\r\n    {file = \"pydantic_core-2.20.0-cp38-cp38-macosx_10_12_x86_64.whl\", hash = \"sha256:d6f2d8b8da1f03f577243b07bbdd3412eee3d37d1f2fd71d1513cbc76a8c1239\"},\r\n    {file = \"pydantic_core-2.20.0-cp38-cp38-macosx_11_0_arm64.whl\", hash = \"sha256:a272785a226869416c6b3c1b7e450506152d3844207331f02f27173562c917e0\"},\r\n    {file = \"pydantic_core-2.20.0-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:efbb412d55a4ffe73963fed95c09ccb83647ec63b711c4b3752be10a56f0090b\"},\r\n    {file = \"pydantic_core-2.20.0-cp38-cp38-manylinux_2_17_armv7l.manylinux2014_armv7l.whl\", hash = \"sha256:1e4f46189d8740561b43655263a41aac75ff0388febcb2c9ec4f1b60a0ec12f3\"},\r\n    {file = \"pydantic_core-2.20.0-cp38-cp38-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl\", hash = \"sha256:87d3df115f4a3c8c5e4d5acf067d399c6466d7e604fc9ee9acbe6f0c88a0c3cf\"},\r\n    {file = \"pydantic_core-2.20.0-cp38-cp38-manylinux_2_17_s390x.manylinux2014_s390x.whl\", hash = \"sha256:a340d2bdebe819d08f605e9705ed551c3feb97e4fd71822d7147c1e4bdbb9508\"},\r\n    {file = \"pydantic_core-2.20.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:616b9c2f882393d422ba11b40e72382fe975e806ad693095e9a3b67c59ea6150\"},\r\n    {file = \"pydantic_core-2.20.0-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.whl\", hash = \"sha256:25c46bb2ff6084859bbcfdf4f1a63004b98e88b6d04053e8bf324e115398e9e7\"},\r\n    {file = \"pydantic_core-2.20.0-cp38-cp38-musllinux_1_1_aarch64.whl\", hash = \"sha256:23425eccef8f2c342f78d3a238c824623836c6c874d93c726673dbf7e56c78c0\"},\r\n    {file = \"pydantic_core-2.20.0-cp38-cp38-musllinux_1_1_x86_64.whl\", hash = \"sha256:52527e8f223ba29608d999d65b204676398009725007c9336651c2ec2d93cffc\"},\r\n    {file = \"pydantic_core-2.20.0-cp38-none-win32.whl\", hash = \"sha256:1c3c5b7f70dd19a6845292b0775295ea81c61540f68671ae06bfe4421b3222c2\"},\r\n    {file = \"pydantic_core-2.20.0-cp38-none-win_amd64.whl\", hash = \"sha256:8093473d7b9e908af1cef30025609afc8f5fd2a16ff07f97440fd911421e4432\"},\r\n    {file = \"pydantic_core-2.20.0-cp39-cp39-macosx_10_12_x86_64.whl\", hash = \"sha256:ee7785938e407418795e4399b2bf5b5f3cf6cf728077a7f26973220d58d885cf\"},\r\n    {file = \"pydantic_core-2.20.0-cp39-cp39-macosx_11_0_arm64.whl\", hash = \"sha256:0e75794883d635071cf6b4ed2a5d7a1e50672ab7a051454c76446ef1ebcdcc91\"},\r\n    {file = \"pydantic_core-2.20.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:344e352c96e53b4f56b53d24728217c69399b8129c16789f70236083c6ceb2ac\"},\r\n    {file = \"pydantic_core-2.20.0-cp39-cp39-manylinux_2_17_armv7l.manylinux2014_armv7l.whl\", hash = \"sha256:978d4123ad1e605daf1ba5e01d4f235bcf7b6e340ef07e7122e8e9cfe3eb61ab\"},\r\n    {file = \"pydantic_core-2.20.0-cp39-cp39-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl\", hash = \"sha256:3c05eaf6c863781eb834ab41f5963604ab92855822a2062897958089d1335dad\"},\r\n    {file = \"pydantic_core-2.20.0-cp39-cp39-manylinux_2_17_s390x.manylinux2014_s390x.whl\", hash = \"sha256:bc7e43b4a528ffca8c9151b6a2ca34482c2fdc05e6aa24a84b7f475c896fc51d\"},\r\n    {file = \"pydantic_core-2.20.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:658287a29351166510ebbe0a75c373600cc4367a3d9337b964dada8d38bcc0f4\"},\r\n    {file = \"pydantic_core-2.20.0-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.whl\", hash = \"sha256:1dacf660d6de692fe351e8c806e7efccf09ee5184865893afbe8e59be4920b4a\"},\r\n    {file = \"pydantic_core-2.20.0-cp39-cp39-musllinux_1_1_aarch64.whl\", hash = \"sha256:3e147fc6e27b9a487320d78515c5f29798b539179f7777018cedf51b7749e4f4\"},\r\n    {file = \"pydantic_core-2.20.0-cp39-cp39-musllinux_1_1_x86_64.whl\", hash = \"sha256:c867230d715a3dd1d962c8d9bef0d3168994ed663e21bf748b6e3a529a129aab\"},\r\n    {file = \"pydantic_core-2.20.0-cp39-none-win32.whl\", hash = \"sha256:22b813baf0dbf612752d8143a2dbf8e33ccb850656b7850e009bad2e101fc377\"},\r\n    {file = \"pydantic_core-2.20.0-cp39-none-win_amd64.whl\", hash = \"sha256:3a7235b46c1bbe201f09b6f0f5e6c36b16bad3d0532a10493742f91fbdc8035f\"},\r\n    {file = \"pydantic_core-2.20.0-pp310-pypy310_pp73-macosx_10_12_x86_64.whl\", hash = \"sha256:cafde15a6f7feaec2f570646e2ffc5b73412295d29134a29067e70740ec6ee20\"},\r\n    {file = \"pydantic_core-2.20.0-pp310-pypy310_pp73-macosx_11_0_arm64.whl\", hash = \"sha256:2aec8eeea0b08fd6bc2213d8e86811a07491849fd3d79955b62d83e32fa2ad5f\"},\r\n    {file = \"pydantic_core-2.20.0-pp310-pypy310_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:840200827984f1c4e114008abc2f5ede362d6e11ed0b5931681884dd41852ff1\"},\r\n    {file = \"pydantic_core-2.20.0-pp310-pypy310_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:f8ea1d8b7df522e5ced34993c423c3bf3735c53df8b2a15688a2f03a7d678800\"},\r\n    {file = \"pydantic_core-2.20.0-pp310-pypy310_pp73-manylinux_2_5_i686.manylinux1_i686.whl\", hash = \"sha256:d5b8376a867047bf08910573deb95d3c8dfb976eb014ee24f3b5a61ccc5bee1b\"},\r\n    {file = \"pydantic_core-2.20.0-pp310-pypy310_pp73-musllinux_1_1_aarch64.whl\", hash = \"sha256:d08264b4460326cefacc179fc1411304d5af388a79910832835e6f641512358b\"},\r\n    {file = \"pydantic_core-2.20.0-pp310-pypy310_pp73-musllinux_1_1_x86_64.whl\", hash = \"sha256:7a3639011c2e8a9628466f616ed7fb413f30032b891898e10895a0a8b5857d6c\"},\r\n    {file = \"pydantic_core-2.20.0-pp310-pypy310_pp73-win_amd64.whl\", hash = \"sha256:05e83ce2f7eba29e627dd8066aa6c4c0269b2d4f889c0eba157233a353053cea\"},\r\n    {file = \"pydantic_core-2.20.0-pp39-pypy39_pp73-macosx_10_12_x86_64.whl\", hash = \"sha256:603a843fea76a595c8f661cd4da4d2281dff1e38c4a836a928eac1a2f8fe88e4\"},\r\n    {file = \"pydantic_core-2.20.0-pp39-pypy39_pp73-macosx_11_0_arm64.whl\", hash = \"sha256:ac76f30d5d3454f4c28826d891fe74d25121a346c69523c9810ebba43f3b1cec\"},\r\n    {file = \"pydantic_core-2.20.0-pp39-pypy39_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:22e3b1d4b1b3f6082849f9b28427ef147a5b46a6132a3dbaf9ca1baa40c88609\"},\r\n    {file = \"pydantic_core-2.20.0-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:2761f71faed820e25ec62eacba670d1b5c2709bb131a19fcdbfbb09884593e5a\"},\r\n    {file = \"pydantic_core-2.20.0-pp39-pypy39_pp73-manylinux_2_5_i686.manylinux1_i686.whl\", hash = \"sha256:a0586cddbf4380e24569b8a05f234e7305717cc8323f50114dfb2051fcbce2a3\"},\r\n    {file = \"pydantic_core-2.20.0-pp39-pypy39_pp73-musllinux_1_1_aarch64.whl\", hash = \"sha256:b8c46a8cf53e849eea7090f331ae2202cd0f1ceb090b00f5902c423bd1e11805\"},\r\n    {file = \"pydantic_core-2.20.0-pp39-pypy39_pp73-musllinux_1_1_x86_64.whl\", hash = \"sha256:b4a085bd04af7245e140d1b95619fe8abb445a3d7fdf219b3f80c940853268ef\"},\r\n    {file = \"pydantic_core-2.20.0-pp39-pypy39_pp73-win_amd64.whl\", hash = \"sha256:116b326ac82c8b315e7348390f6d30bcfe6e688a7d3f1de50ff7bcc2042a23c2\"},\r\n    {file = \"pydantic_core-2.20.0.tar.gz\", hash = \"sha256:366be8e64e0cb63d87cf79b4e1765c0703dd6313c729b22e7b9e378db6b96877\"},\r\n]\r\n\r\n[package.dependencies]\r\ntyping-extensions = \">=4.6.0,<4.7.0 || >4.7.0\"\r\n\r\n[[package]]\r\nname = \"ruff\"\r\nversion = \"0.4.10\"\r\ndescription = \"An extremely fast Python linter and code formatter, written in Rust.\"\r\noptional = false\r\npython-versions = \">=3.7\"\r\nfiles = [\r\n    {file = \"ruff-0.4.10-py3-none-macosx_10_12_x86_64.whl\", hash = \"sha256:5c2c4d0859305ac5a16310eec40e4e9a9dec5dcdfbe92697acd99624e8638dac\"},\r\n    {file = \"ruff-0.4.10-py3-none-macosx_11_0_arm64.whl\", hash = \"sha256:a79489607d1495685cdd911a323a35871abfb7a95d4f98fc6f85e799227ac46e\"},\r\n    {file = \"ruff-0.4.10-py3-none-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:b1dd1681dfa90a41b8376a61af05cc4dc5ff32c8f14f5fe20dba9ff5deb80cd6\"},\r\n    {file = \"ruff-0.4.10-py3-none-manylinux_2_17_armv7l.manylinux2014_armv7l.whl\", hash = \"sha256:c75c53bb79d71310dc79fb69eb4902fba804a81f374bc86a9b117a8d077a1784\"},\r\n    {file = \"ruff-0.4.10-py3-none-manylinux_2_17_i686.manylinux2014_i686.whl\", hash = \"sha256:18238c80ee3d9100d3535d8eb15a59c4a0753b45cc55f8bf38f38d6a597b9739\"},\r\n    {file = \"ruff-0.4.10-py3-none-manylinux_2_17_ppc64.manylinux2014_ppc64.whl\", hash = \"sha256:d8f71885bce242da344989cae08e263de29752f094233f932d4f5cfb4ef36a81\"},\r\n    {file = \"ruff-0.4.10-py3-none-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl\", hash = \"sha256:330421543bd3222cdfec481e8ff3460e8702ed1e58b494cf9d9e4bf90db52b9d\"},\r\n    {file = \"ruff-0.4.10-py3-none-manylinux_2_17_s390x.manylinux2014_s390x.whl\", hash = \"sha256:9e9b6fb3a37b772628415b00c4fc892f97954275394ed611056a4b8a2631365e\"},\r\n    {file = \"ruff-0.4.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:0f54c481b39a762d48f64d97351048e842861c6662d63ec599f67d515cb417f6\"},\r\n    {file = \"ruff-0.4.10-py3-none-musllinux_1_2_aarch64.whl\", hash = \"sha256:67fe086b433b965c22de0b4259ddfe6fa541c95bf418499bedb9ad5fb8d1c631\"},\r\n    {file = \"ruff-0.4.10-py3-none-musllinux_1_2_armv7l.whl\", hash = \"sha256:acfaaab59543382085f9eb51f8e87bac26bf96b164839955f244d07125a982ef\"},\r\n    {file = \"ruff-0.4.10-py3-none-musllinux_1_2_i686.whl\", hash = \"sha256:3cea07079962b2941244191569cf3a05541477286f5cafea638cd3aa94b56815\"},\r\n    {file = \"ruff-0.4.10-py3-none-musllinux_1_2_x86_64.whl\", hash = \"sha256:338a64ef0748f8c3a80d7f05785930f7965d71ca260904a9321d13be24b79695\"},\r\n    {file = \"ruff-0.4.10-py3-none-win32.whl\", hash = \"sha256:ffe3cd2f89cb54561c62e5fa20e8f182c0a444934bf430515a4b422f1ab7b7ca\"},\r\n    {file = \"ruff-0.4.10-py3-none-win_amd64.whl\", hash = \"sha256:67f67cef43c55ffc8cc59e8e0b97e9e60b4837c8f21e8ab5ffd5d66e196e25f7\"},\r\n    {file = \"ruff-0.4.10-py3-none-win_arm64.whl\", hash = \"sha256:dd1fcee327c20addac7916ca4e2653fbbf2e8388d8a6477ce5b4e986b68ae6c0\"},\r\n    {file = \"ruff-0.4.10.tar.gz\", hash = \"sha256:3aa4f2bc388a30d346c56524f7cacca85945ba124945fe489952aadb6b5cd804\"},\r\n]\r\n\r\n[[package]]\r\nname = \"sniffio\"\r\nversion = \"1.3.1\"\r\ndescription = \"Sniff out which async library your code is running under\"\r\noptional = false\r\npython-versions = \">=3.7\"\r\nfiles = [\r\n    {file = \"sniffio-1.3.1-py3-none-any.whl\", hash = \"sha256:2f6da418d1f1e0fddd844478f41680e794e6051915791a034ff65e5f100525a2\"},\r\n    {file = \"sniffio-1.3.1.tar.gz\", hash = \"sha256:f4324edc670a0f49750a81b895f35c3adb843cca46f0530f79fc1babb23789dc\"},\r\n]\r\n\r\n[[package]]\r\nname = \"tomli\"\r\nversion = \"2.0.1\"\r\ndescription = \"A lil' TOML parser\"\r\noptional = false\r\npython-versions = \">=3.7\"\r\nfiles = [\r\n    {file = \"tomli-2.0.1-py3-none-any.whl\", hash = \"sha256:939de3e7a6161af0c887ef91b7d41a53e7c5a1ca976325f429cb46ea9bc30ecc\"},\r\n    {file = \"tomli-2.0.1.tar.gz\", hash = \"sha256:de526c12914f0c550d15924c62d72abc48d6fe7364aa87328337a31007fe8a4f\"},\r\n]\r\n\r\n[[package]]\r\nname = \"typing-extensions\"\r\nversion = \"4.12.2\"\r\ndescription = \"Backported and Experimental Type Hints for Python 3.8+\"\r\noptional = false\r\npython-versions = \">=3.8\"\r\nfiles = [\r\n    {file = \"typing_extensions-4.12.2-py3-none-any.whl\", hash = \"sha256:04e5ca0351e0f3f85c6853954072df659d0d13fac324d0072316b67d7794700d\"},\r\n    {file = \"typing_extensions-4.12.2.tar.gz\", hash = \"sha256:1a7ead55c7e559dd4dee8856e3a88b41225abfe1ce8df57b7c13915fe121ffb8\"},\r\n]\r\n\r\n[metadata]\r\nlock-version = \"2.0\"\r\npython-versions = \"^3.8\"\r\ncontent-hash = \"109a156d3fe479346764588306552bc51ad6173d4afd0277a41678d6bf2b1989\"\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/poetry.lock b/poetry.lock
--- a/poetry.lock	(revision f040b9612ca4349900c8d4bb1178838dc8a97be1)
+++ b/poetry.lock	(date 1723577104040)
@@ -87,6 +87,31 @@
     {file = "certifi-2024.6.2.tar.gz", hash = "sha256:3cd43f1c6fa7dedc5899d69d3ad0398fd018ad1a17fba83ddaf78aa46c747516"},
 ]
 
+[[package]]
+name = "click"
+version = "8.1.7"
+description = "Composable command line interface toolkit"
+optional = false
+python-versions = ">=3.7"
+files = [
+    {file = "click-8.1.7-py3-none-any.whl", hash = "sha256:ae74fb96c20a0277a1d615f1e4d73c8414f5a98db8b799a7931d1582f3390c28"},
+    {file = "click-8.1.7.tar.gz", hash = "sha256:ca9853ad459e787e2192211578cc907e7594e294c7ccc834310722b41b9ca6de"},
+]
+
+[package.dependencies]
+colorama = {version = "*", markers = "platform_system == \"Windows\""}
+
+[[package]]
+name = "colorama"
+version = "0.4.6"
+description = "Cross-platform colored terminal text."
+optional = false
+python-versions = "!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*,!=3.5.*,!=3.6.*,>=2.7"
+files = [
+    {file = "colorama-0.4.6-py2.py3-none-any.whl", hash = "sha256:4f1d9991f5acc0ca119f9d443620b77f9d6b33703e51011c16baf57afb285fc6"},
+    {file = "colorama-0.4.6.tar.gz", hash = "sha256:08695f5cb7ed6e0531a20572697297273c47b8cae5a63ffc6d6ed5c201be6e44"},
+]
+
 [[package]]
 name = "exceptiongroup"
 version = "1.2.1"
@@ -220,6 +245,41 @@
 [package.dependencies]
 backports-datetime-fromisoformat = {version = "*", markers = "python_version < \"3.11\""}
 
+[[package]]
+name = "markdown-it-py"
+version = "3.0.0"
+description = "Python port of markdown-it. Markdown parsing, done right!"
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "markdown-it-py-3.0.0.tar.gz", hash = "sha256:e3f60a94fa066dc52ec76661e37c851cb232d92f9886b15cb560aaada2df8feb"},
+    {file = "markdown_it_py-3.0.0-py3-none-any.whl", hash = "sha256:355216845c60bd96232cd8d8c40e8f9765cc86f46880e43a8fd22dc1a1a8cab1"},
+]
+
+[package.dependencies]
+mdurl = ">=0.1,<1.0"
+
+[package.extras]
+benchmarking = ["psutil", "pytest", "pytest-benchmark"]
+code-style = ["pre-commit (>=3.0,<4.0)"]
+compare = ["commonmark (>=0.9,<1.0)", "markdown (>=3.4,<4.0)", "mistletoe (>=1.0,<2.0)", "mistune (>=2.0,<3.0)", "panflute (>=2.3,<3.0)"]
+linkify = ["linkify-it-py (>=1,<3)"]
+plugins = ["mdit-py-plugins"]
+profiling = ["gprof2dot"]
+rtd = ["jupyter_sphinx", "mdit-py-plugins", "myst-parser", "pyyaml", "sphinx", "sphinx-copybutton", "sphinx-design", "sphinx_book_theme"]
+testing = ["coverage", "pytest", "pytest-cov", "pytest-regressions"]
+
+[[package]]
+name = "mdurl"
+version = "0.1.2"
+description = "Markdown URL utilities"
+optional = false
+python-versions = ">=3.7"
+files = [
+    {file = "mdurl-0.1.2-py3-none-any.whl", hash = "sha256:84008a41e51615a49fc9966191ff91509e3c40b939176e643fd50a5c2196b8f8"},
+    {file = "mdurl-0.1.2.tar.gz", hash = "sha256:bb413d29f5eea38f31dd4754dd7377d4465116fb207585f97bf925588687c1ba"},
+]
+
 [[package]]
 name = "mergedeep"
 version = "1.3.4"
@@ -411,6 +471,73 @@
 [package.dependencies]
 typing-extensions = ">=4.6.0,<4.7.0 || >4.7.0"
 
+[[package]]
+name = "pydantic-settings"
+version = "2.4.0"
+description = "Settings management using Pydantic"
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "pydantic_settings-2.4.0-py3-none-any.whl", hash = "sha256:bb6849dc067f1687574c12a639e231f3a6feeed0a12d710c1382045c5db1c315"},
+    {file = "pydantic_settings-2.4.0.tar.gz", hash = "sha256:ed81c3a0f46392b4d7c0a565c05884e6e54b3456e6f0fe4d8814981172dc9a88"},
+]
+
+[package.dependencies]
+pydantic = ">=2.7.0"
+python-dotenv = ">=0.21.0"
+
+[package.extras]
+azure-key-vault = ["azure-identity (>=1.16.0)", "azure-keyvault-secrets (>=4.8.0)"]
+toml = ["tomli (>=2.0.1)"]
+yaml = ["pyyaml (>=6.0.1)"]
+
+[[package]]
+name = "pygments"
+version = "2.18.0"
+description = "Pygments is a syntax highlighting package written in Python."
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "pygments-2.18.0-py3-none-any.whl", hash = "sha256:b8e6aca0523f3ab76fee51799c488e38782ac06eafcf95e7ba832985c8e7b13a"},
+    {file = "pygments-2.18.0.tar.gz", hash = "sha256:786ff802f32e91311bff3889f6e9a86e81505fe99f2735bb6d60ae0c5004f199"},
+]
+
+[package.extras]
+windows-terminal = ["colorama (>=0.4.6)"]
+
+[[package]]
+name = "python-dotenv"
+version = "1.0.1"
+description = "Read key-value pairs from a .env file and set them as environment variables"
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "python-dotenv-1.0.1.tar.gz", hash = "sha256:e324ee90a023d808f1959c46bcbc04446a10ced277783dc6ee09987c37ec10ca"},
+    {file = "python_dotenv-1.0.1-py3-none-any.whl", hash = "sha256:f7b63ef50f1b690dddf550d03497b66d609393b40b564ed0d674909a68ebf16a"},
+]
+
+[package.extras]
+cli = ["click (>=5.0)"]
+
+[[package]]
+name = "rich"
+version = "13.7.1"
+description = "Render rich text, tables, progress bars, syntax highlighting, markdown and more to the terminal"
+optional = false
+python-versions = ">=3.7.0"
+files = [
+    {file = "rich-13.7.1-py3-none-any.whl", hash = "sha256:4edbae314f59eb482f54e9e30bf00d33350aaa94f4bfcd4e9e3110e64d0d7222"},
+    {file = "rich-13.7.1.tar.gz", hash = "sha256:9be308cb1fe2f1f57d67ce99e95af38a1e2bc71ad9813b0e247cf7ffbcc3a432"},
+]
+
+[package.dependencies]
+markdown-it-py = ">=2.2.0"
+pygments = ">=2.13.0,<3.0.0"
+typing-extensions = {version = ">=4.0.0,<5.0", markers = "python_version < \"3.9\""}
+
+[package.extras]
+jupyter = ["ipywidgets (>=7.5.1,<9)"]
+
 [[package]]
 name = "ruff"
 version = "0.4.10"
@@ -437,6 +564,17 @@
     {file = "ruff-0.4.10.tar.gz", hash = "sha256:3aa4f2bc388a30d346c56524f7cacca85945ba124945fe489952aadb6b5cd804"},
 ]
 
+[[package]]
+name = "shellingham"
+version = "1.5.4"
+description = "Tool to Detect Surrounding Shell"
+optional = false
+python-versions = ">=3.7"
+files = [
+    {file = "shellingham-1.5.4-py2.py3-none-any.whl", hash = "sha256:7ecfff8f2fd72616f7481040475a65b2bf8af90a56c89140852d1120324e8686"},
+    {file = "shellingham-1.5.4.tar.gz", hash = "sha256:8dbca0739d487e5bd35ab3ca4b36e11c4078f3a234bfce294b0a0291363404de"},
+]
+
 [[package]]
 name = "sniffio"
 version = "1.3.1"
@@ -459,6 +597,23 @@
     {file = "tomli-2.0.1.tar.gz", hash = "sha256:de526c12914f0c550d15924c62d72abc48d6fe7364aa87328337a31007fe8a4f"},
 ]
 
+[[package]]
+name = "typer"
+version = "0.12.3"
+description = "Typer, build great CLIs. Easy to code. Based on Python type hints."
+optional = false
+python-versions = ">=3.7"
+files = [
+    {file = "typer-0.12.3-py3-none-any.whl", hash = "sha256:070d7ca53f785acbccba8e7d28b08dcd88f79f1fbda035ade0aecec71ca5c914"},
+    {file = "typer-0.12.3.tar.gz", hash = "sha256:49e73131481d804288ef62598d97a1ceef3058905aa536a1134f90891ba35482"},
+]
+
+[package.dependencies]
+click = ">=8.0.0"
+rich = ">=10.11.0"
+shellingham = ">=1.3.0"
+typing-extensions = ">=3.7.4.3"
+
 [[package]]
 name = "typing-extensions"
 version = "4.12.2"
@@ -473,4 +628,4 @@
 [metadata]
 lock-version = "2.0"
 python-versions = "^3.8"
-content-hash = "109a156d3fe479346764588306552bc51ad6173d4afd0277a41678d6bf2b1989"
+content-hash = "35ff695310f6c0a1d4033556a7254c1cddcfe08151be2c01949062c808de57a3"
Index: pyproject.toml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>[tool.poetry]\r\nname = \"isubrip\"\r\nversion = \"2.5.6\"\r\ndescription = \"A Python package for scraping and downloading subtitles from AppleTV / iTunes movie pages.\"\r\nlicense = \"MIT\"\r\nauthors = [\"Michael Yochpaz\"]\r\nreadme = \"README.md\"\r\nhomepage = \"https://github.com/MichaelYochpaz/iSubRip\"\r\nrepository = \"https://github.com/MichaelYochpaz/iSubRip\"\r\nkeywords = [\r\n    \"iTunes\",\r\n    \"AppleTV\",\r\n    \"movies\",\r\n    \"subtitles\",\r\n    \"scrape\",\r\n    \"scraper\",\r\n    \"download\",\r\n    \"m3u8\"\r\n]\r\nclassifiers = [\r\n    \"Development Status :: 5 - Production/Stable\",\r\n    \"Intended Audience :: End Users/Desktop\",\r\n    \"Intended Audience :: Developers\",\r\n    \"Operating System :: Microsoft :: Windows\",\r\n    \"Operating System :: MacOS\",\r\n    \"Operating System :: POSIX :: Linux\",\r\n    \"Topic :: Utilities\",\r\n    \"License :: OSI Approved :: MIT License\",\r\n    \"Programming Language :: Python :: 3.8\",\r\n    \"Programming Language :: Python :: 3.9\",\r\n    \"Programming Language :: Python :: 3.10\",\r\n    \"Programming Language :: Python :: 3.11\",\r\n    \"Programming Language :: Python :: 3.12\",\r\n]\r\npackages = [\r\n    { include = \"isubrip\" },\r\n]\r\ninclude = [\r\n    \"isubrip/resources\", \"README.md\", \"LICENSE\"\r\n]\r\n\r\n[tool.mypy]\r\ndisallow_untyped_defs = true\r\nexplicit_package_bases = true\r\nignore_missing_imports = true\r\npython_version = \"3.8\"\r\nwarn_return_any = true\r\n\r\n[tool.poetry.scripts]\r\nisubrip = \"isubrip.__main__:main\"\r\n\r\n[tool.poetry.urls]\r\n\"Bug Reports\" = \"https://github.com/MichaelYochpaz/iSubRip/issues\"\r\n\r\n[tool.poetry.dependencies]\r\npython = \"^3.8\"\r\nhttpx = {extras = [\"http2\"], version = \"^0.27.0\"}\r\nm3u8 = \"^4.1.0\"\r\nmergedeep = \"^1.3.4\"\r\npydantic = \"^2.7.0\"\r\ntomli = \"^2.0.1\"\r\n\r\n\r\n[tool.poetry.group.dev.dependencies]\r\nmypy = \"^1.10.0\"\r\nruff = \"^0.4.2\"\r\n\r\n[build-system]\r\nrequires = [\"poetry-core\"]\r\nbuild-backend = \"poetry.core.masonry.api\"\r\n\r\n[tool.poetry_bumpversion.file.\"isubrip/constants.py\"]\r\nsearch = 'PACKAGE_VERSION = \"{current_version}\"'\r\nreplace = 'PACKAGE_VERSION = \"{new_version}\"'\r\n\r\n\r\n[tool.ruff]\r\nline-length = 120\r\ntarget-version = \"py38\"\r\n\r\n[tool.ruff.lint]\r\nselect = [\r\n    \"ARG\",\r\n    \"ASYNC\",\r\n    \"B\",\r\n    \"C4\",\r\n    \"COM\",\r\n    \"E\",\r\n    \"F\",\r\n    \"FA\",\r\n    \"I\",\r\n    \"INP\",\r\n    \"ISC\",\r\n    \"N\",\r\n    \"PIE\",\r\n    \"PGH\",\r\n    \"PT\",\r\n    \"PTH\",\r\n    \"Q\",\r\n    \"RSE\",\r\n    \"RET\",\r\n    \"RUF\",\r\n    \"S\",\r\n    \"SIM\",\r\n    \"SLF\",\r\n    \"T20\",\r\n    \"TCH\",\r\n    \"TID\",\r\n    \"TRY\",\r\n    \"UP\",\r\n]\r\nignore = [\r\n    \"C416\",\r\n    \"Q000\",\r\n    \"RUF010\",\r\n    \"RUF012\",\r\n    \"SIM108\",\r\n    \"TD002\",\r\n    \"TD003\",\r\n    \"TRY003\",\r\n]\r\nunfixable = [\"ARG\"]\r\n\r\n[tool.ruff.lint.flake8-tidy-imports]\r\nban-relative-imports = \"all\"\r\n\r\n[tool.ruff.lint.flake8-quotes]\r\ndocstring-quotes = \"double\"\r\n\r\n[tool.ruff.lint.isort]\r\nforce-sort-within-sections = true\r\n\r\n[tool.ruff.lint.pyupgrade]\r\nkeep-runtime-typing = true
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/pyproject.toml b/pyproject.toml
--- a/pyproject.toml	(revision f040b9612ca4349900c8d4bb1178838dc8a97be1)
+++ b/pyproject.toml	(date 1723577104045)
@@ -59,6 +59,8 @@
 mergedeep = "^1.3.4"
 pydantic = "^2.7.0"
 tomli = "^2.0.1"
+typer = "^0.12.3"
+pydantic-settings = "^2.4.0"
 
 
 [tool.poetry.group.dev.dependencies]
