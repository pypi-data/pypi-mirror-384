Index: isubrip/scrapers/itunes_scraper.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nimport re\r\nfrom typing import TYPE_CHECKING, Iterator\r\n\r\nimport m3u8\r\nfrom requests.exceptions import HTTPError\r\n\r\nfrom isubrip.data_structures import SubtitlesData, SubtitlesFormatType\r\nfrom isubrip.logger import logger\r\nfrom isubrip.scrapers.scraper import HLSScraper, PlaylistLoadError, ScraperError, ScraperFactory\r\nfrom isubrip.subtitle_formats.webvtt import WebVTTSubtitles\r\nfrom isubrip.utils import raise_for_status, merge_dict_values\r\n\r\nif TYPE_CHECKING:\r\n    from isubrip.data_structures import Movie, ScrapedMediaResponse\r\n\r\n\r\nclass ItunesScraper(HLSScraper):\r\n    \"\"\"An iTunes movie data scraper.\"\"\"\r\n    id = \"itunes\"\r\n    name = \"iTunes\"\r\n    abbreviation = \"iT\"\r\n    url_regex = re.compile(r\"(?P<base_url>https?://itunes\\.apple\\.com/(?:(?P<country_code>[a-z]{2})/)?(?P<media_type>movie|tv-show|tv-season|show)/(?:(?P<media_name>[\\w\\-%]+)/)?(?P<media_id>id\\d{9,10}))(?:\\?(?P<url_params>.*))?\", flags=re.IGNORECASE)  # noqa: E501\r\n    subtitles_class = WebVTTSubtitles\r\n    is_movie_scraper = True\r\n    uses_scrapers = [\"appletv\"]\r\n\r\n    _subtitles_filters = {\r\n        HLSScraper.M3U8Attribute.GROUP_ID.value: [\"subtitles_ak\", \"subtitles_vod-ak-amt.tv.apple.com\"],\r\n        **HLSScraper._subtitles_filters,\r\n    }\r\n\r\n    def __init__(self,  user_agent: str | None = None, config_data: dict | None = None):\r\n        super().__init__(user_agent=user_agent, config_data=config_data)\r\n        self._appletv_scraper = ScraperFactory.get_scraper_instance(scraper_id=\"appletv\",\r\n                                                                    kwargs={\"config_data\": self._config_data},\r\n                                                                    raise_error=True)\r\n\r\n    def get_data(self, url: str) -> ScrapedMediaResponse[Movie]:\r\n        \"\"\"\r\n        Scrape iTunes to find info about a movie, and it's M3U8 main_playlist.\r\n\r\n        Args:\r\n            url (str): An iTunes store movie URL.\r\n\r\n        Raises:\r\n            InvalidURL: `itunes_url` is not a valid iTunes store movie URL.\r\n            PageLoadError: HTML page did not load properly.\r\n            HTTPError: HTTP request failed.\r\n\r\n        Returns:\r\n            Movie: A Movie (NamedTuple) object with movie's name, and an M3U8 object of the main_playlist\r\n            if the main_playlist is found. None otherwise.\r\n        \"\"\"\r\n        regex_match = self.match_url(url, raise_error=True)\r\n        url = regex_match.group(1)\r\n        logger.debug(f\"Scraping iTunes URL: {url}.\")\r\n        response = self._session.get(url=url, allow_redirects=False)\r\n\r\n        try:\r\n            raise_for_status(response=response)\r\n\r\n        except HTTPError as e:\r\n            if response.status_code == 404:\r\n                raise ScraperError(\r\n                    \"Media not found. This could indicate that the provided URL is invalid.\",\r\n                ) from e\r\n\r\n            raise\r\n\r\n        redirect_location = response.headers.get(\"Location\")\r\n\r\n        if response.status_code != 301 or not redirect_location:\r\n            logger.debug(f\"iTunes URL: {url} did not redirect to an Apple TV URL.\\n\"\r\n                         f\"Response status code: {response.status_code}.\\n\"\r\n                         f\"Response headers:\\n{response.headers}.\\n\"\r\n                         f\"Response data:\\n{response.text}.\")\r\n            raise ScraperError(\"Apple TV redirect URL not found.\")\r\n\r\n        if not self._appletv_scraper.match_url(redirect_location):\r\n            logger.debug(f\"iTunes URL: {url} redirected to an invalid Apple TV URL: '{redirect_location}'.\")\r\n            raise ScraperError(\"Redirect URL is not a valid Apple TV URL.\")\r\n\r\n        return self._appletv_scraper.get_data(redirect_location)\r\n\r\n    def get_subtitles(self, main_playlist: str | list[str], language_filter: list[str] | str | None = None,\r\n                      subrip_conversion: bool = False) -> Iterator[SubtitlesData]:\r\n        language_filters = {self.M3U8Attribute.LANGUAGE.value: language_filter} if language_filter else None\r\n        main_playlist_m3u8 = self.load_m3u8(url=main_playlist)\r\n\r\n        if main_playlist_m3u8 is None:\r\n            raise PlaylistLoadError(\"Could not load M3U8 playlist.\")\r\n\r\n        playlist_filters = (merge_dict_values(self._subtitles_filters, language_filters)\r\n                            if language_filters\r\n                            else self._subtitles_filters)\r\n\r\n        matched_media_items = self.get_media_playlists(main_playlist=main_playlist_m3u8,\r\n                                                       playlist_filters=playlist_filters)\r\n\r\n        for matched_media in matched_media_items:\r\n            try:\r\n                m3u8_data = self._session.get(url=matched_media.absolute_uri)\r\n                matched_media_playlist = m3u8.loads(content=m3u8_data.text, uri=matched_media.absolute_uri)\r\n                subtitles = self.subtitles_class(language_code=matched_media.language)\r\n                for segment in self._download_segments(matched_media_playlist.segments):\r\n                    subtitles.append_subtitles(subtitles.loads(segment.decode(\"utf-8\")))\r\n\r\n                subtitles.polish(\r\n                    fix_rtl=self.subtitles_fix_rtl,\r\n                    rtl_languages=self.subtitles_fix_rtl_languages,\r\n                    remove_duplicates=self.subtitles_remove_duplicates,\r\n                )\r\n\r\n                language_name = matched_media.name.replace(' (forced)', '').strip()\r\n\r\n                yield SubtitlesData(\r\n                    language_code=matched_media.language,\r\n                    language_name=language_name,\r\n                    subtitles_format=SubtitlesFormatType.SUBRIP if subrip_conversion else SubtitlesFormatType.WEBVTT,\r\n                    content=subtitles.to_srt().dump() if subrip_conversion else subtitles.dump(),\r\n                    special_type=self.detect_subtitles_type(matched_media),\r\n                )\r\n\r\n            except Exception as e:\r\n                logger.warning(f\"Failed to download {matched_media.name} ({matched_media.language}) subtitles. \"\r\n                               f\"Skipping...\")\r\n                logger.debug(e, exc_info=True)\r\n                continue\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/scrapers/itunes_scraper.py b/isubrip/scrapers/itunes_scraper.py
--- a/isubrip/scrapers/itunes_scraper.py	(revision 67c115fc7dbd1dc7520fc499455860dceb009906)
+++ b/isubrip/scrapers/itunes_scraper.py	(date 1707504110122)
@@ -100,12 +100,18 @@
                                                        playlist_filters=playlist_filters)
 
         for matched_media in matched_media_items:
+            language_name = matched_media.name.replace(' (forced)', '').strip()
+            language_info_str = f"{language_name} ({matched_media.language})"
+
             try:
                 m3u8_data = self._session.get(url=matched_media.absolute_uri)
                 matched_media_playlist = m3u8.loads(content=m3u8_data.text, uri=matched_media.absolute_uri)
-                subtitles = self.subtitles_class(language_code=matched_media.language)
-                for segment in self._download_segments(matched_media_playlist.segments):
-                    subtitles.append_subtitles(subtitles.loads(segment.decode("utf-8")))
+
+                subtitles_segments = self._download_segments(matched_media_playlist.segments)
+                subtitles = self.subtitles_class.load(subtitles_segments[0])
+
+                for segment in subtitles_segments[1:]:
+                    subtitles.append_subtitles(subtitles.load(segment))
 
                 subtitles.polish(
                     fix_rtl=self.subtitles_fix_rtl,
@@ -124,7 +130,7 @@
                 )
 
             except Exception as e:
-                logger.warning(f"Failed to download {matched_media.name} ({matched_media.language}) subtitles. "
+                logger.warning(f"Failed to download {language_info_str} subtitles. "
                                f"Skipping...")
                 logger.debug(e, exc_info=True)
                 continue
Index: isubrip/subtitle_formats/webvtt.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nfrom abc import ABCMeta\r\nimport re\r\nfrom typing import TYPE_CHECKING, Any, ClassVar\r\n\r\nfrom isubrip.data_structures import SubtitlesFormatType\r\nfrom isubrip.subtitle_formats.subrip import SubRipCaptionBlock\r\nfrom isubrip.subtitle_formats.subtitles import RTL_CHAR, Subtitles, SubtitlesBlock, SubtitlesCaptionBlock\r\nfrom isubrip.utils import split_subtitles_timestamp\r\n\r\nif TYPE_CHECKING:\r\n    from datetime import time\r\n\r\n# WebVTT Documentation:\r\n# https://www.w3.org/TR/webvtt1/#cues\r\n# https://developer.mozilla.org/en-US/docs/Web/API/WebVTT_API#webvtt_cues\r\n\r\n\r\nclass WebVTTBlock(SubtitlesBlock, metaclass=ABCMeta):\r\n    \"\"\"\r\n    Abstract base class for WEBVTT cue blocks.\r\n    \"\"\"\r\n    is_caption_block: bool = False\r\n\r\n\r\nclass Caption(SubtitlesCaptionBlock, WebVTTBlock):\r\n    \"\"\"An object representing a WebVTT caption block.\"\"\"\r\n    subrip_alignment_conversion: ClassVar[bool] = False\r\n\r\n    is_caption_block: bool = True\r\n\r\n    def __init__(self, start_time: time, end_time: time, payload: str, settings: str = \"\", identifier: str = \"\"):\r\n        \"\"\"\r\n        Initialize a new object representing a WebVTT caption block.\r\n\r\n        Args:\r\n            start_time (time): Cue start time.\r\n            end_time (time): Cue end time.\r\n            settings (str): Cue settings.\r\n            payload (str): Cue payload.\r\n        \"\"\"\r\n        super().__init__(start_time=start_time, end_time=end_time, payload=payload)\r\n        self.identifier = identifier\r\n        self.settings = settings\r\n\r\n    def to_srt(self) -> SubRipCaptionBlock:\r\n        # Add a {\\an8} tag at the start of the payload if it has 'line:0.00%' in the settings\r\n        if \"line:0.00%\" in self.settings and self.subrip_alignment_conversion:\r\n            # If the payload starts with an RTL control char, add the tag after it\r\n            if self.payload.startswith(RTL_CHAR):\r\n                payload = RTL_CHAR + WEBVTT_ALIGN_TOP_TAG + self.payload[len(RTL_CHAR):]\r\n\r\n            else:\r\n                payload = WEBVTT_ALIGN_TOP_TAG + self.payload\r\n\r\n        else:\r\n            payload = self.payload\r\n\r\n        return SubRipCaptionBlock(start_time=self.start_time, end_time=self.end_time, payload=payload)\r\n\r\n    def __eq__(self, other: Any) -> bool:\r\n        return isinstance(other, type(self)) and \\\r\n            self.start_time == other.start_time and self.end_time == other.end_time and self.payload == other.payload\r\n\r\n    def __str__(self) -> str:\r\n        result_str = \"\"\r\n        time_format = \"%H:%M:%S.%f\"\r\n\r\n        # Add identifier (if it exists)\r\n        if self.identifier:\r\n            result_str += f\"{self.identifier}\\n\"\r\n\r\n        result_str += f\"{self.start_time.strftime(time_format)[:-3]} --> {self.end_time.strftime(time_format)[:-3]}\"\r\n\r\n        if self.settings:\r\n            result_str += f\" {self.settings}\"\r\n\r\n        result_str += f\"\\n{self.payload}\"\r\n\r\n        return result_str\r\n\r\n\r\nclass Comment(WebVTTBlock):\r\n    \"\"\"An object representing a WebVTT comment block.\"\"\"\r\n    header = \"NOTE\"\r\n\r\n    def __init__(self, payload: str, inline: bool = False) -> None:\r\n        \"\"\"\r\n        Initialize a new object representing a WebVTT comment block.\r\n\r\n        Args:\r\n            payload (str): Comment payload.\r\n        \"\"\"\r\n        self.payload = payload\r\n        self.inline = inline\r\n\r\n    def __eq__(self, other: Any) -> bool:\r\n        return isinstance(other, type(self)) and self.inline == other.inline and self.payload == other.payload\r\n\r\n    def __str__(self) -> str:\r\n        if self.inline:\r\n            return f\"{self.header} {self.payload}\"\r\n\r\n        if self.payload:\r\n            return f\"{self.header}\\n{self.payload}\"\r\n\r\n        return self.header\r\n\r\n\r\nclass Style(WebVTTBlock):\r\n    \"\"\"An object representing a WebVTT style block.\"\"\"\r\n    header = \"STYLE\"\r\n\r\n    def __init__(self, payload: str) -> None:\r\n        \"\"\"\r\n        Initialize a new object representing a WebVTT style block.\r\n\r\n        Args:\r\n            payload (str): Style payload.\r\n        \"\"\"\r\n        self.payload = payload\r\n\r\n    def __eq__(self, other: Any) -> bool:\r\n        return isinstance(other, type(self)) and self.payload == other.payload\r\n\r\n    def __str__(self) -> str:\r\n        return f\"{self.header} {self.payload}\"\r\n\r\n\r\nclass Region(WebVTTBlock):\r\n    \"\"\"An object representing a WebVTT region block.\"\"\"\r\n    header = \"REGION\"\r\n\r\n    def __init__(self, payload: str) -> None:\r\n        \"\"\"\r\n        Initialize a new object representing a WebVTT region block.\r\n\r\n        Args:\r\n            payload (str): Region payload.\r\n        \"\"\"\r\n        self.payload = payload\r\n\r\n    def __eq__(self, other: Any) -> bool:\r\n        return isinstance(other, type(self)) and self.payload == other.payload\r\n\r\n    def __str__(self) -> str:\r\n        return f\"{self.header} {self.payload}\"\r\n\r\n\r\nclass WebVTTSubtitles(Subtitles[WebVTTBlock]):\r\n    \"\"\"An object representing a WebVTT subtitles file.\"\"\"\r\n    format = SubtitlesFormatType.WEBVTT\r\n\r\n    def dumps(self) -> str:\r\n        \"\"\"\r\n        Dump subtitles to a string representing the subtitles in a WebVTT format.\r\n\r\n        Returns:\r\n            str: The subtitles in a string using a WebVTT format.\r\n        \"\"\"\r\n        subtitles_str = \"WEBVTT\\n\\n\"\r\n\r\n        for block in self.blocks:\r\n            subtitles_str += str(block) + \"\\n\\n\"\r\n\r\n        return subtitles_str.rstrip('\\n')\r\n\r\n    @staticmethod\r\n    def loads(subtitles_data: str) -> WebVTTSubtitles:\r\n        \"\"\"\r\n        Load WebVTT subtitles from a string.\r\n\r\n        Args:\r\n            subtitles_data (str): Subtitles data to load.\r\n\r\n        Returns:\r\n            WebVTTSubtitles: A WebVTTSubtitles object representing the subtitles.\r\n        \"\"\"\r\n        subtitles_obj = WebVTTSubtitles()\r\n        prev_line: str = \"\"\r\n        lines_iterator = iter(subtitles_data.splitlines())\r\n\r\n        for line in lines_iterator:\r\n            # If the line is a timestamp\r\n            if caption_block_regex := re.match(WEBVTT_CAPTION_BLOCK_REGEX, line):\r\n                # If previous line wasn't empty, add it as an identifier\r\n                if prev_line:\r\n                    caption_identifier = prev_line\r\n\r\n                else:\r\n                    caption_identifier = \"\"\r\n\r\n                caption_timestamps = split_subtitles_timestamp(caption_block_regex.group(1))\r\n                caption_settings = caption_block_regex.group(2)\r\n                caption_payload = \"\"\r\n\r\n                for additional_line in lines_iterator:\r\n                    if not additional_line:\r\n                        line = additional_line\r\n                        break\r\n\r\n                    caption_payload += additional_line + \"\\n\"\r\n\r\n                caption_payload = caption_payload.rstrip(\"\\n\")\r\n                subtitles_obj.add_block(Caption(\r\n                    identifier=caption_identifier,\r\n                    start_time=caption_timestamps[0],\r\n                    end_time=caption_timestamps[1],\r\n                    settings=caption_settings,\r\n                    payload=caption_payload))\r\n\r\n            elif comment_block_regex := re.match(WEBVTT_COMMENT_HEADER_REGEX, line):\r\n                comment_payload = \"\"\r\n                inline = False\r\n\r\n                if comment_block_regex.group(1) is not None:\r\n                    comment_payload += comment_block_regex.group(1) + \"\\n\"\r\n                    inline = True\r\n\r\n                for additional_line in lines_iterator:\r\n                    if not additional_line:\r\n                        line = additional_line\r\n                        break\r\n\r\n                    comment_payload += additional_line + \"\\n\"\r\n\r\n                subtitles_obj.add_block(Comment(comment_payload.rstrip(\"\\n\"), inline=inline))\r\n\r\n            elif line.rstrip(' \\t') == Region.header:\r\n                region_payload = \"\"\r\n\r\n                for additional_line in lines_iterator:\r\n                    if not additional_line:\r\n                        line = additional_line\r\n                        break\r\n\r\n                    region_payload += additional_line + \"\\n\"\r\n\r\n                subtitles_obj.add_block(Region(region_payload.rstrip(\"\\n\")))\r\n\r\n            elif line.rstrip(' \\t') == Style.header:\r\n                style_payload = \"\"\r\n\r\n                for additional_line in lines_iterator:\r\n                    if not additional_line:\r\n                        line = additional_line\r\n                        break\r\n\r\n                    style_payload += additional_line + \"\\n\"\r\n\r\n                subtitles_obj.add_block(Region(style_payload.rstrip(\"\\n\")))\r\n\r\n            prev_line = line\r\n        return subtitles_obj\r\n\r\n\r\n# --- Constants ---\r\nWEBVTT_PERCENTAGE_REGEX = r\"\\d{1,3}(?:\\.\\d+)?%\"\r\nWEBVTT_CAPTION_TIMINGS_REGEX = \\\r\n    r\"(?:[0-5]\\d:)?[0-5]\\d:[0-5]\\d[\\.,]\\d{3}[ \\t]+-->[ \\t]+(?:[0-5]\\d:)?[0-5]\\d:[0-5]\\d[\\.,]\\d{3}\"\r\n\r\nWEBVTT_CAPTION_SETTING_ALIGNMENT_REGEX = r\"align:(?:start|center|middle|end|left|right)\"\r\nWEBVTT_CAPTION_SETTING_LINE_REGEX = rf\"line:(?:{WEBVTT_PERCENTAGE_REGEX}|-?\\d+%)(?:,(?:start|center|middle|end))?\"\r\nWEBVTT_CAPTION_SETTING_POSITION_REGEX = rf\"position:{WEBVTT_PERCENTAGE_REGEX}(?:,(?:start|center|middle|end))?\"\r\nWEBVTT_CAPTION_SETTING_REGION_REGEX = r\"region:(?:(?!(?:-->)|\\t)\\S)+\"\r\nWEBVTT_CAPTION_SETTING_SIZE_REGEX = rf\"size:{WEBVTT_PERCENTAGE_REGEX}\"\r\nWEBVTT_CAPTION_SETTING_VERTICAL_REGEX = r\"vertical:(?:lr|rl)\"\r\n\r\nWEBVTT_CAPTION_SETTINGS_REGEX = (\"(?:\"\r\n                                 f\"(?:{WEBVTT_CAPTION_SETTING_ALIGNMENT_REGEX})|\"\r\n                                 f\"(?:{WEBVTT_CAPTION_SETTING_LINE_REGEX})|\"\r\n                                 f\"(?:{WEBVTT_CAPTION_SETTING_POSITION_REGEX})|\"\r\n                                 f\"(?:{WEBVTT_CAPTION_SETTING_REGION_REGEX})|\"\r\n                                 f\"(?:{WEBVTT_CAPTION_SETTING_SIZE_REGEX})|\"\r\n                                 f\"(?:{WEBVTT_CAPTION_SETTING_VERTICAL_REGEX})|\"\r\n                                 f\"(?:[ \\t]+)\"\r\n                                 \")*\")\r\n\r\nWEBVTT_CAPTION_BLOCK_REGEX = rf\"^({WEBVTT_CAPTION_TIMINGS_REGEX})[ \\t]*({WEBVTT_CAPTION_SETTINGS_REGEX})?\"\r\nWEBVTT_COMMENT_HEADER_REGEX = rf\"^{Comment.header}(?:$|[ \\t])(.+)?\"\r\n\r\nWEBVTT_ALIGN_TOP_TAG = \"{\\\\an8}\"\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/subtitle_formats/webvtt.py b/isubrip/subtitle_formats/webvtt.py
--- a/isubrip/subtitle_formats/webvtt.py	(revision 67c115fc7dbd1dc7520fc499455860dceb009906)
+++ b/isubrip/subtitle_formats/webvtt.py	(date 1707504695380)
@@ -166,18 +166,19 @@
 
         return subtitles_str.rstrip('\n')
 
-    @staticmethod
-    def loads(subtitles_data: str) -> WebVTTSubtitles:
+    @classmethod
+    def loads(cls, subtitles_data: str, encoding: str = "utf-8") -> WebVTTSubtitles:
         """
         Load WebVTT subtitles from a string.
 
         Args:
             subtitles_data (str): Subtitles data to load.
+            encoding (str, optional): Encoding of the subtitles. Defaults to "utf-8".
 
         Returns:
             WebVTTSubtitles: A WebVTTSubtitles object representing the subtitles.
         """
-        subtitles_obj = WebVTTSubtitles()
+        subtitles_obj = WebVTTSubtitles(encoding=encoding)
         prev_line: str = ""
         lines_iterator = iter(subtitles_data.splitlines())
 
Index: isubrip/__main__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nimport atexit\r\nimport logging\r\nfrom pathlib import Path\r\nimport shutil\r\nimport sys\r\nfrom typing import List\r\n\r\nimport requests\r\nfrom requests.utils import default_user_agent\r\n\r\nfrom isubrip.config import Config, ConfigError, ConfigSetting, SpecialConfigType\r\nfrom isubrip.constants import (\r\n    ARCHIVE_FORMAT,\r\n    DATA_FOLDER_PATH,\r\n    DEFAULT_CONFIG_PATH,\r\n    LOG_FILE_NAME,\r\n    LOG_FILES_PATH,\r\n    PACKAGE_NAME,\r\n    PACKAGE_VERSION,\r\n    PREORDER_MESSAGE,\r\n    TEMP_FOLDER_PATH,\r\n    USER_CONFIG_FILE,\r\n)\r\nfrom isubrip.data_structures import (\r\n    Episode,\r\n    MediaBase,\r\n    MediaData,\r\n    Movie,\r\n    ScrapedMediaResponse,\r\n    Season,\r\n    Series,\r\n    SubtitlesData,\r\n    SubtitlesDownloadResults,\r\n)\r\nfrom isubrip.logger import CustomLogFileFormatter, CustomStdoutFormatter, logger\r\nfrom isubrip.scrapers.scraper import PlaylistLoadError, Scraper, ScraperError, ScraperFactory\r\nfrom isubrip.subtitle_formats.webvtt import Caption as WebVTTCaption\r\nfrom isubrip.utils import (\r\n    TempDirGenerator,\r\n    download_subtitles_to_file,\r\n    generate_media_description,\r\n    generate_non_conflicting_path,\r\n    generate_release_name,\r\n    raise_for_status,\r\n    single_to_list,\r\n)\r\n\r\nLOG_ROTATION_SIZE: int | None = None\r\n\r\nBASE_CONFIG_SETTINGS = [\r\n    ConfigSetting(\r\n        key=\"check-for-updates\",\r\n        type=bool,\r\n        category=\"general\",\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"log_rotation_size\",\r\n        type=str,\r\n        category=\"general\",\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"add-release-year-to-series\",\r\n        type=bool,\r\n        category=\"downloads\",\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"folder\",\r\n        type=str,\r\n        category=\"downloads\",\r\n        required=True,\r\n        special_type=SpecialConfigType.EXISTING_FOLDER_PATH,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"languages\",\r\n        type=List[str],\r\n        category=\"downloads\",\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"overwrite-existing\",\r\n        type=bool,\r\n        category=\"downloads\",\r\n        required=True,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"zip\",\r\n        type=bool,\r\n        category=\"downloads\",\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"fix-rtl\",\r\n        type=bool,\r\n        category=\"subtitles\",\r\n        required=True,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"rtl-languages\",\r\n        type=List[str],\r\n        category=\"subtitles\",\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"remove-duplicates\",\r\n        type=bool,\r\n        category=\"subtitles\",\r\n        required=True,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"convert-to-srt\",\r\n        type=bool,\r\n        category=\"subtitles\",\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"subrip-alignment-conversion\",\r\n        type=bool,\r\n        category=(\"subtitles\", \"webvtt\"),\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"user-agent\",\r\n        type=str,\r\n        category=\"scrapers\",\r\n        required=True,\r\n    ),\r\n]\r\n\r\n\r\ndef main() -> None:\r\n    try:\r\n        # Assure at least one argument was passed\r\n        if len(sys.argv) < 2:\r\n            print_usage()\r\n            exit(0)\r\n\r\n        create_required_folders()\r\n        setup_loggers(stdout_loglevel=logging.INFO,\r\n                      file_loglevel=logging.DEBUG)\r\n\r\n        cli_args = \" \".join(sys.argv[1:])\r\n        logger.debug(f\"Used CLI Command: {PACKAGE_NAME} {cli_args}\")\r\n        logger.debug(f\"Python version: {sys.version}\")\r\n        logger.debug(f\"Package version: {PACKAGE_VERSION}\")\r\n        logger.debug(f\"OS: {sys.platform}\")\r\n\r\n        config = generate_config()\r\n        update_settings(config)\r\n\r\n        if config.general.get(\"check-for-updates\", True):\r\n            check_for_updates(current_package_version=PACKAGE_VERSION)\r\n\r\n        urls = single_to_list(sys.argv[1:])\r\n        download(urls=urls, config=config)\r\n\r\n    except Exception as ex:\r\n        logger.error(f\"Error: {ex}\")\r\n        logger.debug(f\"Stack trace: {ex}\", exc_info=True)\r\n        exit(1)\r\n\r\n    finally:\r\n        if log_rotation_size := LOG_ROTATION_SIZE:\r\n            handle_log_rotation(log_rotation_size=log_rotation_size)\r\n\r\n        # NOTE: This will only close scrapers that were initialized using the ScraperFactory.\r\n        for scraper in ScraperFactory.get_initialized_scrapers():\r\n            scraper.close()\r\n\r\n        TempDirGenerator.cleanup()\r\n\r\n\r\ndef download(urls: list[str], config: Config) -> None:\r\n    \"\"\"\r\n    Download subtitles from a given URL.\r\n\r\n    Args:\r\n        urls (list[str]): A list of URLs to download subtitles from.\r\n        config (Config): A config to use for downloading subtitles.\r\n    \"\"\"\r\n    for url in urls:\r\n        try:\r\n            logger.info(f\"Scraping '{url}'...\")\r\n\r\n            scraper = ScraperFactory.get_scraper_instance(url=url,\r\n                                                          kwargs={\"config_data\": config.data.get(\"scrapers\")})\r\n            atexit.register(scraper.close)\r\n            scraper.config.check()  # Recheck config after scraper settings were loaded\r\n\r\n            try:\r\n                logger.debug(f\"Fetching '{url}'...\")\r\n                scraper_response: ScrapedMediaResponse = scraper.get_data(url=url)\r\n\r\n            except ScraperError as e:\r\n                logger.error(f\"Error: {e}\")\r\n                logger.debug(\"Debug information:\", exc_info=True)\r\n                continue\r\n\r\n            media_data = scraper_response.media_data\r\n            playlist_scraper = ScraperFactory.get_scraper_instance(scraper_id=scraper_response.playlist_scraper,\r\n                                                                   kwargs={\"config_data\": config.data.get(\"scrapers\")},\r\n                                                                   extract_scraper_config=True)\r\n\r\n            if not media_data:\r\n                logger.error(f\"Error: No supported media was found for {url}.\")\r\n                continue\r\n\r\n            for media_item in media_data:\r\n                try:\r\n                    object_type_str = media_item.__class__.__name__.lower()\r\n\r\n                    logger.info(f\"Found {object_type_str}: {generate_media_description(media_data=media_item)}\")\r\n                    download_media(scraper=playlist_scraper, media_item=media_item, config=config)\r\n\r\n                except Exception as e:\r\n                    if len(media_data) > 1:\r\n                        logger.warning(f\"Error scraping media item \"\r\n                                       f\"'{generate_media_description(media_data=media_item)}': {e}\\n\"\r\n                                       f\"Skipping to next media item...\")\r\n                        logger.debug(\"Debug information:\", exc_info=True)\r\n                        continue\r\n\r\n                    raise\r\n\r\n        except Exception as e:\r\n            logger.error(f\"Error while scraping '{url}': {e}\")\r\n            logger.debug(\"Debug information:\", exc_info=True)\r\n            continue\r\n\r\n\r\ndef download_media(scraper: Scraper, media_item: MediaData, config: Config) -> None:\r\n    \"\"\"\r\n    Download a media item.\r\n\r\n    Args:\r\n        scraper (Scraper): A Scraper object to use for downloading subtitles.\r\n        media_item (MediaData): A media data item to download subtitles for.\r\n        config (Config): A config to use for downloading subtitles.\r\n    \"\"\"\r\n    if isinstance(media_item, Series):\r\n        for season in media_item.seasons:\r\n            download_media(scraper=scraper, media_item=season, config=config)\r\n        return\r\n\r\n    if isinstance(media_item, Season):\r\n        for episode in media_item.episodes:\r\n            logger.info(f\"{generate_media_description(media_data=episode, shortened=True)}:\")\r\n            download_media(scraper=scraper, media_item=episode, config=config)\r\n        return\r\n\r\n    if media_item.playlist:\r\n        download_subtitles_kwargs = {\r\n            \"download_path\": Path(config.downloads[\"folder\"]),\r\n            \"language_filter\": config.downloads.get(\"languages\"),\r\n            \"convert_to_srt\": config.subtitles.get(\"convert-to-srt\", False),\r\n            \"overwrite_existing\": config.downloads.get(\"overwrite-existing\", False),\r\n            \"zip_files\": config.downloads.get(\"zip\", False),\r\n        }\r\n\r\n        try:\r\n            results = download_subtitles(scraper=scraper,\r\n                                         media_data=media_item,\r\n                                         **download_subtitles_kwargs)\r\n\r\n            success_count = len(results.successful_subtitles)\r\n            failed_count = len(results.failed_subtitles)\r\n\r\n            if success_count:\r\n                logger.info(f\"{success_count}/{success_count + failed_count} matching subtitles \"\r\n                            f\"have been successfully downloaded.\")\r\n\r\n            elif failed_count:\r\n                logger.info(f\"{failed_count} subtitles were matched, but failed to download.\")\r\n\r\n            else:\r\n                logger.info(\"No matching subtitles were found.\")\r\n\r\n            return  # noqa: TRY300\r\n\r\n        except PlaylistLoadError:\r\n            pass\r\n\r\n    # We get here if there is no playlist, or there is one, but it failed to load\r\n    if isinstance(media_item, Movie) and media_item.preorder_availability_date:\r\n        preorder_date_str = media_item.preorder_availability_date.strftime(\"%Y-%m-%d\")\r\n        logger.info(PREORDER_MESSAGE.format(movie_name=media_item.name, scraper_name=scraper.name,\r\n                                            preorder_date=preorder_date_str))\r\n\r\n    else:\r\n        logger.error(\"No valid playlist was found.\")\r\n\r\n\r\ndef check_for_updates(current_package_version: str) -> None:\r\n    \"\"\"\r\n    Check and print if a newer version of the package is available, and log accordingly.\r\n\r\n    Args:\r\n        current_package_version (str): The current version of the package.\r\n    \"\"\"\r\n    api_url = f\"https://pypi.org/pypi/{PACKAGE_NAME}/json\"\r\n    logger.debug(\"Checking for package updates on PyPI...\")\r\n    try:\r\n        response = requests.get(\r\n            url=api_url,\r\n            headers={\"Accept\": \"application/json\"},\r\n            timeout=5,\r\n        )\r\n        raise_for_status(response)\r\n        response_data = response.json()\r\n\r\n        pypi_latest_version = response_data[\"info\"][\"version\"]\r\n\r\n        if pypi_latest_version != current_package_version:\r\n            logger.warning(f\"You are currently using version '{current_package_version}' of '{PACKAGE_NAME}', \"\r\n                           f\"however version '{pypi_latest_version}' is available.\"\r\n                           f'\\nConsider upgrading by running \"python3 -m pip install --upgrade {PACKAGE_NAME}\"\\n')\r\n\r\n        else:\r\n            logger.debug(f\"Latest version of '{PACKAGE_NAME}' ({current_package_version}) is currently installed.\")\r\n\r\n    except Exception as e:\r\n        logger.warning(f\"Update check failed: {e}\")\r\n        logger.debug(f\"Stack trace: {e}\", exc_info=True)\r\n        return\r\n\r\n\r\ndef create_required_folders() -> None:\r\n    if not DATA_FOLDER_PATH.is_dir():\r\n        logger.debug(f\"'{DATA_FOLDER_PATH}' directory could not be found and will be created.\")\r\n        LOG_FILES_PATH.mkdir(parents=True, exist_ok=True)\r\n\r\n    else:\r\n        if not LOG_FILES_PATH.is_dir():\r\n            logger.debug(f\"'{LOG_FILES_PATH}' directory could not be found and will be created.\")\r\n            LOG_FILES_PATH.mkdir()\r\n\r\n\r\ndef download_subtitles(scraper: Scraper, media_data: Movie | Episode, download_path: Path,\r\n                       language_filter: list[str] | None = None, convert_to_srt: bool = False,\r\n                       overwrite_existing: bool = True, zip_files: bool = False) -> SubtitlesDownloadResults:\r\n    \"\"\"\r\n    Download subtitles for the given media data.\r\n\r\n    Args:\r\n        scraper (Scraper): A Scraper object to use for downloading subtitles.\r\n        media_data (Movie | Episode): A movie or episode data object.\r\n        download_path (Path): Path to a folder where the subtitles will be downloaded to.\r\n        language_filter (list[str] | None): List of specific languages to download subtitles for.\r\n            None for all languages (no filter). Defaults to None.\r\n        convert_to_srt (bool, optional): Whether to convert the subtitles to SRT format. Defaults to False.\r\n        overwrite_existing (bool, optional): Whether to overwrite existing subtitles. Defaults to True.\r\n        zip_files (bool, optional): Whether to unite the subtitles into a single zip file\r\n            (only if there are multiple subtitles).\r\n\r\n    Returns:\r\n        SubtitlesDownloadResults: A SubtitlesDownloadResults object containing the results of the download.\r\n    \"\"\"\r\n    temp_dir_name = generate_media_folder_name(media_data=media_data, source=scraper.abbreviation)\r\n    temp_download_path = TempDirGenerator.generate(directory_name=temp_dir_name)\r\n\r\n    successful_downloads: list[SubtitlesData] = []\r\n    failed_downloads: list[SubtitlesData] = []\r\n    temp_downloads: list[Path] = []\r\n\r\n    for subtitles_data in scraper.get_subtitles(main_playlist=media_data.playlist,  # type: ignore[arg-type]\r\n                                                language_filter=language_filter,\r\n                                                subrip_conversion=convert_to_srt):\r\n        if subtitles_data.language_name:\r\n            language_data = f\"{subtitles_data.language_name} ({subtitles_data.language_code})\"\r\n\r\n        else:\r\n            language_data = subtitles_data.language_code\r\n\r\n        if subtitles_type := subtitles_data.special_type:\r\n            language_data += f\" [{subtitles_type.value}]\"\r\n\r\n        try:\r\n            temp_downloads.append(download_subtitles_to_file(\r\n                media_data=media_data,\r\n                subtitles_data=subtitles_data,\r\n                output_path=temp_download_path,\r\n                source_abbreviation=scraper.abbreviation,\r\n                overwrite=overwrite_existing,\r\n            ))\r\n\r\n            logger.info(f\"{language_data} subtitles were successfully downloaded.\")\r\n            successful_downloads.append(subtitles_data)\r\n\r\n        except Exception as e:\r\n            logger.error(f\"Error: Failed to download '{language_data}' subtitles: {e}\")\r\n            logger.debug(\"Stack trace:\", exc_info=True)\r\n            failed_downloads.append(subtitles_data)\r\n            continue\r\n\r\n    if not zip_files or len(temp_downloads) == 1:\r\n        for file_path in temp_downloads:\r\n            if overwrite_existing:\r\n                new_path = download_path / file_path.name\r\n\r\n            else:\r\n                new_path = generate_non_conflicting_path(file_path=download_path / file_path.name)\r\n\r\n            # str conversion needed only for Python <= 3.8 - https://github.com/python/cpython/issues/76870\r\n            shutil.move(src=str(file_path), dst=new_path)\r\n\r\n    elif len(temp_downloads) > 0:\r\n        archive_path = Path(shutil.make_archive(\r\n            base_name=str(temp_download_path.parent / temp_download_path.name),\r\n            format=ARCHIVE_FORMAT,\r\n            root_dir=temp_download_path,\r\n        ))\r\n\r\n        file_name = generate_media_folder_name(media_data=media_data,\r\n                                               source=scraper.abbreviation) + f\".{ARCHIVE_FORMAT}\"\r\n\r\n        if overwrite_existing:\r\n            destination_path = download_path / file_name\r\n\r\n        else:\r\n            destination_path = generate_non_conflicting_path(file_path=download_path / file_name)\r\n\r\n        shutil.move(src=str(archive_path), dst=destination_path)\r\n\r\n    return SubtitlesDownloadResults(\r\n        movie_data=media_data,\r\n        successful_subtitles=successful_downloads,\r\n        failed_subtitles=failed_downloads,\r\n        is_zip=zip_files,\r\n    )\r\n\r\n\r\ndef handle_log_rotation(log_rotation_size: int) -> None:\r\n    \"\"\"\r\n    Handle log rotation and remove old log files if needed.\r\n\r\n    Args:\r\n        log_rotation_size (int): Maximum amount of log files to keep.\r\n    \"\"\"\r\n    sorted_log_files = sorted(LOG_FILES_PATH.glob(\"*.log\"), key=lambda file: file.stat().st_mtime, reverse=True)\r\n\r\n    if len(sorted_log_files) > log_rotation_size:\r\n        for log_file in sorted_log_files[log_rotation_size:]:\r\n            log_file.unlink()\r\n\r\n\r\ndef generate_config() -> Config:\r\n    \"\"\"\r\n    Generate a config object using config files, and validate it.\r\n\r\n    Returns:\r\n        Config: A config object.\r\n\r\n    Raises:\r\n        ConfigException: If there is a general config error.\r\n        MissingConfigValue: If a required config value is missing.\r\n        InvalidConfigValue: If a config value is invalid.\r\n    \"\"\"\r\n    if not DEFAULT_CONFIG_PATH.is_file():\r\n        raise ConfigError(\"Default config file could not be found.\")\r\n\r\n    config = Config(config_settings=BASE_CONFIG_SETTINGS)\r\n\r\n    logger.debug(\"Loading default config data...\")\r\n\r\n    with DEFAULT_CONFIG_PATH.open('r') as data:\r\n        config.loads(config_data=data.read(), check_config=True)\r\n\r\n    logger.debug(\"Default config data loaded and validated successfully.\")\r\n\r\n    # If logs folder doesn't exist, create it (also handles data folder)\r\n    if not DATA_FOLDER_PATH.is_dir():\r\n        logger.debug(f\"'{DATA_FOLDER_PATH}' directory could not be found and will be created.\")\r\n        DATA_FOLDER_PATH.mkdir(parents=True, exist_ok=True)\r\n        LOG_FILES_PATH.mkdir()\r\n\r\n    else:\r\n        if not LOG_FILES_PATH.is_dir():\r\n            logger.debug(f\"'{LOG_FILES_PATH}' directory could not be found and will be created.\")\r\n            LOG_FILES_PATH.mkdir()\r\n\r\n        # If a user config file exists, add it to config_files\r\n        if USER_CONFIG_FILE.is_file():\r\n            logger.info(f\"User config file detected at '{USER_CONFIG_FILE}' and will be used.\")\r\n\r\n            with USER_CONFIG_FILE.open('r') as data:\r\n                config.loads(config_data=data.read(), check_config=True)\r\n\r\n            logger.debug(\"User config file loaded and validated successfully.\")\r\n\r\n    return config\r\n\r\n\r\ndef generate_media_folder_name(media_data: Movie | Episode, source: str | None = None) -> str:\r\n    \"\"\"\r\n    Generate a folder name for media data.\r\n\r\n    Args:\r\n        media_data (Movie | Episode): A movie or episode data object.\r\n        source (str | None, optional): Abbreviation of the source to use for file names. Defaults to None.\r\n\r\n    Returns:\r\n        str: A folder name for the media data.\r\n    \"\"\"\r\n    if isinstance(media_data, Movie):\r\n        return generate_release_name(\r\n            title=media_data.name,\r\n            release_date=media_data.release_date,\r\n            media_source=source,\r\n        )\r\n\r\n    # elif isinstance(media_data, Episode):\r\n    return generate_release_name(\r\n        title=media_data.series_name,\r\n        season_number=media_data.season_number,\r\n        media_source=source,\r\n    )\r\n\r\n\r\ndef generate_temp_media_path(media_data: Movie | Episode, source: str | None = None) -> Path:\r\n    \"\"\"\r\n    Generate a temporary directory for downloading media data.\r\n\r\n    Args:\r\n        media_data (Movie | Episode): A movie or episode data object.\r\n        source (str | None, optional): Abbreviation of the source to use for file names. Defaults to None.\r\n\r\n    Returns:\r\n        Path: A path to the temporary folder.\r\n    \"\"\"\r\n    temp_folder_name = generate_media_folder_name(media_data=media_data, source=source)\r\n    path = generate_non_conflicting_path(file_path=TEMP_FOLDER_PATH / temp_folder_name, has_extension=False)\r\n\r\n    return TempDirGenerator.generate(directory_name=path.name)\r\n\r\n\r\ndef update_settings(config: Config) -> None:\r\n    \"\"\"\r\n    Update settings according to config.\r\n\r\n    Args:\r\n        config (Config): An instance of a config to set settings according to.\r\n    \"\"\"\r\n    Scraper.subtitles_fix_rtl = config.subtitles[\"fix-rtl\"]\r\n    Scraper.subtitles_fix_rtl_languages = config.subtitles.get(\"rtl-languages\")\r\n    Scraper.subtitles_remove_duplicates = config.subtitles[\"remove-duplicates\"]\r\n    Scraper.default_user_agent = config.scrapers.get(\"user-agent\", default_user_agent())\r\n    WebVTTCaption.subrip_alignment_conversion = (\r\n        config.subtitles.get(\"webvtt\", {}).get(\"subrip-alignment-conversion\", False)\r\n    )\r\n\r\n    if log_rotation := config.general.get(\"log-rotation-size\"):\r\n        global LOG_ROTATION_SIZE\r\n        LOG_ROTATION_SIZE = log_rotation\r\n\r\n\r\ndef print_usage() -> None:\r\n    \"\"\"Print usage information.\"\"\"\r\n    logger.info(f\"Usage: {PACKAGE_NAME} <iTunes movie URL> [iTunes movie URL...]\")\r\n\r\n\r\ndef setup_loggers(stdout_loglevel: int, file_loglevel: int) -> None:\r\n    \"\"\"\r\n    Configure loggers.\r\n\r\n    Args:\r\n        stdout_loglevel (int): Log level for STDOUT logger.\r\n        file_loglevel (int): Log level for logfile logger.\r\n    \"\"\"\r\n    logger.setLevel(logging.DEBUG)\r\n\r\n    # Setup STDOUT logger\r\n    stdout_handler = logging.StreamHandler(sys.stdout)\r\n    stdout_handler.setLevel(stdout_loglevel)\r\n    stdout_handler.setFormatter(CustomStdoutFormatter())\r\n    logger.addHandler(stdout_handler)\r\n\r\n    # Setup logfile logger\r\n    logfile_path = generate_non_conflicting_path(file_path=LOG_FILES_PATH / LOG_FILE_NAME)\r\n    logfile_handler = logging.FileHandler(filename=logfile_path, encoding=\"utf-8\")\r\n    logfile_handler.setLevel(file_loglevel)\r\n    logfile_handler.setFormatter(CustomLogFileFormatter())\r\n    logger.addHandler(logfile_handler)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/__main__.py b/isubrip/__main__.py
--- a/isubrip/__main__.py	(revision 67c115fc7dbd1dc7520fc499455860dceb009906)
+++ b/isubrip/__main__.py	(date 1707508894254)
@@ -1,6 +1,5 @@
 from __future__ import annotations
 
-import atexit
 import logging
 from pathlib import Path
 import shutil
@@ -25,7 +24,6 @@
 )
 from isubrip.data_structures import (
     Episode,
-    MediaBase,
     MediaData,
     Movie,
     ScrapedMediaResponse,
@@ -139,9 +137,9 @@
             print_usage()
             exit(0)
 
-        create_required_folders()
-        setup_loggers(stdout_loglevel=logging.INFO,
+        setup_loggers(stdout_loglevel=logging.DEBUG,
                       file_loglevel=logging.DEBUG)
+        initial_setup()
 
         cli_args = " ".join(sys.argv[1:])
         logger.debug(f"Used CLI Command: {PACKAGE_NAME} {cli_args}")
@@ -188,7 +186,6 @@
 
             scraper = ScraperFactory.get_scraper_instance(url=url,
                                                           kwargs={"config_data": config.data.get("scrapers")})
-            atexit.register(scraper.close)
             scraper.config.check()  # Recheck config after scraper settings were loaded
 
             try:
@@ -328,16 +325,17 @@
         return
 
 
-def create_required_folders() -> None:
+def initial_setup() -> None:
     if not DATA_FOLDER_PATH.is_dir():
         logger.debug(f"'{DATA_FOLDER_PATH}' directory could not be found and will be created.")
         LOG_FILES_PATH.mkdir(parents=True, exist_ok=True)
 
-    else:
+    else:  # LOG_FILES_PATH is inside DATA_FOLDER_PATH
         if not LOG_FILES_PATH.is_dir():
             logger.debug(f"'{LOG_FILES_PATH}' directory could not be found and will be created.")
             LOG_FILES_PATH.mkdir()
 
+    shutil.rmtree(path=TEMP_FOLDER_PATH, ignore_errors=True)
 
 def download_subtitles(scraper: Scraper, media_data: Movie | Episode, download_path: Path,
                        language_filter: list[str] | None = None, convert_to_srt: bool = False,
Index: isubrip/scrapers/disneyplus_hotstar_scraper.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nimport datetime as dt\r\nimport re\r\nfrom typing import TYPE_CHECKING, Iterator\r\n\r\nimport httpx\r\n\r\nfrom isubrip.config import Config, ConfigSetting\r\nfrom isubrip.data_structures import (\r\n    Episode,\r\n    Movie,\r\n    ScrapedMediaResponse,\r\n    Season,\r\n    Series,\r\n    SubtitlesData,\r\n    SubtitlesFormatType,\r\n)\r\nfrom isubrip.logger import logger\r\nfrom isubrip.parsers.mpeg_dash import MPD\r\nfrom isubrip.scrapers.scraper import DASHScraper, PlaylistLoadError, ScraperError\r\nfrom isubrip.subtitle_formats.webvtt import WebVTTSubtitles\r\nfrom isubrip.utils import (\r\n    extract_host_from_url,\r\n    generate_random_hex_string,\r\n    generate_url_params,\r\n    parse_duration,\r\n    parse_season_and_episode_tag,\r\n    parse_url_params,\r\n    raise_for_status,\r\n    single_to_list,\r\n)\r\n\r\nif TYPE_CHECKING:\r\n    import requests\r\n\r\n\r\nclass DisneyPlusHotstarScraper(DASHScraper):\r\n    \"\"\"\r\n    A Disney+ Hotstar scraper\r\n\r\n    Attributes:\r\n        _api_base_url (str): Disney+ Hotstar's base API URL.\r\n        _player_params (dict): Parameters to send to the API to get the player config.\r\n        jwt_token (str): JWT token used to authenticate with the API.\r\n    \"\"\"\r\n    id = \"dsnphs\"\r\n    name = \"Disney+ (Hotstar)\"\r\n    abbreviation = \"DSNP\"\r\n    url_regex = re.compile(r\"(?P<base_url>https?://(?:www\\.)?apps\\.disneyplus\\.com/(?P<slug>(?:(?P<country_code>[a-z]{2})/)?(?:(?P<media_type>movies|shows)/)?(?:(?P<media_name>[\\w\\-%]+)/)?(?P<media_id>(?:\\d{4,10}))))(?:\\?(?P<url_params>.*))?\", flags=re.IGNORECASE)  # noqa: E501\r\n    # TODO: Update regex - slug can have episode data. Ex: il/shows/mshpkht-sympsvn/1260023404/some-enchanted-evening/1260023628\r\n    subtitles_class = WebVTTSubtitles\r\n    is_movie_scraper = True\r\n    is_series_scraper = True\r\n\r\n    _api_base_url = \"https://www.apps.disneyplus.com/api/internal/bff\"\r\n    _player_params = {\r\n        \"client_capabilities\":\r\n            {\r\n                \"audio_channel\": [\"stereo\"],\r\n                \"container\": [\"fmp4\", \"ts\"],\r\n                \"dvr\": [\"short\"],\r\n                \"dynamic_range\": [\"sdr\"],\r\n                \"encryption\": [\"widevine\", \"plain\"],\r\n                \"ladder\": [\"tv\", \"phone\"],\r\n                \"package\": [\"dash\", \"hls\"],\r\n                \"resolution\": [\"sd\", \"hd\", \"fhd\"],\r\n                \"video_codec\": [\"h264\"],\r\n            },\r\n        \"drm_parameters\":\r\n            {\r\n                \"hdcp_version\": [\"HDCP_V2_2\"],\r\n                \"widevine_security_level\": [\"SW_SECURE_DECODE\"],\r\n                \"playready_security_level\": [],\r\n            },\r\n    }\r\n\r\n    def __init__(self, config_data: dict | None = None):\r\n        super().__init__(config_data=config_data)\r\n\r\n        if self.config is None:\r\n            self.config = Config()\r\n\r\n        # Add \"token\" setting to config\r\n        self.config.add_settings(\r\n            ConfigSetting(\r\n                key=\"token\",\r\n                type=str,\r\n                required=True,\r\n            ),\r\n            check_config=True)\r\n\r\n        self.jwt_token: str = self.config[\"token\"]\r\n        self._session.headers.update({\r\n            \"Accept\": \"application/json\",\r\n            \"X-Hs-Usertoken\": self.jwt_token,\r\n            \"X-Hs-Platform\": \"web\",\r\n            \"X-Hs-Client\": \"platform:web;app_version:23.05.29.0;browser:Chrome;schema_version:0.0.854\",\r\n        })\r\n        self._http2_session = httpx.Client(http2=True)\r\n\r\n        # Add proxy\r\n        import urllib3\r\n        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\r\n\r\n        self._session.proxies.update({\r\n            \"http\": \"http://127.0.0.1:8085\",\r\n            \"https\": \"http://127.0.0.1:8085\",\r\n        })\r\n        self._session.verify = False\r\n\r\n    def _authenticated_get(self, url: str, additional_headers: dict | None = None, **kwargs) -> Response:\r\n        headers = self._generate_headers(url=url,\r\n                                         additional_headers=additional_headers)\r\n\r\n        response = self._session.get(url=url, headers=headers, **kwargs)\r\n        raise_for_status(response)\r\n        return response\r\n\r\n    def _generate_headers(self, url: str, additional_headers: dict | None = None) -> dict:\r\n        \"\"\"\r\n        Generate headers for a Disney+ Hotstar's API request.\r\n\r\n        Args:\r\n            url (str): URL to generate headers for.\r\n            additional_headers (dict, optional): Additional headers to add to the generated headers. Defaults to None.\r\n\r\n        Returns:\r\n            dict: Generated headers for the request.\r\n        \"\"\"\r\n        request_id = self._generate_request_id()\r\n\r\n        headers = {\r\n            **self._session.headers,\r\n            \"Host\": extract_host_from_url(url),\r\n            \"X-Request-Id\": request_id,\r\n            \"X-Hs-Request-Id\": request_id,\r\n            \"Origin\": \"https://www.apps.disneyplus.com\",\r\n            \"Referer\": \"https://www.apps.disneyplus.com/\",\r\n        }\r\n\r\n        if additional_headers:\r\n            headers.update(additional_headers)\r\n\r\n        return headers\r\n\r\n    @staticmethod\r\n    def _generate_request_id() -> str:\r\n        request_id = generate_random_hex_string(8) + '-'\r\n\r\n        for _ in range(3):\r\n            request_id += generate_random_hex_string(4) + '-'\r\n\r\n        return request_id + generate_random_hex_string(12)\r\n\r\n    def _get_api_data(self, endpoint: str) -> dict:\r\n        \"\"\"\r\n        Retrieve data from the Disney+ Hotstar's API.\r\n\r\n        Args:\r\n            endpoint (str): API endpoint.\r\n\r\n        Returns:\r\n            dict: Data returned by the API for the given endpoint.\r\n        \"\"\"\r\n        response = self._authenticated_get(f\"{self._api_base_url}/{endpoint}\")\r\n        return response.json()\r\n\r\n    def _get_media_playlists(self, media_slug: str) -> list[str]:\r\n        player_params = generate_url_params(data=self._player_params, remove_dict_spaces=True)\r\n        api_data = self._get_api_data(endpoint=f\"v2/slugs/{media_slug}/watch?{player_params}\")\r\n\r\n        player_config = (\r\n            api_data[\"success\"][\"page\"][\"spaces\"][\"player\"][\"widget_wrappers\"][0][\"widget\"][\"data\"][\"player_config\"]\r\n        )\r\n\r\n        return_data = [\r\n            player_config.get(\"media_asset_v2\", {}).get(\"primary\", {}).get(\"content_url\"),\r\n            player_config.get(\"media_asset_v2\", {}).get(\"fallback\", {}).get(\"content_url\"),\r\n        ]\r\n\r\n        return [playlist_url for playlist_url in return_data if playlist_url]\r\n\r\n    def _get_season_data(self, show_id: str, season_id: str) -> dict[int, dict]:\r\n        endpoint = f\"v2/pages/841/spaces/803/widgets/1196/widgets/168?content_id={show_id}&season_id={season_id}\"\r\n        paginated_data = []\r\n\r\n        # Get all paginated episodes data for the season\r\n        while endpoint:  # TODO: Increase page size\r\n            api_data = self._get_api_data(endpoint)\r\n            episodes_paginated_data = api_data[\"success\"][\"widget_wrapper\"][\"widget\"][\"data\"]\r\n            paginated_data.extend(episodes_paginated_data[\"items\"])\r\n            endpoint = episodes_paginated_data.get(\"next_tray_url\")\r\n\r\n        api_episodes_data = [episode_data[\"playable_content\"][\"data\"] for episode_data in paginated_data]\r\n        result_data: dict[int, dict] = {}\r\n\r\n        for episode_data in api_episodes_data:\r\n            page_slug = episode_data[\"actions\"][\"on_click\"][1][\"page_navigation\"][\"page_slug\"].split(\"/watch\")[0]\r\n            episode_data[\"playlists\"] = self._get_media_playlists(media_slug=page_slug.lstrip(\"/\"))\r\n            episode_number = parse_season_and_episode_tag(episode_data[\"tags\"][0][\"value\"])[1]\r\n            # Remove unnecessary data\r\n            if 'actions' in episode_data:\r\n                episode_data.pop('actions')\r\n\r\n            if 'download_options' in episode_data:\r\n                episode_data.pop('download_options')\r\n\r\n            result_data[episode_number] = episode_data\r\n\r\n        return result_data\r\n\r\n    def close(self) -> None:\r\n        self._http2_session.close()\r\n        super().close()\r\n\r\n    def load_mpd(self, url: str | list[str], headers: dict | None = None) -> MPD | None:\r\n        _headers = headers or self._session.headers\r\n        _headers[\"Accept\"] = \"application/dash+xml\"\r\n\r\n        for url_item in single_to_list(url):\r\n            try:\r\n                if \"cdn.apps.disneyplus.com\" in url_item:\r\n                    response: requests.models.Response = self._session.get(url=url_item, headers=_headers)\r\n                    response.raise_for_status()\r\n\r\n                else:\r\n                    response = self._http2_session.get(url=url_item, headers=_headers)\r\n                    response.raise_for_status()\r\n\r\n            except Exception as e:\r\n                logger.debug(f\"Failed to load MPD playlist '{url_item}': {e}\")\r\n                continue\r\n\r\n            return MPD(playlist_data=response.text, uri=url_item)\r\n        return None\r\n\r\n    def get_movie_data(self, movie_slug: str) -> ScrapedMediaResponse[Movie]:\r\n        api_data = self._get_api_data(endpoint=\"v2/slugs/\" + movie_slug)\r\n        movie_data = api_data[\"success\"][\"page\"][\"spaces\"][\"hero\"][\"widget_wrappers\"][0][\"widget\"][\"data\"]\r\n\r\n        movie_name = movie_data[\"content_info\"][\"title\"]\r\n        movie_id = movie_data[\"cw_info\"][\"content_id\"]\r\n        movie_release_year = int(movie_data[\"content_info\"][\"core_meta_tags\"][0][\"value\"])\r\n        movie_duration = dt.timedelta(milliseconds=int(movie_data[\"cw_info\"][\"duration\"]))\r\n\r\n        playlists = self._get_media_playlists(media_slug=movie_slug)\r\n\r\n        return ScrapedMediaResponse(\r\n            media_data=Movie(\r\n                name=movie_name,\r\n                id=movie_id,\r\n                release_date=movie_release_year,\r\n                duration=movie_duration,\r\n                playlist=playlists,\r\n            ),\r\n            metadata_scraper=self.id,\r\n            playlist_scraper=self.id,\r\n            original_data=api_data,\r\n        )\r\n\r\n    def get_series_data(self, show_slug: str) -> ScrapedMediaResponse[Series]:\r\n        api_data = self._get_api_data(endpoint=\"v2/slugs/\" + show_slug)\r\n        series_data = api_data[\"success\"][\"page\"][\"spaces\"][\"hero\"][\"widget_wrappers\"][0][\"widget\"][\"data\"]\r\n        seasons_data = (api_data[\"success\"][\"page\"][\"spaces\"][\"tray\"][\"widget_wrappers\"][0][\"widget\"]\r\n                        [\"data\"][\"category_picker\"][\"data\"][\"tabs\"])\r\n\r\n        series_name = series_data[\"content_info\"][\"title\"]\r\n        series_id = (series_data[\"content_actions_row\"][\"content_action_buttons\"][0]\r\n                     [\"watchlist_content_action_button\"][\"info\"][\"content_id\"])\r\n\r\n        series_seasons: list[Season] = []\r\n        result_seasons_data: dict[int, dict[int, dict]] = {}\r\n\r\n        for season_data in [season_data[\"tab\"][\"data\"] for season_data in seasons_data]:\r\n            url_params = parse_url_params(season_data[\"tray_widget_url\"])\r\n            season_episodes_data = self._get_season_data(show_id=url_params[\"content_id\"],\r\n                                                         season_id=url_params[\"season_id\"])\r\n            season_number = int(season_data[\"title\"].split(\" \")[1])\r\n            result_seasons_data[season_number] = season_episodes_data\r\n\r\n            season_episodes: list[Episode] = []\r\n\r\n            for episode_number, episode_data in season_episodes_data.items():\r\n                season_episodes.append(\r\n                    Episode(\r\n                        id=episode_data[\"cw_info\"][\"content_id\"],\r\n                        series_name=series_name,\r\n                        season_number=season_number,\r\n                        episode_number=episode_number,\r\n                        episode_name=episode_data[\"title\"],\r\n                        episode_release_date=dt.datetime.strptime(episode_data[\"tags\"][1][\"value\"], \"%d %b %Y\"),\r\n                        episode_duration=parse_duration(episode_data[\"tags\"][2][\"value\"]),\r\n                        playlist=episode_data[\"playlists\"].copy(),\r\n                    ),\r\n                )\r\n\r\n            series_seasons.append(\r\n                Season(\r\n                    id=series_id,\r\n                    series_name=series_name,\r\n                    season_number=season_number,\r\n                    release_date=None,\r\n                    episodes=season_episodes,\r\n                ))\r\n\r\n        return ScrapedMediaResponse(\r\n            media_data=[Series(\r\n                id=series_id,\r\n                series_name=series_name,\r\n                seasons=series_seasons,\r\n            )],\r\n            metadata_scraper=self.id,\r\n            playlist_scraper=self.id,\r\n            original_data=api_data\r\n        )\r\n\r\n    def get_data(self, url: str) -> ScrapedMediaResponse[Movie] | ScrapedMediaResponse[Series]:\r\n        regex_match = self.match_url(url, raise_error=True)\r\n        url_data = regex_match.groupdict()\r\n\r\n        if not all(url_data.get(key) for key in (\"country_code\", \"media_type\", \"media_name\", \"media_id\")):\r\n            raise ScraperError(f\"Full URL containing the slug is required for scraping from '{self.name}'.\")\r\n            # TODO: Find a way to get the full URL with the complete slug from the given URL\r\n\r\n        if url_data[\"media_type\"] == \"movies\":\r\n            return self.get_movie_data(url_data[\"slug\"])\r\n\r\n        elif url_data[\"media_type\"] == \"shows\":\r\n            return self.get_series_data(url_data[\"slug\"])\r\n\r\n        else:\r\n            raise ScraperError(f\"Unexpected media type URL '{url_data['media_type']}' for '{self.name}'.\")\r\n\r\n    def get_subtitles(self, main_playlist: str | list[str], language_filter: list[str] | str | None = None,\r\n                      subrip_conversion: bool = False) -> Iterator[SubtitlesData]:\r\n        playlist_data = self.load_mpd(url=main_playlist, headers={})\r\n\r\n        if not playlist_data:  # No valid playlist found\r\n            raise PlaylistLoadError(\"Could not find a valid MPD playlist.\")\r\n\r\n        for period in playlist_data.get_periods(filters={\"id\": \"seq:0_0\"}):\r\n            for subtitles_adaptation_set in period.get_adaptation_sets(filters={\"contentType\": \"text\",\r\n                                                                                \"mimeType\": \"text/vtt\"}):\r\n                if language_filter and subtitles_adaptation_set.lang not in language_filter:\r\n                    continue\r\n\r\n                for subtitles_representation in subtitles_adaptation_set.get_representations():\r\n                    # Seems like the \"real\" subtitles are always under the \"seq:0_0\" period\r\n                    # (and other periods have \"dummy\" subtitles), but this is a check just in case.\r\n                    if subtitles_representation.id == \"subtitle/dummy\":\r\n                        logger.warning(\"Dummy subtitles found. Skipping...\")\r\n                        continue\r\n\r\n                    subtitles_url = subtitles_representation.url\r\n                    subtitles_data = self._session.get(url=subtitles_url)\r\n                    subtitles = self.subtitles_class.loads(subtitles_data=subtitles_data.content.decode(\"utf-8\"))\r\n\r\n                    subtitles.polish(\r\n                        fix_rtl=self.subtitles_fix_rtl,\r\n                        rtl_languages=self.subtitles_fix_rtl_languages,\r\n                        remove_duplicates=self.subtitles_remove_duplicates,\r\n                    )\r\n\r\n                    subtitles_type = self.detect_subtitles_type(subtitles_adaptation_set=subtitles_adaptation_set)\r\n\r\n                    yield SubtitlesData(\r\n                        language_code=subtitles_adaptation_set.lang,\r\n                        language_name=None,\r\n                        subtitles_format=SubtitlesFormatType.SUBRIP if subrip_conversion else SubtitlesFormatType.WEBVTT,\r\n                        content=subtitles.to_srt().dump() if subrip_conversion else subtitles.dump(),\r\n                        special_type=subtitles_type,\r\n                    )\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/scrapers/disneyplus_hotstar_scraper.py b/isubrip/scrapers/disneyplus_hotstar_scraper.py
--- a/isubrip/scrapers/disneyplus_hotstar_scraper.py	(revision 67c115fc7dbd1dc7520fc499455860dceb009906)
+++ b/isubrip/scrapers/disneyplus_hotstar_scraper.py	(date 1707506374405)
@@ -316,7 +316,7 @@
         )
 
     def get_data(self, url: str) -> ScrapedMediaResponse[Movie] | ScrapedMediaResponse[Series]:
-        regex_match = self.match_url(url, raise_error=True)
+        regex_match = self.match_url(url=url, raise_error=True)
         url_data = regex_match.groupdict()
 
         if not all(url_data.get(key) for key in ("country_code", "media_type", "media_name", "media_id")):
@@ -324,10 +324,10 @@
             # TODO: Find a way to get the full URL with the complete slug from the given URL
 
         if url_data["media_type"] == "movies":
-            return self.get_movie_data(url_data["slug"])
+            return self.get_movie_data(movie_slug=url_data["slug"])
 
         elif url_data["media_type"] == "shows":
-            return self.get_series_data(url_data["slug"])
+            return self.get_series_data(show_slug=url_data["slug"])
 
         else:
             raise ScraperError(f"Unexpected media type URL '{url_data['media_type']}' for '{self.name}'.")
@@ -353,21 +353,33 @@
                         continue
 
                     subtitles_url = subtitles_representation.url
-                    subtitles_data = self._session.get(url=subtitles_url)
-                    subtitles = self.subtitles_class.loads(subtitles_data=subtitles_data.content.decode("utf-8"))
+                    lang_code = subtitles_adaptation_set.lang
+                    logger.debug(f"Fetching {lang_code} subtitles...")
+
+                    try:
+                        subtitles_data = self._session.get(url=subtitles_url)
+                        lang_code = subtitles_adaptation_set.lang
+                        subtitles = self.subtitles_class.load(subtitles_data=subtitles_data.content)
 
-                    subtitles.polish(
-                        fix_rtl=self.subtitles_fix_rtl,
-                        rtl_languages=self.subtitles_fix_rtl_languages,
-                        remove_duplicates=self.subtitles_remove_duplicates,
-                    )
+                        subtitles.polish(
+                            fix_rtl=self.subtitles_fix_rtl,
+                            rtl_languages=self.subtitles_fix_rtl_languages,
+                            remove_duplicates=self.subtitles_remove_duplicates,
+                        )
 
-                    subtitles_type = self.detect_subtitles_type(subtitles_adaptation_set=subtitles_adaptation_set)
+                        subtitles_type = self.detect_subtitles_type(subtitles_adaptation_set=subtitles_adaptation_set)
 
-                    yield SubtitlesData(
-                        language_code=subtitles_adaptation_set.lang,
-                        language_name=None,
-                        subtitles_format=SubtitlesFormatType.SUBRIP if subrip_conversion else SubtitlesFormatType.WEBVTT,
-                        content=subtitles.to_srt().dump() if subrip_conversion else subtitles.dump(),
-                        special_type=subtitles_type,
-                    )
+                        yield SubtitlesData(
+                            language_code=lang_code,
+                            language_name=None,
+                            subtitles_format=(SubtitlesFormatType.SUBRIP if subrip_conversion
+                                              else SubtitlesFormatType.WEBVTT),
+                            content=subtitles.to_srt().dump() if subrip_conversion else subtitles.dump(),
+                            content_encoding=subtitles.encoding,
+                            special_type=subtitles_type,
+                        )
+
+                    except Exception as e:
+                        logger.warning(f"Failed to download '{lang_code}' subtitles. Skipping...")
+                        logger.debug(e, exc_info=True)
+                        continue
Index: isubrip/subtitle_formats/subtitles.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nfrom abc import ABC, abstractmethod\r\nfrom datetime import time\r\nfrom typing import TYPE_CHECKING, Any, ClassVar, Generic, TypeVar\r\n\r\nif TYPE_CHECKING:\r\n    from isubrip.data_structures import SubtitlesFormatType, SubtitlesType\r\n    from isubrip.subtitle_formats.subrip import SubRipCaptionBlock, SubRipSubtitles\r\n\r\nRTL_CONTROL_CHARS = ('\\u200e', '\\u200f', '\\u202a', '\\u202b', '\\u202c', '\\u202d', '\\u202e')\r\nRTL_CHAR = '\\u202b'\r\nRTL_LANGUAGES = [\"ar\", \"he\"]\r\n\r\nSubtitlesT = TypeVar('SubtitlesT', bound='Subtitles')\r\nSubtitlesBlockT = TypeVar('SubtitlesBlockT', bound='SubtitlesBlock')\r\n\r\n\r\nclass SubtitlesBlock(ABC):\r\n    \"\"\"Abstract base class for subtitles blocks.\"\"\"\r\n    @abstractmethod\r\n    def __str__(self) -> str:\r\n        pass\r\n\r\n    @abstractmethod\r\n    def __eq__(self, other: Any) -> bool:\r\n        pass\r\n\r\n\r\nclass SubtitlesCaptionBlock(SubtitlesBlock, ABC):\r\n    \"\"\"A base class for subtitles caption blocks.\"\"\"\r\n\r\n    def __init__(self, start_time: time, end_time: time, payload: str):\r\n        \"\"\"\r\n        Initialize a new SubtitlesCaptionBlock object.\r\n\r\n        Args:\r\n            start_time: Start timestamp of the caption block.\r\n            end_time: End timestamp of the caption block.\r\n            payload: Caption block's payload (text).\r\n        \"\"\"\r\n        self.start_time = start_time\r\n        self.end_time = end_time\r\n        self.payload = payload\r\n\r\n    def fix_rtl(self) -> None:\r\n        \"\"\"Fix text direction to RTL.\"\"\"\r\n        # Remove previous RTL-related formatting\r\n        for char in RTL_CONTROL_CHARS:\r\n            self.payload = self.payload.replace(char, '')\r\n\r\n        # Add RLM char at the start of every line\r\n        self.payload = RTL_CHAR + self.payload.replace(\"\\n\", f\"\\n{RTL_CHAR}\")\r\n\r\n    @abstractmethod\r\n    def to_srt(self) -> SubRipCaptionBlock:\r\n        \"\"\"\r\n        Convert WebVTT caption block to SRT caption block.\r\n\r\n        Returns:\r\n            SubRipCaptionBlock: The caption block in SRT format.\r\n        \"\"\"\r\n        ...\r\n\r\n\r\nclass Subtitles(Generic[SubtitlesBlockT], ABC):\r\n    \"\"\"\r\n    An object representing subtitles, made out of blocks.\r\n\r\n    Attributes:\r\n        format (SubtitlesFormatType): [Class Attribute] Format of the subtitles (contains name and file extension).\r\n        blocks (list[SubtitlesBlock]): A list of subtitles blocks that make up the subtitles.\r\n        language_code (str | None): Language code of the subtitles.\r\n        special_type (SubtitlesType | None): Special type of the subtitles (if any).\r\n    \"\"\"\r\n    format: ClassVar[SubtitlesFormatType]\r\n\r\n    def __init__(self, blocks: list[SubtitlesBlockT] | None = None,\r\n                 language_code: str | None = None, special_type: SubtitlesType | None = None):\r\n        \"\"\"\r\n        Initialize a new Subtitles object.\r\n\r\n        Args:\r\n            blocks (list[SubtitlesBlock] | None, optional): A list of subtitles to initialize the object with.\r\n                Defaults to None.\r\n            language_code (str | None, optional): Language code of the subtitles. Defaults to None.\r\n            special_type (SubtitlesType | None, optional): Special type of the subtitles (if any). Defaults to None.\r\n        \"\"\"\r\n        self.language_code = language_code\r\n        self.special_type = special_type\r\n\r\n        if blocks is None:\r\n            self.blocks = []\r\n\r\n        else:\r\n            self.blocks = blocks\r\n\r\n    def __add__(self: SubtitlesT, obj: SubtitlesBlockT | SubtitlesT) -> SubtitlesT:\r\n        \"\"\"\r\n        Add a new subtitles block, or append blocks from another subtitles object.\r\n\r\n        Args:\r\n            obj (SubtitlesBlock | Subtitles): A subtitles block or another subtitles object.\r\n\r\n        Returns:\r\n            Subtitles: The current subtitles object.\r\n        \"\"\"\r\n        if isinstance(obj, SubtitlesBlock):\r\n            self.add_block(obj)\r\n\r\n        elif isinstance(obj, self.__class__):\r\n            self.append_subtitles(obj)\r\n\r\n        return self\r\n\r\n    def __eq__(self, other: Any) -> bool:\r\n        return isinstance(other, type(self)) and self.blocks == other.blocks\r\n\r\n    def __str__(self) -> str:\r\n        return self.dumps()\r\n\r\n    @abstractmethod\r\n    def dumps(self) -> str:\r\n        \"\"\"Dump subtitles object to a string representing the subtitles.\"\"\"\r\n\r\n    @staticmethod\r\n    @abstractmethod\r\n    def loads(subtitles_data: str) -> Subtitles:\r\n        pass\r\n\r\n    def add_block(self: SubtitlesT, block: SubtitlesBlockT | list[SubtitlesBlockT]) -> SubtitlesT:\r\n        \"\"\"\r\n        Add a new subtitles block to current subtitles.\r\n\r\n        Args:\r\n            block (SubtitlesBlock | list[SubtitlesBlock]):\r\n                A block object or a list of block objects to append.\r\n\r\n        Returns:\r\n            Subtitles: The current subtitles object.\r\n        \"\"\"\r\n        if isinstance(block, list):\r\n            self.blocks.extend(block)\r\n\r\n        else:\r\n            self.blocks.append(block)\r\n\r\n        return self\r\n\r\n    def append_subtitles(self: SubtitlesT, subtitles: SubtitlesT) -> SubtitlesT:\r\n        \"\"\"\r\n        Append an existing subtitles object.\r\n\r\n        Args:\r\n            subtitles (Subtitles): Subtitles object to append to current subtitles.\r\n\r\n        Returns:\r\n            Subtitles: The current subtitles object.\r\n        \"\"\"\r\n        for block in subtitles.blocks:\r\n            self.add_block(block)\r\n\r\n        return self\r\n\r\n    def dump(self) -> bytes:\r\n        return self.dumps().encode(encoding=\"UTF-8\")\r\n\r\n    def polish(self: SubtitlesT, fix_rtl: bool = False,\r\n               rtl_languages: list[str] | None = None, remove_duplicates: bool = False) -> SubtitlesT:\r\n        \"\"\"\r\n        Apply various fixes to subtitles.\r\n\r\n        Args:\r\n            fix_rtl (bool, optional): Whether to fix text direction of RTL languages. Defaults to False.\r\n            rtl_languages (list[str] | None, optional): Language code of the RTL language.\r\n                If not set, a default list of RTL languages will be used. Defaults to None.\r\n            remove_duplicates (bool, optional): Whether to remove duplicate captions. Defaults to False.\r\n\r\n        Returns:\r\n            Subtitles: The current subtitles object.\r\n        \"\"\"\r\n        rtl_language = rtl_languages or RTL_LANGUAGES\r\n\r\n        if not any((fix_rtl, remove_duplicates)):\r\n            return self\r\n\r\n        previous_block: SubtitlesBlockT | None = None\r\n\r\n        for block in self.blocks:\r\n            if fix_rtl and isinstance(block, SubtitlesCaptionBlock) and \\\r\n                    self.language_code in rtl_language:\r\n                block.fix_rtl()\r\n\r\n            if remove_duplicates and previous_block is not None and block == previous_block:\r\n                self.blocks.remove(previous_block)\r\n\r\n            previous_block = block\r\n\r\n        return self\r\n\r\n    def to_srt(self) -> SubRipSubtitles:\r\n        \"\"\"\r\n        Convert subtitles to SRT format.\r\n\r\n        Returns:\r\n            SubRipSubtitles: The subtitles in SRT format.\r\n        \"\"\"\r\n        from isubrip.subtitle_formats.subrip import SubRipSubtitles\r\n\r\n        return SubRipSubtitles(\r\n            blocks=[block.to_srt() for block in self.blocks if isinstance(block, SubtitlesCaptionBlock)],\r\n            language_code=self.language_code,\r\n            special_type=self.special_type,\r\n        )\r\n\r\n\r\ndef split_timestamp(timestamp: str) -> tuple[time, time]:\r\n    \"\"\"\r\n    Split a subtitles timestamp into start and end.\r\n\r\n    Args:\r\n        timestamp (str): A subtitles timestamp. For example: \"00:00:00.000 --> 00:00:00.000\"\r\n\r\n    Returns:\r\n        tuple(time, time): A tuple containing start and end times as a datetime object.\r\n    \"\"\"\r\n    # Support ',' character in timestamp's milliseconds (used in SubRip format).\r\n    timestamp = timestamp.replace(',', '.')\r\n\r\n    start_time, end_time = timestamp.split(\" --> \")\r\n    return time.fromisoformat(start_time), time.fromisoformat(end_time)\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/subtitle_formats/subtitles.py b/isubrip/subtitle_formats/subtitles.py
--- a/isubrip/subtitle_formats/subtitles.py	(revision 67c115fc7dbd1dc7520fc499455860dceb009906)
+++ b/isubrip/subtitle_formats/subtitles.py	(date 1707510151915)
@@ -4,6 +4,10 @@
 from datetime import time
 from typing import TYPE_CHECKING, Any, ClassVar, Generic, TypeVar
 
+from charset_normalizer import from_bytes
+
+from isubrip.logger import logger
+
 if TYPE_CHECKING:
     from isubrip.data_structures import SubtitlesFormatType, SubtitlesType
     from isubrip.subtitle_formats.subrip import SubRipCaptionBlock, SubRipSubtitles
@@ -70,24 +74,19 @@
     Attributes:
         format (SubtitlesFormatType): [Class Attribute] Format of the subtitles (contains name and file extension).
         blocks (list[SubtitlesBlock]): A list of subtitles blocks that make up the subtitles.
-        language_code (str | None): Language code of the subtitles.
-        special_type (SubtitlesType | None): Special type of the subtitles (if any).
     """
     format: ClassVar[SubtitlesFormatType]
 
-    def __init__(self, blocks: list[SubtitlesBlockT] | None = None,
-                 language_code: str | None = None, special_type: SubtitlesType | None = None):
+    def __init__(self, blocks: list[SubtitlesBlockT] | None = None, encoding: str = "utf-8"):
         """
         Initialize a new Subtitles object.
 
         Args:
             blocks (list[SubtitlesBlock] | None, optional): A list of subtitles to initialize the object with.
                 Defaults to None.
-            language_code (str | None, optional): Language code of the subtitles. Defaults to None.
-            special_type (SubtitlesType | None, optional): Special type of the subtitles (if any). Defaults to None.
+            encoding (str, optional): Encoding of the subtitles. Defaults to "utf-8".
         """
-        self.language_code = language_code
-        self.special_type = special_type
+        self.encoding = encoding
 
         if blocks is None:
             self.blocks = []
@@ -119,14 +118,50 @@
     def __str__(self) -> str:
         return self.dumps()
 
+    def dump(self) -> bytes:
+        return self.dumps().encode(encoding=self.encoding)
+
     @abstractmethod
     def dumps(self) -> str:
         """Dump subtitles object to a string representing the subtitles."""
+        ...
+
+    @classmethod
+    def load(cls, subtitles_data: bytes) -> Subtitles:
+        encoding = "utf-8"
 
-    @staticmethod
+        try:
+            parsed_data = subtitles_data.decode(encoding)
+
+        except UnicodeDecodeError as e:
+            logger.debug(f"Failed to decode subtitles data using 'UTF-8' encoding: '{e}'. "
+                         f"Attempting to detect encoding...")
+
+            charset_normalizer_result = from_bytes(subtitles_data, threshold=0.1)
+
+            if (encoding_match := charset_normalizer_result.best()) and encoding_match.encoding != "utf-8":
+                encoding = encoding_match.encoding
+
+                try:
+                    parsed_data = subtitles_data.decode(encoding)
+                    logger.debug(f"Subtitles data successfully decoded using detected "
+                                 f"'{encoding}' encoding.")
+
+                except UnicodeDecodeError:
+                    logger.debug(f"Failed to decode subtitles data using detected "
+                                 f"'{encoding_match.encoding}' encoding.")
+                    raise
+
+            else:
+                logger.debug("Failed to detect an alternative encoding.")
+                raise
+
+        return cls.loads(subtitles_data=parsed_data, encoding=encoding)
+
+    @classmethod
     @abstractmethod
-    def loads(subtitles_data: str) -> Subtitles:
-        pass
+    def loads(cls, subtitles_data: str, encoding: str = "utf-8") -> Subtitles:
+        ...
 
     def add_block(self: SubtitlesT, block: SubtitlesBlockT | list[SubtitlesBlockT]) -> SubtitlesT:
         """
@@ -162,9 +197,6 @@
 
         return self
 
-    def dump(self) -> bytes:
-        return self.dumps().encode(encoding="UTF-8")
-
     def polish(self: SubtitlesT, fix_rtl: bool = False,
                rtl_languages: list[str] | None = None, remove_duplicates: bool = False) -> SubtitlesT:
         """
@@ -209,8 +241,6 @@
 
         return SubRipSubtitles(
             blocks=[block.to_srt() for block in self.blocks if isinstance(block, SubtitlesCaptionBlock)],
-            language_code=self.language_code,
-            special_type=self.special_type,
         )
 
 
Index: isubrip/constants.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nimport datetime as dt\r\nimport logging\r\nfrom pathlib import Path\r\nfrom tempfile import gettempdir\r\n\r\n# General\r\nPACKAGE_NAME = \"isubrip\"\r\nPACKAGE_VERSION = \"2.5.2\"\r\n\r\n# Logging\r\nPREORDER_MESSAGE = (\"'{movie_name}' is currently unavailable on {scraper_name}, \"\r\n                    \"and will be available on {preorder_date}.\")\r\n\r\nANSI_COLORS = {\r\n    logging.DEBUG: \"\\x1b[37;20m\",  # Light Grey\r\n    logging.INFO: \"\\x1b[38;20m\",  # Grey\r\n    logging.WARNING: \"\\x1b[33;20m\",  # Yellow\r\n    logging.ERROR: \"\\x1b[31;20m\",  # Red\r\n    logging.CRITICAL: \"\\x1b[31;1m\",  # Bold Red\r\n    }\r\nRESET_COLOR = \"\\x1b[0m\"\r\n\r\nLOGGING_DATE_FORMAT = \"%Y-%m-%d %H:%M:%S\"\r\nLOGGING_FILE_METADATA = \"[%(asctime)s | %(levelname)s | %(threadName)s | %(filename)s::%(funcName)s::%(lineno)d] \"\r\n\r\n# Downloads\r\nARCHIVE_FORMAT = \"zip\"\r\n\r\n# Paths\r\nDEFAULT_CONFIG_PATH = Path(__file__).parent / \"resources\" / \"default_config.toml\"\r\nDATA_FOLDER_PATH = Path.home() / f\".{PACKAGE_NAME}\"\r\nSCRAPER_MODULES_SUFFIX = \"_scraper\"\r\nTEMP_FOLDER_PATH = Path(gettempdir()) / PACKAGE_NAME\r\n\r\n# Config Paths\r\nUSER_CONFIG_FILE_NAME = \"config.toml\"\r\nUSER_CONFIG_FILE = DATA_FOLDER_PATH / USER_CONFIG_FILE_NAME\r\n\r\n# Logging Paths\r\nLOG_FILES_PATH = DATA_FOLDER_PATH / \"logs\"\r\nLOG_FILE_NAME = f\"{PACKAGE_NAME}_{dt.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.log\"\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/constants.py b/isubrip/constants.py
--- a/isubrip/constants.py	(revision 67c115fc7dbd1dc7520fc499455860dceb009906)
+++ b/isubrip/constants.py	(date 1707497240101)
@@ -41,3 +41,11 @@
 # Logging Paths
 LOG_FILES_PATH = DATA_FOLDER_PATH / "logs"
 LOG_FILE_NAME = f"{PACKAGE_NAME}_{dt.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.log"
+
+# Other
+TITLE_REPLACEMENT_STRINGS = {  # Replacements will be done by the order of the keys.
+    ": ": ".", ":": ".", " - ": "-", ", ": ".", ". ": ".", " ": ".", "|": ".", "/": ".", "": ".",
+    "<": "", ">": "", "(": "", ")": "", '"': "", "?": "", "*": "",
+}
+WINDOWS_RESERVED_FILE_NAMES = ("CON", "PRN", "AUX", "NUL", "COM1", "COM2", "COM3", "COM4", "COM5", "COM6", "COM7",
+                               "COM8", "COM9", "LPT1", "LPT2", "LPT3", "LPT4", "LPT5", "LPT6", "LPT7", "LPT8", "LPT9")
Index: isubrip/utils.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nfrom abc import ABCMeta\r\nimport datetime as dt\r\nfrom functools import lru_cache\r\nimport json\r\nfrom pathlib import Path\r\nimport re\r\nimport secrets\r\nimport sys\r\nfrom typing import TYPE_CHECKING, Any, Type, Union, get_args, get_origin\r\n\r\nfrom isubrip.constants import TEMP_FOLDER_PATH\r\nfrom isubrip.data_structures import (\r\n    Episode,\r\n    MediaBase,\r\n    Movie,\r\n    Season,\r\n    Series,\r\n    SubtitlesData,\r\n    SubtitlesFormatType,\r\n    SubtitlesType,\r\n)\r\nfrom isubrip.logger import logger\r\n\r\nif TYPE_CHECKING:\r\n    from os import PathLike\r\n    from types import TracebackType\r\n\r\n    import requests\r\n\r\n\r\nHOST_REGEX = re.compile(\r\n    r\"(?i)^(?:https?://)?(?P<host>[^/:?]+)\",\r\n)\r\nDURATION_TAG_REGEX = re.compile(\r\n    r\"(?i)^(?:(?P<hours>\\d{1,2})H)?\\s?(?:(?P<minutes>\\d{1,2})M)?\\s?(?:(?P<seconds>\\d{1,2})S)?$\"\r\n)\r\nISO8601_DURATION_REGEX = re.compile(\r\n    r\"(?i)^PT(?:(?P<hours>\\d{1,2})H)?(?:(?P<minutes>\\d{1,2})M)?(?:(?P<seconds>\\d{1,2})(?:\\.(?P<milliseconds>\\d{1,3}))?S)?\"  # noqa: E501\r\n)\r\n\r\n\r\nclass SingletonMeta(ABCMeta):\r\n    \"\"\"\r\n    A metaclass that implements the Singleton pattern.\r\n    When a class using this metaclass is initialized, it will return the same instance every time.\r\n    \"\"\"\r\n    _instances: dict[object, object] = {}\r\n\r\n    def __call__(cls, *args: Any, **kwargs: Any) -> object:\r\n        if cls._instances.get(cls) is None:\r\n            cls._instances[cls] = super().__call__(*args, **kwargs)\r\n\r\n        return cls._instances[cls]\r\n\r\n\r\nclass TempDirGenerator:\r\n    \"\"\"A class for generating temporary directories, and disposing them once the object is destroyed.\"\"\"\r\n    _generated_temp_directories: list[Path] = []\r\n\r\n    def __exit__(self, exc_type: Type[BaseException] | None,\r\n                 exc_val: BaseException | None, exc_tb: TracebackType | None) -> None:\r\n        self.cleanup()\r\n\r\n    @classmethod\r\n    def generate(cls, directory_name: str | None = None) -> Path:\r\n        \"\"\"\r\n        Generate a temporary directory within 'TEMP_FOLDER_PATH'.\r\n\r\n        Args:\r\n            directory_name (str | None, optional): Name of the directory to generate.\r\n                If not specified, a random string will be generated. Defaults to None.\r\n\r\n        Returns:\r\n            Path: Path to the generated directory.\r\n        \"\"\"\r\n        directory_name = directory_name or secrets.token_hex(5)\r\n        full_path = TEMP_FOLDER_PATH / directory_name\r\n\r\n        if not full_path.is_dir():\r\n            full_path.mkdir(parents=True)\r\n            logger.debug(f\"Temporary directory has been generated: '{full_path}'\")\r\n            cls._generated_temp_directories.append(full_path)\r\n\r\n        else:\r\n            logger.debug(f\"Using existing temporary directory: '{full_path}'.\")\r\n\r\n        return full_path\r\n\r\n    @classmethod\r\n    def cleanup(cls) -> None:\r\n        \"\"\"Remove all temporary directories generated by this object.\"\"\"\r\n        for temp_directory in cls._generated_temp_directories:\r\n            logger.debug(f\"Removing temporary directory: '{temp_directory}'\")\r\n\r\n            try:\r\n                temp_directory.rmdir()\r\n\r\n            except Exception as e:\r\n                logger.debug(f\"Failed to remove temporary directory '{temp_directory}': {e}\")\r\n\r\n        cls._generated_temp_directories = []\r\n\r\n\r\ndef check_type(value: Any, type_) -> bool:  # type: ignore[no-untyped-def]\r\n    \"\"\"\r\n    Check if a value is of a certain type.\r\n    Works with parameterized generics.\r\n\r\n    Args:\r\n        value (Any): Value to check.\r\n        type_: Type to check against.\r\n\r\n    Returns:\r\n        bool: True if the value is of the specified type, False otherwise.\r\n    \"\"\"\r\n    origin = get_origin(type_)\r\n    args = get_args(type_)\r\n\r\n    if origin is Union:\r\n        return any(check_type(value, union_sub_type) for union_sub_type in args)\r\n\r\n    if origin is tuple:\r\n        if args[-1] is Ellipsis:\r\n            # Example: (int, str, ...)\r\n            args_len = len(args)\r\n\r\n            return check_type(value[:args_len - 1], tuple(args[:-1])) and \\\r\n                all(check_type(item, args[-2]) for item in value[args_len - 1:])\r\n\r\n        return isinstance(value, tuple) and \\\r\n            len(value) == len(args) and \\\r\n            all(check_type(item, item_type) for item, item_type in zip(value, args))\r\n\r\n    if origin is list:\r\n        return isinstance(value, list) and \\\r\n            all(check_type(item, args[0]) for item in value)\r\n\r\n    if origin is dict:\r\n        return isinstance(value, dict) and \\\r\n            all(check_type(k, args[0]) and check_type(v, args[1]) for k, v in value.items())\r\n\r\n    return isinstance(value, type_)\r\n\r\n\r\ndef convert_epoch_to_datetime(epoch_timestamp: int) -> dt.datetime:\r\n    \"\"\"\r\n    Convert an epoch timestamp to a datetime object.\r\n\r\n    Args:\r\n        epoch_timestamp (int): Epoch timestamp.\r\n\r\n    Returns:\r\n        datetime: A datetime object representing the timestamp.\r\n    \"\"\"\r\n    if epoch_timestamp >= 0:\r\n        return dt.datetime.fromtimestamp(epoch_timestamp)\r\n\r\n    return dt.datetime(1970, 1, 1) + dt.timedelta(seconds=epoch_timestamp)\r\n\r\n\r\ndef download_subtitles_to_file(media_data: Movie | Episode, subtitles_data: SubtitlesData, output_path: str | PathLike,\r\n                               source_abbreviation: str | None = None, overwrite: bool = False) -> Path:\r\n    \"\"\"\r\n    Download subtitles to a file.\r\n\r\n    Args:\r\n        media_data (Movie | Episode): An object containing media data.\r\n        subtitles_data (SubtitlesData): A SubtitlesData object containing subtitles data.\r\n        output_path (str | PathLike): Path to the output folder.\r\n        source_abbreviation (str | None, optional): Abbreviation of the source the subtitles are downloaded from.\r\n            Defaults to None.\r\n        overwrite (bool, optional): Whether to overwrite files if they already exist. Defaults to True.\r\n\r\n    Returns:\r\n        Path: Path to the downloaded subtitles file.\r\n\r\n    Raises:\r\n        ValueError: If the path in `output_path` does not exist.\r\n    \"\"\"\r\n    output_path = Path(output_path)\r\n\r\n    if not output_path.is_dir():\r\n        raise ValueError(f\"Invalid path: {output_path}\")\r\n\r\n    if isinstance(media_data, Movie):\r\n        file_name = generate_release_name(title=media_data.name,\r\n                                          release_date=media_data.release_date,\r\n                                          media_source=source_abbreviation,\r\n                                          language_code=subtitles_data.language_code,\r\n                                          subtitles_type=subtitles_data.special_type,\r\n                                          file_format=subtitles_data.subtitles_format)\r\n    else:  # isinstance(media_data, Episode):\r\n        file_name = generate_release_name(title=media_data.series_name,\r\n                                          release_date=media_data.release_date,\r\n                                          season_number=media_data.season_number,\r\n                                          episode_number=media_data.episode_number,\r\n                                          episode_name=media_data.episode_name,\r\n                                          media_source=source_abbreviation,\r\n                                          language_code=subtitles_data.language_code,\r\n                                          subtitles_type=subtitles_data.special_type,\r\n                                          file_format=subtitles_data.subtitles_format)\r\n\r\n    file_path = output_path / file_name\r\n\r\n    if file_path.exists() and not overwrite:\r\n        file_path = generate_non_conflicting_path(file_path=file_path)\r\n\r\n    with file_path.open('wb') as f:\r\n        f.write(subtitles_data.content)\r\n\r\n    return file_path\r\n\r\n\r\ndef generate_media_description(media_data: MediaBase, shortened: bool = False) -> str:\r\n    \"\"\"\r\n    Generate a short description string of a media object.\r\n\r\n    Args:\r\n        media_data (MediaBase): An object containing media data.\r\n        shortened (bool, optional): Whether to generate a shortened description. Defaults to False.\r\n\r\n    Returns:\r\n        str: A short description string of the media object.\r\n    \"\"\"\r\n    if isinstance(media_data, Movie):\r\n        release_year = (\r\n            media_data.release_date.year\r\n            if isinstance(media_data.release_date, dt.datetime)\r\n            else media_data.release_date\r\n        )\r\n        description_str = f\"{media_data.name} [{release_year}]\"\r\n\r\n        if media_data.id:\r\n            description_str += f\" (ID: {media_data.id})\"\r\n\r\n        return description_str\r\n\r\n    if isinstance(media_data, Series):\r\n        description_str = f\"{media_data.series_name}\"\r\n\r\n        if media_data.series_release_date:\r\n            if isinstance(media_data.series_release_date, dt.datetime):\r\n                description_str += f\" [{media_data.series_release_date.year}]\"\r\n\r\n            else:\r\n                description_str += f\" [{media_data.series_release_date}]\"\r\n\r\n        if media_data.id:\r\n            description_str += f\" (ID: {media_data.id})\"\r\n\r\n        return description_str\r\n\r\n    if isinstance(media_data, Season):\r\n        if shortened:\r\n            description_str = f\"Season {media_data.season_number:02d}\"\r\n\r\n        else:\r\n            description_str = f\"{media_data.series_name} - Season {media_data.season_number:02d}\"\r\n\r\n        if media_data.season_name:\r\n            description_str += f\" - {media_data.season_name}\"\r\n\r\n        if media_data.id:\r\n            description_str += f\" (ID: {media_data.id})\"\r\n\r\n        return description_str\r\n\r\n    if isinstance(media_data, Episode):\r\n        if shortened:\r\n            description_str = f\"S{media_data.season_number:02d}E{media_data.episode_number:02d}\"\r\n\r\n        else:\r\n            description_str = (f\"{media_data.series_name} - \"\r\n                               f\"S{media_data.season_number:02d}E{media_data.episode_number:02d}\")\r\n\r\n        if media_data.episode_name:\r\n            description_str += f\" - {media_data.episode_name}\"\r\n\r\n        if media_data.id:\r\n            description_str += f\" (ID: {media_data.id})\"\r\n\r\n        return description_str\r\n\r\n    raise ValueError(f\"Unsupported media type: '{type(media_data)}'\")\r\n\r\n\r\ndef extract_host_from_url(url: str) -> str:\r\n    \"\"\"\r\n    Extract the host from a URL.\r\n\r\n    Args:\r\n        url (str): A URL.\r\n\r\n    Returns:\r\n        str: The host of the URL.\r\n    \"\"\"\r\n    return re.match(HOST_REGEX, url).group('host')\r\n\r\n\r\ndef generate_non_conflicting_path(file_path: Path, has_extension: bool = True) -> Path:\r\n    \"\"\"\r\n    Generate a non-conflicting path for a file.\r\n    If the file already exists, a number will be added to the end of the file name.\r\n\r\n    Args:\r\n        file_path (Path): Path to a file.\r\n        has_extension (bool, optional): Whether the name of the file includes file extension. Defaults to True.\r\n\r\n    Returns:\r\n        Path: A non-conflicting file path.\r\n    \"\"\"\r\n    if isinstance(file_path, str):\r\n        file_path = Path(file_path)\r\n\r\n    if not file_path.exists():\r\n        return file_path\r\n\r\n    i = 1\r\n    while True:\r\n        if has_extension:\r\n            new_file_path = file_path.parent / f\"{file_path.stem}-{i}{file_path.suffix}\"\r\n\r\n        else:\r\n            new_file_path = file_path.parent / f\"{file_path}-{i}\"\r\n\r\n        if not new_file_path.exists():\r\n            return new_file_path\r\n\r\n        i += 1\r\n\r\n\r\ndef generate_random_hex_string(length: int) -> str:\r\n    \"\"\"\r\n    Generate a random hexadecimal string.\r\n\r\n    Args:\r\n        length (int): Length of the string to generate.\r\n\r\n    Returns:\r\n        str: A random hexadecimal string.\r\n    \"\"\"\r\n    result = secrets.token_hex(length // 2)\r\n\r\n    if length % 2 == 1:\r\n        result += secrets.token_hex(1)[0]\r\n\r\n    return result\r\n\r\n\r\ndef generate_release_name(title: str,\r\n                          release_date: dt.datetime | int | None = None,\r\n                          season_number: int | None = None,\r\n                          episode_number: int | None = None,\r\n                          episode_name: str | None = None,\r\n                          media_source: str | None = None,\r\n                          source_type: str | None = \"WEB\",\r\n                          additional_info: str | list[str] | None = None,\r\n                          language_code: str | None = None,\r\n                          subtitles_type: SubtitlesType | None = None,\r\n                          file_format: str | SubtitlesFormatType | None = None) -> str:\r\n    \"\"\"\r\n    Generate a release name.\r\n\r\n    Args:\r\n        title (str): Media title.\r\n        release_date (int | None, optional): Release date (datetime), or year (int) of the media. Defaults to None.\r\n        season_number (int | None, optional): Season number. Defaults to None.\r\n        episode_number (int | None, optional): Episode number. Defaults to None.\r\n        episode_name (str | None, optional): Episode name. Defaults to None.\r\n        media_source (str | None, optional): Media source name (full or abbreviation). Defaults to None.\r\n        source_type(str | None, optional): General source type (WEB, BluRay, etc.). Defaults to None.\r\n        additional_info (list[str] | str | None, optional): Additional info to add to the file name. Defaults to None.\r\n        language_code (str | None, optional): Language code. Defaults to None.\r\n        subtitles_type (SubtitlesType | None, optional): Subtitles type. Defaults to None.\r\n        file_format (SubtitlesFormat | str | None, optional): File format to use.  Defaults to None.\r\n\r\n    Returns:\r\n        str: Generated file name.\r\n    \"\"\"\r\n    file_name = standardize_title(title).rstrip('.')\r\n\r\n    if release_date is not None:\r\n        if isinstance(release_date, dt.datetime):\r\n            release_year = release_date.year\r\n\r\n        else:\r\n            release_year = release_date\r\n\r\n        file_name += f\".{release_year}\"\r\n\r\n    if season_number is not None and episode_number is not None:\r\n        file_name += f\".S{season_number:02}E{episode_number:02}\"\r\n\r\n    if episode_name is not None:\r\n        file_name += f\".{standardize_title(episode_name).rstrip('.')}\"\r\n\r\n    if media_source is not None:\r\n        file_name += f\".{media_source}\"\r\n\r\n    if source_type is not None:\r\n        file_name += f\".{source_type}\"\r\n\r\n    if additional_info is not None:\r\n        if isinstance(additional_info, (list, tuple)):\r\n            additional_info = '.'.join(additional_info)\r\n\r\n        file_name += f\".{additional_info}\"\r\n\r\n    if language_code is not None:\r\n        file_name += f\".{language_code}\"\r\n\r\n    if subtitles_type is not None:\r\n        file_name += f\".{subtitles_type.value.lower()}\"\r\n\r\n    if file_format is not None:\r\n        if isinstance(file_format, SubtitlesFormatType):\r\n            file_format = file_format.value.file_extension\r\n\r\n        file_name += f\".{file_format}\"\r\n\r\n    return file_name\r\n\r\n\r\ndef generate_url_params(data: dict[str, Any], remove_dict_spaces: bool = False) -> str:\r\n    \"\"\"\r\n    Generate a URL query string from a dictionary.\r\n\r\n    Args:\r\n        data (dict[str, Any]): Dictionary to generate a URL query string from.\r\n        remove_dict_spaces (bool, optional): Whether to remove spaces from stringified dictionary values.\r\n            Defaults to False.\r\n\r\n    Returns:\r\n        str: Generated URL query string.\r\n    \"\"\"\r\n    stringified_data = {}\r\n    json_dumps_separators = (',', ':') if remove_dict_spaces else None\r\n\r\n    for key, value in data.items():\r\n        if isinstance(value, (list, tuple, dict)):\r\n            stringified_data[key] = json.dumps(value, separators=json_dumps_separators)\r\n\r\n        elif isinstance(value, bool):\r\n            stringified_data[key] = str(value).lower()\r\n\r\n        else:\r\n            stringified_data[key] = str(value)\r\n\r\n    return '&'.join([f\"{key}={value}\" for key, value in stringified_data.items() if value is not None])\r\n\r\n\r\ndef merge_dict_values(*dictionaries: dict) -> dict:\r\n    \"\"\"\r\n    A function for merging the values of multiple dictionaries using the same keys.\r\n    If a key already exists, the value will be added to a list of values mapped to that key.\r\n\r\n    Note:\r\n        This function support only merging of lists, without any nesting.\r\n\r\n    Args:\r\n        *dictionaries (dict): Dictionaries to merge.\r\n\r\n    Returns:\r\n        dict: A merged dictionary.\r\n    \"\"\"\r\n    dictionaries = [d for d in dictionaries if d]\r\n\r\n    if len(dictionaries) == 0:\r\n        return {}\r\n\r\n    elif len(dictionaries) == 1:\r\n        return dictionaries[0]\r\n\r\n    result: dict = {}\r\n\r\n    for _dict in dictionaries:\r\n        for key, value in _dict.items():\r\n            if key in result:\r\n                if isinstance(result[key], list):\r\n                    if isinstance(value, list):\r\n                        result[key].extend(value)\r\n                    else:\r\n                        result[key].append(value)\r\n                else:\r\n                    if isinstance(value, list):\r\n                        result[key] = [result[key], *value]\r\n                    else:\r\n                        result[key] = [result[key], value]\r\n            else:\r\n                result[key] = value\r\n\r\n    return result\r\n\r\n\r\ndef raise_for_status(response: requests.Response) -> None:\r\n    \"\"\"\r\n    Raise an exception if the response status code is invalid.\r\n    Uses 'response.raise_for_status()' internally, with additional logging.\r\n\r\n    Args:\r\n        response (requests.Response): A response object.\r\n    \"\"\"\r\n    truncation_threshold = 1500\r\n\r\n    if response.ok:\r\n        return\r\n\r\n    if len(response.text) > truncation_threshold:\r\n        # Truncate the response as in some cases there could be an unexpected long HTML response\r\n        response_text = response.text[:truncation_threshold].rstrip() + \" <TRUNCATED...>\"\r\n\r\n    else:\r\n        response_text = response.text\r\n\r\n    logger.debug(f\"Response status code: {response.status_code}\")\r\n\r\n    if response.headers.get('Content-Type'):\r\n        logger.debug(f\"Response type: {response.headers['Content-Type']}\")\r\n\r\n    logger.debug(f\"Response text: {response_text}\")\r\n\r\n    response.raise_for_status()\r\n\r\n\r\ndef parse_duration(duration_string: str) -> dt.timedelta:\r\n    \"\"\"\r\n    Parse a duration ISO 8601 string (e.g. PT1H30M15S), or a duration tag (e.g. '1h 30m', '30m') to a timedelta object.\r\n\r\n    Args:\r\n        duration_string (str): Duration tag to parse.\r\n\r\n    Returns:\r\n        dt.timedelta: A timedelta object representing the duration.\r\n    \"\"\"\r\n    if regex_match := re.match(ISO8601_DURATION_REGEX, duration_string):\r\n        data = regex_match.groupdict()\r\n\r\n    elif regex_match := re.match(DURATION_TAG_REGEX, duration_string):\r\n        data = regex_match.groupdict()\r\n\r\n    else:\r\n        raise ValueError(f\"Invalid / unsupported duration string: '{duration_string}'\")\r\n\r\n    hours = int(data[\"hours\"]) if data.get(\"hours\") else 0\r\n    minutes = int(data[\"minutes\"]) if data.get(\"minutes\") else 0\r\n    seconds = int(data[\"seconds\"]) if data.get(\"seconds\") else 0\r\n    milliseconds = int(data[\"milliseconds\"]) if data.get(\"milliseconds\") else 0\r\n\r\n    return dt.timedelta(hours=hours, minutes=minutes, seconds=seconds, milliseconds=milliseconds)\r\n\r\n\r\ndef parse_season_and_episode_tag(tag: str) -> tuple[int, int]:\r\n    \"\"\"\r\n    Parse a season and episode tag (e.g. 'S01E01') to a tuple containing the season number and episode number.\r\n\r\n    Args:\r\n        tag (str): Season and episode tag. (e.g. 'S01E02')\r\n\r\n    Returns:\r\n        tuple[int, int]: A tuple containing the season number (first item) and episode number (second item).\r\n    \"\"\"\r\n    regex_pattern = re.compile(r\"(?i)^S(?P<season>\\d{1,2})[\\s.]?E(?P<episode>\\d{1,3})$\")\r\n\r\n    if regex_match := re.match(regex_pattern, tag):\r\n        return int(regex_match.group('season')), int(regex_match.group('episode'))\r\n\r\n    raise ValueError(f\"Invalid season and episode tag: '{tag}'\")\r\n\r\n\r\ndef parse_url_params(url_params: str) -> dict:\r\n    \"\"\"\r\n    Parse GET parameters from a URL to a dictionary.\r\n\r\n    Args:\r\n        url_params (str): URL parameters. (e.g. 'param1=value1&param2=value2')\r\n\r\n    Returns:\r\n        dict: A dictionary containing the URL parameters.\r\n    \"\"\"\r\n    url_params = url_params.split('?')[-1].rstrip('&')\r\n    params_list = url_params.split('&')\r\n\r\n    if len(params_list) == 0 or \\\r\n            (len(params_list) == 1 and '=' not in params_list[0]):\r\n        return {}\r\n\r\n    return {key: value for key, value in (param.split('=') for param in params_list)}\r\n\r\n\r\ndef single_to_list(obj: Any) -> list:\r\n    \"\"\"\r\n    Convert a single non-iterable object to a list.\r\n    If None is passed, an empty list will be returned.\r\n\r\n    Args:\r\n        obj: Object to convert.\r\n\r\n    Returns:\r\n        list: A list containing the object.\r\n            If the object is already an iterable, it will be converted to a list.\r\n    \"\"\"\r\n    if isinstance(obj, list):\r\n        return obj\r\n\r\n    if obj is None:\r\n        return []\r\n\r\n    # tuple (not a namedtuple) or a set\r\n    if (isinstance(obj, tuple) and not hasattr(obj, '_fields')) or isinstance(obj, set):\r\n        return list(obj)\r\n\r\n    return [obj]\r\n\r\n\r\ndef split_subtitles_timestamp(timestamp: str) -> tuple[dt.time, dt.time]:\r\n    \"\"\"\r\n    Split a subtitles timestamp into start and end.\r\n\r\n    Args:\r\n        timestamp (str): A subtitles timestamp. For example: \"00:00:00.000 --> 00:00:00.000\"\r\n\r\n    Returns:\r\n        tuple(time, time): A tuple containing start and end times as a datetime object.\r\n    \"\"\"\r\n    # Support ',' character in timestamp's milliseconds (used in SubRip format).\r\n    timestamp = timestamp.replace(',', '.')\r\n\r\n    start_time, end_time = timestamp.split(\" --> \")\r\n    return dt.time.fromisoformat(start_time), dt.time.fromisoformat(end_time)\r\n\r\n\r\n@lru_cache\r\ndef standardize_title(title: str) -> str:\r\n    \"\"\"\r\n    Format movie title to a standardized title that can be used as a file name.\r\n\r\n    Args:\r\n        title (str): A movie title.\r\n\r\n    Returns:\r\n        str: The movie title, in a file-name-friendly format.\r\n    \"\"\"\r\n    windows_reserved_file_names = (\"CON\", \"PRN\", \"AUX\", \"NUL\", \"COM1\", \"COM2\", \"COM3\", \"COM4\",\r\n                                   \"COM5\", \"COM6\", \"COM7\", \"COM8\", \"COM9\", \"LPT1\", \"LPT2\",\r\n                                   \"LPT3\", \"LPT4\", \"LPT5\", \"LPT6\", \"LPT7\", \"LPT8\", \"LPT9\")\r\n\r\n    title = title.strip()\r\n\r\n    # Replacements will be done in the same order of this list\r\n    replacement_pairs = [\r\n        (': ', '.'),\r\n        (':', '.'),\r\n        (' - ', '-'),\r\n        (', ', '.'),\r\n        ('. ', '.'),\r\n        (' ', '.'),\r\n        ('|', '.'),\r\n        ('/', '.'),\r\n        ('', '.'),\r\n        ('<', ''),\r\n        ('>', ''),\r\n        ('(', ''),\r\n        (')', ''),\r\n        ('\"', ''),\r\n        ('?', ''),\r\n        ('*', ''),\r\n    ]\r\n\r\n    for pair in replacement_pairs:\r\n        title = title.replace(pair[0], pair[1])\r\n\r\n    title = re.sub(r\"\\.+\", \".\", title)  # Replace multiple dots with a single dot\r\n\r\n    # If running on Windows, rename Windows reserved names to allow file creation\r\n    if sys.platform == 'win32':\r\n        split_title = title.split('.')\r\n\r\n        if split_title[0].upper() in windows_reserved_file_names:\r\n            if len(split_title) > 1:\r\n                return split_title[0] + split_title[1] + '.'.join(split_title[2:])\r\n\r\n            if len(split_title) == 1:\r\n                return \"_\" + title\r\n\r\n    return title\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/utils.py b/isubrip/utils.py
--- a/isubrip/utils.py	(revision 67c115fc7dbd1dc7520fc499455860dceb009906)
+++ b/isubrip/utils.py	(date 1707509036916)
@@ -10,7 +10,7 @@
 import sys
 from typing import TYPE_CHECKING, Any, Type, Union, get_args, get_origin
 
-from isubrip.constants import TEMP_FOLDER_PATH
+from isubrip.constants import TEMP_FOLDER_PATH, WINDOWS_RESERVED_FILE_NAMES, TITLE_REPLACEMENT_STRINGS
 from isubrip.data_structures import (
     Episode,
     MediaBase,
@@ -642,34 +642,10 @@
     Returns:
         str: The movie title, in a file-name-friendly format.
     """
-    windows_reserved_file_names = ("CON", "PRN", "AUX", "NUL", "COM1", "COM2", "COM3", "COM4",
-                                   "COM5", "COM6", "COM7", "COM8", "COM9", "LPT1", "LPT2",
-                                   "LPT3", "LPT4", "LPT5", "LPT6", "LPT7", "LPT8", "LPT9")
-
     title = title.strip()
 
-    # Replacements will be done in the same order of this list
-    replacement_pairs = [
-        (': ', '.'),
-        (':', '.'),
-        (' - ', '-'),
-        (', ', '.'),
-        ('. ', '.'),
-        (' ', '.'),
-        ('|', '.'),
-        ('/', '.'),
-        ('', '.'),
-        ('<', ''),
-        ('>', ''),
-        ('(', ''),
-        (')', ''),
-        ('"', ''),
-        ('?', ''),
-        ('*', ''),
-    ]
-
-    for pair in replacement_pairs:
-        title = title.replace(pair[0], pair[1])
+    for string, replacement_string in TITLE_REPLACEMENT_STRINGS.items():
+        title = title.replace(string, replacement_string)
 
     title = re.sub(r"\.+", ".", title)  # Replace multiple dots with a single dot
 
@@ -677,7 +653,7 @@
     if sys.platform == 'win32':
         split_title = title.split('.')
 
-        if split_title[0].upper() in windows_reserved_file_names:
+        if split_title[0].upper() in WINDOWS_RESERVED_FILE_NAMES:
             if len(split_title) > 1:
                 return split_title[0] + split_title[1] + '.'.join(split_title[2:])
 
Index: isubrip/scrapers/yesplus_scraper.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nimport datetime as dt\r\nimport re\r\nfrom typing import Iterator\r\n\r\nfrom isubrip.config import Config, ConfigSetting\r\nfrom isubrip.data_structures import Episode, Movie, ScrapedMediaResponse, Season, Series, SubtitlesData\r\nfrom isubrip.scrapers.scraper import DASHScraper, PlaylistLoadError, ScraperError\r\nfrom isubrip.utils import (\r\n    generate_url_params,\r\n    parse_duration,\r\n    parse_season_and_episode_tag,\r\n    parse_url_params,\r\n    raise_for_status,\r\n    single_to_list,\r\n)\r\n\r\n\r\nclass YesPlusScraper(DASHScraper):\r\n    \"\"\"A Yes+ scraper\"\"\"\r\n    id = \"yesplus\"\r\n    name = \"yes+\"\r\n    abbreviation = \"YESP\"\r\n    # https://go-cgw-prod.stingtv.co.il:4443/ctap/r1.6.0/contentinstances/SHOW0000000001951653~vod\r\n    url_regex = re.compile(r\"(?P<base_url>https?://(?:www\\.)?apps\\.disneyplus\\.com/(?P<slug>(?:(?P<country_code>[a-z]{2})/)?(?:(?P<media_type>movies|shows)/)?(?:(?P<media_name>[\\w\\-%]+)/)?(?P<media_id>(?:\\d{4,10}))))(?:\\?(?P<url_params>.*))?\", flags=re.IGNORECASE)  # noqa: E501\r\n    subtitles_class = None  # TODO\r\n    is_movie_scraper = True\r\n    is_series_scraper = True\r\n\r\n    _api_base_url = \"https://go-cgw-prod.stingtv.co.il:4443/ctap/r1.6.0\"\r\n\r\n    def __init__(self, config_data: dict | None = None):\r\n        super().__init__(config_data)\r\n\r\n        if self.config is None:\r\n            self.config = Config()\r\n\r\n        # Add \"token\" setting to config\r\n        self.config.add_settings(\r\n            ConfigSetting(\r\n                key=\"token\",\r\n                type=str,\r\n                required=True,\r\n            ),\r\n            check_config=True)\r\n\r\n        self.jwt_token: str = self.config[\"token\"]\r\n\r\n        self._session.headers.update({\r\n            \"Accept\": \"application/json\",  # TODO: Remove?\r\n            \"X-Hs-Usertoken\": self.config[\"token\"],\r\n            \"X-Hs-Platform\": \"web\",\r\n            \"X-Hs-Client\": \"platform:web;app_version:23.05.29.0;browser:Chrome;schema_version:0.0.854\",\r\n        })\r\n\r\n    def _get_api_data(self, endpoint: str) -> dict:\r\n        \"\"\"\r\n        Retrieve data from Yes+'s API.\r\n\r\n        Args:\r\n            endpoint (str): API endpoint.\r\n\r\n        Returns:\r\n            dict: Data returned by the API for the given endpoint.\r\n        \"\"\"\r\n        response = self._session.get(f\"{self._api_base_url}/{endpoint}\")\r\n        raise_for_status(response)\r\n        return response.json()\r\n\r\n    def _get_episode_playlists(self, episode_slug: str) -> list[str]:\r\n        player_params = generate_url_params(data=self.player_params, remove_dict_spaces=True)\r\n        api_data = self._get_api_data(endpoint=f\"v2/slugs/{episode_slug}?{player_params}\")\r\n\r\n        player_config = (\r\n            api_data[\"success\"][\"page\"][\"spaces\"][\"player\"][\"widget_wrappers\"][0][\"widget\"][\"data\"][\"player_config\"]\r\n        )\r\n\r\n        return_data = [\r\n            player_config.get(\"media_asset_v2\", {}).get(\"primary\", {}).get(\"content_url\"),\r\n            player_config.get(\"media_asset_v2\", {}).get(\"fallback\", {}).get(\"content_url\"),\r\n        ]\r\n\r\n        return [playlist_url for playlist_url in return_data if playlist_url]\r\n\r\n    def _get_season_data(self, show_id: str, season_id: str) -> dict[int, dict]:\r\n        endpoint = f\"v2/pages/841/spaces/803/widgets/1196/widgets/168?content_id={show_id}&season_id={season_id}\"\r\n        paginated_data = []\r\n\r\n        # Get all paginated episodes data for the season\r\n        while endpoint:  # TODO: Increase page size\r\n            api_data = self._get_api_data(endpoint)\r\n            episodes_paginated_data = api_data[\"success\"][\"widget_wrapper\"][\"widget\"][\"data\"]\r\n            paginated_data.extend(episodes_paginated_data[\"items\"])\r\n            endpoint = episodes_paginated_data.get(\"next_tray_url\")\r\n\r\n        api_episodes_data = [episode_data[\"playable_content\"][\"data\"] for episode_data in paginated_data]\r\n        result_data: dict[int, dict] = {}\r\n\r\n        for episode_data in api_episodes_data:\r\n            page_slug = episode_data[\"actions\"][\"on_click\"][1][\"page_navigation\"][\"page_slug\"].split(\"?\")[0]\r\n            episode_data[\"playlists\"] = self._get_episode_playlists(episode_slug=page_slug.lstrip(\"/\"))\r\n            episode_number = parse_season_and_episode_tag(episode_data[\"tags\"][0][\"value\"])[1]\r\n            # Remove unnecessary data\r\n            if 'actions' in episode_data:\r\n                episode_data.pop('actions')\r\n\r\n            if 'download_options' in episode_data:\r\n                episode_data.pop('download_options')\r\n\r\n            result_data[episode_number] = episode_data\r\n\r\n        return result_data\r\n\r\n    def get_media_data(self, media_id: str) -> dict:\r\n        \"\"\"\r\n        Get media data from the API.\r\n        This call also sets the 'WsbSession' cookie required for\r\n\r\n        Args:\r\n            media_id (str): Media ID.\r\n\r\n        Returns:\r\n            dict: Media data.\r\n        \"\"\"\r\n        return self._get_api_data(endpoint=f\"contentinstances/{media_id}\")\r\n\r\n    def generate_play_session(self, media_id: str) -> dict:\r\n        \"\"\"\r\n        Generate a play session for the given media ID.\r\n\r\n        Args:\r\n            media_id (str): Media ID.\r\n\r\n        Returns:\r\n            str: Play session.\r\n        \"\"\"\r\n        return self._get_api_data(endpoint=\"devices/me/playsessions\", params={\"instanceId\": media_id})\r\n\r\n    def get_movie_data(self, movie_id: str) -> ScrapedMediaResponse[Movie]:\r\n        raise NotImplementedError  # TODO\r\n\r\n    def get_series_data(self, show_slug: str) -> ScrapedMediaResponse[Series]:\r\n        api_data = self._get_api_data(endpoint=\"v2/slugs/\" + show_slug)\r\n        media_data = api_data[\"success\"][\"page\"][\"spaces\"][\"hero\"][\"widget_wrappers\"][0][\"widget\"][\"data\"]\r\n        seasons_data = api_data[\"success\"][\"page\"][\"spaces\"][\"tray\"][\"widget_wrappers\"][0][\"widget\"][\"data\"] \\\r\n            [\"category_picker\"][\"data\"][\"tabs\"]\r\n\r\n        series_name = media_data[\"content_info\"][\"title\"]\r\n        series_id = media_data[\"content_actions_row\"][\"content_action_buttons\"][0][\"watchlist_content_action_button\"] \\\r\n            [\"info\"][\"content_id\"]\r\n        series_seasons: list[Season] = []\r\n        result_seasons_data: dict[int, dict[int, dict]] = {}\r\n\r\n        for season_data in [season_data[\"tab\"][\"data\"] for season_data in seasons_data]:\r\n            url_params = parse_url_params(season_data[\"tray_widget_url\"])  # TODO: Use the URL instead of parsing it and recreating it\r\n            season_episodes_data = self._get_season_data(show_id=url_params[\"content_id\"],\r\n                                                         season_id=url_params[\"season_id\"])\r\n            season_number = int(season_data[\"title\"].split(\" \")[1])\r\n            result_seasons_data[season_number] = season_episodes_data\r\n\r\n            season_episodes: list[Episode] = []\r\n\r\n            for episode_number, episode_data in season_episodes_data.items():\r\n                season_episodes.append(\r\n                    Episode(\r\n                        id=episode_data[\"cw_info\"][\"content_id\"],\r\n                        series_name=series_name,\r\n                        season_number=season_number,\r\n                        episode_number=episode_number,\r\n                        episode_name=episode_data[\"title\"],\r\n                        episode_release_date=dt.datetime.strptime(episode_data[\"tags\"][1][\"value\"], \"%d %b %Y\"),\r\n                        episode_duration=parse_duration(episode_data[\"tags\"][2][\"value\"]),\r\n                        playlist=episode_data[\"playlists\"].copy(),\r\n                    ),\r\n                )\r\n\r\n            series_seasons.append(\r\n                Season(\r\n                    id=series_id,\r\n                    series_name=series_name,\r\n                    season_number=season_number,\r\n                    release_date=None,\r\n                    episodes=season_episodes,\r\n                ))\r\n\r\n        series_data = Series(\r\n            id=series_id,\r\n            series_name=series_name,\r\n            seasons=series_seasons,\r\n        )\r\n\r\n        return ScrapedMediaResponse(\r\n            media_data=series_data,\r\n            metadata_scraper=self.id,\r\n            playlist_scraper=self.id,\r\n            original_data={\r\n                \"series_data\": api_data,\r\n                \"seasons_data\": result_seasons_data,\r\n            },\r\n        )\r\n\r\n    def get_data(self, url: str) -> ScrapedMediaResponse[Movie] | ScrapedMediaResponse[Series]:\r\n        regex_match = self.match_url(url=url, raise_error=True)\r\n        url_data = regex_match.groupdict()\r\n\r\n        media_id = url_data[\"media_id\"]\r\n\r\n        if not all(url_data.get(key) for key in (\"country_code\", \"media_type\", \"media_name\", \"media_id\")):\r\n            raise ScraperError(f\"Full URL containing the slug is required for scraping from '{self.name}'.\")\r\n            # TODO: Find a way to get the full URL with the complete slug from the given URL\r\n\r\n        if url_data[\"media_type\"] == \"movies\":\r\n            return self.get_movie_data(url_data[\"media_id\"])\r\n\r\n        elif url_data[\"media_type\"] == \"shows\":\r\n            return self.get_series_data(url_data[\"slug\"])\r\n\r\n        else:\r\n            raise ScraperError(f\"Unexpected media type URL '{url_data['media_type']}' for '{self.name}'.\")\r\n\r\n    def get_subtitles(self, main_playlist: str | list[str], language_filter: list[str] | str | None = None,\r\n                      subrip_conversion: bool = False) -> Iterator[SubtitlesData]:\r\n        playlist_data: ET.Element | None = None\r\n        for url in single_to_list(main_playlist):\r\n            if playlist_data := self.load_mpd(url=url,\r\n                                              headers=self._generate_headers(\r\n                                                  url=url,\r\n                                                  additional_headers={\"Accept\": \"application/dash+xml\"},\r\n                                                  include_hotstarauth=True,\r\n                                              )):\r\n                break\r\n\r\n        if playlist_data:\r\n            pass\r\n\r\n        else:\r\n            raise PlaylistLoadError(\"Could not load MPD playlist.\")\r\n\r\n        ET.tostring(playlist_data, encoding=\"unicode\")\r\n        raise NotImplementedError\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/scrapers/yesplus_scraper.py b/isubrip/scrapers/yesplus_scraper.py
--- a/isubrip/scrapers/yesplus_scraper.py	(revision 67c115fc7dbd1dc7520fc499455860dceb009906)
+++ b/isubrip/scrapers/yesplus_scraper.py	(date 1707497240064)
@@ -22,8 +22,7 @@
     id = "yesplus"
     name = "yes+"
     abbreviation = "YESP"
-    # https://go-cgw-prod.stingtv.co.il:4443/ctap/r1.6.0/contentinstances/SHOW0000000001951653~vod
-    url_regex = re.compile(r"(?P<base_url>https?://(?:www\.)?apps\.disneyplus\.com/(?P<slug>(?:(?P<country_code>[a-z]{2})/)?(?:(?P<media_type>movies|shows)/)?(?:(?P<media_name>[\w\-%]+)/)?(?P<media_id>(?:\d{4,10}))))(?:\?(?P<url_params>.*))?", flags=re.IGNORECASE)  # noqa: E501
+    url_regex = re.compile(r"(?P<base_url>https?://go-cgw-prod\.stingtv\.co\.il:4443)/ctap/r1\.6\.0/contentinstances/(?P<media_id>[^?]*)(?:\?(?P<url_params>.*))?", flags=re.IGNORECASE)  # noqa: E501
     subtitles_class = None  # TODO
     is_movie_scraper = True
     is_series_scraper = True
@@ -54,7 +53,7 @@
             "X-Hs-Client": "platform:web;app_version:23.05.29.0;browser:Chrome;schema_version:0.0.854",
         })
 
-    def _get_api_data(self, endpoint: str) -> dict:
+    def _get_api_data(self, endpoint: str, params: dict | None = None) -> dict:
         """
         Retrieve data from Yes+'s API.
 
@@ -64,7 +63,7 @@
         Returns:
             dict: Data returned by the API for the given endpoint.
         """
-        response = self._session.get(f"{self._api_base_url}/{endpoint}")
+        response = self._session.get(f"{self._api_base_url}/{endpoint}", params=params)
         raise_for_status(response)
         return response.json()
 
@@ -137,11 +136,11 @@
         """
         return self._get_api_data(endpoint="devices/me/playsessions", params={"instanceId": media_id})
 
-    def get_movie_data(self, movie_id: str) -> ScrapedMediaResponse[Movie]:
+    def get_movie_data(self, data: dict) -> ScrapedMediaResponse[Movie]:
         raise NotImplementedError  # TODO
 
-    def get_series_data(self, show_slug: str) -> ScrapedMediaResponse[Series]:
-        api_data = self._get_api_data(endpoint="v2/slugs/" + show_slug)
+    def get_series_data(self, data: dict) -> ScrapedMediaResponse[Series]:
+
         media_data = api_data["success"]["page"]["spaces"]["hero"]["widget_wrappers"][0]["widget"]["data"]
         seasons_data = api_data["success"]["page"]["spaces"]["tray"]["widget_wrappers"][0]["widget"]["data"] \
             ["category_picker"]["data"]["tabs"]
@@ -205,19 +204,19 @@
         url_data = regex_match.groupdict()
 
         media_id = url_data["media_id"]
+        media_data = self.get_media_data(media_id=media_id)
 
-        if not all(url_data.get(key) for key in ("country_code", "media_type", "media_name", "media_id")):
-            raise ScraperError(f"Full URL containing the slug is required for scraping from '{self.name}'.")
-            # TODO: Find a way to get the full URL with the complete slug from the given URL
+        if media_data["contentType"] == "standalone":
+            return self.get_movie_data()
 
-        if url_data["media_type"] == "movies":
-            return self.get_movie_data(url_data["media_id"])
+        elif media_data["contentType"] == "show":
+            return self.get_series_data()
 
-        elif url_data["media_type"] == "shows":
-            return self.get_series_data(url_data["slug"])
+        elif media_data["contentType"] == "episode":
+            return self.get_episode_data()
 
         else:
-            raise ScraperError(f"Unexpected media type URL '{url_data['media_type']}' for '{self.name}'.")
+            raise ScraperError(f"Unexpected content type: '{media_data['contentType']}'.")
 
     def get_subtitles(self, main_playlist: str | list[str], language_filter: list[str] | str | None = None,
                       subrip_conversion: bool = False) -> Iterator[SubtitlesData]:
Index: isubrip/subtitle_formats/subrip.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nfrom typing import Any\r\n\r\nfrom isubrip.data_structures import SubtitlesFormatType\r\nfrom isubrip.subtitle_formats.subtitles import Subtitles, SubtitlesCaptionBlock\r\n\r\n\r\nclass SubRipCaptionBlock(SubtitlesCaptionBlock):\r\n    \"\"\"A subtitles caption block based on the SUBRIP format.\"\"\"\r\n    def __str__(self) -> str:\r\n        result_str = \"\"\r\n        time_format = \"%H:%M:%S,%f\"\r\n\r\n        result_str += f\"{self.start_time.strftime(time_format)[:-3]} --> {self.end_time.strftime(time_format)[:-3]}\\n\"\r\n        result_str += f\"{self.payload}\"\r\n\r\n        return result_str\r\n\r\n    def __eq__(self, other: Any) -> bool:\r\n        return isinstance(other, type(self)) and \\\r\n               self.start_time == other.start_time and self.end_time == other.end_time and self.payload == other.payload\r\n\r\n    def to_srt(self) -> SubRipCaptionBlock:\r\n        return self\r\n\r\n\r\nclass SubRipSubtitles(Subtitles[SubRipCaptionBlock]):\r\n    \"\"\"An object representing a SubRip subtitles file.\"\"\"\r\n    format = SubtitlesFormatType.SUBRIP\r\n\r\n    def dumps(self) -> str:\r\n        subtitles_str = \"\"\r\n        count = 0\r\n\r\n        for block in self.blocks:\r\n            subtitles_str += f\"{(count + 1)}\\n{str(block)}\\n\\n\"\r\n            count += 1\r\n\r\n        return subtitles_str.rstrip('\\n')\r\n\r\n    @staticmethod\r\n    def loads(subtitles_data: str) -> SubRipSubtitles:\r\n        raise NotImplementedError(\"SubRip subtitles loading is not supported.\")\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/subtitle_formats/subrip.py b/isubrip/subtitle_formats/subrip.py
--- a/isubrip/subtitle_formats/subrip.py	(revision 67c115fc7dbd1dc7520fc499455860dceb009906)
+++ b/isubrip/subtitle_formats/subrip.py	(date 1707497240070)
@@ -39,6 +39,6 @@
 
         return subtitles_str.rstrip('\n')
 
-    @staticmethod
-    def loads(subtitles_data: str) -> SubRipSubtitles:
+    @classmethod
+    def loads(cls, subtitles_data: str, encoding: str = "utf-8") -> SubRipSubtitles:
         raise NotImplementedError("SubRip subtitles loading is not supported.")
Index: isubrip/data_structures.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nfrom abc import ABC\r\nimport datetime as dt  # noqa: TCH003\r\nfrom enum import Enum\r\nfrom typing import Generic, List, NamedTuple, Optional, TypeVar, Union\r\n\r\nfrom pydantic import BaseModel\r\n\r\nMediaData = TypeVar(\"MediaData\", bound=\"MediaBase\")\r\n\r\n\r\nclass SubtitlesDownloadResults(NamedTuple):\r\n    \"\"\"\r\n    A named tuple containing download results.\r\n\r\n    Attributes:\r\n        movie_data (Movie): Movie data object.\r\n        successful_subtitles (list[SubtitlesData]): List of subtitles that were successfully downloaded.\r\n        failed_subtitles (list[SubtitlesData]): List of subtitles that failed to download.\r\n        is_zip (bool): Whether the subtitles were saved in a zip file.\r\n    \"\"\"\r\n    movie_data: Movie\r\n    successful_subtitles: list[SubtitlesData]\r\n    failed_subtitles: list[SubtitlesData]\r\n    is_zip: bool\r\n\r\n\r\nclass SubtitlesFormat(BaseModel):\r\n    \"\"\"\r\n    An object containing subtitles format data.\r\n\r\n    Attributes:\r\n        name (str): Name of the format.\r\n        file_extension (str): File extension of the format.\r\n    \"\"\"\r\n    name: str\r\n    file_extension: str\r\n\r\n\r\nclass SubtitlesFormatType(Enum):\r\n    \"\"\"\r\n    An Enum representing subtitles formats.\r\n\r\n    Attributes:\r\n        SUBRIP (SubtitlesFormat): SubRip format.\r\n        WEBVTT (SubtitlesFormat): WebVTT format.\r\n    \"\"\"\r\n    SUBRIP = SubtitlesFormat(name=\"SubRip\", file_extension=\"srt\")\r\n    WEBVTT = SubtitlesFormat(name=\"WebVTT\", file_extension=\"vtt\")\r\n\r\n\r\nclass SubtitlesType(Enum):\r\n    \"\"\"\r\n    Subtitles special type.\r\n\r\n    Attributes:\r\n        CC (SubtitlesType): Closed captions.\r\n        FORCED (SubtitlesType): Forced subtitles.\r\n    \"\"\"\r\n    CC = \"CC\"\r\n    FORCED = \"Forced\"\r\n\r\n\r\n# TODO: Use `kw_only` on dataclasses, and set default values of None for optional arguments once min version => 3.10\r\n\r\nclass SubtitlesData(BaseModel):\r\n    \"\"\"\r\n    An object containing subtitles data and metadata.\r\n\r\n    Attributes:\r\n        language_code (str): Language code of the language the subtitles are in.\r\n        language_name (str | None, optional): Name of the language the subtitles are in.\r\n        subtitles_format (SubtitlesFormatType): Format of the subtitles.\r\n        content (bytes): Content of the subtitles in binary format.\r\n        special_type (SubtitlesType | None, optional): Type of the subtitles, if they're not regular. Defaults to None.\r\n    \"\"\"\r\n    language_code: str\r\n    subtitles_format: SubtitlesFormatType\r\n    content: bytes\r\n    language_name: str | None = None\r\n    special_type: Union[SubtitlesType, None] = None\r\n\r\n    class ConfigDict:\r\n        str_strip_whitespace = True\r\n\r\n\r\nclass MediaBase(BaseModel, ABC):\r\n    \"\"\"A base class for media objects.\"\"\"\r\n\r\n\r\nclass Movie(MediaBase):\r\n    \"\"\"\r\n    An object containing movie metadata.\r\n\r\n    Attributes:\r\n        id (str | None, optional): ID of the movie on the service it was scraped from. Defaults to None.\r\n        referer_id (str | None, optional): ID of the movie on the original referring service. Defaults to None.\r\n        name (str): Title of the movie.\r\n        release_date (datetime | int | None, optional): Release date (datetime), or year (int) of the movie.\r\n            Defaults to None.\r\n        duration (timedelta | None, optional): Duration of the movie. Defaults to None.\r\n        preorder_availability_date (datetime | None, optional):\r\n            Date when the movie will be available for pre-order on the service it was scraped from.\r\n            None if not a pre-order. Defaults to None.\r\n        playlist (str | None, optional): Main playlist URL(s).\r\n    \"\"\"\r\n    name: str\r\n    release_date: Union[dt.datetime, int]\r\n    id: Optional[str] = None\r\n    referer_id: Optional[str] = None\r\n    duration: Optional[dt.timedelta] = None\r\n    preorder_availability_date: Optional[dt.datetime] = None\r\n    playlist: Union[str, List[str], None] = None\r\n\r\n\r\nclass Episode(MediaBase):\r\n    \"\"\"\r\n    An object containing episode metadata.\r\n\r\n    Attributes:\r\n        id (str | None, optional): ID of the episode on the service it was scraped from. Defaults to None.\r\n        referer_id (str | None, optional): ID of the episode on the original referring service. Defaults to None.\r\n        series_name (str): Name of the series the episode is from.\r\n        series_release_date (datetime | int | None, optional): Release date (datetime), or year (int) of the series.\r\n            Defaults to None.\r\n        season_number (int): Season number.\r\n        season_name (str | None, optional): Season name. Defaults to None.\r\n        episode_number (int): Episode number.\r\n        episode_name (str | None, optional): Episode name. Defaults to None.\r\n        episode_release_date (datetime | None): Release date of the episode. Defaults to None.\r\n        episode_duration (timedelta | None, optional): Duration of the episode. Defaults to None.\r\n        playlist (str | None, optional): Main playlist URL(s).\r\n    \"\"\"\r\n    series_name: str\r\n    season_number: int\r\n    episode_number: int\r\n    id: Optional[str] = None\r\n    referer_id: Optional[str] = None\r\n    series_release_date: Union[dt.datetime, int, None] = None\r\n    season_name: Optional[str] = None\r\n    release_date: Optional[dt.datetime] = None\r\n    duration: Optional[dt.timedelta] = None\r\n    episode_name: Optional[str] = None\r\n    episode_release_date: Optional[dt.datetime] = None\r\n    episode_duration: Optional[dt.timedelta] = None\r\n    playlist: Union[str, List[str], None] = None\r\n\r\n\r\nclass Season(MediaBase):\r\n    \"\"\"\r\n    An object containing season metadata.\r\n\r\n    Attributes:\r\n        id (str | None, optional): ID of the season on the service it was scraped from. Defaults to None.\r\n        referer_id (str | None, optional): ID of the season on the original referring service. Defaults to None.\r\n        series_name (str): Name of the series the season is from.\r\n        series_release_date (datetime | int | None, optional): Release date (datetime), or year (int) of the series.\r\n            Defaults to None.\r\n        season_name (str | None, optional): Season name. Defaults to None.\r\n        season_release_date (datetime | None, optional): Release date of the season, or release year. Defaults to None.\r\n        episodes (list[Episode]): A list of episode objects containing metadata about episodes of the season.\r\n    \"\"\"\r\n    series_name: str\r\n    season_number: int\r\n    id: Optional[str] = None\r\n    referer_id: Optional[str] = None\r\n    series_release_date: Union[dt.datetime, int, None] = None\r\n    season_name: Optional[str] = None\r\n    season_release_date: Union[dt.datetime, int, None] = None\r\n    episodes: List[Episode] = []\r\n\r\n\r\nclass Series(MediaBase):\r\n    \"\"\"\r\n    An object containing series metadata.\r\n\r\n    Attributes:\r\n        id (str | None, optional): ID of the series on the service it was scraped from. Defaults to None.\r\n        series_name (str): Series name.\r\n        referer_id (str | None, optional): ID of the series on the original referring service. Defaults to None.\r\n        series_release_date (datetime | int | None, optional): Release date (datetime), or year (int) of the series.\r\n            Defaults to None.\r\n        seasons (list[Season]): A list of season objects containing metadata about seasons of the series.\r\n    \"\"\"\r\n    series_name: str\r\n    seasons: List[Season] = []\r\n    id: Optional[str] = None\r\n    referer_id: Optional[str] = None\r\n    series_release_date: Union[dt.datetime, int, None] = None\r\n\r\n\r\nclass ScrapedMediaResponse(BaseModel, Generic[MediaData]):\r\n    \"\"\"\r\n    An object containing scraped media data and metadata.\r\n\r\n    Attributes:\r\n        media_data (list[Movie] | list[Episode] | list[Season] | list[Series]):\r\n            An object containing the scraped media data.\r\n        metadata_scraper (str): ID of the scraper that was used to scrape metadata.\r\n        playlist_scraper (str): ID of the scraper that should be used to parse and scrape the playlist.\r\n        original_data (dict): Original raw data from the API that was used to extract media's data.\r\n    \"\"\"\r\n    media_data: List[MediaData]\r\n    metadata_scraper: str\r\n    playlist_scraper: str\r\n    original_data: dict\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/data_structures.py b/isubrip/data_structures.py
--- a/isubrip/data_structures.py	(revision 67c115fc7dbd1dc7520fc499455860dceb009906)
+++ b/isubrip/data_structures.py	(date 1707506374400)
@@ -73,11 +73,13 @@
         language_name (str | None, optional): Name of the language the subtitles are in.
         subtitles_format (SubtitlesFormatType): Format of the subtitles.
         content (bytes): Content of the subtitles in binary format.
+        content_encoding (str): Encoding of subtitles content (ex. "utf-8").
         special_type (SubtitlesType | None, optional): Type of the subtitles, if they're not regular. Defaults to None.
     """
     language_code: str
     subtitles_format: SubtitlesFormatType
     content: bytes
+    content_encoding: str
     language_name: str | None = None
     special_type: Union[SubtitlesType, None] = None
 
Index: pyproject.toml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># --- Poetry ---\r\n[tool.poetry]\r\nname = \"isubrip\"\r\nversion = \"2.5.2\"\r\ndescription = \"A Python package for scraping and downloading subtitles from AppleTV / iTunes movie pages.\"\r\nlicense = \"MIT\"\r\nauthors = [\"Michael Yochpaz\"]\r\nreadme = \"README.md\"\r\nhomepage = \"https://github.com/MichaelYochpaz/iSubRip\"\r\nrepository = \"https://github.com/MichaelYochpaz/iSubRip\"\r\nkeywords = [\r\n    \"iTunes\",\r\n    \"AppleTV\",\r\n    \"movies\",\r\n    \"subtitles\",\r\n    \"scrape\",\r\n    \"scraper\",\r\n    \"download\",\r\n    \"m3u8\"\r\n]\r\nclassifiers = [\r\n    \"Development Status :: 5 - Production/Stable\",\r\n    \"Intended Audience :: End Users/Desktop\",\r\n    \"Intended Audience :: Developers\",\r\n    \"Operating System :: Microsoft :: Windows\",\r\n    \"Operating System :: MacOS\",\r\n    \"Operating System :: POSIX :: Linux\",\r\n    \"Topic :: Utilities\",\r\n    \"License :: OSI Approved :: MIT License\",\r\n    \"Programming Language :: Python :: 3.8\",\r\n    \"Programming Language :: Python :: 3.9\",\r\n    \"Programming Language :: Python :: 3.10\",\r\n    \"Programming Language :: Python :: 3.11\",\r\n]\r\npackages = [\r\n    { include = \"isubrip\" },\r\n]\r\ninclude = [\r\n    \"isubrip/resources\", \"README.md\", \"LICENSE\"\r\n]\r\n\r\n[tool.mypy]\r\ndisallow_untyped_defs = true\r\nexplicit_package_bases = true\r\nignore_missing_imports = true\r\npython_version = \"3.8\"\r\nwarn_return_any = true\r\n\r\n[tool.poetry.scripts]\r\nisubrip = \"isubrip.__main__:main\"\r\nrelease-date-check = \"isubrip.scripts.release_date_check:main\"\r\n\r\n[tool.poetry.urls]\r\n\"Bug Reports\" = \"https://github.com/MichaelYochpaz/iSubRip/issues\"\r\n\r\n[tool.poetry.dependencies]\r\npython = \"^3.8\"\r\nrequests = \"^2.31.0\"\r\nhttpx = {extras = [\"http2\"], version = \"^0.26.0\"}\r\nm3u8 = \"^4.0.0\"\r\nmergedeep = \"^1.3.4\"\r\npydantic = \"^2.5.2\"\r\ntomli = \"^2.0.1\"\r\nlxml = \"^5.1.0\"\r\nrich = \"^13.7.0\"\r\n\r\n[build-system]\r\nrequires = [\"poetry-core\"]\r\nbuild-backend = \"poetry.core.masonry.api\"\r\n\r\n[tool.poetry_bumpversion.file.\"isubrip/constants.py\"]\r\nsearch = 'PACKAGE_VERSION = \"{current_version}\"'\r\nreplace = 'PACKAGE_VERSION = \"{new_version}\"'\r\n\r\n[tool.poetry_bumpversion.file.\"README.md\"]\r\nsearch = 'Latest version: {current_version}'\r\nreplace = 'Latest version: {new_version}'\r\n\r\n# --- Ruff ---\r\n[tool.ruff]\r\nline-length = 120\r\ntarget-version = \"py38\"\r\nselect = [\r\n    \"ARG\",\r\n    \"ASYNC\",\r\n    \"B\",\r\n    \"C4\",\r\n    \"COM\",\r\n    \"E\",\r\n    \"F\",\r\n    \"FA\",\r\n    \"I\",\r\n    \"INP\",\r\n    \"ISC\",\r\n    \"N\",\r\n    \"PIE\",\r\n    \"PGH\",\r\n    \"PT\",\r\n    \"PTH\",\r\n    \"Q002\",\r\n    \"Q003\",\r\n    \"RSE\",\r\n    \"RET\",\r\n    \"RUF\",\r\n    \"S\",\r\n    \"SIM\",\r\n    \"SLF\",\r\n    \"T20\",\r\n    \"TCH\",\r\n    \"TID\",\r\n    \"TRY\",\r\n#    \"UP\",\r\n]\r\nignore = [\r\n    \"C416\",\r\n    \"RUF010\",\r\n    \"RUF012\",\r\n    \"SIM108\",\r\n    \"TD002\",\r\n    \"TD003\",\r\n    \"TRY003\",\r\n#    \"UP015\",\r\n]\r\nunfixable = [\"ARG\"]\r\n\r\n[tool.ruff.flake8-tidy-imports]\r\nban-relative-imports = \"all\"\r\n\r\n[tool.ruff.flake8-quotes]\r\ndocstring-quotes = \"double\"\r\n\r\n[tool.ruff.isort]\r\nforce-sort-within-sections = true\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/pyproject.toml b/pyproject.toml
--- a/pyproject.toml	(revision 67c115fc7dbd1dc7520fc499455860dceb009906)
+++ b/pyproject.toml	(date 1707497240119)
@@ -63,6 +63,7 @@
 tomli = "^2.0.1"
 lxml = "^5.1.0"
 rich = "^13.7.0"
+charset-normalizer = "^3.3.2"
 
 [build-system]
 requires = ["poetry-core"]
