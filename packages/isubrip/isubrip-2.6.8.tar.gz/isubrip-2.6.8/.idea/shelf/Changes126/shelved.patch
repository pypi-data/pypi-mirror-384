Index: isubrip/parsers/mpeg_dash.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nfrom urllib.parse import urljoin\r\n\r\nfrom lxml import etree as ET\r\n\r\nDEFAULT_NAMESPACE = {None: \"urn:mpeg:dash:schema:mpd:2011\"}\r\n\r\n\r\nclass MPDElement:\r\n    \"\"\"\r\n    A base class for MPD elements.\r\n\r\n    Attributes:\r\n        _data (ET._Element): Element data.\r\n    \"\"\"\r\n    def __init__(self, data: ET._Element):\r\n        self._data = data\r\n\r\n    def find(self, path: str, filters: dict[str, str] | None = None) -> ET._Element:\r\n        \"\"\"\r\n        Find the first element matching the given XPath expression.\r\n\r\n        Args:\r\n            path (str): XPath expression.\r\n            filters (dict[str, str], optional): Filters to apply to the element. Defaults to None.\r\n\r\n        Returns:\r\n            ET._Element: The first element matching the given XPath expression.\r\n        \"\"\"\r\n        xpath = self.generate_path(path=path, filters=filters)\r\n        return self._data.find(path=xpath, namespaces=DEFAULT_NAMESPACE)\r\n\r\n    def findall(self, path: str, filters: dict[str, str] | None = None) -> list[ET._Element]:\r\n        \"\"\"\r\n        Find all elements matching the given XPath expression.\r\n\r\n        Args:\r\n            path (str): XPath expression.\r\n            filters (dict[str, str], optional): Filters to apply to the elements. Defaults to None.\r\n\r\n        Returns:\r\n            list[ET._Element]: All elements matching the given XPath expression.\r\n        \"\"\"\r\n        xpath = self.generate_path(path=path, filters=filters)\r\n        return self._data.findall(path=xpath, namespaces=DEFAULT_NAMESPACE)\r\n\r\n    @staticmethod\r\n    def generate_path(path: str, filters: dict[str, str] | None = None) -> str:\r\n        \"\"\"\r\n        Generate an XPath expression with filters.\r\n\r\n        Args:\r\n            path (str): XPath expression.\r\n            filters (dict[str, str] | None, optional): Filters to apply to the expression. Defaults to None.\r\n\r\n        Returns:\r\n            str: The XPath expression with filters.\r\n        \"\"\"\r\n        if filters:\r\n            path += \"\".join([f\"[@{key}='{value}']\" for key, value in filters.items()])\r\n\r\n        return path\r\n\r\n\r\nclass MPD(MPDElement):\r\n    \"\"\"\r\n    A class representing an MPD (MPEG-Dash) playlist.\r\n\r\n    Attributes:\r\n        base_url (str): URI of the playlist.\r\n    \"\"\"\r\n    def __init__(self, playlist_data: str, uri: str):\r\n        super().__init__(data=ET.fromstring(playlist_data.encode(\"utf-8\")))\r\n        self.base_url = urljoin(uri, \".\")\r\n\r\n    def get_periods(self, filters: dict[str, str] | None = None) -> list[Period]:\r\n        \"\"\"\r\n        Get all periods in the MPD playlist.\r\n\r\n        Args:\r\n            filters (dict[str, str], optional): Filters to apply to the periods. Defaults to None.\r\n\r\n        Returns:\r\n            list[Period]: A list of period objects.\r\n        \"\"\"\r\n        xpath = self.generate_path(path=\"./Period\", filters=filters)\r\n        periods = self.findall(path=xpath)\r\n\r\n        return [Period(period=period, mpd=self) for period in periods]\r\n\r\n\r\nclass Period(MPDElement):\r\n    \"\"\"\r\n    A class representing a period in an MPD playlist.\r\n\r\n    Attributes:\r\n        mpd (MPD): The MPD playlist the period is in.\r\n    \"\"\"\r\n    def __init__(self, period: ET._Element, mpd: MPD):\r\n        super().__init__(data=period)\r\n        self.mpd = mpd\r\n        self.id = self._data.get(\"id\")\r\n        self.duration = self._data.get(\"duration\")\r\n\r\n    def get_adaptation_sets(self, filters: dict[str, str] | None = None) -> list[AdaptationSet]:\r\n        \"\"\"\r\n        Get all adaptation sets (matching the filters, if provided) in the period.\r\n\r\n        Args:\r\n            filters (dict[str, str], optional): Filters to apply to the adaptation sets. Defaults to None.\r\n\r\n        Returns:\r\n            list[AdaptationSet]: A list of adaptation set objects.\r\n        \"\"\"\r\n        xpath = self.generate_path(path=\"./AdaptationSet\", filters=filters)\r\n        adaptation_sets = self.findall(path=xpath)\r\n\r\n        return [AdaptationSet(adaptation_set=adaptation_set, period=self) for adaptation_set in adaptation_sets]\r\n\r\n\r\nclass AdaptationSet(MPDElement):\r\n    \"\"\"\r\n    A class representing an adaptation set in an MPD playlist.\r\n\r\n    Attributes:\r\n        period (Period): The period the adaptation set is in.\r\n        content_type (str): Content type of the adaptation set.\r\n        mime_type (str): MIME type of the adaptation set.\r\n        lang (str): Language of the adaptation set.\r\n    \"\"\"\r\n    def __init__(self, adaptation_set: ET._Element, period: Period):\r\n        super().__init__(data=adaptation_set)\r\n        self.period = period\r\n\r\n        self.id = self._data.get(\"id\")\r\n        self.content_type = self._data.get(\"contentType\")\r\n        self.mime_type = self._data.get(\"mimeType\")\r\n        self.lang = self._data.get(\"lang\")\r\n\r\n    def get_segment_template(self, filters: dict[str, str] | None = None) -> SegmentTemplate:\r\n        \"\"\"\r\n        Get the segment template in the adaptation set.\r\n\r\n        Args:\r\n            filters (dict[str, str], optional): Filters to apply to the segment template. Defaults to None.\r\n\r\n        Returns:\r\n            SegmentTemplate: A segment template object.\r\n        \"\"\"\r\n        xpath = self.generate_path(path=\"./SegmentTemplate\", filters=filters)\r\n        segment_template = self.find(path=xpath)\r\n\r\n        return SegmentTemplate(segment_template=segment_template, adaptation_set=self)\r\n\r\n    def get_representations(self, filters: dict[str, str] | None = None) -> list[Representation]:\r\n        \"\"\"\r\n        Get all representations in the adaptation set.\r\n\r\n        Args:\r\n            filters (dict[str, str], optional): Filters to apply to the representations. Defaults to None.\r\n\r\n        Returns:\r\n            list[Representation]: A list of representation objects.\r\n        \"\"\"\r\n        xpath = self.generate_path(path=\"./Representation\", filters=filters)\r\n        representations = self.findall(path=xpath)\r\n\r\n        return [Representation(representation=representation, adaptation_set=self)\r\n                for representation in representations]\r\n\r\n\r\nclass SegmentTemplate(MPDElement):\r\n    \"\"\"\r\n    A class representing a segment template in an adaptation set in an MPD playlist.\r\n\r\n    Attributes:\r\n        adaptation_set (AdaptationSet): The adaptation set the segment template is in.\r\n    \"\"\"\r\n    def __init__(self, segment_template: ET._Element, adaptation_set: AdaptationSet):\r\n        super().__init__(data=segment_template)\r\n        self.adaptation_set = adaptation_set\r\n        self.media = self._data.get(\"media\")\r\n        self.start_number = self._data.get(\"startNumber\")\r\n        self.timescale = self._data.get(\"timescale\")\r\n        self.initialization = self._data.get(\"initialization\")\r\n\r\n\r\nclass SegmentTimeline(MPDElement):\r\n    \"\"\"\r\n    A class representing a segment timeline in a segment template in an adaptation set in an MPD playlist.\r\n\r\n    Attributes:\r\n        segment_template (SegmentTemplate): The segment template the segment timeline is in.\r\n    \"\"\"\r\n    def __init__(self, segment_timeline: ET._Element, segment_template: SegmentTemplate):\r\n        super().__init__(data=segment_timeline)\r\n        self.segment_template = segment_template\r\n        self.timeline = self.findall(path=\"./S\")\r\n\r\n    def get_timeline(self) -> list[dict[str, str | None]]:\r\n        \"\"\"\r\n        Get the segment timeline.\r\n\r\n        Returns:\r\n            list[dict[str, str]]: A list of dictionaries containing the segment timeline data.\r\n        \"\"\"\r\n        return [{\"t\": s.get(\"t\"), \"d\": s.get(\"d\"), \"r\": s.get(\"r\")} for s in self.timeline]\r\n\r\n\r\nclass Representation(MPDElement):\r\n    \"\"\"\r\n    A class representing a representation in an adaptation set in an MPD playlist.\r\n\r\n    Attributes:\r\n        adaptation_set (AdaptationSet): The adaptation set the representation is in.\r\n    \"\"\"\r\n    def __init__(self, representation: ET._Element, adaptation_set: AdaptationSet):\r\n        super().__init__(data=representation)\r\n        self.adaptation_set = adaptation_set\r\n        self.id = self._data.get(\"id\")\r\n        self.codecs = self._data.get(\"codecs\")\r\n        self.width = self._data.get(\"width\")\r\n        self.height = self._data.get(\"height\")\r\n        self.scan_type = self._data.get(\"scanType\")\r\n        self.frame_rate = self._data.get(\"frameRate\")\r\n        self.bandwidth = self._data.get(\"bandwidth\")\r\n        self.audio_sampling_rate = self._data.get(\"audioSamplingRate\")\r\n\r\n        self._base_url = None\r\n        self.url = None\r\n\r\n        if self.find(path=\"./BaseURL\") is not None:\r\n            self._base_url = self.find(path=\"./BaseURL\").text\r\n            self.url = urljoin(self.adaptation_set.period.mpd.base_url, self._base_url)\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/parsers/mpeg_dash.py b/isubrip/parsers/mpeg_dash.py
--- a/isubrip/parsers/mpeg_dash.py	(revision d0959cc740ebbc24f4887e2926c52a39d34dda02)
+++ b/isubrip/parsers/mpeg_dash.py	(date 1722288457396)
@@ -43,7 +43,7 @@
             list[ET._Element]: All elements matching the given XPath expression.
         """
         xpath = self.generate_path(path=path, filters=filters)
-        return self._data.findall(path=xpath, namespaces=DEFAULT_NAMESPACE)
+        return self._data.findall(path=xpath, namespaces=DEFAULT_NAMESPACE)  # type: ignore[no-any-return]
 
     @staticmethod
     def generate_path(path: str, filters: dict[str, str] | None = None) -> str:
Index: isubrip/scripts/release_date_check.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nfrom contextlib import suppress\r\nfrom dataclasses import dataclass\r\nimport sys\r\nfrom typing import TYPE_CHECKING, Any, Iterator\r\n\r\nfrom rich.console import Console\r\nfrom rich.progress import (\r\n    BarColumn,\r\n    MofNCompleteColumn,\r\n    Progress,\r\n    SpinnerColumn,\r\n    TaskProgressColumn,\r\n    TextColumn,\r\n    TimeElapsedColumn,\r\n)\r\nfrom rich.table import Table\r\n\r\nfrom isubrip.scrapers.appletv_scraper import AppleTVScraper\r\nfrom isubrip.scrapers.itunes_scraper import ItunesScraper\r\nfrom isubrip.scrapers.scraper import PlaylistLoadError\r\n\r\nif TYPE_CHECKING:\r\n    import datetime as dt\r\n\r\n    from m3u8.model import M3U8\r\n\r\n    from isubrip.data_structures import Movie\r\n\r\nUSER_AGENT = (\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) \"\r\n              \"Chrome/100.0.4896.127 Safari/537.36\")\r\n\r\n\r\n@dataclass\r\nclass AppleTVResult:\r\n    movie_data: Movie | None\r\n    storefront: str\r\n    released: bool\r\n    release_date: dt.datetime | None = None\r\n\r\n\r\ndef main():\r\n    apple_tv_scraper = AppleTVScraper(user_agent=USER_AGENT)\r\n    itunes_scraper = ItunesScraper(user_agent=USER_AGENT)\r\n\r\n    console = Console()\r\n\r\n    if len(sys.argv) != 2:\r\n        print(\"Usage: generate_release_dates_report.py <AppleTV URL>\")\r\n        sys.exit(1)\r\n\r\n    url = sys.argv[1]\r\n\r\n    released_items: list[AppleTVResult] = []\r\n    unreleased_items_with_release_date: list[AppleTVResult] = []\r\n    unknown_release_items: list[AppleTVResult] = []\r\n    no_store_page_items: list[AppleTVResult] = []\r\n\r\n    with Progress(\r\n            SpinnerColumn(),\r\n            TextColumn(\"[progress.description]{task.description}\"),\r\n            BarColumn(),\r\n            MofNCompleteColumn(),\r\n            TaskProgressColumn(),\r\n            TimeElapsedColumn(),\r\n            console=console,\r\n            transient=False,\r\n    ) as progress:\r\n        task = progress.add_task(\"[bold green]Fetching data from all storefronts[/bold green]\",\r\n                                 total=len(apple_tv_scraper.storefronts_mapping.keys()))\r\n\r\n        for results_list in fetch_movie_from_all_storefronts(apple_tv_scraper=apple_tv_scraper,\r\n                                                             itunes_scraper=itunes_scraper, url=url):\r\n            for result_item in results_list:\r\n                if result_item.movie_data is None:\r\n                    no_store_page_items.append(result_item)\r\n\r\n                elif result_item.released is True:\r\n                    released_items.append(result_item)\r\n\r\n                elif result_item.released is False:\r\n                    unreleased_items_with_release_date.append(result_item)\r\n\r\n                elif result_item.released is None:\r\n                    unknown_release_items.append(result_item)\r\n\r\n            progress.advance(task)\r\n\r\n    # Released Items Table:\r\n    if len(released_items) > 0:\r\n        released_items_table = create_released_results_table(\r\n            itunes_scraper=itunes_scraper,\r\n            result_items=released_items,\r\n        )\r\n        console.print(\"[bold green]Released Items:[/bold green]\")\r\n        console.print(released_items_table)\r\n\r\n    # Unreleased Items Table:\r\n    if len(unreleased_items_with_release_date) > 0:\r\n        unreleased_items_with_release_date_table = create_unreleased_results_table(\r\n            itunes_scraper=itunes_scraper,\r\n            result_items=unreleased_items_with_release_date,\r\n        )\r\n        console.print(\"[bold yellow]Unreleased Items:[/bold yellow]\")\r\n        console.print(unreleased_items_with_release_date_table)\r\n\r\n\r\ndef fetch_movie_from_all_storefronts(apple_tv_scraper: AppleTVScraper,\r\n                                     itunes_scraper: ItunesScraper, url: str) -> Iterator[list[AppleTVResult]]:\r\n    regex_match = apple_tv_scraper.match_url(url=url, raise_error=True)\r\n    regex_extracted_data = regex_match.groupdict()\r\n    movie_id = str(regex_extracted_data[\"media_id\"])\r\n    original_storefront = str(regex_extracted_data[\"country_code\"]).upper()\r\n\r\n    if regex_extracted_data[\"media_type\"] != \"movie\":\r\n        exit(\"Provided URL is not a movie URL.\")\r\n\r\n    storefronts = set(apple_tv_scraper.storefronts_mapping.keys())\r\n\r\n    with suppress(KeyError):\r\n        storefronts.remove(original_storefront)\r\n\r\n    with suppress(Exception):\r\n        yield fetch_movie_from_storefront(\r\n            apple_tv_scraper=apple_tv_scraper,\r\n            itunes_scraper=itunes_scraper,\r\n            movie_id=movie_id,\r\n            storefront=original_storefront,\r\n        )\r\n\r\n    for storefront in storefronts:\r\n        yield fetch_movie_from_storefront(\r\n            apple_tv_scraper=apple_tv_scraper,\r\n            itunes_scraper=itunes_scraper,\r\n            movie_id=movie_id,\r\n            storefront=storefront,\r\n        )\r\n\r\n\r\ndef fetch_movie_from_storefront(apple_tv_scraper: AppleTVScraper, itunes_scraper: ItunesScraper,\r\n                                movie_id: str, storefront: str) -> list[AppleTVResult] | None:\r\n    storefront_id = apple_tv_scraper.storefronts_mapping[storefront]\r\n\r\n    try:\r\n        response = apple_tv_scraper.get_movie_data(\r\n            storefront_id=storefront_id,\r\n            movie_id=movie_id,\r\n        )\r\n\r\n    except Exception:  # Movie is not available in this storefront\r\n        return [\r\n            AppleTVResult(\r\n                movie_data=None,\r\n                storefront=storefront,\r\n                released=False,\r\n                release_date=None,\r\n            ),\r\n        ]\r\n\r\n    results: list[AppleTVResult] = []\r\n\r\n    for movie_data in response.media_data:\r\n        if movie_data.playlist:\r\n            try:\r\n                playlist = itunes_scraper.load_m3u8(url=movie_data.playlist)\r\n\r\n            except Exception:\r\n                playlist = None\r\n\r\n        else:\r\n            playlist = None\r\n\r\n        results.append(\r\n            AppleTVResult(\r\n                movie_data=movie_data,\r\n                storefront=storefront,\r\n                released=determine_release_status(movie_data=movie_data, loaded_playlist=playlist),\r\n                release_date=movie_data.preorder_availability_date,\r\n            ),\r\n        )\r\n\r\n    return results\r\n\r\n\r\ndef determine_release_status(movie_data: Movie, loaded_playlist: M3U8 | None) -> bool | None:\r\n    if bool(loaded_playlist):\r\n        return True\r\n\r\n    else:\r\n        if movie_data.preorder_availability_date:\r\n            return False\r\n\r\n        return None\r\n\r\n\r\ndef create_released_results_table(itunes_scraper: ItunesScraper, result_items: list[AppleTVResult]) -> Table:\r\n    result_items = sorted(result_items, key=lambda item: item.storefront)\r\n    result_items_table = Table(show_header=True, header_style=\"bold green\", show_lines=True)\r\n    result_items_table.add_column(\"iTunes ID\")\r\n    result_items_table.add_column(\"Storefronts\")\r\n    result_items_table.add_column(\"Available Languages\")\r\n\r\n    id_mapping: dict[str, dict[str, Any]] = {}\r\n\r\n    for result in result_items:\r\n        result_id = result.movie_data.id\r\n\r\n        if result_id in id_mapping:\r\n            id_mapping[result_id][\"storefronts\"].append(result.storefront)\r\n\r\n            if id_mapping[result_id][\"languages\"] is None:\r\n                try:\r\n                    available_languages = list_available_subtitles_languages(\r\n                        itunes_scraper=itunes_scraper,\r\n                        main_playlist=result.movie_data.playlist,\r\n                    )\r\n\r\n                except PlaylistLoadError:\r\n                    available_languages = None\r\n\r\n                id_mapping[result_id][\"languages\"] = available_languages\r\n\r\n        else:\r\n            try:\r\n                available_languages = sorted(list_available_subtitles_languages(\r\n                    itunes_scraper=itunes_scraper,\r\n                    main_playlist=result.movie_data.playlist,\r\n                ))\r\n\r\n            except PlaylistLoadError:\r\n                available_languages = None\r\n\r\n            id_mapping[result_id] = {\r\n                \"storefronts\": [result.storefront],\r\n                \"languages\": available_languages if available_languages else [],\r\n            }\r\n\r\n    for result_id, data in id_mapping.items():\r\n        if data[\"languages\"] is None:\r\n            languages_str = \"Could not load languages.\"\r\n\r\n        else:\r\n            languages_str = \", \".join(data[\"languages\"])\r\n\r\n        result_items_table.add_row(\r\n            result_id,\r\n            \", \".join(data[\"storefronts\"]),\r\n            languages_str,\r\n        )\r\n\r\n    return result_items_table\r\n\r\n\r\ndef create_unreleased_results_table(itunes_scraper: ItunesScraper, result_items: list[AppleTVResult]) -> Table:\r\n    result_items = sorted(result_items, key=lambda item: item.storefront)\r\n    result_items_table = Table(show_header=True, header_style=\"bold green\", show_lines=True)\r\n    result_items_table.add_column(\"iTunes ID\")\r\n    result_items_table.add_column(\"Storefronts\")\r\n    result_items_table.add_column(\"Release Date\")\r\n    result_items_table.add_column(\"Available Languages\")\r\n\r\n    id_languages_mapping: dict[str, list[str] | None] = {}\r\n    results: list[dict[str, Any]] = []\r\n\r\n    for result in result_items:\r\n        result_id = result.movie_data.id\r\n\r\n        if result_id in id_languages_mapping:\r\n            available_languages = id_languages_mapping[result_id]\r\n\r\n            if id_languages_mapping[result_id] is None:\r\n                try:\r\n                    available_languages = list_available_subtitles_languages(\r\n                        itunes_scraper=itunes_scraper,\r\n                        main_playlist=result.movie_data.playlist,\r\n                    )\r\n                    id_languages_mapping[result_id] = available_languages\r\n\r\n                except PlaylistLoadError:\r\n                    pass\r\n\r\n        else:\r\n            try:\r\n                id_languages_mapping[result_id] = sorted(list_available_subtitles_languages(\r\n                    itunes_scraper=itunes_scraper,\r\n                    main_playlist=result.movie_data.playlist,\r\n                ))\r\n                available_languages = id_languages_mapping[result_id]\r\n\r\n            except PlaylistLoadError:\r\n                available_languages = None\r\n\r\n        results.append({\r\n            \"id\": result_id,\r\n            \"storefronts\": [result.storefront],\r\n            \"release_date\": result.release_date,\r\n            \"languages\": available_languages,\r\n        })\r\n\r\n    results = sorted(results, key=lambda x: x[\"release_date\"])\r\n\r\n    for result in results:\r\n        if result[\"languages\"] is None:\r\n            languages_str = \"Could not load languages.\"\r\n\r\n        else:\r\n            languages_str = \", \".join(result[\"languages\"])\r\n\r\n        result_items_table.add_row(\r\n            result[\"id\"],\r\n            \", \".join(result[\"storefronts\"]),\r\n            result[\"release_date\"].strftime(\"%Y-%m-%d\"),\r\n            languages_str,\r\n        )\r\n\r\n    return result_items_table\r\n\r\n\r\ndef list_available_subtitles_languages(itunes_scraper: ItunesScraper,\r\n                                       main_playlist: str | list[str]) -> list[str]:\r\n    main_playlist_m3u8 = itunes_scraper.load_m3u8(url=main_playlist)\r\n\r\n    if main_playlist_m3u8 is None:\r\n        raise PlaylistLoadError(\"Could not load M3U8 playlist.\")\r\n\r\n    playlist_results = itunes_scraper.get_media_playlists(main_playlist=main_playlist_m3u8,\r\n                                                          playlist_filters=itunes_scraper._subtitles_filters)\r\n\r\n    return list({\r\n        f\"{result.name} ({result.language})\" for result in playlist_results\r\n        if None not in (result.name, result.language)\r\n    })\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/scripts/release_date_check.py b/isubrip/scripts/release_date_check.py
--- a/isubrip/scripts/release_date_check.py	(revision d0959cc740ebbc24f4887e2926c52a39d34dda02)
+++ b/isubrip/scripts/release_date_check.py	(date 1722287991415)
@@ -1,9 +1,10 @@
 from __future__ import annotations
 
+import asyncio
 from contextlib import suppress
 from dataclasses import dataclass
 import sys
-from typing import TYPE_CHECKING, Any, Iterator
+from typing import TYPE_CHECKING, Any
 
 from rich.console import Console
 from rich.progress import (
@@ -17,6 +18,7 @@
 )
 from rich.table import Table
 
+from isubrip.constants import EVENT_LOOP
 from isubrip.scrapers.appletv_scraper import AppleTVScraper
 from isubrip.scrapers.itunes_scraper import ItunesScraper
 from isubrip.scrapers.scraper import PlaylistLoadError
@@ -70,8 +72,15 @@
         task = progress.add_task("[bold green]Fetching data from all storefronts[/bold green]",
                                  total=len(apple_tv_scraper.storefronts_mapping.keys()))
 
-        for results_list in fetch_movie_from_all_storefronts(apple_tv_scraper=apple_tv_scraper,
-                                                             itunes_scraper=itunes_scraper, url=url):
+        results_lists = EVENT_LOOP.run_until_complete(
+            fetch_movie_from_all_storefronts(
+                apple_tv_scraper=apple_tv_scraper,
+                itunes_scraper=itunes_scraper,
+                url=url,
+            ),
+        )
+
+        for results_list in results_lists:
             for result_item in results_list:
                 if result_item.movie_data is None:
                     no_store_page_items.append(result_item)
@@ -106,8 +115,8 @@
         console.print(unreleased_items_with_release_date_table)
 
 
-def fetch_movie_from_all_storefronts(apple_tv_scraper: AppleTVScraper,
-                                     itunes_scraper: ItunesScraper, url: str) -> Iterator[list[AppleTVResult]]:
+async def fetch_movie_from_all_storefronts(apple_tv_scraper: AppleTVScraper,
+                                     itunes_scraper: ItunesScraper, url: str) -> list[AppleTVResult | None]:
     regex_match = apple_tv_scraper.match_url(url=url, raise_error=True)
     regex_extracted_data = regex_match.groupdict()
     movie_id = str(regex_extracted_data["media_id"])
@@ -121,29 +130,37 @@
     with suppress(KeyError):
         storefronts.remove(original_storefront)
 
+    results: list[AppleTVResult | None] = []
+
     with suppress(Exception):
-        yield fetch_movie_from_storefront(
-            apple_tv_scraper=apple_tv_scraper,
-            itunes_scraper=itunes_scraper,
-            movie_id=movie_id,
-            storefront=original_storefront,
+        results.append(
+            await fetch_movie_from_storefront(
+                apple_tv_scraper=apple_tv_scraper,
+                itunes_scraper=itunes_scraper,
+                movie_id=movie_id,
+                storefront=original_storefront,
+            ),
         )
 
-    for storefront in storefronts:
-        yield fetch_movie_from_storefront(
+    results_coroutines = [
+        fetch_movie_from_storefront(
             apple_tv_scraper=apple_tv_scraper,
             itunes_scraper=itunes_scraper,
             movie_id=movie_id,
             storefront=storefront,
-        )
+        ) for storefront in storefronts
+    ]
 
+    results.extend(await asyncio.gather(*results_coroutines))
+    return results
 
-def fetch_movie_from_storefront(apple_tv_scraper: AppleTVScraper, itunes_scraper: ItunesScraper,
-                                movie_id: str, storefront: str) -> list[AppleTVResult] | None:
+
+async def fetch_movie_from_storefront(apple_tv_scraper: AppleTVScraper, itunes_scraper: ItunesScraper,
+                                      movie_id: str, storefront: str) -> list[AppleTVResult] | None:
     storefront_id = apple_tv_scraper.storefronts_mapping[storefront]
 
     try:
-        response = apple_tv_scraper.get_movie_data(
+        response = await apple_tv_scraper.get_movie_data(
             storefront_id=storefront_id,
             movie_id=movie_id,
         )
@@ -163,7 +180,7 @@
     for movie_data in response.media_data:
         if movie_data.playlist:
             try:
-                playlist = itunes_scraper.load_m3u8(url=movie_data.playlist)
+                playlist = itunes_scraper.load_playlist(url=movie_data.playlist)
 
             except Exception:
                 playlist = None
@@ -187,11 +204,10 @@
     if bool(loaded_playlist):
         return True
 
-    else:
-        if movie_data.preorder_availability_date:
-            return False
+    if movie_data.preorder_availability_date:
+        return False
 
-        return None
+    return None
 
 
 def create_released_results_table(itunes_scraper: ItunesScraper, result_items: list[AppleTVResult]) -> Table:
@@ -319,13 +335,12 @@
 
 def list_available_subtitles_languages(itunes_scraper: ItunesScraper,
                                        main_playlist: str | list[str]) -> list[str]:
-    main_playlist_m3u8 = itunes_scraper.load_m3u8(url=main_playlist)
+    main_playlist_m3u8 = itunes_scraper.load_playlist(url=main_playlist)
 
     if main_playlist_m3u8 is None:
         raise PlaylistLoadError("Could not load M3U8 playlist.")
 
-    playlist_results = itunes_scraper.get_media_playlists(main_playlist=main_playlist_m3u8,
-                                                          playlist_filters=itunes_scraper._subtitles_filters)
+    playlist_results = itunes_scraper.find_matching_subtitles(main_playlist=main_playlist_m3u8)
 
     return list({
         f"{result.name} ({result.language})" for result in playlist_results
Index: isubrip/__main__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nimport asyncio\r\nimport logging\r\nfrom pathlib import Path\r\nimport shutil\r\nimport sys\r\nfrom typing import List, Union\r\n\r\nimport httpx\r\n\r\nfrom isubrip.config import Config, ConfigError, ConfigSetting, SpecialConfigType\r\nfrom isubrip.constants import (\r\n    ARCHIVE_FORMAT,\r\n    DATA_FOLDER_PATH,\r\n    DEFAULT_CONFIG_PATH,\r\n    EVENT_LOOP,\r\n    LOG_FILE_NAME,\r\n    LOG_FILES_PATH,\r\n    PACKAGE_NAME,\r\n    PACKAGE_VERSION,\r\n    PREORDER_MESSAGE,\r\n    TEMP_FOLDER_PATH,\r\n    USER_CONFIG_FILE,\r\n)\r\nfrom isubrip.data_structures import (\r\n    Episode,\r\n    MediaData,\r\n    Movie,\r\n    ScrapedMediaResponse,\r\n    Season,\r\n    Series,\r\n    SubtitlesData,\r\n    SubtitlesDownloadResults,\r\n)\r\nfrom isubrip.logger import CustomLogFileFormatter, CustomStdoutFormatter, logger\r\nfrom isubrip.scrapers.scraper import PlaylistLoadError, Scraper, ScraperError, ScraperFactory, SubtitlesDownloadError\r\nfrom isubrip.subtitle_formats.webvtt import WebVTTCaptionBlock\r\nfrom isubrip.utils import (\r\n    TempDirGenerator,\r\n    download_subtitles_to_file,\r\n    format_media_description,\r\n    format_release_name,\r\n    format_subtitles_description,\r\n    generate_non_conflicting_path,\r\n    raise_for_status,\r\n    single_to_list,\r\n)\r\n\r\nLOG_ROTATION_SIZE: int | None = None\r\n\r\nBASE_CONFIG_SETTINGS = [\r\n    ConfigSetting(\r\n        key=\"check-for-updates\",\r\n        value_type=bool,\r\n        category=\"general\",\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"log_rotation_size\",\r\n        value_type=str,\r\n        category=\"general\",\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"add-release-year-to-series\",\r\n        value_type=bool,\r\n        category=\"downloads\",\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"folder\",\r\n        value_type=str,\r\n        category=\"downloads\",\r\n        required=True,\r\n        special_type=SpecialConfigType.EXISTING_FOLDER_PATH,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"languages\",\r\n        value_type=List[str],\r\n        category=\"downloads\",\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"overwrite-existing\",\r\n        value_type=bool,\r\n        category=\"downloads\",\r\n        required=True,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"zip\",\r\n        value_type=bool,\r\n        category=\"downloads\",\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"fix-rtl\",\r\n        value_type=bool,\r\n        category=\"subtitles\",\r\n        required=True,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"rtl-languages\",\r\n        value_type=List[str],\r\n        category=\"subtitles\",\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"remove-duplicates\",\r\n        value_type=bool,\r\n        category=\"subtitles\",\r\n        required=True,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"convert-to-srt\",\r\n        value_type=bool,\r\n        category=\"subtitles\",\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"subrip-alignment-conversion\",\r\n        value_type=bool,\r\n        category=(\"subtitles\", \"webvtt\"),\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"timeout\",\r\n        value_type=Union[int, float],\r\n        category=\"scrapers\",\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"user-agent\",\r\n        value_type=str,\r\n        category=\"scrapers\",\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"proxy\",\r\n        value_type=str,\r\n        category=\"scrapers\",\r\n        required=False,\r\n    ),\r\n    ConfigSetting(\r\n        key=\"verify-ssl\",\r\n        value_type=bool,\r\n        category=\"scrapers\",\r\n        required=False,\r\n    ),\r\n]\r\n\r\n\r\ndef main() -> None:\r\n    try:\r\n        # Assure at least one argument was passed\r\n        if len(sys.argv) < 2:\r\n            print_usage()\r\n            exit(0)\r\n\r\n        if not DATA_FOLDER_PATH.is_dir():\r\n            DATA_FOLDER_PATH.mkdir(parents=True)\r\n\r\n        setup_loggers(stdout_loglevel=logging.INFO,\r\n                      file_loglevel=logging.DEBUG)\r\n\r\n        cli_args = \" \".join(sys.argv[1:])\r\n        logger.debug(f\"CLI Command: {PACKAGE_NAME} {cli_args}\")\r\n        logger.debug(f\"Python version: {sys.version}\")\r\n        logger.debug(f\"Package version: {PACKAGE_VERSION}\")\r\n        logger.debug(f\"OS: {sys.platform}\")\r\n\r\n        config = generate_config()\r\n        update_settings(config)\r\n\r\n        if config.general.get(\"check-for-updates\", True):\r\n            check_for_updates(current_package_version=PACKAGE_VERSION)\r\n\r\n        urls = single_to_list(sys.argv[1:])\r\n        EVENT_LOOP.run_until_complete(download(urls=urls, config=config))\r\n\r\n    except Exception as ex:\r\n        logger.error(f\"Error: {ex}\")\r\n        logger.debug(\"Debug information:\", exc_info=True)\r\n        exit(1)\r\n\r\n    finally:\r\n        if log_rotation_size := LOG_ROTATION_SIZE:\r\n            handle_log_rotation(log_rotation_size=log_rotation_size)\r\n\r\n        # NOTE: This will only close scrapers that were initialized using the ScraperFactory.\r\n        async_cleanup_coroutines = []\r\n        for scraper in ScraperFactory.get_initialized_scrapers():\r\n            # Log scraper.requests_count\r\n            logger.debug(f\"Requests count for '{scraper.name}' scraper: {scraper.requests_count}\")\r\n            scraper.close()\r\n            async_cleanup_coroutines.append(scraper.async_close())\r\n\r\n        EVENT_LOOP.run_until_complete(asyncio.gather(*async_cleanup_coroutines))\r\n        TempDirGenerator.cleanup()\r\n\r\n\r\nasync def download(urls: list[str], config: Config) -> None:\r\n    \"\"\"\r\n    Download subtitles from a given URL.\r\n\r\n    Args:\r\n        urls (list[str]): A list of URLs to download subtitles from.\r\n        config (Config): A config to use for downloading subtitles.\r\n    \"\"\"\r\n    for url in urls:\r\n        try:\r\n            logger.info(f\"Scraping '{url}'...\")\r\n\r\n            scraper = ScraperFactory.get_scraper_instance(url=url,\r\n                                                          kwargs={\"config_data\": config.data.get(\"scrapers\")},\r\n                                                          extract_scraper_config=True)\r\n            scraper.config.check()  # Recheck config after scraper settings were loaded\r\n\r\n            try:\r\n                logger.debug(f\"Fetching '{url}'...\")\r\n                scraper_response: ScrapedMediaResponse = await scraper.get_data(url=url)\r\n\r\n            except ScraperError as e:\r\n                logger.error(f\"Error: {e}\")\r\n                logger.debug(\"Debug information:\", exc_info=True)\r\n                continue\r\n\r\n            media_data = scraper_response.media_data\r\n            playlist_scraper = ScraperFactory.get_scraper_instance(scraper_id=scraper_response.playlist_scraper,\r\n                                                                   kwargs={\"config_data\": config.data.get(\"scrapers\")},\r\n                                                                   extract_scraper_config=True)\r\n\r\n            if not media_data:\r\n                logger.error(f\"Error: No supported media was found for {url}.\")\r\n                continue\r\n\r\n            for media_item in media_data:\r\n                try:\r\n                    logger.info(f\"Found {media_item.media_type}: {format_media_description(media_data=media_item)}\")\r\n                    await download_media(scraper=playlist_scraper, media_item=media_item, config=config)\r\n\r\n                except Exception as e:\r\n                    if len(media_data) > 1:\r\n                        logger.warning(f\"Error scraping media item \"\r\n                                       f\"'{format_media_description(media_data=media_item)}': {e}\\n\"\r\n                                       f\"Skipping to next media item...\")\r\n                        logger.debug(\"Debug information:\", exc_info=True)\r\n                        continue\r\n\r\n                    raise\r\n\r\n        except Exception as e:\r\n            logger.error(f\"Error while scraping '{url}': {e}\")\r\n            logger.debug(\"Debug information:\", exc_info=True)\r\n            continue\r\n\r\n\r\nasync def download_media(scraper: Scraper, media_item: MediaData, config: Config) -> None:\r\n    \"\"\"\r\n    Download a media item.\r\n\r\n    Args:\r\n        scraper (Scraper): A Scraper object to use for downloading subtitles.\r\n        media_item (MediaData): A media data item to download subtitles for.\r\n        config (Config): A config to use for downloading subtitles.\r\n    \"\"\"\r\n    if isinstance(media_item, Series):\r\n        for season in media_item.seasons:\r\n            await download_media(scraper=scraper, media_item=season, config=config)\r\n\r\n    elif isinstance(media_item, Season):\r\n        for episode in media_item.episodes:\r\n            logger.info(f\"{format_media_description(media_data=episode, shortened=True)}:\")\r\n            await download_media_item(scraper=scraper, media_item=episode, config=config)\r\n\r\n    elif isinstance(media_item, (Movie, Episode)):\r\n        await download_media_item(scraper=scraper, media_item=media_item, config=config)\r\n\r\n\r\nasync def download_media_item(scraper: Scraper, media_item: Movie | Episode, config: Config) -> None:\r\n    if media_item.playlist:\r\n        download_subtitles_kwargs = {\r\n            \"download_path\": Path(config.downloads[\"folder\"]),\r\n            \"language_filter\": config.downloads.get(\"languages\"),\r\n            \"convert_to_srt\": config.subtitles.get(\"convert-to-srt\", False),\r\n            \"overwrite_existing\": config.downloads.get(\"overwrite-existing\", False),\r\n            \"zip_files\": config.downloads.get(\"zip\", False),\r\n        }\r\n\r\n        try:\r\n            results = await download_subtitles(scraper=scraper,\r\n                                               media_data=media_item,\r\n                                               **download_subtitles_kwargs)\r\n\r\n            success_count = len(results.successful_subtitles)\r\n            failed_count = len(results.failed_subtitles)\r\n\r\n            if success_count or failed_count:\r\n                logger.info(f\"{success_count}/{success_count + failed_count} matching subtitles \"\r\n                            f\"were successfully downloaded.\")\r\n\r\n            else:\r\n                logger.info(\"No matching subtitles were found.\")\r\n\r\n            return  # noqa: TRY300\r\n\r\n        except PlaylistLoadError:\r\n            pass\r\n\r\n    # We get here if there is no playlist, or there is one, but it failed to load\r\n    if isinstance(media_item, Movie) and media_item.preorder_availability_date:\r\n        preorder_date_str = media_item.preorder_availability_date.strftime(\"%Y-%m-%d\")\r\n        logger.info(PREORDER_MESSAGE.format(movie_name=media_item.name, scraper_name=scraper.name,\r\n                                            preorder_date=preorder_date_str))\r\n\r\n    else:\r\n        logger.error(\"No valid playlist was found.\")\r\n\r\n\r\ndef check_for_updates(current_package_version: str) -> None:\r\n    \"\"\"\r\n    Check and print if a newer version of the package is available, and log accordingly.\r\n\r\n    Args:\r\n        current_package_version (str): The current version of the package.\r\n    \"\"\"\r\n    api_url = f\"https://pypi.org/pypi/{PACKAGE_NAME}/json\"\r\n    logger.debug(\"Checking for package updates on PyPI...\")\r\n    try:\r\n        response = httpx.get(\r\n            url=api_url,\r\n            headers={\"Accept\": \"application/json\"},\r\n            timeout=5,\r\n        )\r\n        raise_for_status(response)\r\n        response_data = response.json()\r\n\r\n        pypi_latest_version = response_data[\"info\"][\"version\"]\r\n\r\n        if pypi_latest_version != current_package_version:\r\n            logger.warning(f\"You are currently using version '{current_package_version}' of '{PACKAGE_NAME}', \"\r\n                           f\"however version '{pypi_latest_version}' is available.\"\r\n                           f'\\nConsider upgrading by running \"pip install --upgrade {PACKAGE_NAME}\"\\n')\r\n\r\n        else:\r\n            logger.debug(f\"Latest version of '{PACKAGE_NAME}' ({current_package_version}) is currently installed.\")\r\n\r\n    except Exception as e:\r\n        logger.warning(f\"Update check failed: {e}\")\r\n        logger.debug(\"Debug information:\", exc_info=True)\r\n        return\r\n\r\n\r\nasync def download_subtitles(scraper: Scraper, media_data: Movie | Episode, download_path: Path,\r\n                             language_filter: list[str] | None = None, convert_to_srt: bool = False,\r\n                             overwrite_existing: bool = True, zip_files: bool = False) -> SubtitlesDownloadResults:\r\n    \"\"\"\r\n    Download subtitles for the given media data.\r\n\r\n    Args:\r\n        scraper (Scraper): A Scraper object to use for downloading subtitles.\r\n        media_data (Movie | Episode): A movie or episode data object.\r\n        download_path (Path): Path to a folder where the subtitles will be downloaded to.\r\n        language_filter (list[str] | None): List of specific languages to download subtitles for.\r\n            None for all languages (no filter). Defaults to None.\r\n        convert_to_srt (bool, optional): Whether to convert the subtitles to SRT format. Defaults to False.\r\n        overwrite_existing (bool, optional): Whether to overwrite existing subtitles. Defaults to True.\r\n        zip_files (bool, optional): Whether to unite the subtitles into a single zip file\r\n            (only if there are multiple subtitles).\r\n\r\n    Returns:\r\n        SubtitlesDownloadResults: A SubtitlesDownloadResults object containing the results of the download.\r\n    \"\"\"\r\n    temp_dir_name = generate_media_folder_name(media_data=media_data, source=scraper.abbreviation)\r\n    temp_download_path = TempDirGenerator.generate(directory_name=temp_dir_name)\r\n\r\n    successful_downloads: list[SubtitlesData] = []\r\n    failed_downloads: list[SubtitlesDownloadError] = []\r\n    temp_downloads: list[Path] = []\r\n\r\n    if not media_data.playlist:\r\n        raise PlaylistLoadError(\"No playlist was found for provided media data.\")\r\n\r\n    main_playlist = scraper.load_playlist(url=media_data.playlist)\r\n    matching_subtitles = scraper.find_matching_subtitles(main_playlist=main_playlist,  # type: ignore[var-annotated]\r\n                                                         language_filter=language_filter)\r\n\r\n    logger.debug(f\"{len(matching_subtitles)} matching subtitles were found.\")\r\n\r\n    for matching_subtitles_item in matching_subtitles:\r\n        subtitles_data = await scraper.download_subtitles(media_data=matching_subtitles_item,\r\n                                                          subrip_conversion=convert_to_srt)\r\n        language_info = format_subtitles_description(language_code=subtitles_data.language_code,\r\n                                                     language_name=subtitles_data.language_name,\r\n                                                     special_type=subtitles_data.special_type)\r\n\r\n        if isinstance(subtitles_data, SubtitlesDownloadError):\r\n            logger.warning(f\"Failed to download '{language_info}' subtitles. Skipping...\")\r\n            logger.debug(\"Debug information:\", exc_info=subtitles_data.original_exc)\r\n            failed_downloads.append(subtitles_data)\r\n            continue\r\n\r\n        try:\r\n            temp_downloads.append(download_subtitles_to_file(\r\n                media_data=media_data,\r\n                subtitles_data=subtitles_data,\r\n                output_path=temp_download_path,\r\n                source_abbreviation=scraper.abbreviation,\r\n                overwrite=overwrite_existing,\r\n            ))\r\n\r\n            logger.info(f\"'{language_info}' subtitles were successfully downloaded.\")\r\n            successful_downloads.append(subtitles_data)\r\n\r\n        except Exception as e:\r\n            logger.error(f\"Error: Failed to save '{language_info}' subtitles: {e}\")\r\n            logger.debug(\"Debug information:\", exc_info=True)\r\n            failed_downloads.append(\r\n                SubtitlesDownloadError(\r\n                    language_code=subtitles_data.language_code,\r\n                    language_name=subtitles_data.language_name,\r\n                    special_type=subtitles_data.special_type,\r\n                    original_exc=e,\r\n                ),\r\n            )\r\n\r\n    if not zip_files or len(temp_downloads) == 1:\r\n        for file_path in temp_downloads:\r\n            if overwrite_existing:\r\n                new_path = download_path / file_path.name\r\n\r\n            else:\r\n                new_path = generate_non_conflicting_path(file_path=download_path / file_path.name)\r\n\r\n            # str conversion needed only for Python <= 3.8 - https://github.com/python/cpython/issues/76870\r\n            shutil.move(src=str(file_path), dst=new_path)\r\n\r\n    elif len(temp_downloads) > 0:\r\n        archive_path = Path(shutil.make_archive(\r\n            base_name=str(temp_download_path.parent / temp_download_path.name),\r\n            format=ARCHIVE_FORMAT,\r\n            root_dir=temp_download_path,\r\n        ))\r\n\r\n        file_name = generate_media_folder_name(media_data=media_data,\r\n                                               source=scraper.abbreviation) + f\".{ARCHIVE_FORMAT}\"\r\n\r\n        if overwrite_existing:\r\n            destination_path = download_path / file_name\r\n\r\n        else:\r\n            destination_path = generate_non_conflicting_path(file_path=download_path / file_name)\r\n\r\n        shutil.move(src=str(archive_path), dst=destination_path)\r\n\r\n    return SubtitlesDownloadResults(\r\n        media_data=media_data,\r\n        successful_subtitles=successful_downloads,\r\n        failed_subtitles=failed_downloads,\r\n        is_zip=zip_files,\r\n    )\r\n\r\n\r\ndef handle_log_rotation(log_rotation_size: int) -> None:\r\n    \"\"\"\r\n    Handle log rotation and remove old log files if needed.\r\n\r\n    Args:\r\n        log_rotation_size (int): Maximum amount of log files to keep.\r\n    \"\"\"\r\n    sorted_log_files = sorted(LOG_FILES_PATH.glob(\"*.log\"), key=lambda file: file.stat().st_mtime, reverse=True)\r\n\r\n    if len(sorted_log_files) > log_rotation_size:\r\n        for log_file in sorted_log_files[log_rotation_size:]:\r\n            log_file.unlink()\r\n\r\n\r\ndef generate_config() -> Config:\r\n    \"\"\"\r\n    Generate a config object using config files, and validate it.\r\n\r\n    Returns:\r\n        Config: A config object.\r\n\r\n    Raises:\r\n        ConfigException: If there is a general config error.\r\n        MissingConfigValue: If a required config value is missing.\r\n        InvalidConfigValue: If a config value is invalid.\r\n    \"\"\"\r\n    if not DEFAULT_CONFIG_PATH.is_file():\r\n        raise ConfigError(\"Default config file could not be found.\")\r\n\r\n    config = Config(config_settings=BASE_CONFIG_SETTINGS)\r\n\r\n    logger.debug(\"Loading default config data...\")\r\n\r\n    with DEFAULT_CONFIG_PATH.open('r') as data:\r\n        config.loads(config_data=data.read(), check_config=True)\r\n\r\n    logger.debug(\"Default config data loaded and validated successfully.\")\r\n\r\n    # If logs folder doesn't exist, create it (also handles data folder)\r\n    if not DATA_FOLDER_PATH.is_dir():\r\n        logger.debug(f\"'{DATA_FOLDER_PATH}' directory could not be found and will be created.\")\r\n        DATA_FOLDER_PATH.mkdir(parents=True, exist_ok=True)\r\n        LOG_FILES_PATH.mkdir()\r\n\r\n    else:\r\n        if not LOG_FILES_PATH.is_dir():\r\n            logger.debug(f\"'{LOG_FILES_PATH}' directory could not be found and will be created.\")\r\n            LOG_FILES_PATH.mkdir()\r\n\r\n        # If a user config file exists, add it to config_files\r\n        if USER_CONFIG_FILE.is_file():\r\n            logger.info(f\"User config file detected at '{USER_CONFIG_FILE}' and will be used.\")\r\n\r\n            with USER_CONFIG_FILE.open('r') as data:\r\n                config.loads(config_data=data.read(), check_config=True)\r\n\r\n            logger.debug(\"User config file loaded and validated successfully.\")\r\n\r\n    return config\r\n\r\n\r\ndef generate_media_folder_name(media_data: Movie | Episode, source: str | None = None) -> str:\r\n    \"\"\"\r\n    Generate a folder name for media data.\r\n\r\n    Args:\r\n        media_data (Movie | Episode): A movie or episode data object.\r\n        source (str | None, optional): Abbreviation of the source to use for file names. Defaults to None.\r\n\r\n    Returns:\r\n        str: A folder name for the media data.\r\n    \"\"\"\r\n    if isinstance(media_data, Movie):\r\n        return format_release_name(\r\n            title=media_data.name,\r\n            release_date=media_data.release_date,\r\n            media_source=source,\r\n        )\r\n\r\n    # elif isinstance(media_data, Episode):\r\n    return format_release_name(\r\n        title=media_data.series_name,\r\n        season_number=media_data.season_number,\r\n        media_source=source,\r\n    )\r\n\r\n\r\ndef generate_temp_media_path(media_data: Movie | Episode, source: str | None = None) -> Path:\r\n    \"\"\"\r\n    Generate a temporary directory for downloading media data.\r\n\r\n    Args:\r\n        media_data (Movie | Episode): A movie or episode data object.\r\n        source (str | None, optional): Abbreviation of the source to use for file names. Defaults to None.\r\n\r\n    Returns:\r\n        Path: A path to the temporary folder.\r\n    \"\"\"\r\n    temp_folder_name = generate_media_folder_name(media_data=media_data, source=source)\r\n    path = generate_non_conflicting_path(file_path=TEMP_FOLDER_PATH / temp_folder_name, has_extension=False)\r\n\r\n    return TempDirGenerator.generate(directory_name=path.name)\r\n\r\n\r\ndef update_settings(config: Config) -> None:\r\n    \"\"\"\r\n    Update settings according to config.\r\n\r\n    Args:\r\n        config (Config): An instance of a config to set settings according to.\r\n    \"\"\"\r\n    Scraper.subtitles_fix_rtl = config.subtitles[\"fix-rtl\"]\r\n    Scraper.subtitles_remove_duplicates = config.subtitles[\"remove-duplicates\"]\r\n    Scraper.default_timeout = config.scrapers.get(\"timeout\", 10)\r\n    Scraper.default_user_agent = config.scrapers.get(\"user-agent\", httpx._client.USER_AGENT)  # noqa: SLF001\r\n    Scraper.default_proxy = config.scrapers.get(\"proxy\")\r\n    Scraper.default_verify_ssl = config.scrapers.get(\"verify-ssl\", True)\r\n\r\n    if not Scraper.default_verify_ssl:\r\n        import urllib3\r\n        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\r\n\r\n    WebVTTCaptionBlock.subrip_alignment_conversion = (\r\n        config.subtitles.get(\"webvtt\", {}).get(\"subrip-alignment-conversion\", False)\r\n    )\r\n\r\n    if log_rotation := config.general.get(\"log-rotation-size\"):\r\n        global LOG_ROTATION_SIZE\r\n        LOG_ROTATION_SIZE = log_rotation\r\n\r\n\r\ndef print_usage() -> None:\r\n    \"\"\"Print usage information.\"\"\"\r\n    logger.info(f\"Usage: {PACKAGE_NAME} <iTunes movie URL> [iTunes movie URL...]\")\r\n\r\n\r\ndef setup_loggers(stdout_loglevel: int, file_loglevel: int) -> None:\r\n    \"\"\"\r\n    Configure loggers.\r\n\r\n    Args:\r\n        stdout_loglevel (int): Log level for STDOUT logger.\r\n        file_loglevel (int): Log level for logfile logger.\r\n    \"\"\"\r\n    logger.setLevel(logging.DEBUG)\r\n\r\n    # Setup STDOUT logger\r\n    stdout_handler = logging.StreamHandler(sys.stdout)\r\n    stdout_handler.setLevel(stdout_loglevel)\r\n    stdout_handler.setFormatter(CustomStdoutFormatter())\r\n    logger.addHandler(stdout_handler)\r\n\r\n    # Setup logfile logger\r\n    if not LOG_FILES_PATH.is_dir():\r\n        logger.debug(\"Logs directory could not be found and will be created.\")\r\n        LOG_FILES_PATH.mkdir()\r\n\r\n    logfile_path = generate_non_conflicting_path(file_path=LOG_FILES_PATH / LOG_FILE_NAME)\r\n    logfile_handler = logging.FileHandler(filename=logfile_path, encoding=\"utf-8\")\r\n    logfile_handler.setLevel(file_loglevel)\r\n    logfile_handler.setFormatter(CustomLogFileFormatter())\r\n    logger.debug(f\"Log file location: '{logfile_path}'\")\r\n    logger.addHandler(logfile_handler)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/__main__.py b/isubrip/__main__.py
--- a/isubrip/__main__.py	(revision d0959cc740ebbc24f4887e2926c52a39d34dda02)
+++ b/isubrip/__main__.py	(date 1722287621421)
@@ -160,7 +160,7 @@
         if not DATA_FOLDER_PATH.is_dir():
             DATA_FOLDER_PATH.mkdir(parents=True)
 
-        setup_loggers(stdout_loglevel=logging.INFO,
+        setup_loggers(stdout_loglevel=logging.DEBUG,
                       file_loglevel=logging.DEBUG)
 
         cli_args = " ".join(sys.argv[1:])
@@ -627,4 +627,8 @@
 
 
 if __name__ == "__main__":
+    from timeit import default_timer as timer
+    start_time = timer()
     main()
+    end_time = timer()
+    print(f"Elapsed time: {end_time - start_time:.2f} seconds.")
diff --git a/isubrip/parsers/__init__.py b/isubrip/parsers/__init__.py
new file mode 100644
