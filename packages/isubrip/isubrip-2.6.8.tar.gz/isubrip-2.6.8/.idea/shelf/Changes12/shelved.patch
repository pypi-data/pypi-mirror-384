Index: isubrip/scrapers/scraper.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nimport abc\r\nimport asyncio\r\nimport importlib\r\nimport inspect\r\nimport os\r\nimport re\r\nimport sys\r\nfrom abc import abstractmethod, ABC\r\nfrom enum import Enum\r\nfrom glob import glob\r\nfrom pathlib import Path\r\nfrom typing import Dict, Iterator, List, Optional, Tuple, Type, Union, NamedTuple, TypeVar\r\n\r\nimport aiohttp\r\nimport m3u8\r\nimport requests\r\nfrom m3u8 import M3U8, Media\r\n\r\nfrom isubrip.config import Config, ConfigSetting\r\nfrom isubrip.constants import PACKAGE_NAME\r\nfrom isubrip.utils import merge_dict_values\r\nfrom isubrip.data_structures import EpisodeData, MovieData, SeasonData, SeriesData, SubtitlesData, SubtitlesFormat, SubtitlesType\r\nfrom isubrip.subtitle_formats.subtitles import Subtitles\r\n\r\n\r\nScraper = TypeVar('Scraper', bound='ScraperBase')\r\n\r\n\r\nclass PlaylistData(NamedTuple):\r\n    \"\"\"A named tuple containing main_playlist data.\"\"\"\r\n    url: str\r\n    id: Optional[str] = None\r\n\r\n\r\nclass ScraperMeta(abc.ABCMeta):\r\n    \"\"\"\r\n    A metaclass for scrapers.\r\n    This metaclass ensures only one instance of each scraper is created (singleton).\r\n    \"\"\"\r\n    _instances: Dict[str, ScraperBase] = {}  # TODO REFACTOR: Set checkpoint here and assure this works (only one instance of each scraper is generated for multiple links)\r\n\r\n    def __call__(cls, *args, **kwargs) -> ScraperBase:\r\n        if cls._instances.get(cls.__name__) is None:\r\n            cls._instances[cls.__name__] = super().__call__(*args, **kwargs)\r\n\r\n        return cls._instances[cls.__name__]\r\n\r\n\r\nclass ScraperBase(ABC, metaclass=ScraperMeta):  # TODO REFACTOR: Move to ScaperMeta? Assure everything works beforehand and then test if that breaks stuff\r\n    \"\"\"A base class for scrapers.\"\"\"\r\n    _config_category: str = \"main_playlist-filters\"\r\n\r\n    default_user_agent = None\r\n\r\n    is_movie_scraper: bool = False\r\n    is_series_scraper: bool = False\r\n\r\n    # --- Class Attributes ---\r\n    # TODO REFACTOR: Somehow assert these are set in subclasses\r\n    subtitles_class: Type[Subtitles]\r\n    \"\"\"The scraper's subtitles class.\"\"\"\r\n\r\n    service_abbreviation: str\r\n    \"\"\"A short abbreviation of the service name.\"\"\"\r\n\r\n    service_name: str\r\n    \"\"\"The name of the service.\"\"\"\r\n\r\n    url_regex: Union[str, List[str]]\r\n    \"\"\"A RegEx pattern to find URLs matching the service.\"\"\"\r\n\r\n    def __init__(self, config_data: Optional[dict] = None):\r\n        self._session = requests.Session()\r\n        self._session.headers.update({\"User-Agent\": self.default_user_agent})\r\n        self.config: Optional[Config] = Config(config_data=config_data)\r\n        self.default_filters: dict = config_data if config_data else {}\r\n\r\n    @classmethod\r\n    def check_url_match(cls, url: str) -> bool:\r\n        \"\"\"\r\n        Checks if a URL matches scraper's url regex.\r\n\r\n        Args:\r\n            url: The URL to check.\r\n\r\n        Returns:\r\n            bool: True if URL matches, False otherwise.\r\n        \"\"\"\r\n        if not cls.url_regex:\r\n            return False\r\n\r\n        if isinstance(cls.url_regex, str):\r\n            return re.fullmatch(cls.url_regex, url) is not None\r\n\r\n        elif isinstance(cls.url_regex, (list, tuple)):\r\n            for regex in cls.url_regex:\r\n                if re.fullmatch(regex, url) is not None:\r\n                    return True\r\n\r\n            return False\r\n\r\n    def __enter__(self):\r\n        return self\r\n\r\n    def __exit__(self, exc_type, exc_val, exc_tb):\r\n        self.close()\r\n\r\n    def close(self):\r\n        self._session.close()\r\n\r\n    @abstractmethod\r\n    def get_data(self, url: str) -> Union[MovieData, SeriesData, SeasonData, EpisodeData]:\r\n        \"\"\"\r\n        Scrape media information about the media on a URL.\r\n\r\n        Args:\r\n            url: The URL to get information about.\r\n\r\n        Returns:\r\n            Union[MovieData, SeriesData, SubtitlesData, PlaylistData]: Information about the media.\r\n        \"\"\"\r\n        pass\r\n\r\n    @abstractmethod\r\n    def get_subtitles(self, main_playlist: M3U8, playlist_filters: Union[Dict[str, Union[str, List[str]]], None] = None,\r\n                      subrip_conversion: bool = False) -> Iterator[SubtitlesData]:\r\n        \"\"\"\r\n        Find and yield subtitles data from a main_playlist.\r\n        \"\"\"\r\n        pass\r\n\r\n\r\nclass MovieScraper(ScraperBase, ABC, metaclass=ScraperMeta):\r\n    \"\"\"\r\n    A base class for movie scrapers.\r\n    \"\"\"\r\n    is_movie_scraper: bool = True\r\n\r\n    @abstractmethod\r\n    def _get_movie_data(self, url: str) -> MovieData:\r\n        pass\r\n\r\n\r\nclass SeriesScraper(ScraperBase, ABC, metaclass=ScraperMeta):\r\n    \"\"\"\r\n    A base class for TV scrapers.\r\n    \"\"\"\r\n    is_series_scraper: bool = True\r\n\r\n    @abstractmethod\r\n    def _get_series_data(self, url: str) -> SeriesData:\r\n        pass\r\n\r\n\r\nclass M3U8Scraper(ScraperBase, ABC, metaclass=ScraperMeta):\r\n    \"\"\"A base class for M3U8 scrapers.\"\"\"\r\n    class M3U8Attribute(Enum):\r\n        \"\"\"\r\n        An enum representing all possible M3U8 attributes.\r\n        Names / Keys represent M3U8 attributes (should be converted to lowercase),\r\n        and values represent the name of the key for config usage.\r\n        \"\"\"\r\n        ASSOC_LANGUAGE = \"assoc-language\"\r\n        AUTOSELECT = \"autoselect\"\r\n        CHARACTERISTICS = \"characteristics\"\r\n        CHANNELS = \"channels\"\r\n        DEFAULT = \"default\"\r\n        FORCED = \"forced\"\r\n        GROUP_ID = \"group-id\"\r\n        INSTREAM_ID = \"instream-id\"\r\n        LANGUAGE = \"language\"\r\n        NAME = \"name\"\r\n        STABLE_RENDITION_ID = \"stable-rendition-id\"\r\n        TYPE = \"type\"\r\n\r\n    def __init__(self, config_data: Optional[dict] = None):\r\n        super().__init__(config_data)\r\n        # TODO REFACTOR: Move async stuff to a different class, and than inherient from it if async is needed? (in case non-m3u8 scrapers need it as well)\r\n        self.async_session = aiohttp.ClientSession()\r\n        self.async_session.headers.update({\"User-Agent\": self.default_user_agent})\r\n\r\n        # Add M3U8 filters settings\r\n        self.config.add_settings([\r\n            ConfigSetting(\r\n                category=ScraperBase._config_category,\r\n                key=m3u8_attribute.value,\r\n                type=Union[str, List[str]],\r\n                required=False,\r\n            ) for m3u8_attribute in self.M3U8Attribute],\r\n            check_config=False)\r\n\r\n    def close(self):\r\n        asyncio.get_event_loop().run_in_executor(None, self._async_close)\r\n        super().close()\r\n\r\n    async def _async_close(self):\r\n        await self.async_session.close()\r\n\r\n    def _download_segments_async(self, segments: m3u8.SegmentList[m3u8.Segment]) -> List[bytes]:\r\n        \"\"\"\r\n        Download M3U8 segments asynchronously.\r\n\r\n        Args:\r\n            segments (m3u8.SegmentList[m3u8.Segment]): List of segments to download.\r\n\r\n        Returns:\r\n            List[bytes]: List of downloaded segments.\r\n        \"\"\"\r\n        loop = asyncio.get_event_loop()\r\n        async_tasks = [loop.create_task(self._download_segment_async(segment.absolute_uri)) for segment in segments]\r\n        segments_bytes = loop.run_until_complete(asyncio.gather(*async_tasks))\r\n\r\n        return list(segments_bytes)\r\n\r\n    async def _download_segment_async(self, url: str) -> bytes:\r\n        \"\"\"\r\n        Download an M3U8 segment asynchronously.\r\n\r\n        Args:\r\n            url (str): URL of the segment to download.\r\n\r\n        Returns:\r\n            bytes: Downloaded segment.\r\n        \"\"\"\r\n        async with self._get_async_session().get(url) as response:\r\n            return await response.read()\r\n\r\n    def _get_async_session(self) -> aiohttp.ClientSession:\r\n        \"\"\"\r\n        Get an asynchronous session (singleton).\r\n\r\n        Returns:\r\n            aiohttp.ClientSession: An asynchronous session.\r\n        \"\"\"\r\n        if not hasattr(self, \"_async_session\"):\r\n            self._async_session = aiohttp.ClientSession()\r\n\r\n        self._async_session._default_headers = self._session.headers\r\n        return self._async_session\r\n\r\n    @staticmethod\r\n    def detect_subtitles_type(subtitles_media: m3u8.Media) -> Optional[SubtitlesType]:\r\n        \"\"\"\r\n        Detect the type of subtitles from a m3u8 Media object.\r\n\r\n        Args:\r\n            subtitles_media (m3u8.Media): Subtitles Media object to detect the type of.\r\n\r\n        Returns:\r\n            Optional[SubtitlesType]: The type of the subtitles, None for regular subtitles.\r\n        \"\"\"\r\n        if subtitles_media.forced == \"YES\":\r\n            return SubtitlesType.FORCED\r\n\r\n        elif subtitles_media.characteristics is not None and \"public.accessibility\" in subtitles_media.characteristics:\r\n            return SubtitlesType.CC\r\n\r\n        return None\r\n\r\n    def get_media_playlists(self, main_playlist: m3u8.M3U8,\r\n                            playlist_filters: Union[Dict[str, Union[str, List[str], Tuple[str]]], None] = None,\r\n                            include_default_filters: bool = True) -> Iterator[Media]:\r\n        \"\"\"\r\n        Find and yield playlists of media within an M3U8 main_playlist using optional filters.\r\n\r\n        Args:\r\n            main_playlist (m3u8.M3U8): an M3U8 object of the main main_playlist.\r\n            playlist_filters (dict, optional): A dictionary of filters to use when searching for subtitles.\r\n                Will be added to filters set by the config (unless `include_default_filters` is set to false).\r\n                Defaults to None.\r\n            include_default_filters (bool, optional): Whether to include the default filters set by the config or not.\r\n                Defaults to True.\r\n\r\n        Yields:\r\n            SubtitlesData: A NamedTuple with a matching main_playlist, and it's metadata:\r\n            Language Code, Language Name, SubtitlesType, Playlist URL.\r\n        \"\"\"\r\n        default_playlist_filters: Optional[dict] = self.default_filters.get(\"playlist-filters\")\r\n\r\n        if include_default_filters and default_playlist_filters:\r\n            if not playlist_filters:\r\n                playlist_filters = default_playlist_filters\r\n\r\n            else:\r\n                playlist_filters = merge_dict_values(default_playlist_filters, playlist_filters)\r\n\r\n        for media in main_playlist.media:\r\n            if playlist_filters is None:\r\n                yield media\r\n\r\n            is_valid = True\r\n\r\n            for filter_name, filter_value in playlist_filters.items():\r\n                try:\r\n                    filter_name = M3U8Scraper.M3U8Attribute(filter_name)\r\n\r\n                except ValueError:\r\n                    continue\r\n                    # TODO: Add logger warning \"invalid main_playlist filter, skipping...\"\r\n\r\n                attribute_value = getattr(media, filter_name.name.lower(), None)\r\n\r\n                if attribute_value is None:\r\n                    is_valid = False\r\n                    break\r\n\r\n                if isinstance(filter_value, (list, tuple)) and \\\r\n                        attribute_value.casefold() not in (x.casefold() for x in filter_value):\r\n                    is_valid = False\r\n                    break\r\n\r\n                elif isinstance(filter_value, str) and filter_value.casefold() != attribute_value.casefold():\r\n                    is_valid = False\r\n                    break\r\n\r\n            if not is_valid:\r\n                continue\r\n\r\n            yield media\r\n\r\n    def get_subtitles(self, main_playlist: m3u8.M3U8,\r\n                      playlist_filters: Union[Dict[str, Union[str, List[str]]], None] = None,\r\n                      subrip_conversion: bool = False) -> Iterator[SubtitlesData]:\r\n        \"\"\"\r\n        Find and yield subtitles for a movie using optional filters.\r\n\r\n        Args:\r\n            main_playlist (m3u8.M3U8): an M3U8 object of the main playlist.\r\n            playlist_filters (dict, optional): A dictionary of filters to use when searching for subtitles.\r\n                Will be added to filters set by the config. Defaults to None.\r\n            subrip_conversion (bool, optional): Whether to convert and return the subtitles as an SRT file or not.\r\n\r\n        Yields:\r\n            SubtitlesData: A SubtitlesData NamedTuple with a matching playlist, and it's metadata.\r\n        \"\"\"\r\n        if playlist_filters is None:\r\n            playlist_filters = {}\r\n\r\n        playlist_filters[\"type\"] = \"SUBTITLES\"\r\n\r\n        for matched_media in self.get_media_playlists(main_playlist=main_playlist, playlist_filters=playlist_filters):\r\n            # TODO: Add logger info \"Found subtitles for language: {matched_media.name}\"\r\n            try:\r\n                matched_media_playlist = m3u8.load(matched_media.absolute_uri)\r\n\r\n            except (ValueError, IOError) as e:\r\n                pass  # TODO: Add logger warning\r\n                continue\r\n\r\n            subtitles = self.subtitles_class(language_code=matched_media.language, language_name=matched_media.name)\r\n\r\n            for segment in self._download_segments_async(matched_media_playlist.segments):\r\n                subtitles.append_subtitles(subtitles.loads(segment.decode(\"utf-8\")))\r\n\r\n            yield SubtitlesData(\r\n                language_code=matched_media.language,\r\n                language_name=matched_media.name,\r\n                format=SubtitlesFormat.SUBRIP if subrip_conversion else SubtitlesFormat.WEBVTT,\r\n                content=subtitles.to_srt().dump() if subrip_conversion else subtitles.dump(),\r\n                special_type=self.detect_subtitles_type(matched_media),\r\n            )\r\n\r\n\r\nclass ScraperException(Exception):\r\n    pass\r\n\r\n\r\nclass ScraperFactory:\r\n    def __init__(self):\r\n        self._scrapers: list[Type[Scraper]] = [scraper_class for scraper_class in self.get_scraper_classes()]\r\n        self._scrapers_cache: dict[Type[Scraper], Scraper] = {}\r\n\r\n    def get_initialized_scrapers(self) -> list[Scraper]:\r\n        \"\"\"\r\n        Get a list of all previously initialized scrapers.\r\n\r\n        Returns:\r\n            list[Scraper]: A list of initialized scrapers.\r\n        \"\"\"\r\n        return list(self._scrapers_cache.values())\r\n\r\n    @staticmethod\r\n    def get_scraper_classes() -> Iterator[Type[Scraper]]:\r\n        \"\"\"\r\n        Find and yield all scraper classes.\r\n\r\n        Yield:\r\n            Type[Scraper]: A scraper class.\r\n        \"\"\"\r\n        scraper_modules_paths = glob(os.path.dirname(__file__) + \"/*_scraper.py\")\r\n\r\n        for scraper_module_path in scraper_modules_paths:\r\n            sys.path.append(scraper_module_path)\r\n\r\n            module = importlib.import_module(f\"{PACKAGE_NAME}.scrapers.{Path(scraper_module_path).stem}\")\r\n\r\n            # find Scraper subclasses\r\n            for name, obj in inspect.getmembers(module,\r\n                                                predicate=lambda x: inspect.isclass(x) and issubclass(x, ScraperBase)):\r\n                if inspect.isabstract(obj):\r\n                    continue\r\n\r\n                yield obj\r\n\r\n    def get_matching_scraper(self, url: str, scrapers_config_data: dict = {}) -> Scraper:\r\n        \"\"\"\r\n        Find and return a scraper that matches the given URL.\r\n\r\n        Args:\r\n            url (str): The URL to check.\r\n            scrapers_config_data (dict, optional): A dictionary containing scrapers config data to use\r\n                when creating a new scraper.\r\n\r\n        Returns:\r\n            Optional[Scraper]: An instance of the scraper that matches the given URL, or None if no match was found.\r\n        \"\"\"\r\n        for scraper in self._scrapers:\r\n            if scraper.check_url_match(url):\r\n                if scraper not in self._scrapers_cache:\r\n                    self._scrapers_cache[scraper] = scraper(config_data=scrapers_config_data.get(scraper.service_name.lower()))\r\n\r\n                return self._scrapers_cache[scraper]\r\n\r\n        raise ScraperException(f\"No scraper found for URL: {url}\")\r\n\r\n\r\ndef get_matching_scraper(url: str, config_data: Optional[dict] = None) -> Optional[Scraper]:\r\n    \"\"\"\r\n\r\n    Args:\r\n        url (str): The URL to check.\r\n        config_data (dict, optional): A dictionary of config data to use when creating a new scraper.\r\n\r\n    Returns:\r\n        Optional[Scraper]: An instance of the scraper that matches the given URL, or None if no match was found.\r\n    \"\"\"\r\n    scraper_modules_paths = glob(os.path.dirname(__file__) + \"/*_scraper.py\")\r\n\r\n    for scraper_module_path in scraper_modules_paths:\r\n        sys.path.append(scraper_module_path)\r\n\r\n        module = importlib.import_module(f\"scrapers.{Path(scraper_module_path).stem}\")\r\n\r\n        # find Scraper subclasses\r\n        for name, obj in inspect.getmembers(module,\r\n                                            predicate=lambda x: inspect.isclass(x) and issubclass(x, ScraperBase)):\r\n            if obj.check_url_match(url):\r\n                return obj(config_data=config_data)\r\n\r\n            else:\r\n                pass  # TODO: Add logger debug message \"Scraper {obj} does not match URL {url}\"\r\n    return None\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/scrapers/scraper.py b/isubrip/scrapers/scraper.py
--- a/isubrip/scrapers/scraper.py	(revision 5c6b27d57567a311e8396a879a5a25dd3914d881)
+++ b/isubrip/scrapers/scraper.py	(date 1678482372879)
@@ -192,13 +192,13 @@
             check_config=False)
 
     def close(self):
-        asyncio.get_event_loop().run_in_executor(None, self._async_close)
-        super().close()
+        async_loop = asyncio.get_event_loop()
+        async_loop.run_until_complete(asyncio.wait([self._async_close()]))
 
     async def _async_close(self):
         await self.async_session.close()
 
-    def _download_segments_async(self, segments: m3u8.SegmentList[m3u8.Segment]) -> List[bytes]:
+    async def _download_segments_async(self, segments: m3u8.SegmentList[m3u8.Segment]) -> List[bytes]:
         """
         Download M3U8 segments asynchronously.
 
@@ -208,11 +208,7 @@
         Returns:
             List[bytes]: List of downloaded segments.
         """
-        loop = asyncio.get_event_loop()
-        async_tasks = [loop.create_task(self._download_segment_async(segment.absolute_uri)) for segment in segments]
-        segments_bytes = loop.run_until_complete(asyncio.gather(*async_tasks))
-
-        return list(segments_bytes)
+        return [await self._download_segment_async(segment.absolute_uri) for segment in segments]
 
     async def _download_segment_async(self, url: str) -> bytes:
         """
@@ -224,22 +220,9 @@
         Returns:
             bytes: Downloaded segment.
         """
-        async with self._get_async_session().get(url) as response:
+        async with self.async_session.get(url) as response:
             return await response.read()
 
-    def _get_async_session(self) -> aiohttp.ClientSession:
-        """
-        Get an asynchronous session (singleton).
-
-        Returns:
-            aiohttp.ClientSession: An asynchronous session.
-        """
-        if not hasattr(self, "_async_session"):
-            self._async_session = aiohttp.ClientSession()
-
-        self._async_session._default_headers = self._session.headers
-        return self._async_session
-
     @staticmethod
     def detect_subtitles_type(subtitles_media: m3u8.Media) -> Optional[SubtitlesType]:
         """
Index: isubrip/__main__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import atexit\r\nimport shutil\r\nimport sys\r\n\r\nfrom xml.etree import ElementTree\r\n\r\nimport m3u8\r\nimport requests\r\n\r\nfrom isubrip.config import Config\r\nfrom isubrip.constants import *\r\nfrom isubrip.exceptions import ConfigError\r\nfrom isubrip.scrapers.scraper import M3U8Scraper, MovieData, ScraperBase, ScraperFactory\r\nfrom isubrip.subtitle_formats.subtitles import Subtitles\r\nfrom isubrip.utils import download_subtitles, generate_non_conflicting_path, generate_release_name\r\n\r\n# TODO REFACTOR: Check behavior when an AppleTV link contains multiple playlists following the deprecation of the `merge-playlists` option.\r\n# https://tv.apple.com/ca/movie/high-school-musical-3-senior-year/umc.cmc.1dnklw3pn12eioitik6rds3w4\r\ndef main():\r\n    # Load default and user (if it exists) config files\r\n    config_files = [DEFAULT_CONFIG_PATH]\r\n\r\n    # If data folder doesn't exist, create it\r\n    if not DATA_FOLDER_PATH.is_dir():\r\n        DATA_FOLDER_PATH.mkdir(parents=True, exist_ok=True)\r\n\r\n    else:\r\n        # If a user config file exists, add it\r\n        if USER_CONFIG_FILE.is_file():\r\n            config_files.append(USER_CONFIG_FILE)\r\n\r\n    # Check if at least one argument was passed, exit if not\r\n    if len(sys.argv) < 2:\r\n        print_usage()\r\n        exit(1)\r\n\r\n    # Exit if default config file is missing for some reason\r\n    if not DEFAULT_CONFIG_PATH.is_file():\r\n        print(\"Error: Default config file could not be found.\")\r\n        exit(1)\r\n\r\n    config = Config(config_settings=DEFAULT_CONFIG_SETTINGS)\r\n\r\n    try:\r\n        for file_path in config_files:\r\n            with open(file_path, 'r') as data:\r\n                config.loads(config_data=data.read(), check_config=True)\r\n\r\n        config.check()\r\n\r\n    except (ConfigError, FileNotFoundError) as e:\r\n        print(f\"Error: {e}\")\r\n        exit(1)\r\n\r\n    # Set `Subtitles` settings from config\r\n    Subtitles.remove_duplicates = config.subtitles[\"remove-duplicates\"]\r\n    Subtitles.fix_rtl = config.subtitles[\"fix-rtl\"]\r\n    Subtitles.rtl_languages = config.subtitles[\"rtl-languages\"]\r\n\r\n    download_path: Path\r\n    download_to_temp: bool\r\n\r\n    # Set download path to temp folder \"zip\" setting is used\r\n    if config.downloads[\"zip\"]:\r\n        download_path = TEMP_FOLDER_PATH\r\n        download_to_temp = True\r\n\r\n        # Remove temp folder if it already exists\r\n        if TEMP_FOLDER_PATH.is_dir():\r\n            shutil.rmtree(TEMP_FOLDER_PATH)\r\n\r\n        TEMP_FOLDER_PATH.mkdir(parents=True, exist_ok=True)\r\n        atexit.register(shutil.rmtree, TEMP_FOLDER_PATH)\r\n\r\n    else:\r\n        download_path = Path(config.downloads[\"folder\"])\r\n        download_to_temp = False\r\n\r\n    if config.scrapers[\"user-agent\"]:\r\n        ScraperBase.default_user_agent = config.scrapers[\"user-agent\"]\r\n\r\n    if config.general[\"check-for-updates\"]:\r\n        check_for_updates()\r\n\r\n    scraper_factory = ScraperFactory()\r\n\r\n    for idx, url in enumerate(sys.argv[1:]):\r\n        if idx > 0:\r\n            print(\"\\n--------------------------------------------------\\n\")  # Print between different movies\r\n\r\n        print(f\"Scraping {url}...\")\r\n\r\n        try:\r\n            with scraper_factory.get_matching_scraper(url, config.data.get(\"scrapers\", {})) as scraper:\r\n                scraper.config.check()\r\n\r\n                movie_data: MovieData = scraper.get_data(url)\r\n                has_multiple_playlists = len(movie_data.playlist) > 1\r\n\r\n                print(f\"Found movie: {movie_data.name}\")\r\n\r\n                if has_multiple_playlists:\r\n                    print(f\"{len(movie_data.playlist)} matching playlists were found.\\n\")\r\n\r\n                if not movie_data.playlist:\r\n                    print(f\"Error: No valid playlist were found.\")\r\n                    continue\r\n\r\n                downloaded_subtitles_paths = []\r\n                subtitles_count = 0\r\n\r\n                # Create temp folder if needed\r\n                if download_to_temp:\r\n                    temp_folder_name = generate_release_name(\r\n                        title=movie_data.name,\r\n                        release_year=movie_data.release_year,\r\n                        media_source=scraper.service_abbreviation\r\n                    )\r\n                    movie_download_path = download_path / temp_folder_name\r\n                    movie_download_path.mkdir(exist_ok=True)\r\n\r\n                else:\r\n                    movie_download_path = download_path\r\n\r\n                for idy, playlist_data in enumerate(movie_data.playlist):\r\n                    # Print empty line between different playlists\r\n                    if idy > 0:\r\n                        print()\r\n\r\n                    if has_multiple_playlists:\r\n                        print(f\"id{playlist_data.id}:\")\r\n                        playlist_download_path = movie_download_path / f\"id{playlist_data.id}\"\r\n                        playlist_download_path.mkdir(exist_ok=True)\r\n\r\n                    else:\r\n                        playlist_download_path = movie_download_path\r\n\r\n                    m3u8_playlist: m3u8.M3U8 = m3u8.load(playlist_data.url)\r\n                    playlist_subtitles_count = 0\r\n                    subtitles_media_filter = None\r\n\r\n                    if config.downloads.get(\"languages\"):\r\n                        subtitles_media_filter = \\\r\n                            {M3U8Scraper.M3U8Attribute.LANGUAGE.value: config.downloads[\"languages\"]}\r\n\r\n                    subtitles: m3u8.Media\r\n                    for subtitles_data in \\\r\n                            scraper.get_subtitles(main_playlist=m3u8_playlist,\r\n                                                  playlist_filters=subtitles_media_filter,\r\n                                                  subrip_conversion=config.subtitles.get(\"convert-to-srt\", False)):\r\n                        playlist_subtitles_count += 1\r\n\r\n                        downloaded_subtitles = download_subtitles(\r\n                            scraper=scraper,\r\n                            media_data=movie_data,\r\n                            subtitles_data=subtitles_data,\r\n                            output_path=playlist_download_path,\r\n                            overwrite=config.downloads[\"overwrite-existing\"],\r\n                            add_release_year_to_series=config.downloads[\"add-release-year-to-series\"],\r\n                        )\r\n\r\n                        # Assure subtitles downloaded successfully\r\n                        if downloaded_subtitles.is_file():\r\n                            downloaded_subtitles_paths.append(downloaded_subtitles)\r\n                            print(f\"Downloaded \\\"{subtitles_data.language_name}\\\" ({subtitles_data.language_code}) \"\r\n                                  f\"subtitles successfully.\")\r\n\r\n                        else:\r\n                            pass  # TODO: Add logger warning\r\n\r\n                    if has_multiple_playlists:\r\n                        print(f\"{playlist_subtitles_count} subtitles were downloaded.\")\r\n\r\n                        # Remove main_playlist folder if it's empty\r\n                        if playlist_subtitles_count == 0:\r\n                            playlist_download_path.rmdir()\r\n\r\n                    subtitles_count += playlist_subtitles_count\r\n\r\n                # If files were downloaded to a temp folder (\"zip\" option was used)\r\n                # TODO: If files were downloaded only from a single playlist, remove the \"idX\" folder\r\n                if download_to_temp:\r\n                    if len(downloaded_subtitles_paths) == 1:\r\n                        shutil.copy(downloaded_subtitles_paths[0], config.downloads[\"folder\"])\r\n\r\n                    # If multiple files were downloaded, create a zip file\r\n                    elif len(downloaded_subtitles_paths) > 1:\r\n                        print(f\"\\nCreating zip archive...\")\r\n\r\n                        archive_path = Path(shutil.make_archive(\r\n                            base_name=str(download_path / movie_download_path),\r\n                            format=\"zip\",\r\n                            root_dir=movie_download_path,\r\n                        ))\r\n\r\n                        destination_path = Path(config.downloads[\"folder\"]) / archive_path.name\r\n                        destination_path = generate_non_conflicting_path(destination_path)\r\n\r\n                        shutil.copy(archive_path, destination_path)\r\n\r\n                    # Remove temp dir\r\n                    shutil.rmtree(movie_download_path)\r\n                    atexit.unregister(shutil.rmtree)\r\n\r\n                # Add playlists count only if it's more than 1\r\n                playlists_message = f\"from {len(movie_data.playlist)} playlists \" \\\r\n                    if len(movie_data.playlist) > 0 else \"\"\r\n\r\n                print(f\"\\n{len(downloaded_subtitles_paths)}/{subtitles_count} matching subtitles \",\r\n                      f\"for \\\"{movie_data.name}\\\" were downloaded {playlists_message}\",\r\n                      f\"to {Path(config.downloads['folder']).absolute()}\\\".\", sep=\"\")\r\n\r\n        except Exception as e:\r\n            raise e  # TODO: Remove\r\n            # print(f\"Error: {e}\")\r\n\r\n\r\ndef check_for_updates() -> None:\r\n    \"\"\"Check and print if a newer version of the package is available.\"\"\"\r\n    # If anything breaks, just skip update check\r\n    try:\r\n        current_version = sys.modules[PACKAGE_NAME].__version__\r\n\r\n        response = requests.get(PYPI_RSS_URL).text\r\n        xml_data = ElementTree.fromstring(response)\r\n        latest_version = xml_data.find(\"channel/item/title\").text\r\n\r\n        # If the latest PyPI release is different from current one, print a message\r\n        if latest_version != current_version:\r\n            print(f\"Note: You are currently using version {current_version} of {PACKAGE_NAME}, however version {latest_version} is available.\",\r\n                  f\"\\nConsider upgrading by running \\\"python3 -m pip install --upgrade {PACKAGE_NAME}\\\"\\n\")\r\n\r\n        else:\r\n            pass  # TODO: Add logger info\r\n\r\n    except Exception:\r\n        # TODO: Add logger warning\r\n        return\r\n\r\n\r\ndef print_usage() -> None:\r\n    \"\"\"Print usage information.\"\"\"\r\n    print(f\"Usage: {PACKAGE_NAME} <iTunes movie URL> [iTunes movie URL...]\")\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/__main__.py b/isubrip/__main__.py
--- a/isubrip/__main__.py	(revision 5c6b27d57567a311e8396a879a5a25dd3914d881)
+++ b/isubrip/__main__.py	(date 1678482372893)
@@ -16,7 +16,9 @@
 
 # TODO REFACTOR: Check behavior when an AppleTV link contains multiple playlists following the deprecation of the `merge-playlists` option.
 # https://tv.apple.com/ca/movie/high-school-musical-3-senior-year/umc.cmc.1dnklw3pn12eioitik6rds3w4
-def main():
+
+
+async def main():
     # Load default and user (if it exists) config files
     config_files = [DEFAULT_CONFIG_PATH]
 
@@ -91,129 +93,133 @@
         print(f"Scraping {url}...")
 
         try:
-            with scraper_factory.get_matching_scraper(url, config.data.get("scrapers", {})) as scraper:
-                scraper.config.check()
+            scraper = scraper_factory.get_matching_scraper(url, config.data.get("scrapers", {}))
+
+            scraper.config.check()
 
-                movie_data: MovieData = scraper.get_data(url)
-                has_multiple_playlists = len(movie_data.playlist) > 1
+            movie_data: MovieData = scraper.get_data(url)
+            has_multiple_playlists = len(movie_data.playlist) > 1
 
-                print(f"Found movie: {movie_data.name}")
+            print(f"Found movie: {movie_data.name}")
 
-                if has_multiple_playlists:
-                    print(f"{len(movie_data.playlist)} matching playlists were found.\n")
+            if has_multiple_playlists:
+                print(f"{len(movie_data.playlist)} matching playlists were found.\n")
 
-                if not movie_data.playlist:
-                    print(f"Error: No valid playlist were found.")
-                    continue
+            if not movie_data.playlist:
+                print(f"Error: No valid playlist were found.")
+                continue
 
-                downloaded_subtitles_paths = []
-                subtitles_count = 0
+            downloaded_subtitles_paths = []
+            subtitles_count = 0
 
-                # Create temp folder if needed
-                if download_to_temp:
-                    temp_folder_name = generate_release_name(
-                        title=movie_data.name,
-                        release_year=movie_data.release_year,
-                        media_source=scraper.service_abbreviation
-                    )
-                    movie_download_path = download_path / temp_folder_name
-                    movie_download_path.mkdir(exist_ok=True)
+            # Create temp folder if needed
+            if download_to_temp:
+                temp_folder_name = generate_release_name(
+                    title=movie_data.name,
+                    release_year=movie_data.release_year,
+                    media_source=scraper.service_abbreviation
+                )
+                movie_download_path = download_path / temp_folder_name
+                movie_download_path.mkdir(exist_ok=True)
 
-                else:
-                    movie_download_path = download_path
+            else:
+                movie_download_path = download_path
 
-                for idy, playlist_data in enumerate(movie_data.playlist):
-                    # Print empty line between different playlists
-                    if idy > 0:
-                        print()
+            for idy, playlist_data in enumerate(movie_data.playlist):
+                # Print empty line between different playlists
+                if idy > 0:
+                    print()
 
-                    if has_multiple_playlists:
-                        print(f"id{playlist_data.id}:")
-                        playlist_download_path = movie_download_path / f"id{playlist_data.id}"
-                        playlist_download_path.mkdir(exist_ok=True)
+                if has_multiple_playlists:
+                    print(f"id{playlist_data.id}:")
+                    playlist_download_path = movie_download_path / f"id{playlist_data.id}"
+                    playlist_download_path.mkdir(exist_ok=True)
 
-                    else:
-                        playlist_download_path = movie_download_path
+                else:
+                    playlist_download_path = movie_download_path
 
-                    m3u8_playlist: m3u8.M3U8 = m3u8.load(playlist_data.url)
-                    playlist_subtitles_count = 0
-                    subtitles_media_filter = None
+                m3u8_playlist: m3u8.M3U8 = m3u8.load(playlist_data.url)
+                playlist_subtitles_count = 0
+                subtitles_media_filter = None
 
-                    if config.downloads.get("languages"):
-                        subtitles_media_filter = \
-                            {M3U8Scraper.M3U8Attribute.LANGUAGE.value: config.downloads["languages"]}
+                if config.downloads.get("languages"):
+                    subtitles_media_filter = \
+                        {M3U8Scraper.M3U8Attribute.LANGUAGE.value: config.downloads["languages"]}
 
-                    subtitles: m3u8.Media
-                    for subtitles_data in \
-                            scraper.get_subtitles(main_playlist=m3u8_playlist,
-                                                  playlist_filters=subtitles_media_filter,
-                                                  subrip_conversion=config.subtitles.get("convert-to-srt", False)):
-                        playlist_subtitles_count += 1
+                subtitles: m3u8.Media
+                for subtitles_data in \
+                        scraper.get_subtitles(main_playlist=m3u8_playlist,
+                                              playlist_filters=subtitles_media_filter,
+                                              subrip_conversion=config.subtitles.get("convert-to-srt", False)):
+                    playlist_subtitles_count += 1
 
-                        downloaded_subtitles = download_subtitles(
-                            scraper=scraper,
-                            media_data=movie_data,
-                            subtitles_data=subtitles_data,
-                            output_path=playlist_download_path,
-                            overwrite=config.downloads["overwrite-existing"],
-                            add_release_year_to_series=config.downloads["add-release-year-to-series"],
-                        )
+                    downloaded_subtitles = download_subtitles(
+                        scraper=scraper,
+                        media_data=movie_data,
+                        subtitles_data=subtitles_data,
+                        output_path=playlist_download_path,
+                        overwrite=config.downloads["overwrite-existing"],
+                        add_release_year_to_series=config.downloads["add-release-year-to-series"],
+                    )
 
-                        # Assure subtitles downloaded successfully
-                        if downloaded_subtitles.is_file():
-                            downloaded_subtitles_paths.append(downloaded_subtitles)
-                            print(f"Downloaded \"{subtitles_data.language_name}\" ({subtitles_data.language_code}) "
-                                  f"subtitles successfully.")
+                    # Assure subtitles downloaded successfully
+                    if downloaded_subtitles.is_file():
+                        downloaded_subtitles_paths.append(downloaded_subtitles)
+                        print(f"Downloaded \"{subtitles_data.language_name}\" ({subtitles_data.language_code}) "
+                              f"subtitles successfully.")
 
-                        else:
-                            pass  # TODO: Add logger warning
+                    else:
+                        pass  # TODO: Add logger warning
 
-                    if has_multiple_playlists:
-                        print(f"{playlist_subtitles_count} subtitles were downloaded.")
+                if has_multiple_playlists:
+                    print(f"{playlist_subtitles_count} subtitles were downloaded.")
 
-                        # Remove main_playlist folder if it's empty
-                        if playlist_subtitles_count == 0:
-                            playlist_download_path.rmdir()
+                    # Remove main_playlist folder if it's empty
+                    if playlist_subtitles_count == 0:
+                        playlist_download_path.rmdir()
 
-                    subtitles_count += playlist_subtitles_count
+                subtitles_count += playlist_subtitles_count
 
-                # If files were downloaded to a temp folder ("zip" option was used)
-                # TODO: If files were downloaded only from a single playlist, remove the "idX" folder
-                if download_to_temp:
-                    if len(downloaded_subtitles_paths) == 1:
-                        shutil.copy(downloaded_subtitles_paths[0], config.downloads["folder"])
+            # If files were downloaded to a temp folder ("zip" option was used)
+            # TODO: If files were downloaded only from a single playlist, remove the "idX" folder
+            if download_to_temp:
+                if len(downloaded_subtitles_paths) == 1:
+                    shutil.copy(downloaded_subtitles_paths[0], config.downloads["folder"])
 
-                    # If multiple files were downloaded, create a zip file
-                    elif len(downloaded_subtitles_paths) > 1:
-                        print(f"\nCreating zip archive...")
+                # If multiple files were downloaded, create a zip file
+                elif len(downloaded_subtitles_paths) > 1:
+                    print(f"\nCreating zip archive...")
 
-                        archive_path = Path(shutil.make_archive(
-                            base_name=str(download_path / movie_download_path),
-                            format="zip",
-                            root_dir=movie_download_path,
-                        ))
+                    archive_path = Path(shutil.make_archive(
+                        base_name=str(download_path / movie_download_path),
+                        format="zip",
+                        root_dir=movie_download_path,
+                    ))
 
-                        destination_path = Path(config.downloads["folder"]) / archive_path.name
-                        destination_path = generate_non_conflicting_path(destination_path)
+                    destination_path = Path(config.downloads["folder"]) / archive_path.name
+                    destination_path = generate_non_conflicting_path(destination_path)
 
-                        shutil.copy(archive_path, destination_path)
+                    shutil.copy(archive_path, destination_path)
 
-                    # Remove temp dir
-                    shutil.rmtree(movie_download_path)
-                    atexit.unregister(shutil.rmtree)
+                # Remove temp dir
+                atexit.unregister(shutil.rmtree)
+                shutil.rmtree(movie_download_path)
 
-                # Add playlists count only if it's more than 1
-                playlists_message = f"from {len(movie_data.playlist)} playlists " \
-                    if len(movie_data.playlist) > 0 else ""
+            # Add playlists count only if it's more than 1
+            playlists_message = f"from {len(movie_data.playlist)} playlists " \
+                if len(movie_data.playlist) > 0 else ""
 
-                print(f"\n{len(downloaded_subtitles_paths)}/{subtitles_count} matching subtitles ",
-                      f"for \"{movie_data.name}\" were downloaded {playlists_message}",
-                      f"to {Path(config.downloads['folder']).absolute()}\".", sep="")
+            print(f"\n{len(downloaded_subtitles_paths)}/{subtitles_count} matching subtitles ",
+                  f"for \"{movie_data.name}\" were downloaded {playlists_message}",
+                  f"to {Path(config.downloads['folder']).absolute()}\".", sep="")
 
         except Exception as e:
             raise e  # TODO: Remove
             # print(f"Error: {e}")
 
+    for scraper in scraper_factory.get_initialized_scrapers():
+        scraper.close()
+
 
 def check_for_updates() -> None:
     """Check and print if a newer version of the package is available."""
