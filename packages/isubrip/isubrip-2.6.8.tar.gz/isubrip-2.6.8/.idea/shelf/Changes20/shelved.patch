Index: requirements.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>aiohttp==3.8.1\r\nbeautifulsoup4==4.11.1\r\nlxml==4.9.1\r\nm3u8==3.2.0\r\nmergedeep==1.3.4\r\nrequests==2.28.1\r\ntomli==2.0.1\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/requirements.txt b/requirements.txt
--- a/requirements.txt	(revision 2e359abca21aea0e94ef93086b16e7f7b0714786)
+++ b/requirements.txt	(date 1682711765158)
@@ -1,6 +1,4 @@
 aiohttp==3.8.1
-beautifulsoup4==4.11.1
-lxml==4.9.1
 m3u8==3.2.0
 mergedeep==1.3.4
 requests==2.28.1
Index: README.md
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># iSubRip\r\nA Python package for scraping and downloading subtitles from iTunes movie pages.  \r\nLatest version: 2.3.3 ([changelog](https://github.com/MichaelYochpaz/iSubRip/blob/main/CHANGELOG.md))  \r\n\r\n<br/>\r\n  \r\n[![PyPI - Version](https://img.shields.io/pypi/v/isubrip)](https://python.org/pypi/isubrip)\r\n[![PyPI - Monthly Downloads](https://pepy.tech/badge/isubrip/month)](https://python.org/pypi/isubrip)\r\n[![PyPI - Total Downloads](https://pepy.tech/badge/isubrip)](https://python.org/pypi/isubrip)\r\n[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/isubrip)](https://python.org/pypi/isubrip)\r\n[![GitHub - License](https://img.shields.io/github/license/MichaelYochpaz/iSubRip)](https://github.com/MichaelYochpaz/iSubRip/blob/main/LICENSE)\r\n[![GitHub - issues](https://img.shields.io/github/issues/MichaelYochpaz/iSubRip)](https://github.com/MichaelYochpaz/iSubRip/issues)\r\n[![GitHub - Repo stars](https://img.shields.io/github/stars/MichaelYochpaz/iSubRip.svg?color=yellow)](https://github.com/MichaelYochpaz/iSubRip)\r\n\r\n<p align=\"center\">\r\n  <a href=\"#\"><img src=\"https://user-images.githubusercontent.com/8832013/194750946-8b4d4d4e-0230-4653-bede-3ec191df161b.gif\" width=\"800\"></a>\r\n</p>\r\n\r\n\r\n##  Requirements\r\n* Python 3.8+\r\n\r\n##  Installation\r\n### PyPI (Recommended)\r\n```\r\npython3 -m pip install isubrip\r\n```\r\n\r\n### Git Source Code\r\n```\r\npython3 -m pip install -e git+https://github.com/MichaelYochpaz/iSubRip.git#egg=isubrip\r\n```\r\n\r\n## Usage\r\n```\r\nisubrip <iTunes movie URL> [iTunes movie URL...]\r\n```  \r\n\r\n## Configuration\r\nIt's possible to configure different options and enable / disable different features using a [TOML](https://toml.io) config file.   \r\nA config file will be looked for in one of the following paths according to OS: \r\n\r\n**Windows**: `%USERPROFILE%\\.isubrip\\config.toml`  \r\n**Linux / macOS**: `$HOME/.isubrip/config.toml`  \r\n\r\n### Examples:\r\n**Windows**: `C:\\Users\\Michael\\.isubrip\\config.toml`  \r\n**Linux**: `/home/Michael/.isubrip/config.toml`  \r\n**macOS**: `/Users/Michael/.isubrip/config.toml`  \r\n\r\n---\r\n\r\n### Example Config:\r\n```toml\r\n[downloads]\r\nfolder = \"C:\\\\iTunes-Subtitles\"\r\nformat = \"srt\"\r\nlanguages = [\"en-US\"]\r\nzip = false\r\n\r\n[subtitles]\r\nfix-rtl = true\r\n```\r\n\r\nA complete config with all the available options and explanations for each configuration can be found [here](https://github.com/MichaelYochpaz/iSubRip/blob/main/config.toml)\r\n\r\n### Notes\r\n* All settings are optional. Not specifying a setting will result in using the default value.\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/README.md b/README.md
--- a/README.md	(revision 2e359abca21aea0e94ef93086b16e7f7b0714786)
+++ b/README.md	(date 1682712337296)
@@ -1,5 +1,5 @@
 # iSubRip
-A Python package for scraping and downloading subtitles from iTunes movie pages.  
+A Python package for scraping and downloading subtitles from AppleTV / iTunes movie pages.  
 Latest version: 2.3.3 ([changelog](https://github.com/MichaelYochpaz/iSubRip/blob/main/CHANGELOG.md))  
 
 <br/>
Index: setup.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nimport re\r\nfrom pathlib import Path\r\nfrom setuptools import setup\r\n\r\nCURRENT_PATH = Path(__file__).parent.absolute()\r\nPACKAGE_NAME = \"isubrip\"\r\nREADME_PATH = CURRENT_PATH / \"README.md\"\r\n\r\n\r\ndef get_version() -> str:\r\n    init_file_path = CURRENT_PATH / PACKAGE_NAME / \"__init__.py\"\r\n    version_regex = r\"^__version__ = ['\\\"](\\d+(?:\\.\\d+){2,3})['\\\"]\"\r\n\r\n    if not init_file_path.exists():\r\n        raise FileNotFoundError(f\"{init_file_path} file is missing.\")\r\n\r\n    with open(init_file_path, 'r') as fp:\r\n        file_data = fp.read()\r\n\r\n    for line in file_data.splitlines():\r\n        if line.startswith(\"__version__\"):\r\n            if result := re.match(version_regex, line).group(1):\r\n                return result\r\n\r\n            else:\r\n                raise RuntimeError('__version__ assignment does not match expected regex.')\r\n\r\n    raise RuntimeError('Unable to find version string.')\r\n\r\n\r\ndef get_long_description() -> str:\r\n    readme_path = CURRENT_PATH / \"README.md\"\r\n\r\n    if not readme_path.exists():\r\n        raise FileNotFoundError(f\"{readme_path} file is missing.\")\r\n\r\n    with open(readme_path, \"r\") as file:\r\n        return file.read()\r\n\r\n\r\nsetup(\r\n    name=PACKAGE_NAME,\r\n    version=get_version(),\r\n    author=\"Michael Yochpaz\",\r\n    license=\"MIT\",\r\n    license_files=('LICENSE',),\r\n    description=\"A Python package for scraping and downloading subtitles from iTunes movie pages.\",\r\n    long_description=get_long_description(),\r\n    long_description_content_type=\"text/markdown\",\r\n    url=\"https://github.com/MichaelYochpaz/iSubRip\",\r\n\r\n    project_urls={\r\n        \"Bug Reports\": \"https://github.com/MichaelYochpaz/iSubRip/issues\",\r\n        \"Source\": \"https://github.com/MichaelYochpaz/iSubRip\"\r\n    },\r\n\r\n    classifiers=[\r\n        \"Development Status :: 5 - Production/Stable\",\r\n        \"Intended Audience :: End Users/Desktop\",\r\n        \"Intended Audience :: Developers\",\r\n        \"Topic :: Utilities\",\r\n        \"License :: OSI Approved :: MIT License\",\r\n        \"Programming Language :: Python :: 3.8\",\r\n        \"Programming Language :: Python :: 3.9\",\r\n        \"Programming Language :: Python :: 3.10\"\r\n    ],\r\n\r\n    keywords=[\"iTunes\", \"movies\", \"subtitles\", \"scrape\", \"scraper\", \"download\", \"m3u8\"],\r\n    packages=[PACKAGE_NAME],\r\n    install_requires=[\"aiohttp\", \"beautifulsoup4\", \"lxml\", \"m3u8\", \"mergedeep\", \"requests\", \"tomli\"],\r\n    package_data={PACKAGE_NAME: [\"resources/*\"]},\r\n    python_requires=\">=3.8\",\r\n    entry_points={\r\n        \"console_scripts\":\r\n            [f\"{PACKAGE_NAME} = {PACKAGE_NAME}.__main__:main\"]\r\n    },\r\n)\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/setup.py b/setup.py
--- a/setup.py	(revision 2e359abca21aea0e94ef93086b16e7f7b0714786)
+++ b/setup.py	(date 1682711765163)
@@ -69,7 +69,7 @@
 
     keywords=["iTunes", "movies", "subtitles", "scrape", "scraper", "download", "m3u8"],
     packages=[PACKAGE_NAME],
-    install_requires=["aiohttp", "beautifulsoup4", "lxml", "m3u8", "mergedeep", "requests", "tomli"],
+    install_requires=["aiohttp", "m3u8", "mergedeep", "requests", "tomli"],
     package_data={PACKAGE_NAME: ["resources/*"]},
     python_requires=">=3.8",
     entry_points={
Index: isubrip/utils.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nimport os\r\nimport re\r\nimport sys\r\nfrom abc import ABCMeta\r\n\r\nfrom datetime import time\r\nfrom os import PathLike\r\nfrom pathlib import Path\r\nfrom typing import Any, Iterable, Union, get_args, get_origin\r\n\r\nfrom isubrip.data_structures import EpisodeData, MovieData, SubtitlesData, SubtitlesFormat, SubtitlesType\r\n\r\n\r\nclass SingletonMeta(ABCMeta):\r\n    \"\"\"\r\n    A metaclass that implements the Singleton pattern.\r\n    When a class using this metaclass is initialized, it will return the same instance every time.\r\n    \"\"\"\r\n    _instances: dict[object, object] = {}\r\n\r\n    def __call__(cls, *args, **kwargs) -> object:\r\n        if cls._instances.get(cls) is None:\r\n            cls._instances[cls] = super().__call__(*args, **kwargs)\r\n\r\n        return cls._instances[cls]\r\n\r\n\r\ndef check_type(value: Any, type_) -> bool:\r\n    \"\"\"\r\n    Check if a value is of a certain type.\r\n    Works with parameterized generics.\r\n\r\n    Args:\r\n        value: Value to check.\r\n        type_: Type to check against.\r\n\r\n    Returns:\r\n        bool: True if the value is of the specified type, False otherwise.\r\n    \"\"\"\r\n    origin = get_origin(type_)\r\n    args = get_args(type_)\r\n\r\n    if origin is Union:\r\n        return any(check_type(value, union_sub_type) for union_sub_type in args)\r\n\r\n    elif origin is tuple:\r\n        if args[-1] is Ellipsis:\r\n            # Example: (int, str, ...)\r\n            args_len = len(args)\r\n\r\n            return check_type(value[:args_len - 1], tuple(args[:-1])) and \\\r\n                all(check_type(item, args[-2]) for item in value[args_len - 1:])\r\n\r\n        else:\r\n            return isinstance(value, tuple) and \\\r\n                len(value) == len(args) and \\\r\n                all(check_type(item, item_type) for item, item_type in zip(value, args))\r\n\r\n    elif origin is list:\r\n        return isinstance(value, list) and \\\r\n            all(check_type(item, args[0]) for item in value)\r\n\r\n    elif origin is dict:\r\n        return isinstance(value, dict) and \\\r\n            all(check_type(k, args[0]) and check_type(v, args[1]) for k, v in value.items())\r\n\r\n    return isinstance(value, type_)\r\n\r\n\r\ndef download_subtitles_to_file(media_data: MovieData | EpisodeData, subtitles_data: SubtitlesData,\r\n                               output_path: str | PathLike, overwrite: bool = False) -> Path:\r\n    \"\"\"\r\n    Download subtitles to a file.\r\n\r\n    Args:\r\n        media_data (MovieData | EpisodeData): An object containing media data.\r\n        subtitles_data (SubtitlesData): A SubtitlesData object containing subtitles data.\r\n        output_path (str | PathLike): Path to the output folder.\r\n        overwrite (bool, optional): Whether to overwrite files if they already exist. Defaults to True.\r\n\r\n    Returns:\r\n        Path: Path to the downloaded subtitles file.\r\n\r\n    Raises:\r\n        ValueError: If the path in `output_path` does not exist.\r\n    \"\"\"\r\n    if not os.path.isdir(output_path):\r\n        raise ValueError(f'Invalid path: {output_path}')\r\n\r\n    if isinstance(media_data, MovieData):\r\n        file_name = generate_release_name(title=media_data.name,\r\n                                          release_year=media_data.release_year,\r\n                                          media_source=media_data.source.abbreviation,\r\n                                          language_code=subtitles_data.language_code,\r\n                                          subtitles_type=subtitles_data.special_type,\r\n                                          file_format=subtitles_data.subtitles_format)\r\n    elif isinstance(media_data, EpisodeData):\r\n        file_name = generate_release_name(title=media_data.name,\r\n                                          release_year=media_data.release_year,\r\n                                          season_number=media_data.season_number,\r\n                                          episode_number=media_data.episode_number,\r\n                                          episode_name=media_data.episode_name,\r\n                                          media_source=media_data.source.abbreviation,\r\n                                          language_code=subtitles_data.language_code,\r\n                                          subtitles_type=subtitles_data.special_type,\r\n                                          file_format=subtitles_data.subtitles_format)\r\n\r\n    else:\r\n        raise TypeError(f'This function only supports MovieData and EpisodeData objects. Got {type(media_data)}.')\r\n\r\n    file_path = Path(output_path) / file_name\r\n\r\n    if file_path.exists() and not overwrite:\r\n        file_path = generate_non_conflicting_path(file_path)\r\n\r\n    with open(file_path, 'wb') as f:\r\n        f.write(subtitles_data.content)\r\n\r\n    return file_path\r\n\r\n\r\ndef generate_non_conflicting_path(file_path: str | Path, has_extension: bool = True) -> Path:\r\n    \"\"\"\r\n    Generate a non-conflicting path for a file.\r\n    If the file already exists, a number will be added to the end of the file name.\r\n\r\n    Args:\r\n        file_path (str | Path): Path to a file.\r\n        has_extension (bool, optional): Whether the name of the file includes file extension. Defaults to True.\r\n\r\n    Returns:\r\n        Path: A non-conflicting file path.\r\n    \"\"\"\r\n    if isinstance(file_path, str):\r\n        file_path = Path(file_path)\r\n\r\n    if not file_path.exists():\r\n        return file_path\r\n\r\n    i = 1\r\n    while True:\r\n        if has_extension:\r\n            new_file_path = file_path.parent / f'{file_path.stem}-{i}{file_path.suffix}'\r\n\r\n        else:\r\n            new_file_path = file_path.parent / f'{file_path}-{i}'\r\n\r\n        if not new_file_path.exists():\r\n            return new_file_path\r\n\r\n        i += 1\r\n\r\n\r\ndef generate_release_name(title: str,\r\n                          release_year: int | None = None,\r\n                          season_number: int | None = None,\r\n                          episode_number: int | None = None,\r\n                          episode_name: str | None = None,\r\n                          media_source: str | None = None,\r\n                          source_type: str | None = \"WEB\",\r\n                          additional_info: str | list[str] | None = None,\r\n                          language_code: str | None = None,\r\n                          subtitles_type: SubtitlesType | None = None,\r\n                          file_format: str | SubtitlesFormat | None = None) -> str:\r\n    \"\"\"\r\n    Generate a release name.\r\n\r\n    Args:\r\n        title (str): Media title.\r\n        release_year (int | None, optional): Release year. Defaults to None.\r\n        season_number (int | None, optional): Season number. Defaults to None.\r\n        episode_number (int | None, optional): Episode number. Defaults to None.\r\n        episode_name (str | None, optional): Episode name. Defaults to None.\r\n        media_source (str | None, optional): Media source name (full or abbreviation). Defaults to None.\r\n        source_type(str | None, optional): General source type (WEB, BluRay, etc.). Defaults to None.\r\n        additional_info (list[str] | str | None, optional): Additional info to add to the file name. Defaults to None.\r\n        language_code (str | None, optional): Language code. Defaults to None.\r\n        subtitles_type (SubtitlesType | None, optional): Subtitles type. Defaults to None.\r\n        file_format (SubtitlesFormat | str | None, optional): File format to use.  Defaults to None.\r\n\r\n    Returns:\r\n        str: Generated file name.\r\n    \"\"\"\r\n    file_name = standardize_title(title)\r\n\r\n    if release_year is not None and str(release_year) not in file_name:\r\n        file_name += f'.{release_year}'\r\n\r\n    if season_number is not None:\r\n        file_name += f'.S{season_number:02}'\r\n\r\n    if episode_number is not None:\r\n        file_name += f'.E{episode_number:02}'\r\n\r\n    if episode_name is not None:\r\n        file_name += f'.{standardize_title(episode_name)}'\r\n\r\n    if media_source is not None:\r\n        file_name += f'.{media_source}'\r\n\r\n    if source_type is not None:\r\n        file_name += f'.{source_type}'\r\n\r\n    if additional_info is not None:\r\n        if isinstance(additional_info, (list, tuple)):\r\n            additional_info = '.'.join(additional_info)\r\n\r\n        file_name += f'.{additional_info}'\r\n\r\n    if language_code is not None:\r\n        file_name += f'.{language_code}'\r\n\r\n    if subtitles_type is not None:\r\n        file_name += f'.{subtitles_type.value.lower()}'\r\n\r\n    if file_format is not None:\r\n        if isinstance(file_format, SubtitlesFormat):\r\n            file_format = file_format.value.file_extension\r\n\r\n        file_name += f'.{file_format}'\r\n\r\n    return file_name\r\n\r\n\r\ndef merge_dict_values(*dictionaries: dict) -> dict:\r\n    \"\"\"\r\n    A function for merging the values of multiple dictionaries using the same keys.\r\n    If a key already exists, the value will be added to a list of values mapped to that key.\r\n\r\n    Args:\r\n        *dictionaries (dict): Dictionaries to merge.\r\n\r\n    Returns:\r\n        dict: A merged dictionary.\r\n    \"\"\"\r\n    result: dict = {}\r\n\r\n    for dict_ in dictionaries:\r\n        for key, value in dict_.items():\r\n            if key in result:\r\n                if isinstance(result[key], list) and value not in result[key]:\r\n                    result[key].append(value)\r\n\r\n                elif isinstance(result[key], tuple) and value not in result[key]:\r\n                    result[key] = result[key] + (value,)\r\n\r\n                elif value != result[key]:\r\n                    result[key] = [result[key], value]\r\n            else:\r\n                result[key] = value\r\n\r\n    return result\r\n\r\n\r\ndef single_to_list(obj) -> list:\r\n    \"\"\"\r\n    Convert a single non-iterable object to a list.\r\n    If None is passed, an empty list will be returned.\r\n\r\n    Args:\r\n        obj: Object to convert.\r\n\r\n    Returns:\r\n        list: A list containing the object.\r\n            If the object is already an iterable, it will be converted to a list.\r\n    \"\"\"\r\n    if isinstance(obj, Iterable) and not isinstance(obj, str):\r\n        return list(obj)\r\n\r\n    elif obj is None:\r\n        return []\r\n\r\n    return [obj]\r\n\r\n\r\ndef split_subtitles_timestamp(timestamp: str) -> tuple[time, time]:\r\n    \"\"\"\r\n    Split a subtitles timestamp into start and end.\r\n\r\n    Args:\r\n        timestamp (str): A subtitles timestamp. For example: \"00:00:00.000 --> 00:00:00.000\"\r\n\r\n    Returns:\r\n        tuple(time, time): A tuple containing start and end times as a datetime object.\r\n    \"\"\"\r\n    # Support ',' character in timestamp's milliseconds (used in SubRip format).\r\n    timestamp = timestamp.replace(',', '.')\r\n\r\n    start_time, end_time = timestamp.split(\" --> \")\r\n    return time.fromisoformat(start_time), time.fromisoformat(end_time)\r\n\r\n\r\ndef standardize_title(title: str) -> str:\r\n    \"\"\"\r\n    Format movie title to a standardized title that can be used as a file name.\r\n\r\n    Args:\r\n        title (str): A movie title.\r\n\r\n    Returns:\r\n        str: The movie title, in a file-name-friendly format.\r\n    \"\"\"\r\n    windows_reserved_file_names = (\"CON\", \"PRN\", \"AUX\", \"NUL\", \"COM1\", \"COM2\", \"COM3\", \"COM4\",\r\n                                   \"COM5\", \"COM6\", \"COM7\", \"COM8\", \"COM9\", \"LPT1\", \"LPT2\",\r\n                                   \"LPT3\", \"LPT4\", \"LPT5\", \"LPT6\", \"LPT7\", \"LPT8\", \"LPT9\")\r\n\r\n    title = title.strip()\r\n\r\n    # Replacements will be done in the same order of this list\r\n    replacement_pairs = [\r\n        (': ', '.'),\r\n        (':', '.'),\r\n        (' - ', '-'),\r\n        (', ', '.'),\r\n        ('. ', '.'),\r\n        (' ', '.'),\r\n        ('|', '.'),\r\n        ('/', '.'),\r\n        ('<', ''),\r\n        ('>', ''),\r\n        ('(', ''),\r\n        (')', ''),\r\n        ('\"', ''),\r\n        ('?', ''),\r\n        ('*', ''),\r\n    ]\r\n\r\n    for pair in replacement_pairs:\r\n        title = title.replace(pair[0], pair[1])\r\n\r\n    title = re.sub(r\"\\.+\", \".\", title)  # Replace multiple dots with a single dot\r\n\r\n    # If running on Windows, rename Windows reserved names to allow file creation\r\n    if sys.platform == 'win32':\r\n        split_title = title.split('.')\r\n\r\n        if split_title[0].upper() in windows_reserved_file_names:\r\n            if len(split_title) > 1:\r\n                return split_title[0] + split_title[1] + '.'.join(split_title[2:])\r\n\r\n            elif len(split_title) == 1:\r\n                return \"_\" + title\r\n\r\n    return title\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/utils.py b/isubrip/utils.py
--- a/isubrip/utils.py	(revision 2e359abca21aea0e94ef93086b16e7f7b0714786)
+++ b/isubrip/utils.py	(date 1682714047325)
@@ -185,7 +185,7 @@
     """
     file_name = standardize_title(title)
 
-    if release_year is not None and str(release_year) not in file_name:
+    if release_year is not None:
         file_name += f'.{release_year}'
 
     if season_number is not None:
Index: isubrip/scrapers/appletv_scraper.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nfrom isubrip.data_structures import MovieData\r\nfrom isubrip.scrapers.itunes_scraper import iTunesScraper\r\nfrom isubrip.scrapers.scraper import M3U8Scraper, MediaSourceData, MovieScraper, ScraperException, \\\r\n    SeriesScraper, ScraperFactory\r\nfrom isubrip.subtitle_formats.webvtt import WebVTTSubtitles\r\n\r\n\r\nclass AppleTVPlusScraper(M3U8Scraper, MovieScraper, SeriesScraper):\r\n    \"\"\"\r\n    An Apple TV+ movie data scraper.\r\n    Also works for Apple TV items that include iTunes links (by redirecting to the iTunes scraper).\r\n    \"\"\"\r\n    url_regex = r\"(https?://tv\\.apple\\.com/([a-z]{2})/(movie|show)/(?:[\\w\\-%]+/)?(umc\\.cmc\\.[a-z\\d]{24,25}))(?:\\?.*)?\"\r\n    service_data = MediaSourceData(id=\"appletvplus\", name=\"Apple TV+\", abbreviation=\"ATVP\")\r\n    subtitles_class = WebVTTSubtitles\r\n    is_movie_scraper = True\r\n    is_series_scraper = True\r\n    uses_scrapers = [iTunesScraper]\r\n\r\n    _api_url = \"https://tv.apple.com/api/uts/v3/movies/\"\r\n    _api_request_params = {\r\n        \"utscf\": \"OjAAAAAAAAA~\",\r\n        \"utsk\": \"6e3013c6d6fae3c2::::::235656c069bb0efb\",\r\n        \"caller\": \"web\",\r\n        \"v\": \"58\",\r\n        \"pfm\": \"web\",\r\n        \"locale\": \"en-US\"\r\n    }\r\n    _storefronts_mapping = {\r\n        \"AF\": \"143610\", \"AO\": \"143564\", \"AI\": \"143538\", \"AL\": \"143575\", \"AD\": \"143611\", \"AE\": \"143481\", \"AR\": \"143505\",\r\n        \"AM\": \"143524\", \"AG\": \"143540\", \"AU\": \"143460\", \"AT\": \"143445\", \"AZ\": \"143568\", \"BE\": \"143446\", \"BJ\": \"143576\",\r\n        \"BF\": \"143578\", \"BD\": \"143490\", \"BG\": \"143526\", \"BH\": \"143559\", \"BS\": \"143539\", \"BA\": \"143612\", \"BY\": \"143565\",\r\n        \"BZ\": \"143555\", \"BM\": \"143542\", \"BO\": \"143556\", \"BR\": \"143503\", \"BB\": \"143541\", \"BN\": \"143560\", \"BT\": \"143577\",\r\n        \"BW\": \"143525\", \"CF\": \"143623\", \"CA\": \"143455\", \"CH\": \"143459\", \"CL\": \"143483\", \"CN\": \"143465\", \"CI\": \"143527\",\r\n        \"CM\": \"143574\", \"CD\": \"143613\", \"CG\": \"143582\", \"CO\": \"143501\", \"CV\": \"143580\", \"CR\": \"143495\", \"KY\": \"143544\",\r\n        \"CY\": \"143557\", \"CZ\": \"143489\", \"DE\": \"143443\", \"DM\": \"143545\", \"DK\": \"143458\", \"DO\": \"143508\", \"DZ\": \"143563\",\r\n        \"EC\": \"143509\", \"EG\": \"143516\", \"ES\": \"143454\", \"EE\": \"143518\", \"ET\": \"143569\", \"FI\": \"143447\", \"FJ\": \"143583\",\r\n        \"FR\": \"143442\", \"FM\": \"143591\", \"GA\": \"143614\", \"GB\": \"143444\", \"GE\": \"143615\", \"GH\": \"143573\", \"GN\": \"143616\",\r\n        \"GM\": \"143584\", \"GW\": \"143585\", \"GR\": \"143448\", \"GD\": \"143546\", \"GT\": \"143504\", \"GY\": \"143553\", \"HK\": \"143463\",\r\n        \"HN\": \"143510\", \"HR\": \"143494\", \"HU\": \"143482\", \"ID\": \"143476\", \"IN\": \"143467\", \"IE\": \"143449\", \"IQ\": \"143617\",\r\n        \"IS\": \"143558\", \"IL\": \"143491\", \"IT\": \"143450\", \"JM\": \"143511\", \"JO\": \"143528\", \"JP\": \"143462\", \"KZ\": \"143517\",\r\n        \"KE\": \"143529\", \"KG\": \"143586\", \"KH\": \"143579\", \"KN\": \"143548\", \"KR\": \"143466\", \"KW\": \"143493\", \"LA\": \"143587\",\r\n        \"LB\": \"143497\", \"LR\": \"143588\", \"LY\": \"143567\", \"LC\": \"143549\", \"LI\": \"143522\", \"LK\": \"143486\", \"LT\": \"143520\",\r\n        \"LU\": \"143451\", \"LV\": \"143519\", \"MO\": \"143515\", \"MA\": \"143620\", \"MC\": \"143618\", \"MD\": \"143523\", \"MG\": \"143531\",\r\n        \"MV\": \"143488\", \"MX\": \"143468\", \"MK\": \"143530\", \"ML\": \"143532\", \"MT\": \"143521\", \"MM\": \"143570\", \"ME\": \"143619\",\r\n        \"MN\": \"143592\", \"MZ\": \"143593\", \"MR\": \"143590\", \"MS\": \"143547\", \"MU\": \"143533\", \"MW\": \"143589\", \"MY\": \"143473\",\r\n        \"NA\": \"143594\", \"NE\": \"143534\", \"NG\": \"143561\", \"NI\": \"143512\", \"NL\": \"143452\", \"NO\": \"143457\", \"NP\": \"143484\",\r\n        \"NR\": \"143606\", \"NZ\": \"143461\", \"OM\": \"143562\", \"PK\": \"143477\", \"PA\": \"143485\", \"PE\": \"143507\", \"PH\": \"143474\",\r\n        \"PW\": \"143595\", \"PG\": \"143597\", \"PL\": \"143478\", \"PT\": \"143453\", \"PY\": \"143513\", \"PS\": \"143596\", \"QA\": \"143498\",\r\n        \"RO\": \"143487\", \"RU\": \"143469\", \"RW\": \"143621\", \"SA\": \"143479\", \"SN\": \"143535\", \"SG\": \"143464\", \"SB\": \"143601\",\r\n        \"SL\": \"143600\", \"SV\": \"143506\", \"RS\": \"143500\", \"ST\": \"143598\", \"SR\": \"143554\", \"SK\": \"143496\", \"SI\": \"143499\",\r\n        \"SE\": \"143456\", \"SZ\": \"143602\", \"SC\": \"143599\", \"TC\": \"143552\", \"TD\": \"143581\", \"TH\": \"143475\", \"TJ\": \"143603\",\r\n        \"TM\": \"143604\", \"TO\": \"143608\", \"TT\": \"143551\", \"TN\": \"143536\", \"TR\": \"143480\", \"TW\": \"143470\", \"TZ\": \"143572\",\r\n        \"UG\": \"143537\", \"UA\": \"143492\", \"UY\": \"143514\", \"US\": \"143441\", \"UZ\": \"143566\", \"VC\": \"143550\", \"VE\": \"143502\",\r\n        \"VG\": \"143543\", \"VN\": \"143471\", \"VU\": \"143609\", \"WS\": \"143607\", \"XK\": \"143624\", \"YE\": \"143571\", \"ZA\": \"143472\",\r\n        \"ZM\": \"143622\", \"ZW\": \"143605\",\r\n    }\r\n\r\n    def __init__(self, config_data: dict | None = None):\r\n        super().__init__(config_data=config_data)\r\n        self.itunes_scraper = ScraperFactory().get_scraper_instance_by_scraper(\r\n            scraper_class=iTunesScraper,\r\n            scrapers_config_data=config_data,\r\n        )\r\n\r\n    def fetch_api_data(self, url: str) -> dict:\r\n        \"\"\"\r\n        Send a request to AppleTV's API and return the JSON response.\r\n\r\n        Args:\r\n            url: The URL to send the request to.\r\n\r\n        Returns:\r\n            dict: The JSON response.\r\n\r\n        Raises:\r\n            HttpError: If an HTTP error response is received.\r\n        \"\"\"\r\n        regex_match = self.match_url(url, raise_error=True)\r\n\r\n        # Add storefront ID to params\r\n        request_params = self._api_request_params.copy()\r\n\r\n        if regex_match.group(2).upper() in self._storefronts_mapping:\r\n            request_params[\"sf\"] = self._storefronts_mapping[regex_match.group(2).upper()]\r\n\r\n        else:\r\n            raise ScraperException(f\"ID mapping for storefront '{regex_match.group(2).upper()}' could not be found.\")\r\n\r\n        response = self._session.get(self._api_url + regex_match.group(4), params=request_params)\r\n        response.raise_for_status()\r\n        response_json = response.json()\r\n\r\n        return response_json.get(\"data\", {})\r\n\r\n    def get_data(self, url: str) -> MovieData | list[MovieData] | None:\r\n        json_data = self.fetch_api_data(url)\r\n        itunes_channel: str | None = None\r\n        appletvplus_channel: str | None = None\r\n\r\n        for channel in json_data[\"channels\"].values():\r\n            if channel.get(\"isAppleTvPlus\", False):\r\n                appletvplus_channel = channel[\"id\"]\r\n\r\n            elif channel.get(\"isItunes\", False):\r\n                itunes_channel = channel[\"id\"]\r\n        \r\n        if appletvplus_channel:\r\n            media_type = json_data.get(\"content\", {}).get(\"type\")\r\n\r\n            if media_type in (\"Movie\", \"Show\"):\r\n                for playable in json_data[\"playables\"].values():\r\n                    if playable.get(\"channelId\") == appletvplus_channel:\r\n                        raise NotImplementedError(\"AppleTV+ content scraping is not currently supported.\")\r\n\r\n            else:\r\n                raise ScraperException(f\"Unsupported media type: '{media_type}'.\")\r\n\r\n        elif itunes_channel:\r\n            itunes_playables = []\r\n\r\n            for playable in json_data[\"playables\"].values():\r\n                if playable.get(\"channelId\", '') == itunes_channel:\r\n                    itunes_playables.append(playable)\r\n\r\n            return self._get_data_itunes(playables_data=itunes_playables)\r\n\r\n        return None\r\n\r\n    def _get_data_itunes(self, playables_data: list[dict]) -> MovieData | list[MovieData]:\r\n        results = []\r\n\r\n        for playable_data in playables_data:\r\n            itunes_url = playable_data[\"punchoutUrls\"][\"open\"].replace(\"itmss://\", \"https://\")\r\n            results.append(self.itunes_scraper.get_data(itunes_url))\r\n\r\n        if len(results) == 1:\r\n            return results[0]\r\n\r\n        return results\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/scrapers/appletv_scraper.py b/isubrip/scrapers/appletv_scraper.py
--- a/isubrip/scrapers/appletv_scraper.py	(revision 2e359abca21aea0e94ef93086b16e7f7b0714786)
+++ b/isubrip/scrapers/appletv_scraper.py	(date 1682765206227)
@@ -19,14 +19,12 @@
     is_series_scraper = True
     uses_scrapers = [iTunesScraper]
 
-    _api_url = "https://tv.apple.com/api/uts/v3/movies/"
-    _api_request_params = {
+    _api_url = "https://tv.apple.com/api/uts/v3"
+    _api_const_params = {
         "utscf": "OjAAAAAAAAA~",
-        "utsk": "6e3013c6d6fae3c2::::::235656c069bb0efb",
         "caller": "web",
-        "v": "58",
+        "v": "64",
         "pfm": "web",
-        "locale": "en-US"
     }
     _storefronts_mapping = {
         "AF": "143610", "AO": "143564", "AI": "143538", "AL": "143575", "AD": "143611", "AE": "143481", "AR": "143505",
@@ -65,6 +63,29 @@
             scrapers_config_data=config_data,
         )
 
+    def _generate_api_request_params(self, sf: str, locale: str, utsk: str | None = None) -> dict:
+        """
+        Generate request params for the AppleTV's API.
+
+        Args:
+            sf (str): ID of the storefront to use.
+            locale (str): ID of the locale to use.
+            utsk (str | None, optional): utsk Defaults to None.
+
+        Returns:
+            dict: The request params, generated from the given arguments.
+        """
+        params = self._api_const_params.copy()
+
+        if utsk:
+            params["utsk"] = utsk
+
+        params["sf"] = sf
+        params["locale"] = locale
+
+        return params
+
+
     def fetch_api_data(self, url: str) -> dict:
         """
         Send a request to AppleTV's API and return the JSON response.
@@ -78,23 +99,32 @@
         Raises:
             HttpError: If an HTTP error response is received.
         """
+        # Add storefront ID and locale to request params
         regex_match = self.match_url(url, raise_error=True)
+        stroefront_cc = regex_match.group(2).upper()
+        media_id = regex_match.group(4)
+        request_params = self._api_base_request_params.copy()
 
-        # Add storefront ID to params
-        request_params = self._api_request_params.copy()
-
-        if regex_match.group(2).upper() in self._storefronts_mapping:
-            request_params["sf"] = self._storefronts_mapping[regex_match.group(2).upper()]
+        if stroefront_cc in self._storefronts_mapping:
+            request_params["sf"] = self._storefronts_mapping[stroefront_cc]
 
         else:
-            raise ScraperException(f"ID mapping for storefront '{regex_match.group(2).upper()}' could not be found.")
+            raise ScraperException(f"ID mapping for storefront '{stroefront_cc}' could not be found.")
+
+        response = self._session.get(f"{self._api_url}/movies/{media_id}", params=request_params)
 
-        response = self._session.get(self._api_url + regex_match.group(4), params=request_params)
+
+        # Send request to fetch media data
+        response = self._session.get(f"{self._api_url}/movies/{media_id}", params=request_params)
         response.raise_for_status()
         response_json = response.json()
 
         return response_json.get("data", {})
 
+    def get_media_data(self, media_id: str, ):
+
+    def get_configuration_data(self, storefront_id: str) -> dict:
+
     def get_data(self, url: str) -> MovieData | list[MovieData] | None:
         json_data = self.fetch_api_data(url)
         itunes_channel: str | None = None
Index: isubrip/scrapers/itunes_scraper.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\r\n\r\nimport json\r\nfrom datetime import datetime\r\n\r\nimport m3u8\r\nfrom bs4 import BeautifulSoup, Tag, NavigableString\r\nfrom requests import HTTPError\r\n\r\nfrom isubrip.data_structures import MediaSourceData, MovieData\r\nfrom isubrip.scrapers.scraper import M3U8Scraper, MovieScraper, ScraperException\r\nfrom isubrip.subtitle_formats.webvtt import WebVTTSubtitles\r\n\r\n\r\nclass iTunesScraper(M3U8Scraper, MovieScraper):\r\n    \"\"\"An iTunes movie data scraper.\"\"\"\r\n    url_regex = r\"(https?://itunes\\.apple\\.com/[a-z]{2}/movie/(?:[\\w\\-%]+/)?(id\\d{9,10}))(?:\\?.*)?\"\r\n    service_data = MediaSourceData(id=\"itunes\", name=\"iTunes\", abbreviation=\"iT\")\r\n    subtitles_class = WebVTTSubtitles\r\n    is_movie_scraper = True\r\n\r\n    def get_data(self, url: str) -> MovieData:\r\n        \"\"\"\r\n        Scrape iTunes to find info about a movie, and it's M3U8 main_playlist.\r\n\r\n        Args:\r\n            url (str): An iTunes store movie URL.\r\n\r\n        Raises:\r\n            InvalidURL: `itunes_url` is not a valid iTunes store movie URL.\r\n            PageLoadError: HTML page did not load properly.\r\n            HTTPError: HTTP request failed.\r\n\r\n        Returns:\r\n            MovieData: A MovieData (NamedTuple) object with movie's name, and an M3U8 object of the main_playlist\r\n            if the main_playlist is found. None otherwise.\r\n        \"\"\"\r\n        regex_match = self.match_url(url, raise_error=True)\r\n\r\n        url = regex_match.group(1)\r\n        response = self._session.get(url)\r\n        response.raise_for_status()\r\n\r\n        # Response is JSON formatted\r\n        if \"application/json\" in response.headers['content-type']:\r\n            try:\r\n                json_data = json.loads(response.content)\r\n\r\n            except json.JSONDecodeError:\r\n                raise ScraperException(\"Received an invalid JSON response.\")\r\n\r\n            return self._find_playlist_data_json(json_data)\r\n\r\n        # Response is HTML formatted\r\n        elif \"text/html\" in response.headers['content-type'] and response.status_code != 404:\r\n            html_data = BeautifulSoup(response.content, \"lxml\")\r\n            return self._find_playlist_data_html(html_data)\r\n\r\n        raise ScraperException(\"Received an unexpected response.\")\r\n\r\n    def _find_playlist_data_json(self, json_data: dict) -> MovieData:\r\n        \"\"\"\r\n        Scrape an iTunes JSON response to get movie info.\r\n\r\n        Args:\r\n            json_data (dict): A dictionary with iTunes data loaded from a JSON response.\r\n\r\n        Returns:\r\n            MovieData: A MovieData (NamedTuple) object with movie's name, and an M3U8 object of the main_playlist\r\n            if the main_playlist is found. None otherwise.\r\n        \"\"\"\r\n        itunes_id = json_data[\"pageData\"][\"id\"]\r\n        movie_data = json_data[\"storePlatformData\"][\"product-dv\"][\"results\"][itunes_id]\r\n\r\n        movie_title = movie_data[\"nameRaw\"]\r\n        movie_release_year = datetime.strptime(movie_data[\"releaseDate\"], '%Y-%m-%d').year\r\n\r\n        # Loop safely to find a matching main_playlist\r\n        for offer in movie_data[\"offers\"]:\r\n            if isinstance(offer.get(\"type\"), str) and offer[\"type\"] in [\"buy\", \"rent\"]:\r\n                if isinstance(offer.get(\"assets\"), list) and len(offer[\"assets\"]) > 0:\r\n                    for asset in offer[\"assets\"]:\r\n                        playlist_url: str = asset[\"hlsUrl\"]\r\n\r\n                        # Assure main_playlist is valid\r\n                        try:\r\n                            m3u8.load(playlist_url)\r\n\r\n                        # If m3u8 main_playlist is invalid, skip it\r\n                        except (ValueError, HTTPError):\r\n                            continue\r\n\r\n                        return MovieData(\r\n                            id=itunes_id,\r\n                            name=movie_title,\r\n                            release_year=movie_release_year,\r\n                            playlist=playlist_url,\r\n                            source=self.service_data,\r\n                            scraper=self,\r\n                        )\r\n\r\n        return MovieData(\r\n            id=itunes_id,\r\n            name=movie_title,\r\n            release_year=movie_release_year,\r\n            playlist=None,\r\n            source=self.service_data,\r\n            scraper=self,\r\n        )\r\n\r\n    def _find_playlist_data_html(self, html_data: BeautifulSoup) -> MovieData:\r\n        \"\"\"\r\n        Scrape an iTunes HTML page to get movie info.\r\n\r\n        Note:\r\n            This function uses web-scraping and because of that,\r\n            it's a lot less reliable than `_find_playlist_data_itunes_json_`.\r\n\r\n        Args:\r\n            html_data (BeautifulSoup): A BeautifulSoup object of the page.\r\n\r\n        Raises:\r\n            PageLoadError: HTML page did not load properly.\r\n\r\n        Returns:\r\n            MovieData: A MovieData (NamedTuple) object with movie's name, and an M3U8 object of the main_playlist\r\n            if the main_playlist is found. None otherwise.\r\n        \"\"\"\r\n        itunes_id_tag: Tag | NavigableString | None = html_data.find(\"meta\", attrs={\"name\": \"apple:content_id\"})\r\n        if not isinstance(itunes_id_tag, Tag):\r\n            raise ScraperException(\"HTML page did not load properly.\")\r\n\r\n        itunes_id: str = itunes_id_tag.attrs[\"content\"]\r\n\r\n        # Scrape a dictionary on the webpage that has playlists data\r\n        shoebox_data_tag: Tag | NavigableString | None = \\\r\n            html_data.find(\"script\", attrs={\"id\": \"shoebox-ember-data-store\", \"type\": \"fastboot/shoebox\"})\r\n\r\n        # fastboot/shoebox data could not be found\r\n        if not isinstance(shoebox_data_tag, Tag):\r\n            raise ScraperException(\"fastboot/shoebox data could not be found.\")\r\n\r\n        # Convert to dictionary structure\r\n        shoebox_data: dict = json.loads(str(shoebox_data_tag.contents[0]).strip())\r\n\r\n        # Loop safely to find a matching main_playlist\r\n        if isinstance(shoebox_data[itunes_id].get(\"included\"), list):\r\n            movie_data: dict = shoebox_data[itunes_id]\r\n            movie_title: str = movie_data[\"data\"][\"attributes\"][\"name\"]\r\n            movie_release_year = datetime.strptime(movie_data[\"data\"][\"attributes\"][\"releaseDate\"], '%Y-%m-%d').year\r\n\r\n            for item in movie_data[\"included\"]:\r\n                if isinstance(item.get(\"type\"), str) and item[\"type\"] == \"offer\":\r\n                    if isinstance(item.get(\"attributes\"), dict) and \\\r\n                        isinstance(item[\"attributes\"].get(\"assets\"), list) and \\\r\n                            len(item[\"attributes\"][\"assets\"]) > 0:\r\n\r\n                        for asset in item[\"attributes\"][\"assets\"]:\r\n                            if isinstance(asset, dict) and isinstance(asset.get(\"hlsUrl\"), str):\r\n                                playlist_url: str = item[\"attributes\"][\"assets\"][0][\"hlsUrl\"]\r\n\r\n                                # Try loading the main_playlist to assure it's working\r\n                                try:\r\n                                    m3u8.load(playlist_url)\r\n\r\n                                # If m3u8 main_playlist is invalid, skip it\r\n                                except (ValueError, HTTPError):\r\n                                    continue\r\n\r\n                                return MovieData(\r\n                                    id=itunes_id,\r\n                                    name=movie_title,\r\n                                    release_year=movie_release_year,\r\n                                    playlist=playlist_url,\r\n                                    source=self.service_data,\r\n                                    scraper=self,\r\n                                )\r\n        else:\r\n            raise ScraperException(\"Invalid shoebox data.\")\r\n\r\n        return MovieData(\r\n            id=itunes_id,\r\n            name=movie_title,\r\n            release_year=movie_release_year,\r\n            playlist=None,\r\n            source=self.service_data,\r\n            scraper=self,\r\n        )\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/isubrip/scrapers/itunes_scraper.py b/isubrip/scrapers/itunes_scraper.py
--- a/isubrip/scrapers/itunes_scraper.py	(revision 2e359abca21aea0e94ef93086b16e7f7b0714786)
+++ b/isubrip/scrapers/itunes_scraper.py	(date 1682711765154)
@@ -4,7 +4,6 @@
 from datetime import datetime
 
 import m3u8
-from bs4 import BeautifulSoup, Tag, NavigableString
 from requests import HTTPError
 
 from isubrip.data_structures import MediaSourceData, MovieData
@@ -51,11 +50,6 @@
 
             return self._find_playlist_data_json(json_data)
 
-        # Response is HTML formatted
-        elif "text/html" in response.headers['content-type'] and response.status_code != 404:
-            html_data = BeautifulSoup(response.content, "lxml")
-            return self._find_playlist_data_html(html_data)
-
         raise ScraperException("Received an unexpected response.")
 
     def _find_playlist_data_json(self, json_data: dict) -> MovieData:
@@ -107,82 +101,3 @@
             source=self.service_data,
             scraper=self,
         )
-
-    def _find_playlist_data_html(self, html_data: BeautifulSoup) -> MovieData:
-        """
-        Scrape an iTunes HTML page to get movie info.
-
-        Note:
-            This function uses web-scraping and because of that,
-            it's a lot less reliable than `_find_playlist_data_itunes_json_`.
-
-        Args:
-            html_data (BeautifulSoup): A BeautifulSoup object of the page.
-
-        Raises:
-            PageLoadError: HTML page did not load properly.
-
-        Returns:
-            MovieData: A MovieData (NamedTuple) object with movie's name, and an M3U8 object of the main_playlist
-            if the main_playlist is found. None otherwise.
-        """
-        itunes_id_tag: Tag | NavigableString | None = html_data.find("meta", attrs={"name": "apple:content_id"})
-        if not isinstance(itunes_id_tag, Tag):
-            raise ScraperException("HTML page did not load properly.")
-
-        itunes_id: str = itunes_id_tag.attrs["content"]
-
-        # Scrape a dictionary on the webpage that has playlists data
-        shoebox_data_tag: Tag | NavigableString | None = \
-            html_data.find("script", attrs={"id": "shoebox-ember-data-store", "type": "fastboot/shoebox"})
-
-        # fastboot/shoebox data could not be found
-        if not isinstance(shoebox_data_tag, Tag):
-            raise ScraperException("fastboot/shoebox data could not be found.")
-
-        # Convert to dictionary structure
-        shoebox_data: dict = json.loads(str(shoebox_data_tag.contents[0]).strip())
-
-        # Loop safely to find a matching main_playlist
-        if isinstance(shoebox_data[itunes_id].get("included"), list):
-            movie_data: dict = shoebox_data[itunes_id]
-            movie_title: str = movie_data["data"]["attributes"]["name"]
-            movie_release_year = datetime.strptime(movie_data["data"]["attributes"]["releaseDate"], '%Y-%m-%d').year
-
-            for item in movie_data["included"]:
-                if isinstance(item.get("type"), str) and item["type"] == "offer":
-                    if isinstance(item.get("attributes"), dict) and \
-                        isinstance(item["attributes"].get("assets"), list) and \
-                            len(item["attributes"]["assets"]) > 0:
-
-                        for asset in item["attributes"]["assets"]:
-                            if isinstance(asset, dict) and isinstance(asset.get("hlsUrl"), str):
-                                playlist_url: str = item["attributes"]["assets"][0]["hlsUrl"]
-
-                                # Try loading the main_playlist to assure it's working
-                                try:
-                                    m3u8.load(playlist_url)
-
-                                # If m3u8 main_playlist is invalid, skip it
-                                except (ValueError, HTTPError):
-                                    continue
-
-                                return MovieData(
-                                    id=itunes_id,
-                                    name=movie_title,
-                                    release_year=movie_release_year,
-                                    playlist=playlist_url,
-                                    source=self.service_data,
-                                    scraper=self,
-                                )
-        else:
-            raise ScraperException("Invalid shoebox data.")
-
-        return MovieData(
-            id=itunes_id,
-            name=movie_title,
-            release_year=movie_release_year,
-            playlist=None,
-            source=self.service_data,
-            scraper=self,
-        )
