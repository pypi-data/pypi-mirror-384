---
title: 'Configuration System'
description: 'Complete guide to DroidRun configuration including LLM profiles, safe execution, and SDK usage'
---

# Configuration System

DroidRun uses a YAML-based configuration system that controls agent behavior, LLM selection, device settings, and execution safety.

<Warning>
**CRITICAL: SDK vs CLI Configuration**

DroidRun has two configuration interfaces:

1. **`DroidRunConfig`** - For SDK/Python developers (YOU SHOULD USE THIS)
   - Load with `DroidRunConfig.from_yaml("config.yaml")`
   - Create programmatically with `DroidRunConfig()`
   - Pass to `DroidAgent(config=config)`
   - Direct, simple, straightforward

2. **`ConfigManager`** - For CLI internal use only (DO NOT USE IN YOUR CODE)
   - Singleton pattern used by `droidrun` CLI command
   - Handles CLI flag overrides automatically
   - Not intended for SDK usage

**TL;DR**: Always use `DroidRunConfig` in your Python code. Never use `ConfigManager`.
</Warning>

---

## Overview

The configuration system follows a **three-tier priority model**:

1. **CLI flags** (highest priority) - Override everything when using CLI
2. **DroidAgent parameters** (medium priority) - Override config when creating agent
3. **Config file** (lowest priority) - Base configuration from `config.yaml`

### How Config Files Are Found

DroidRun searches for `config.yaml` in this order:

1. **Explicit path**: Via `--config` CLI flag or `DroidRunConfig.from_yaml(path)`
2. **Environment variable**: `DROIDRUN_CONFIG` environment variable
3. **Working directory**: `./config.yaml` in your current directory
4. **Package directory**: Falls back to bundled `config.yaml` in DroidRun installation

If no config file exists, DroidRun creates a default `config.yaml` automatically.

---

## Quick Start

### For SDK Users (Recommended)

**Load configuration from file:**

```python
from droidrun import DroidAgent, ResultEvent
from droidrun.config_manager.config_manager import DroidRunConfig

# Load config from YAML file
config = DroidRunConfig.from_yaml("config.yaml")

# Access settings
print(config.agent.max_steps)  # 15
print(config.device.platform)  # "android"
print(config.logging.debug)    # False

# Access LLM profiles
manager_profile = config.llm_profiles["manager"]
print(f"{manager_profile.provider}/{manager_profile.model}")

# Pass to DroidAgent
agent = DroidAgent(goal="Open settings", config=config)
handler = agent.run()
result: ResultEvent = await handler
```

**Create config programmatically (no YAML file):**

```python
from droidrun.config_manager.config_manager import DroidRunConfig, AgentConfig, DeviceConfig

# Create config with defaults
config = DroidRunConfig()

# Or customize on creation
config = DroidRunConfig(
    agent=AgentConfig(max_steps=25, reasoning=True),
    device=DeviceConfig(platform="android", use_tcp=True)
)

# Pass to DroidAgent
agent = DroidAgent(goal="Open Chrome", config=config)
```

**Modify and save config:**

```python
# Load existing config
config = DroidRunConfig.from_yaml("config.yaml")

# Modify settings
config.agent.max_steps = 25
config.agent.reasoning = True
config.tracing.enabled = True

# Save to YAML file
import yaml
with open("config.yaml", "w") as f:
    yaml.dump(config.to_dict(), f)
```

### For CLI Users

DroidRun creates a default config automatically on first run:

```sh
# This creates config.yaml in your current directory
droidrun devices
```

Override config via CLI flags:

```sh
# Override max steps and enable vision
droidrun run "Open settings" --steps 30 --vision --reasoning
```

---

## Common Patterns

### Pattern 1: Load and Use (Simplest)

```python
from droidrun import DroidAgent, ResultEvent
from droidrun.config_manager.config_manager import DroidRunConfig

# Load from file
config = DroidRunConfig.from_yaml("config.yaml")

# Use directly
agent = DroidAgent(goal="Open Chrome", config=config)
handler = agent.run()
result: ResultEvent = await handler
```

### Pattern 2: Load, Modify, Use

```python
from droidrun import DroidAgent, ResultEvent
from droidrun.config_manager.config_manager import DroidRunConfig

# Load from file
config = DroidRunConfig.from_yaml("config.yaml")

# Modify as needed
config.agent.max_steps = 30
config.agent.reasoning = True
config.agent.manager.vision = True

# Use modified config
agent = DroidAgent(goal="Complex task", config=config)
handler = agent.run()
result: ResultEvent = await handler
```

### Pattern 3: Create from Scratch

```python
from droidrun import DroidAgent
from droidrun.config_manager.config_manager import DroidRunConfig, AgentConfig, LLMProfile

# Create config programmatically (no YAML file needed)
config = DroidRunConfig()

# Customize
config.agent.max_steps = 25
config.agent.reasoning = True

# Set custom LLM profiles
config.llm_profiles["manager"] = LLMProfile(
    provider="Anthropic",
    model="claude-sonnet-4-5",
    temperature=0.2
)

# Use
agent = DroidAgent(goal="Task", config=config)
```

### Pattern 4: Override via DroidAgent Parameters

```python
from droidrun import DroidAgent
from droidrun.config_manager.config_manager import DroidRunConfig, AgentConfig, DeviceConfig

# Load base config
config = DroidRunConfig.from_yaml("config.yaml")

# Override specific parts via DroidAgent parameters
agent = DroidAgent(
    goal="Task",
    config=config,  # Base config
    agent_config=AgentConfig(max_steps=30, reasoning=True),  # Override agent
    device_config=DeviceConfig(serial="emulator-5554"),  # Override device
)
```

---

## DroidRunConfig API Reference

### Key Methods

```python
# Load from YAML file
config = DroidRunConfig.from_yaml("config.yaml")

# Create from dictionary
config_dict = {...}
config = DroidRunConfig.from_dict(config_dict)

# Create with defaults
config = DroidRunConfig()

# Convert to dictionary
config_dict = config.to_dict()

# Save to YAML (manually)
import yaml
with open("config.yaml", "w") as f:
    yaml.dump(config.to_dict(), f)
```

### Main Configuration Objects

```python
# Access configuration sections
config.agent           # AgentConfig - agent behavior settings
config.device          # DeviceConfig - device connection settings
config.logging         # LoggingConfig - logging and trajectory settings
config.tracing         # TracingConfig - Arize Phoenix tracing
config.telemetry       # TelemetryConfig - anonymous telemetry
config.tools           # ToolsConfig - tool settings (e.g., allow_drag)
config.credentials     # CredentialsConfig - credential management
config.safe_execution  # SafeExecutionConfig - code execution restrictions
config.llm_profiles    # Dict[str, LLMProfile] - LLM configurations per agent
```

### Agent Sub-Configs

```python
# Agent-specific settings
config.agent.codeact   # CodeActConfig - direct execution mode
config.agent.manager   # ManagerConfig - planning agent (reasoning mode)
config.agent.executor  # ExecutorConfig - action agent (reasoning mode)
config.agent.scripter  # ScripterConfig - off-device script execution
config.agent.app_cards # AppCardConfig - app-specific instructions
```

---

## Complete Configuration Schema

### Full Example

Here's a complete `config.yaml` with all available options:

```yaml
# === Agent Settings ===
agent:
  # Maximum number of steps per task
  max_steps: 15

  # Enable planning with reasoning mode (Manager-Executor workflow)
  reasoning: false

  # Sleep duration after each action (seconds)
  after_sleep_action: 1.0

  # Wait duration for UI to stabilize (seconds)
  wait_for_stable_ui: 0.3

  # Base directory for prompt templates
  prompts_dir: config/prompts

  # CodeAct Agent Configuration (direct execution mode)
  codeact:
    vision: false
    system_prompt: system.jinja2
    user_prompt: user.jinja2
    safe_execution: false

  # Manager Agent Configuration (planning agent in reasoning mode)
  manager:
    vision: false
    system_prompt: system.jinja2

  # Executor Agent Configuration (execution agent in reasoning mode)
  executor:
    vision: false
    system_prompt: system.jinja2

  # Scripter Agent Configuration (off-device Python execution)
  scripter:
    enabled: true
    max_steps: 10
    execution_timeout: 30.0
    system_prompt_path: system.jinja2
    safe_execution: false

  # App Cards Configuration
  app_cards:
    enabled: true
    mode: local  # local | server | composite
    app_cards_dir: config/app_cards
    server_url: null
    server_timeout: 2.0
    server_max_retries: 2

# === LLM Profiles ===
llm_profiles:
  # Manager: Plans and reasons about task progress
  manager:
    provider: GoogleGenAI
    model: models/gemini-2.5-pro
    temperature: 0.2
    kwargs:
      max_tokens: 8192

  # Executor: Selects and executes atomic actions
  executor:
    provider: GoogleGenAI
    model: models/gemini-2.5-pro
    temperature: 0.1
    kwargs:
      max_tokens: 4096

  # CodeAct: Generates and executes code actions
  codeact:
    provider: GoogleGenAI
    model: models/gemini-2.5-pro
    temperature: 0.2
    kwargs:
      max_tokens: 8192

  # Text Manipulator: Edits text in input fields
  text_manipulator:
    provider: GoogleGenAI
    model: models/gemini-2.5-pro
    temperature: 0.3
    kwargs:
      max_tokens: 4096

  # App Opener: Opens apps by name/description
  app_opener:
    provider: OpenAI
    model: gpt-4o-mini
    temperature: 0.0
    kwargs:
      max_tokens: 512

  # Scripter: Executes Python scripts for off-device operations
  scripter:
    provider: GoogleGenAI
    model: models/gemini-2.5-flash
    temperature: 0.1
    kwargs:
      max_tokens: 4096

  # Structured Output: Extracts structured data from final answers
  structured_output:
    provider: GoogleGenAI
    model: models/gemini-2.5-flash
    temperature: 0.0
    kwargs:
      max_tokens: 2048

# === Device Settings ===
device:
  # Default device serial (null = auto-detect for Android)
  serial: null

  # Platform: android or ios
  platform: android

  # Use TCP communication instead of content provider
  use_tcp: false

# === Telemetry Settings ===
telemetry:
  # Enable anonymous telemetry
  enabled: true

# === Tracing Settings ===
tracing:
  # Enable Arize Phoenix tracing
  enabled: false

# === Logging Settings ===
logging:
  # Enable debug logging
  debug: false

  # Trajectory saving level (none, step, action)
  save_trajectory: none

  # Enable rich text console output
  rich_text: false

# === Safe Execution Settings ===
safe_execution:
  # Allow all imports (ignores allowed_modules, respects blocked_modules)
  allow_all_imports: false

  # Allowed modules (empty + allow_all_imports=false = no imports allowed)
  allowed_modules: []

  # Blocked modules (takes precedence over allowed_modules)
  blocked_modules:
    - os
    - sys
    - subprocess
    - shutil
    - pathlib
    - socket
    - asyncio

  # Allow all builtins (ignores allowed_builtins, respects blocked_builtins)
  allow_all_builtins: false

  # Allowed builtins (empty + allow_all_builtins=false = use safe defaults)
  allowed_builtins: []

  # Blocked builtins (takes precedence over allowed_builtins)
  blocked_builtins:
    - open
    - compile
    - exec
    - eval
    - __import__
    - breakpoint
    - exit
    - quit
    - input

# === Tool Settings ===
tools:
  # Enable drag tool
  allow_drag: false

# === Credential Settings ===
credentials:
  # Enable credential manager
  enabled: false

  # Path to credentials file (resolved via PathResolver)
  file_path: credentials.yaml
```

---

## LLM Profiles

LLM profiles define which language models to use for each agent type. DroidRun supports per-agent LLM configuration, allowing you to use different models for different tasks.

### Profile Structure

Each LLM profile has these fields:

| Field | Type | Description |
|-------|------|-------------|
| `provider` | String | LLM provider name (e.g., `"GoogleGenAI"`, `"OpenAI"`, `"Anthropic"`) |
| `model` | String | Model identifier (e.g., `"models/gemini-2.5-pro"`, `"gpt-4o"`) |
| `temperature` | Float | Sampling temperature (0.0 = deterministic, 1.0 = creative) |
| `base_url` | String (optional) | Custom API endpoint (for Ollama, OpenRouter, etc.) |
| `api_base` | String (optional) | Alternative API base URL (OpenAI-compatible APIs) |
| `kwargs` | Dict | Additional LLM parameters (max_tokens, top_p, etc.) |

### Default Profiles

DroidRun includes 7 default LLM profiles:

#### 1. Manager
Plans and creates subgoals in reasoning mode.

```yaml
manager:
  provider: GoogleGenAI
  model: models/gemini-2.5-pro
  temperature: 0.2
  kwargs:
    max_tokens: 8192
```

**Recommended models:**
- `models/gemini-2.5-pro` (best planning)
- `claude-3-7-sonnet-latest` (Anthropic)
- `gpt-4o` (OpenAI)

#### 2. Executor
Executes atomic actions in reasoning mode.

```yaml
executor:
  provider: GoogleGenAI
  model: models/gemini-2.5-pro
  temperature: 0.1  # Low temperature for precise execution
  kwargs:
    max_tokens: 4096
```

**Recommended models:**
- `models/gemini-2.5-pro`
- `models/gemini-2.5-flash` (faster, cheaper)

#### 3. CodeAct
Generates and executes Python code in direct mode.

```yaml
codeact:
  provider: GoogleGenAI
  model: models/gemini-2.5-pro
  temperature: 0.2
  kwargs:
    max_tokens: 8192
```

**Recommended models:**
- `models/gemini-2.5-pro`
- `deepseek-coder` (DeepSeek - excellent for code)
- `gpt-4o` (OpenAI)

#### 4. Text Manipulator
Edits text in input fields (helper agent).

```yaml
text_manipulator:
  provider: GoogleGenAI
  model: models/gemini-2.5-pro
  temperature: 0.3
  kwargs:
    max_tokens: 4096
```

#### 5. App Opener
Opens apps by name or description (helper agent).

```yaml
app_opener:
  provider: OpenAI
  model: gpt-4o-mini
  temperature: 0.0  # Deterministic app selection
  kwargs:
    max_tokens: 512
```

**Note:** Can use fast, cheap models since task is simple.

#### 6. Scripter
Executes off-device Python scripts.

```yaml
scripter:
  provider: GoogleGenAI
  model: models/gemini-2.5-flash
  temperature: 0.1
  kwargs:
    max_tokens: 4096
```

**Recommended models:**
- `models/gemini-2.5-flash` (fast, cheap)
- `deepseek-coder` (excellent for code)

#### 7. Structured Output
Extracts structured data from agent responses.

```yaml
structured_output:
  provider: GoogleGenAI
  model: models/gemini-2.5-flash
  temperature: 0.0
  kwargs:
    max_tokens: 2048
```

---

## Customizing LLM Profiles

### Example 1: Use Different Providers

Mix and match providers for different agents:

```yaml
llm_profiles:
  # Use Anthropic Claude for planning (best reasoning)
  manager:
    provider: Anthropic
    model: claude-3-7-sonnet-latest
    temperature: 0.2
    kwargs:
      max_tokens: 8192

  # Use DeepSeek for code generation (cost-effective)
  codeact:
    provider: DeepSeek
    model: deepseek-coder
    temperature: 0.2
    kwargs:
      max_tokens: 8192

  # Use local Ollama for simple tasks (no API costs)
  app_opener:
    provider: Ollama
    model: llama3.2:3b
    base_url: http://localhost:11434
    temperature: 0.0
    kwargs:
      max_tokens: 512
```

### Example 2: Use OpenRouter

Use OpenRouter for access to multiple models:

```yaml
llm_profiles:
  manager:
    provider: OpenAILike
    model: anthropic/claude-3.7-sonnet
    api_base: https://openrouter.ai/api/v1
    temperature: 0.2
    kwargs:
      max_tokens: 8192
      # OpenRouter requires API key in OPENAI_API_KEY env var

  executor:
    provider: OpenAILike
    model: google/gemini-2.5-flash
    api_base: https://openrouter.ai/api/v1
    temperature: 0.1
    kwargs:
      max_tokens: 4096
```

**Set API key:**

```sh
export OPENAI_API_KEY=sk-or-v1-your-openrouter-key
```

### Example 3: Use Ollama Locally

Run everything locally with Ollama:

```yaml
llm_profiles:
  manager:
    provider: Ollama
    model: llama3.3:70b
    base_url: http://localhost:11434
    temperature: 0.2
    kwargs:
      max_tokens: 8192

  executor:
    provider: Ollama
    model: llama3.3:70b
    base_url: http://localhost:11434
    temperature: 0.1
    kwargs:
      max_tokens: 4096

  codeact:
    provider: Ollama
    model: qwen2.5-coder:32b
    base_url: http://localhost:11434
    temperature: 0.2
    kwargs:
      max_tokens: 8192
```

**No API keys required!**

### Example 4: Budget-Conscious Setup

Optimize costs with cheaper models:

```yaml
llm_profiles:
  # Use Pro only for complex planning
  manager:
    provider: GoogleGenAI
    model: models/gemini-2.5-pro
    temperature: 0.2
    kwargs:
      max_tokens: 8192

  # Use Flash for everything else
  executor:
    provider: GoogleGenAI
    model: models/gemini-2.5-flash
    temperature: 0.1
    kwargs:
      max_tokens: 4096

  codeact:
    provider: GoogleGenAI
    model: models/gemini-2.5-flash
    temperature: 0.2
    kwargs:
      max_tokens: 8192

  # Use mini models for simple tasks
  app_opener:
    provider: OpenAI
    model: gpt-4o-mini
    temperature: 0.0
    kwargs:
      max_tokens: 256
```

---

## Loading LLMs from Profiles

### Automatic Loading (Recommended)

DroidAgent automatically loads LLMs from config.llm_profiles:

```python
from droidrun import DroidAgent, ResultEvent
from droidrun.config_manager.config_manager import DroidRunConfig

# Load config with LLM profiles
config = DroidRunConfig.from_yaml("config.yaml")

# DroidAgent automatically loads LLMs from config.llm_profiles
agent = DroidAgent(
    goal="Open settings",
    config=config,  # LLMs loaded automatically
)

handler = agent.run()
result: ResultEvent = await handler
```

### Manual LLM Loading

For advanced use cases, load LLMs manually and pass to DroidAgent:

```python
from droidrun import DroidAgent
from droidrun.config_manager.config_manager import DroidRunConfig
from droidrun.agent.utils.llm_picker import load_llms_from_profiles

config = DroidRunConfig.from_yaml("config.yaml")

# Load all LLM profiles manually
llms = load_llms_from_profiles(config.llm_profiles)

# Access individual LLMs
manager_llm = llms["manager"]
executor_llm = llms["executor"]
codeact_llm = llms["codeact"]

# Pass manually loaded LLMs to DroidAgent
agent = DroidAgent(
    goal="Open settings",
    config=config,
    llms=llms  # Override auto-loading
)
```

**Load specific profiles with overrides:**

```python
# Load only manager and executor
llms = load_llms_from_profiles(
    config.llm_profiles,
    profile_names=["manager", "executor"]
)

# Load with temperature override
llms = load_llms_from_profiles(
    config.llm_profiles,
    profile_names=["manager"],
    manager={"temperature": 0.1}  # Override temperature
)
```

### CLI LLM Overrides

Override LLM settings via CLI:

```sh
# Override provider and model for ALL agents
droidrun run "Open settings" \
  --provider GoogleGenAI \
  --model models/gemini-2.5-flash \
  --temperature 0.3

# These override ALL profiles (manager, executor, codeact)
```

<Warning>
CLI LLM overrides (`--provider`, `--model`, `--temperature`) apply to ALL agent profiles. For fine-grained per-agent control, edit `config.yaml` or use the SDK with manual LLM loading.
</Warning>

---

## Agent Configuration

### Agent Modes

DroidRun supports two execution modes:

#### Direct Mode (Default)

Uses **CodeActAgent** for immediate code execution:

```yaml
agent:
  reasoning: false  # Direct mode
  codeact:
    vision: false
    system_prompt: system.jinja2
    user_prompt: user.jinja2
    safe_execution: false
```

**When to use:**
- Simple, single-step tasks
- Fast execution needed
- Direct action sequences

#### Reasoning Mode

Uses **Manager-Executor** workflow for complex planning:

```yaml
agent:
  reasoning: true  # Reasoning mode
  manager:
    vision: false
    system_prompt: system.jinja2
  executor:
    vision: false
    system_prompt: system.jinja2
```

**When to use:**
- Multi-step tasks requiring planning
- Complex workflows with error handling
- Tasks needing subgoal decomposition

### Vision Configuration

Enable vision (screenshot processing) per agent:

```yaml
agent:
  # Vision for planning (Manager)
  manager:
    vision: true  # Sees screenshots when planning

  # Vision for execution (Executor)
  executor:
    vision: true  # Sees screenshots when acting

  # Vision for direct mode (CodeAct)
  codeact:
    vision: true  # Sees screenshots when generating code
```

**CLI overrides:**

```sh
# Enable vision for all agents
droidrun run "Open settings" --vision

# Disable vision for all agents
droidrun run "Open settings" --no-vision
```

<Warning>
Vision increases token usage and costs significantly. Only enable when needed (e.g., UI-based tasks, image recognition).
</Warning>

### Timing Configuration

Control execution timing:

```yaml
agent:
  # Sleep after each action (UI update time)
  after_sleep_action: 1.0  # seconds

  # Wait for UI to stabilize before capturing state
  wait_for_stable_ui: 0.3  # seconds
```

**When to adjust:**
- Increase for slow devices or apps with animations
- Decrease for fast devices or when speed is critical

### Scripter Configuration

Configure off-device Python execution:

```yaml
agent:
  scripter:
    enabled: true  # Enable scripter agent
    max_steps: 10  # Maximum scripter execution steps
    execution_timeout: 30.0  # Timeout per code block (seconds)
    system_prompt_path: system.jinja2
    safe_execution: false  # Enable safe execution mode
```

**Use cases:**
- Complex calculations or data processing
- API calls or web scraping
- File operations (reading, parsing, etc.)

**When scripter is triggered:**

Manager agent can delegate to scripter using `<script>` tags:

```xml
<script>
import requests
response = requests.get("https://api.example.com/data")
result = response.json()["value"]
</script>
```

---

## Safe Execution

Safe execution restricts code execution to prevent dangerous operations. It applies to **CodeAct** and **Scripter** agents.

### Overview

When `safe_execution: true`:
- Imports are restricted to allowed modules
- Builtins are restricted to safe operations
- Dangerous operations (file I/O, subprocess, eval) are blocked

### Configuration

```yaml
safe_execution:
  # === Import Control ===
  allow_all_imports: false  # Allow all imports (dangerous!)
  allowed_modules:
    - json
    - requests
    - re
    - datetime
    - math
    - collections
  blocked_modules:
    - os
    - sys
    - subprocess
    - shutil
    - socket

  # === Builtin Control ===
  allow_all_builtins: false  # Allow all builtins (dangerous!)
  allowed_builtins: []  # Empty = use safe defaults
  blocked_builtins:
    - open
    - exec
    - eval
    - __import__
    - compile
    - breakpoint
```

### Enabling Safe Execution

**Per agent:**

```yaml
agent:
  codeact:
    safe_execution: true  # Enable for CodeAct

  scripter:
    safe_execution: true  # Enable for Scripter
```

### Safe Defaults

When `allow_all_builtins: false` and `allowed_builtins: []`, DroidRun uses safe defaults:

**Safe builtins include:**
- Type constructors: `int`, `float`, `str`, `bool`, `list`, `dict`, `tuple`, `set`
- Iteration: `range`, `enumerate`, `zip`, `map`, `filter`, `sorted`
- Math: `abs`, `round`, `pow`, `sum`, `min`, `max`
- Type checking: `type`, `isinstance`, `callable`
- Output: `print`, `repr`, `format`
- Exceptions: `Exception`, `ValueError`, `TypeError`, etc.

**Blocked by default:**
- File I/O: `open`, `input`
- Code execution: `exec`, `eval`, `compile`, `__import__`
- System: `exit`, `quit`, `breakpoint`

### Custom Safe Execution

Allow specific modules for trusted use cases:

```yaml
safe_execution:
  allow_all_imports: false
  allowed_modules:
    - json          # Parse JSON
    - requests      # HTTP requests
    - re            # Regex
    - datetime      # Date/time
    - math          # Math operations
    - collections   # Data structures
    - itertools     # Iterator tools
    - functools     # Functional programming
  blocked_modules:
    - os            # Prevent file system access
    - subprocess    # Prevent process execution
    - socket        # Prevent network sockets
    - sys           # Prevent system access
```

### Dangerous: Allow All

<Warning>
**Only use this in trusted environments!** Allows arbitrary code execution.
</Warning>

```yaml
safe_execution:
  allow_all_imports: true   # Allow ANY import
  allow_all_builtins: true  # Allow ANY builtin
  blocked_modules:          # Still block these (recommended)
    - os
    - subprocess
```

---

## Prompt Customization

DroidRun uses Jinja2 templates for agent prompts. You can customize prompts to change agent behavior.

### Prompt Directory Structure

```
config/prompts/
├── codeact/
│   ├── system.jinja2
│   └── user.jinja2
├── manager/
│   ├── system.jinja2
│   └── rev1.jinja2
├── executor/
│   ├── system.jinja2
│   └── rev1.jinja2
└── scripter/
    └── system.jinja2
```

### Prompt Configuration

Specify prompt files in config:

```yaml
agent:
  prompts_dir: config/prompts  # Base directory

  codeact:
    system_prompt: system.jinja2  # codeact/system.jinja2
    user_prompt: user.jinja2      # codeact/user.jinja2

  manager:
    system_prompt: system.jinja2  # manager/system.jinja2

  executor:
    system_prompt: system.jinja2  # executor/system.jinja2

  scripter:
    system_prompt_path: system.jinja2  # scripter/system.jinja2
```

### Custom Prompts

Create custom prompt files:

```sh
mkdir -p config/prompts/manager
touch config/prompts/manager/custom.jinja2
```

**config.yaml:**

```yaml
agent:
  manager:
    system_prompt: custom.jinja2  # Use custom prompt
```

### Prompt Variables

Prompts support Jinja2 template variables:

**Example prompt:**

```jinja2
You are an agent operating an Android phone.

<user_request>
{{ instruction }}
</user_request>

{% if device_date %}
<device_date>
{{ device_date }}
</device_date>
{% endif %}

{% if app_card %}
<app_card>
{{ app_card }}
</app_card>
{% endif %}
```

**Available variables:**
- `instruction` - User's goal/command
- `device_date` - Current device date/time
- `app_card` - App-specific guidance (if available)
- `state` - Current device state (accessibility tree)
- `history` - Action history

---

## Path Resolution

DroidRun uses a unified path resolution system for all file operations.

### Resolution Order

For relative paths, DroidRun searches:

1. **Working directory**: `./path/to/file`
2. **Package directory**: `<droidrun-package>/path/to/file`

Absolute paths are used as-is.

### Examples

```yaml
agent:
  # Relative paths (checks working dir, then package dir)
  prompts_dir: config/prompts

  app_cards:
    app_cards_dir: config/app_cards

credentials:
  file_path: credentials.yaml

# Absolute paths (used as-is)
agent:
  prompts_dir: /home/user/my_prompts
  app_cards:
    app_cards_dir: /opt/droidrun/app_cards
```

### Custom Paths

**Working directory structure:**

```
my_project/
├── config.yaml
├── config/
│   ├── prompts/
│   │   ├── manager/
│   │   └── executor/
│   └── app_cards/
│       ├── app_cards.json
│       └── gmail.md
└── credentials.yaml
```

All paths resolve from working directory first, falling back to package directory.

---

## CLI Override Patterns

CLI flags take precedence over config file settings.

### Common Overrides

```sh
# Override max steps
droidrun run "Open settings" --steps 30

# Enable reasoning mode
droidrun run "Complex task" --reasoning

# Enable vision for all agents
droidrun run "Find the cat" --vision

# Enable debug logging
droidrun run "Test command" --debug

# Save action-level trajectory
droidrun run "Perform task" --save-trajectory action

# Enable tracing
droidrun run "Debug issue" --tracing

# Override device
droidrun run "Open settings" --device 192.168.1.100:5555

# Use TCP communication
droidrun run "Open settings" --tcp

# Custom config file
droidrun run "Open settings" --config /path/to/config.yaml
```

### LLM Overrides

```sh
# Override provider and model (applies to ALL agents)
droidrun run "Open settings" \
  --provider GoogleGenAI \
  --model models/gemini-2.5-flash

# Override temperature
droidrun run "Open settings" --temperature 0.5

# Use Ollama locally
droidrun run "Open settings" \
  --provider Ollama \
  --model llama3.3:70b \
  --base_url http://localhost:11434

# Use OpenRouter
droidrun run "Open settings" \
  --provider OpenAILike \
  --model anthropic/claude-3.7-sonnet \
  --api_base https://openrouter.ai/api/v1
```

### SDK Override Pattern (Recommended)

For SDK users, override configuration by modifying DroidRunConfig:

```python
from droidrun import DroidAgent
from droidrun.config_manager.config_manager import DroidRunConfig

# Load config
config = DroidRunConfig.from_yaml("config.yaml")

# Override settings before passing to DroidAgent
config.agent.manager.vision = True
config.agent.executor.vision = True
config.agent.codeact.vision = True
config.agent.reasoning = True
config.agent.max_steps = 30
config.tracing.enabled = True

# Pass modified config to DroidAgent
agent = DroidAgent(goal="Complex task", config=config)
handler = agent.run()
result: ResultEvent = await handler
```

**Alternative: Override via DroidAgent parameters:**

```python
from droidrun import DroidAgent
from droidrun.config_manager.config_manager import DroidRunConfig, AgentConfig

config = DroidRunConfig.from_yaml("config.yaml")

# Override specific configs via DroidAgent parameters
agent = DroidAgent(
    goal="Complex task",
    config=config,  # Base config
    agent_config=AgentConfig(max_steps=30, reasoning=True),  # Override
)
```

### CLI Override Pattern (Internal Use Only)

<Warning>
**For DroidRun maintainers only**: CLI overrides use `ConfigManager` singleton internally. SDK users should NOT use ConfigManager - use DroidRunConfig as shown above.
</Warning>

CLI overrides work via direct mutation of ConfigManager:

```python
# INTERNAL CLI USE ONLY - DO NOT USE IN YOUR CODE
from droidrun.config_manager import ConfigManager

# ConfigManager is a singleton used by CLI
config_manager = ConfigManager()
config = config_manager.config  # Returns DroidRunConfig

# CLI mutates config directly (bypasses thread safety after lock release)
if vision is not None:
    config.agent.manager.vision = vision
    config.agent.executor.vision = vision
    config.agent.codeact.vision = vision
```

---

## Best Practices

### 1. Version Control Config

Store `config.yaml` in version control:

```sh
git add config.yaml
git commit -m "Update LLM profiles"
```

**Exclude sensitive data:**

```gitignore
# .gitignore
credentials.yaml
.env
```

### 2. Use Environment Variables for API Keys

Never hardcode API keys in config:

```yaml
# DON'T do this
llm_profiles:
  manager:
    kwargs:
      api_key: sk-abc123  # BAD!

# DO this instead
# Set environment variable:
# export GOOGLE_API_KEY=your-key-here
```

LlamaIndex automatically reads API keys from environment variables.

### 3. Profile Naming

Use consistent profile names:

```yaml
llm_profiles:
  manager:          # Planning agent
  executor:         # Action agent
  codeact:          # Direct execution
  text_manipulator: # Text editing
  app_opener:       # App launching
  scripter:         # Off-device code
  structured_output: # Data extraction
```

These names are used throughout DroidRun and must match exactly.

### 4. Test Configuration Changes

Validate config after changes:

```python
from droidrun.config_manager.config_manager import DroidRunConfig

config = DroidRunConfig.from_yaml("config.yaml")

# Check values
print(f"Max steps: {config.agent.max_steps}")
print(f"Manager LLM: {config.llm_profiles['manager'].model}")

# Test LLM loading
from droidrun.agent.utils.llm_picker import load_llms_from_profiles

llms = load_llms_from_profiles(
    config.llm_profiles,
    profile_names=["manager"]
)
print(f"Manager LLM loaded: {llms['manager']}")
```

### 5. Validate Config

Validate configuration before using:

```python
from droidrun.config_manager.config_manager import DroidRunConfig

def validate_config(config):
    """Custom validation logic."""
    if config.agent.max_steps < 5:
        raise ValueError("max_steps must be at least 5")

    if config.agent.reasoning and not config.agent.manager.vision:
        print("Warning: Reasoning mode works best with manager vision enabled")

# Load and validate
config = DroidRunConfig.from_yaml("config.yaml")
validate_config(config)

# Config is validated, safe to use
from droidrun import DroidAgent
agent = DroidAgent(goal="Task", config=config)
```

### 6. Separate Environments

Use different configs for different environments:

```
project/
├── config.dev.yaml      # Development
├── config.staging.yaml  # Staging
└── config.prod.yaml     # Production
```

**Load specific config:**

```sh
droidrun run "Open settings" --config config.dev.yaml
```

Or use environment variable:

```sh
export DROIDRUN_CONFIG=config.prod.yaml
droidrun run "Open settings"
```

### 7. Document Custom Settings

Add comments to custom configurations:

```yaml
agent:
  max_steps: 30  # Increased for complex workflows

  manager:
    # Using Claude for best reasoning performance
    # Cost: ~$0.02 per task
    vision: true

llm_profiles:
  manager:
    provider: Anthropic
    model: claude-3-7-sonnet-latest
    # Temperature tuned for consistent planning
    temperature: 0.15
```

---

## Troubleshooting

### Config not found

**Problem:** `FileNotFoundError: config.yaml not found`

**Solution for SDK users:**
```python
from droidrun.config_manager.config_manager import DroidRunConfig
import yaml

# Create default config
config = DroidRunConfig()

# Save to file
with open("config.yaml", "w") as f:
    yaml.dump(config.to_dict(), f)
```

**Solution for CLI users:**
1. Run `droidrun devices` to generate default config
2. Or specify path: `droidrun run --config /path/to/config.yaml`

### CLI overrides not working

**Problem:** CLI flags don't seem to override config.

**Solution:**
- Ensure you're using the correct flag name
- Check CLI flag is before or after the command:
  ```sh
  # Correct
  droidrun run "Open settings" --vision

  # Also correct
  droidrun run --vision "Open settings"
  ```

### LLM not loading

**Problem:** `ModuleNotFoundError: llama_index.llms.google_genai`

**Solution:**
Install the required LlamaIndex integration:

```sh
pip install llama-index-llms-google-genai
# Or
pip install 'droidrun[google]'
```

### Invalid API key

**Problem:** Authentication errors when using LLMs.

**Solution:**
Set the correct environment variable:

```sh
# Google Gemini
export GOOGLE_API_KEY=your-key

# OpenAI
export OPENAI_API_KEY=your-key

# Anthropic
export ANTHROPIC_API_KEY=your-key

# DeepSeek
export DEEPSEEK_API_KEY=your-key
```

### Prompt file not found

**Problem:** `FileNotFoundError: Prompt file not found`

**Solution:**
1. Check `prompts_dir` path in config
2. Verify prompt file exists: `ls config/prompts/manager/system.jinja2`
3. Ensure correct filename in config (case-sensitive)

### Safe execution blocking needed imports

**Problem:** `ImportError: Module 'requests' is not allowed`

**Solution:**
Add module to allowed list:

```yaml
safe_execution:
  allowed_modules:
    - requests
    - json
    - re
```

Or disable safe execution (not recommended):

```yaml
agent:
  codeact:
    safe_execution: false
```

---

## Related Documentation

- [CLI Usage](/docs/v4/guides/cli) - DroidRun CLI command reference
- [App Cards](/docs/v4/guides/app-cards) - App-specific instruction cards
- [Agent Architecture](/docs/v3/concepts/agent) - How agents use configuration
- [LLM Integration](/docs/v3/concepts/models) - Supported LLM providers

---

**Master DroidRun configuration for complete control over agent behavior!**
