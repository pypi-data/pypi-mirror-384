# ----------------------------------------------------------------------------------------------------
# IBM Confidential
# Licensed Materials - Property of IBM
# 5737-H76, 5900-A3Q
# Â© Copyright IBM Corp. 2025  All Rights Reserved.
# US Government Users Restricted Rights - Use, duplication or disclosure restricted by
# GSA ADPSchedule Contract with IBM Corp.
# ----------------------------------------------------------------------------------------------------

from typing import Annotated, List, Optional, Type

from langchain.callbacks.manager import CallbackManagerForToolRun
from langchain.tools import BaseTool
from pydantic import BaseModel, Field, PrivateAttr

import ibm_watsonx_gov.tools.clients.detector_client as dc


class AnswerRelevanceInput(BaseModel):
    """
        Model that can be used for setting input args for answer relevance tool
    """
    input: Annotated[str,
                     Field(..., description="The original user input/question.")]
    generated_text: Annotated[str,
                     Field(..., description="The response generated by the LLM.")]
    threshold: Annotated[Optional[float], Field(
        0.7, description="Threshold for answer relevance detection, values range from 0.0 to 1.0")]
    
    
class AnswerRelevanceConfig(BaseModel):
    """
        Model that can be used for setting config args for answer relevance tool
    """
    threshold: Annotated[Optional[float], Field(
        0.7, description="Threshold for answer relevance detection, values range from 0.0 to 1.0")]


class AnswerRelevanceDetectorTool(BaseTool):
    """
    Tool to detect answer relevance for given input and response from LLM

    Examples:
        Basic usage
            .. code-block:: python

                answer_relevance_detector = class AnswerRelevanceDetectorTool(BaseTool)()
                answer_relevance_detector.invoke({"input":"<USER_INPUT>","generated_text":"<LLM response>"})
    """
    name: str = "answer_relevance_detector"
    description: str = (
        "Tool that analyzes whether the generated text meaningfully and directly addresses the user's input."\
        "It compares the user input and generated text to return a boolean flag and a numeric score indicating the degree of relevance.")
    args_schema: Type[BaseModel] = AnswerRelevanceInput

    _url: any = PrivateAttr()
    _threshold: any = PrivateAttr()

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        config = AnswerRelevanceConfig(**kwargs)
        self._threshold = config.threshold
        self._url = dc.DETECTIONS_GENRATE_URL.format(dc.get_base_url())

    # Define Answer relevace tool
    def _run(self,
             input: str,
             generated_text: str,
             run_manager: Optional[CallbackManagerForToolRun] = None,
             **kwargs) -> List[str]:
        """
        Sample Response:
            {
                "detections": [
                    {
                        "detection_type": "risk",
                        "detector_id": "granite_guardian_3_2_5b",
                        "score": 0.03726182132959366
                    }
                ],
                "is_answer_relevant":True
            }
        """
        threshold = kwargs.get("threshold",self._threshold)

        #set payload
        base_payload = dc.get_base_payload(dc.GRANITE_GUADIAN,
                                           detector_params={
                                                                "risk_name": "answer_relevance",
                                                                "threshold": 0.0
                                                            })
        ar_payload = {
            "prompt":input,
            "generated_text": generated_text
        }

        payload = {**base_payload,**ar_payload}
        detections_response = dc.call_detections(self._url, payload)

        #Remove unwanted properties
        detections = detections_response.get("detections",[])
        for detection in detections:
            detection.pop("detection",None)
        score = detections[0].get("score")

        #Propogate a boolen to get a intutive response
        is_answer_relevant = False if score > threshold else True

        detections_response["detections"] = detections
        detections_response["is_answer_relevant"] = is_answer_relevant
        return detections_response
    
    async def _arun(self,
                    input: str,
                    generated_text: str,
                    run_manager: Optional[CallbackManagerForToolRun] = None,
                    **kwargs) -> List[str]:
        
        return self._run(input , generated_text, kwargs)
