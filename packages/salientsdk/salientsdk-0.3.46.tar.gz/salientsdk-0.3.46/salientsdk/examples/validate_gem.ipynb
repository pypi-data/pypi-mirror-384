{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate GEM Skill\n",
    "\n",
    "This example shows how to evaluate Salient's native daily GEM forecasts and calculate meaningful metrics. It demonstrates [validation best practices](https://salientpredictions.notion.site/Validation-0220c48b9460429fa86f577914ea5248) such as:\n",
    "\n",
    "- Proper scoring using the Ensemble Continuous Ranked Probability Score (CRPS)\n",
    "- Considers the full forecast distribution to reward both accuracy and precision\n",
    "- Less sensitive to climatology decisions than metrics like Anomaly Correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<requests.sessions.Session at 0x7fab7a6ff2d0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from reprlib import repr as rrepr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import salientsdk as sk\n",
    "except ModuleNotFoundError as e:\n",
    "    if os.path.exists(\"../salientsdk\"):\n",
    "        sys.path.append(os.path.abspath(\"..\"))\n",
    "        import salientsdk as sk\n",
    "    else:\n",
    "        raise ModuleNotFoundError(\"Install salient SDK with: pip install salientsdk\")\n",
    "\n",
    "# Prevent wrapping on tables for readability\n",
    "pd.set_option(\"display.width\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.expand_frame_repr\", False)\n",
    "\n",
    "sk.set_file_destination(\"validate_gem_example\")\n",
    "sk.login(\"SALIENT_USERNAME\", \"SALIENT_PASSWORD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize The Validation\n",
    "\n",
    "This notebook is written flexibly so you have the option of validating Salient and other forecasts multiple ways. These variables will control what, when, and how the validation proceeds.\n",
    "\n",
    "More information on available hindcast dates is available in the [salient documentation](https://salientpredictions.notion.site/Hindcasts-18fc9d5a921b8073a781e599e6d46be3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. The meteorological variable that we'll be evaluating:\n",
    "var = \"tmax\"\n",
    "# var = \"tmin\"\n",
    "\n",
    "# 2. Set the number of forecast samples to download:\n",
    "(start_date, end_date) = (\"2020-10-16\", \"2025-04-04\")\n",
    "count_date = 4  # Get a few date samples from the range for a fast proof-of-concept\n",
    "# count_date = 128  # Get a healthy range of samples for a good but quick test\n",
    "# count_date = None # get all available date samples (N=1632) from the date range for a comprehensive test\n",
    "\n",
    "# 3. The reference model to compare Salient GEM to\n",
    "# ref_model = None  # skip the reference model comparison\n",
    "ref_model = \"noaa_gefs\"\n",
    "# ref_model = \"ecmwf_ens\"\n",
    "# ref_model = \"gem\"  # Good for conparing GEM debiased to GEM native\n",
    "\n",
    "# 4. Specify the source of \"truth\"\n",
    "# debias = False  # Native ERA5-based model predictions\n",
    "debias = True  # Debias to station data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast dates to test [4]: ['2020-10-16', '2022-04-12', '2023-10-08', '2025-04-04']\n"
     ]
    }
   ],
   "source": [
    "# ===== Additional shared variables ==========================\n",
    "# Not recommended to change these.\n",
    "\n",
    "force = False  # Cache data to save on repeat API calls\n",
    "verbose = False  # Show diagnostic details\n",
    "gem_model = \"gem\"\n",
    "leads = {\"noaa_gefs\": 35, \"ecmwf_ens\": 46}.get(ref_model, 50)\n",
    "freq = \"daily\"\n",
    "figsize = (8, 5)  # Make all figures have a consistent size\n",
    "\n",
    "poc_warn = f\"INDICATIVE (N={count_date}) \" if count_date < 128 else \"\"\n",
    "gem_name = (\"Debiased \" if debias else \"\") + gem_model.replace(\"_\", \" \").upper()\n",
    "ref_name = \"\" if ref_model is None else ref_model.replace(\"_\", \" \").upper()\n",
    "\n",
    "# Determine which dates for which to request forecasts:\n",
    "if ref_model == \"ecmwf_ens\":\n",
    "    date_range = sk.get_hindcast_dates(\n",
    "        start_date=start_date, end_date=end_date, timescale=ref_model, extend=True\n",
    "    )\n",
    "    date_range = pd.to_datetime(date_range)\n",
    "else:\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq=\"D\")\n",
    "\n",
    "if count_date is not None and len(date_range) > count_date:\n",
    "    date_range = date_range[np.linspace(0, len(date_range) - 1, count_date, dtype=int)]\n",
    "\n",
    "date_range = date_range.strftime(\"%Y-%m-%d\").tolist()\n",
    "\n",
    "print(f\"Forecast dates to test [{len(date_range)}]: {rrepr(date_range)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the Area of Interest\n",
    "\n",
    "The Salient SDK uses a \"Location\" object to specify the geographic bounds of a request. In this case, we will be validating against the vector of airport locations.  If you have a list of locations already defined in a separate CSV file, you can use [`upload_file`](https://sdk.salientpredictions.com/api/#salientsdk.upload_file) to upload the file directly without building it in code via `upload_location_file`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        lat        lon name        ghcnd          description                     geometry\n",
      "0  40.77945  -73.88027  LGA  USW00014732  New York La Guardia   POINT (-73.88027 40.77945)\n",
      "1  36.07190 -115.16343  LAS  USW00023169   Las Vegas McCarran   POINT (-115.16343 36.0719)\n",
      "2  29.98438  -95.36072  IAH  USW00012960  Houston-George Bush   POINT (-95.36072 29.98438)\n",
      "3  38.50659 -121.49604  SAC  USW00023232      Sacramento Exec  POINT (-121.49604 38.50659)\n",
      "4  37.61970 -122.36560  SFO  USW00023234   San Francisco Intl    POINT (-122.3656 37.6197)\n",
      "5  25.78810  -80.31690  MIA  USW00012839           Miami Intl     POINT (-80.3169 25.7881)\n",
      "6  40.77060 -111.96500  SLC  USW00024127  Salt Lake City Intl     POINT (-111.965 40.7706)\n",
      "7  21.32390 -157.93940  HNL  USW00022521        Honolulu Intl    POINT (-157.9394 21.3239)\n"
     ]
    }
   ],
   "source": [
    "# fmt: off\n",
    "loc = sk.Location(location_file=sk.upload_location_file(\n",
    "        lats =[40.77945     ,      36.07190,      29.98438,      38.50659,      37.61970,      25.78810,      40.77060,      21.32390],\n",
    "        lons =[-73.88027    ,    -115.16343,     -95.36072,    -121.49604,    -122.36560,     -80.31690,    -111.96500,    -157.93940],\n",
    "        names=[\"LGA\"        ,         \"LAS\",         \"IAH\",         \"SAC\",         \"SFO\",         \"MIA\",         \"SLC\",         \"HNL\"],\n",
    "        ghcnd=[\"USW00014732\", \"USW00023169\", \"USW00012960\", \"USW00023232\", \"USW00023234\", \"USW00012839\", \"USW00024127\", \"USW00022521\"],\n",
    "        geoname=\"validate_stations\",\n",
    "        force=True,\n",
    "        description=[\"New York La Guardia\", \"Las Vegas McCarran\", \"Houston-George Bush\", \"Sacramento Exec\", \"San Francisco Intl\", \"Miami Intl\", \"Salt Lake City Intl\", \"Honolulu Intl\"],\n",
    "    ))\n",
    "# fmt: on\n",
    "stations = loc.load_location_file()\n",
    "print(stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect station locations\n",
    "\n",
    "If we're testing debiasing, we want to validate that that debiasing will use the expected stations.\n",
    "This is optional.  If you have modified the location list and not supplied a list of reference stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Name Source      Station                  Description  Latitude  Longitude       Start         End Location ID  Requested Latitude  Requested Longitude  Distance (km)\n",
      "0  efa5deba  ghcnd  USW00014732                 LAGUARDIA AP   40.7794   -73.8803  1990-01-01  2025-08-12         LGA            40.77945            -73.88027       0.006103\n",
      "1  3b734ff2  ghcnd  USW00023169             MCCARRAN INTL AP   36.0719  -115.1633  1990-01-01  2025-08-12         LAS            36.07190           -115.16343       0.011711\n",
      "2  d192c788  ghcnd  USW00012960  HOUSTON INTERCONTINENTAL AP   29.9844   -95.3608  1990-01-01  2025-08-12         IAH            29.98438            -95.36072       0.008032\n",
      "3  a6fe33bd  ghcnd  USW00023232           SACRAMENTO AP ASOS   38.5067  -121.4961  1990-01-01  2025-08-12         SAC            38.50659           -121.49604       0.013285\n",
      "4  197b383e  ghcnd  USW00023234        SAN FRANCISCO INTL AP   37.6197  -122.3656  1990-01-01  2025-08-12         SFO            37.61970           -122.36560       0.000000\n",
      "5  c0c6397b  ghcnd  USW00012839                MIAMI INTL AP   25.7881   -80.3169  1990-01-01  2025-08-12         MIA            25.78810            -80.31690       0.000000\n",
      "6  f23d06e8  ghcnd  USW00024127       SALT LAKE CITY INTL AP   40.7706  -111.9650  1990-01-01  2025-08-12         SLC            40.77060           -111.96500       0.000000\n",
      "7  ec4f25b3  ghcnd  USW00022521             HONOLULU INTL AP   21.3239  -157.9394  1990-01-01  2025-08-12         HNL            21.32390           -157.93940       0.000000\n"
     ]
    }
   ],
   "source": [
    "if debias:\n",
    "    found_stations = pd.read_csv(\n",
    "        sk.met_stations(\n",
    "            loc=loc,\n",
    "            variables=\"tmax\" if var in [\"cdd\", \"hdd\"] else var,\n",
    "            force=force,\n",
    "            max_distance=40,\n",
    "        )\n",
    "    )\n",
    "    pd.testing.assert_series_equal(found_stations.Station, stations.ghcnd, check_names=False)\n",
    "    print(found_stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Forecasts\n",
    "\n",
    "The [`forecast_timeseries`](https://api.salientpredictions.com/v2/documentation/api/#/Forecasts/forecast_timeseries) API endpoint and SDK function gets a forecast from a particular forecast date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 899kB\n",
      "Dimensions:        (forecast_date: 4, lead: 35, location: 8, ensemble: 200)\n",
      "Coordinates:\n",
      "  * forecast_date  (forecast_date) datetime64[ns] 32B 2020-10-16 ... 2025-04-04\n",
      "  * ensemble       (ensemble) int64 2kB 0 1 2 3 4 5 ... 194 195 196 197 198 199\n",
      "    lat            (location) float64 64B dask.array<chunksize=(8,), meta=np.ndarray>\n",
      "    lon            (location) float64 64B dask.array<chunksize=(8,), meta=np.ndarray>\n",
      "  * location       (location) <U3 96B 'LGA' 'LAS' 'IAH' ... 'MIA' 'SLC' 'HNL'\n",
      "  * lead           (lead) timedelta64[ns] 280B 1 days 2 days ... 34 days 35 days\n",
      "    time           (forecast_date, lead) datetime64[ns] 1kB 2020-10-16 ... 20...\n",
      "Data variables:\n",
      "    vals_ens       (forecast_date, lead, location, ensemble) float32 896kB dask.array<chunksize=(1, 35, 8, 200), meta=np.ndarray>\n",
      "Attributes:\n",
      "    debias:   true\n"
     ]
    }
   ],
   "source": [
    "fcst_args = dict(\n",
    "    loc=loc,\n",
    "    variable=var,\n",
    "    debias=debias,\n",
    "    field=\"vals_ens\",\n",
    "    date=date_range,\n",
    "    timescale=freq,\n",
    "    leads=leads,\n",
    "    verbose=verbose,\n",
    "    force=force,\n",
    "    strict=False,  # if one downscale call fails, proceed with others\n",
    ")\n",
    "gem_src = sk.forecast_timeseries(model=gem_model, **fcst_args)\n",
    "gem = sk.stack_forecast(gem_src, compute=False)\n",
    "print(gem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 4MB\n",
      "Dimensions:        (forecast_date: 128, lead: 35, location: 8, ensemble: 31)\n",
      "Coordinates:\n",
      "  * forecast_date  (forecast_date) datetime64[ns] 1kB 2020-10-16 ... 2025-04-04\n",
      "  * ensemble       (ensemble) int64 248B 0 1 2 3 4 5 6 ... 24 25 26 27 28 29 30\n",
      "  * lead           (lead) timedelta64[ns] 280B 1 days 2 days ... 34 days 35 days\n",
      "    lat            (location) float64 64B dask.array<chunksize=(8,), meta=np.ndarray>\n",
      "    lon            (location) float64 64B dask.array<chunksize=(8,), meta=np.ndarray>\n",
      "  * location       (location) <U3 96B 'LGA' 'LAS' 'IAH' ... 'MIA' 'SLC' 'HNL'\n",
      "    time           (forecast_date, lead) datetime64[ns] 36kB 2020-10-16 ... 2...\n",
      "Data variables:\n",
      "    vals_ens       (forecast_date, lead, location, ensemble) float32 4MB dask.array<chunksize=(1, 35, 8, 31), meta=np.ndarray>\n"
     ]
    }
   ],
   "source": [
    "if ref_model is not None:\n",
    "    if ref_model == \"gem\" or ref_model == \"ecmwf_ens\":\n",
    "        # If ref_model is GEM, the point is to compare debiased and native forecasts\n",
    "        # ECMWF_ENS does not support debiasing\n",
    "        fcst_args[\"debias\"] = False\n",
    "\n",
    "    ref_src = sk.forecast_timeseries(model=ref_model, **fcst_args)\n",
    "    ref = sk.stack_forecast(ref_src, compute=False)\n",
    "    print(ref)\n",
    "else:\n",
    "    ref = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Historical Truth\n",
    "\n",
    "Download daily historical values from [`data_timeseries`](https://sdk.salientpredictions.com/api/#salientsdk.data_timeseries) and [`met_observations`](https://api.salientpredictions.com/v2/documentation/api/#/Meteorological%20Stations/met_observations). When `debias=True` we will use met station observations as ground truth.  When `debias=False`, ERA5 historicals are considered truth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 5kB\n",
      "Dimensions:        (forecast_date: 4, lead: 35, location: 8)\n",
      "Coordinates:\n",
      "  * forecast_date  (forecast_date) datetime64[ns] 32B 2020-10-16 ... 2025-04-04\n",
      "  * location       (location) <U3 96B 'LGA' 'LAS' 'IAH' ... 'MIA' 'SLC' 'HNL'\n",
      "  * lead           (lead) timedelta64[ns] 280B 1 days 2 days ... 34 days 35 days\n",
      "Data variables:\n",
      "    vals_ens       (forecast_date, lead, location) float32 4kB dask.array<chunksize=(1, 35, 8), meta=np.ndarray>\n"
     ]
    }
   ],
   "source": [
    "hist_args = {\n",
    "    \"loc\": loc,\n",
    "    \"start\": np.datetime64(start_date) - np.timedelta64(5, \"D\"),\n",
    "    \"end\": np.datetime64(end_date) + np.timedelta64(leads + 1, \"D\"),\n",
    "    \"verbose\": verbose,\n",
    "    \"force\": force,\n",
    "}\n",
    "obs_src = sk.met_observations(variables=var, **hist_args)\n",
    "era_src = sk.data_timeseries(variable=var, field=\"vals\", **hist_args)\n",
    "\n",
    "\n",
    "obs = (\n",
    "    sk.stack_history(obs_src, forecast_date=gem.forecast_date, lead=gem.lead, compute=False)\n",
    "    .rename({var: \"vals_ens\"})\n",
    "    .reset_coords(drop=True)\n",
    ")\n",
    "era = (\n",
    "    sk.stack_history(era_src, forecast_date=gem.forecast_date, lead=gem.lead, compute=False)\n",
    "    .rename({\"vals\": \"vals_ens\"})\n",
    "    .reset_coords(drop=True)\n",
    ")\n",
    "print(obs if debias else era)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some locations (like HNL and SAC) can have significant disagreements between ERA5 and station observations.  The more consistent bias, the more headroom the debiaser has to improve forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debias:\n",
    "    err = (era - obs)[\"vals_ens\"].mean(dim=[\"forecast_date\", \"lead\"])\n",
    "    err = err.sortby(err, ascending=False)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.bar(err.location.values, err.values)\n",
    "    plt.title(\"Bias: ERA5 - Station Observations\")\n",
    "    plt.ylabel(f\"{era.attrs['long_name']} [{era.attrs['units']}]\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Forecast Skill Metrics\n",
    "\n",
    "Compare the forecast and ERA5 datasets to see how well they match. Here we will calculate the same \"Continuous Ranked Probability Score\" that resulted from the call to `hindcast_summary` earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 7kB\n",
      "Dimensions:        (forecast_date: 4, lead: 35, location: 8)\n",
      "Coordinates:\n",
      "  * forecast_date  (forecast_date) datetime64[ns] 32B 2020-10-16 ... 2025-04-04\n",
      "  * location       (location) <U3 96B 'LGA' 'LAS' 'IAH' ... 'MIA' 'SLC' 'HNL'\n",
      "  * lead           (lead) timedelta64[ns] 280B 1 days 2 days ... 34 days 35 days\n",
      "    lat            (location) float64 64B 40.78 36.07 29.98 ... 40.77 21.32\n",
      "    lon            (location) float64 64B -73.88 -115.2 -95.36 ... -112.0 -157.9\n",
      "    time           (forecast_date, lead) datetime64[ns] 1kB 2020-10-16 ... 20...\n",
      "Data variables:\n",
      "    crps_ens_all   (forecast_date, lead, location) float32 4kB 0.7379 ... 1.757\n",
      "    crps_ens       (lead, location) float32 1kB 1.408 1.804 1.929 ... 3.311 1.53\n",
      "Attributes:\n",
      "    debias:      true\n",
      "    short_name:  crps\n",
      "    long_name:   CRPS\n"
     ]
    }
   ],
   "source": [
    "skill_gem = sk.skill.crps_ensemble(observations=obs if debias else era, forecasts=gem)\n",
    "print(skill_gem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 7kB\n",
      "Dimensions:        (forecast_date: 4, lead: 35, location: 8)\n",
      "Coordinates:\n",
      "  * forecast_date  (forecast_date) datetime64[ns] 32B 2020-10-16 ... 2025-04-04\n",
      "  * location       (location) <U3 96B 'LGA' 'LAS' 'IAH' ... 'MIA' 'SLC' 'HNL'\n",
      "  * lead           (lead) timedelta64[ns] 280B 1 days 2 days ... 34 days 35 days\n",
      "    lat            (location) float64 64B 40.78 36.07 29.98 ... 40.77 21.32\n",
      "    lon            (location) float64 64B -73.88 -115.2 -95.36 ... -112.0 -157.9\n",
      "    time           (forecast_date, lead) datetime64[ns] 1kB 2020-10-16 ... 20...\n",
      "Data variables:\n",
      "    crps_ens_all   (forecast_date, lead, location) float32 4kB 0.03331 ... 4.795\n",
      "    crps_ens       (lead, location) float32 1kB 1.257 2.78 2.136 ... 4.047 3.521\n",
      "Attributes:\n",
      "    short_name:  crps\n",
      "    long_name:   CRPS\n"
     ]
    }
   ],
   "source": [
    "if ref is None:\n",
    "    print(\"No reference model, skipping relative skill calculation\")\n",
    "    skill_ref = None\n",
    "else:\n",
    "    # Skill of the reference model:\n",
    "    skill_ref = sk.skill.crps_ensemble(observations=obs if debias else era, forecasts=ref)\n",
    "    print(skill_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 7kB\n",
      "Dimensions:        (forecast_date: 4, location: 8, lead: 35)\n",
      "Coordinates:\n",
      "  * forecast_date  (forecast_date) datetime64[ns] 32B 2020-10-16 ... 2025-04-04\n",
      "  * location       (location) <U3 96B 'LGA' 'LAS' 'IAH' ... 'MIA' 'SLC' 'HNL'\n",
      "  * lead           (lead) timedelta64[ns] 280B 1 days 2 days ... 34 days 35 days\n",
      "    lat            (location) float64 64B 40.78 36.07 29.98 ... 40.77 21.32\n",
      "    lon            (location) float64 64B -73.88 -115.2 -95.36 ... -112.0 -157.9\n",
      "    time           (forecast_date, lead) datetime64[ns] 1kB 2020-10-16 ... 20...\n",
      "Data variables:\n",
      "    crpss_ens_all  (forecast_date, lead, location) float32 4kB -21.15 ... 0.6335\n",
      "    crpss_ens      (lead, location) float32 1kB -0.1208 0.3511 ... 0.1817 0.5654\n",
      "Attributes:\n",
      "    short_name:  crpss\n",
      "    long_name:   CRPSS\n"
     ]
    }
   ],
   "source": [
    "if ref is None:\n",
    "    print(\"No reference model, skipping relative comparison\")\n",
    "    skill_rel = None\n",
    "else:\n",
    "    # Relative skills score of Salient downscale vs the reference model:\n",
    "    skill_rel = sk.skill.crpss(forecast=skill_gem, reference=skill_ref)\n",
    "    print(skill_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "if skill_ref is not None:\n",
    "    skill_ref[f\"crps_ens\"].mean(\"location\", keep_attrs=True).plot(\n",
    "        ax=ax,\n",
    "        color=\"#FF7F00\",\n",
    "        linewidth=2,\n",
    "        label=ref_name,\n",
    "    )\n",
    "\n",
    "skill_gem[f\"crps_ens\"].mean(\"location\", keep_attrs=True).plot(\n",
    "    ax=ax,\n",
    "    color=\"dodgerblue\",\n",
    "    linewidth=2,\n",
    "    label=gem_name,\n",
    ")\n",
    "\n",
    "ax.xaxis.set_major_formatter(lambda x, pos: f\"{x/1e9/86400:.0f}\")\n",
    "ax.set_xlabel(\"Lead Time (days)\")\n",
    "ax.set_ylabel(f\"CRPS {gem.vals_ens.attrs['long_name']} [{gem.vals_ens.attrs['units']}]\")\n",
    "ax.set_title(f\"{poc_warn} All-locations Mean CRPS (lower is better)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if skill_rel is None:\n",
    "    print(\"Skipping relative skill boxplot\")\n",
    "else:\n",
    "    medians = skill_rel[f\"crpss_ens\"].median(\"lead\")\n",
    "    sorted_locations = medians.sortby(medians, ascending=False).location.values\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    df = skill_rel[f\"crpss_ens\"].to_pandas().melt(ignore_index=False)\n",
    "    ax.boxplot(\n",
    "        [df[df[\"location\"] == loc][\"value\"] for loc in sorted_locations],\n",
    "        tick_labels=sorted_locations,  # Updated parameter name\n",
    "        patch_artist=True,\n",
    "        showfliers=False,\n",
    "        medianprops=dict(color=\"black\"),\n",
    "        boxprops=dict(facecolor=\"dodgerblue\"),\n",
    "    )\n",
    "    ax.axhline(y=0, color=\"grey\", linestyle=\":\", zorder=0)\n",
    "    ax.set_xlabel(\"Location\")\n",
    "    ax.set_ylabel(f\"CRPSS {gem.vals_ens.attrs['long_name']}\")\n",
    "    ax.set_title(f\"{poc_warn} Relative Skill {gem_name} vs {ref_name} (higher is better)\")\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    ax.set_ylim(max(-1, ymin), min(1, ymax))\n",
    "    plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salientsdk-54A4kIpb-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
