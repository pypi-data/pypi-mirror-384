{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Forecast Skill vs. ERA5 or Observations\n",
    "\n",
    "This example shows how to evaluate Salient's probabilistic forecasts against observations and calculate meaningful metrics. It demonstrates [validation best practices](https://salientpredictions.notion.site/Validation-0220c48b9460429fa86f577914ea5248) such as:\n",
    "\n",
    "- Proper scoring using the Continuous Ranked Probability Score (CRPS)\n",
    "  - Considers the full forecast distribution to reward both accuracy and precision\n",
    "  - Less sensitive to climatology decisions than metrics like Anomaly Correlation\n",
    "- A long backtesting period (2015-2022)\n",
    "  - Short evaluation periods are subject to noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<requests.sessions.Session at 0x7f398ce778d0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the environment:\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "try:\n",
    "    import salientsdk as sk\n",
    "except ModuleNotFoundError as e:\n",
    "    if os.path.exists(\"../salientsdk\"):\n",
    "        sys.path.append(os.path.abspath(\"..\"))\n",
    "        import salientsdk as sk\n",
    "    else:\n",
    "        raise ModuleNotFoundError(\"Install salient SDK with: pip install salientsdk\")\n",
    "\n",
    "# Prevent wrapping on tables for readability\n",
    "pd.set_option(\"display.width\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.expand_frame_repr\", False)\n",
    "\n",
    "sk.set_file_destination(\"validation_example\")\n",
    "sk.login(\"SALIENT_USERNAME\", \"SALIENT_PASSWORD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize The Validation\n",
    "\n",
    "This notebook is written flexibly so you have the option of validating Salient and other forecasts multiple ways. These variables will control what, when, and how the validation proceeds.\n",
    "\n",
    "The `split_set` variable controls the amount of data to request via the `start_date` and `end_date` variables.\n",
    "\n",
    "- `sample` - a single season of data, good for quickly making sure that the mechanics of the process work.\n",
    "- `test` - gets data from 2015-2022, which is completely out-of-sample from model training. This requests a medium amount of data and is recommended for most validation processes.\n",
    "- `all` - gets data from 2000-2022, representing the full historical evaluation record. This will download quite a bit of data and is not recommended for most applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Set the meteorological variable that we'll be evaluating:\n",
    "var = \"temp\"  # temperature\n",
    "# var = \"precip\"  # precipitation\n",
    "# var = \"wspd\" # wind\n",
    "# var = \"tsi\" # solar\n",
    "\n",
    "# 2. Set the forecast look-ahead amount:\n",
    "timescale = \"sub-seasonal\"  # weeks 1-5\n",
    "# timescale = \"seasonal\"  # months 1-3\n",
    "# timescale = \"long-range\" # quarters 1-4\n",
    "\n",
    "# 3. Set the number of hindcasts to download for validation:\n",
    "split_set = \"sample\"  # fast demonstration of mechanics\n",
    "# split_set = \"test\"  # recommended to validate out-of-sample with hindcast_summary\n",
    "# split_set = \"all\"  # download every hindcast since 2000\n",
    "\n",
    "# 4. Set the reference model to compare Salient blend to\n",
    "ref_model = \"clim\"  # Climatology.  Works across all timescale values.\n",
    "# ref_model = \"noaa_gefs\"  # Valid for the sub-seasonal timescale\n",
    "# ref_model = \"ecmwf_ens\" # Valid for sub-seasonal timescale\n",
    "# ref_model = \"ecmwf_seas5\" # Valid for seasonal and long-range timescales\n",
    "\n",
    "# 5. Use meteorological station observations in validation:\n",
    "validate_obs = True  # Calculate skill of debiased forecast vs met stations\n",
    "# validate_obs = False  # Calculate skill of undebiased forecast vs ERA5\n",
    "\n",
    "# ===== Additional shared variables ==========================\n",
    "fld = \"vals\"  # Evaluate in absolute space, not anomaly\n",
    "model = \"blend\"  # Validate the primary Salient blend model\n",
    "force = False  # If \"False\", cache data calls.  Set to \"True\" to overwrite caches\n",
    "\n",
    "frequency = {\"sub-seasonal\": \"weekly\", \"seasonal\": \"monthly\", \"long-range\": \"quarterly\"}[timescale]\n",
    "(start_date, end_date) = {\n",
    "    \"sample\": (\"2021-04-01\", \"2021-08-31\"),\n",
    "    \"test\": (\"2015-01-01\", \"2022-12-31\"),\n",
    "    \"all\": (\"2000-01-01\", \"2022-12-31\"),\n",
    "}[split_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the Area of Interest\n",
    "\n",
    "The Salient SDK uses a \"Location\" object to specify the geographic bounds of a request. In this case, we will be validating against the vector of airport locations that are used to settle the Chicago Mercantile Exchange's Cooling and Heating Degree Day contracts. With `load_location_file` we can see that the file contains:\n",
    "\n",
    "- `lat` / `lon`: latitude and longitude of the met station, standard for a `location_file`\n",
    "- `name`: the 3-letter IATA airport code of the location, also `location_file` standard\n",
    "- `ghcnd`: the global climate network ID of the station, used to validate against observations. To customize this analysis for any set of observation stations, use the NCEI [stations list](https://www.ncei.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt).\n",
    "- `cme`: the CME code for the location used to create CDD/HDD strip codes.\n",
    "- `description`: full name of the airport\n",
    "\n",
    "If you have a list of locations already defined in a separate CSV file, you can use [`upload_file`](https://sdk.salientpredictions.com/api/#salientsdk.upload_file) to upload the file directly without building it in code via `upload_location_file`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         lat        lon name        ghcnd cme                description                     geometry\n",
      "0   33.62972  -84.44224  ATL  USW00013874   1         Atlanta Hartsfield   POINT (-84.44224 33.62972)\n",
      "1   42.36057  -71.00975  BOS  USW00014739   W               Boston Logan   POINT (-71.00975 42.36057)\n",
      "2   34.19966 -118.36543  BUR  USW00023152   P  Burbank-Glendale-Pasadena  POINT (-118.36543 34.19966)\n",
      "3   41.96017  -87.93164  ORD  USW00094846   2             Chicago O'Hare   POINT (-87.93164 41.96017)\n",
      "4   39.04443  -84.67241  CVG  USW00093814   3     Cincinnati (Covington)   POINT (-84.67241 39.04443)\n",
      "5   32.89744  -97.02196  DFW  USW00003927   5          Dallas-Fort Worth   POINT (-97.02196 32.89744)\n",
      "6   29.98438  -95.36072  IAH  USW00012960   R        Houston-George Bush   POINT (-95.36072 29.98438)\n",
      "7   36.07190 -115.16343  LAS  USW00023169   0         Las Vegas McCarran   POINT (-115.16343 36.0719)\n",
      "8   44.88523  -93.23133  MSP  USW00014922   Q         Minneapolis-StPaul   POINT (-93.23133 44.88523)\n",
      "9   40.77945  -73.88027  LGA  USW00014732   4        New York La Guardia   POINT (-73.88027 40.77945)\n",
      "10  39.87326  -75.22681  PHL  USW00013739   6               Philadelphia   POINT (-75.22681 39.87326)\n",
      "11  45.59578 -122.60919  PDX  USW00024229   7                   Portland  POINT (-122.60919 45.59578)\n",
      "12  38.50659 -121.49604  SAC  USW00023232   S            Sacramento Exec  POINT (-121.49604 38.50659)\n"
     ]
    }
   ],
   "source": [
    "# fmt: off\n",
    "loc = sk.Location(location_file=sk.upload_location_file(\n",
    "    lats =[33.62972     ,      42.36057,      34.19966,      41.96017,      39.04443,      32.89744,      29.98438,      36.07190,      44.88523,      40.77945,      39.87326,      45.59578,      38.50659],\n",
    "    lons =[-84.44224    ,     -71.00975,    -118.36543,     -87.93164,     -84.67241,     -97.02196,     -95.36072,    -115.16343,     -93.23133,     -73.88027,     -75.22681,    -122.60919,    -121.49604],\n",
    "    names=[\"ATL\"        ,         \"BOS\",         \"BUR\",         \"ORD\",         \"CVG\",         \"DFW\",         \"IAH\",         \"LAS\",         \"MSP\",         \"LGA\",         \"PHL\",         \"PDX\",         \"SAC\"],\n",
    "    ghcnd=[\"USW00013874\", \"USW00014739\", \"USW00023152\", \"USW00094846\", \"USW00093814\", \"USW00003927\", \"USW00012960\", \"USW00023169\", \"USW00014922\", \"USW00014732\", \"USW00013739\", \"USW00024229\", \"USW00023232\"],\n",
    "    cme  =[\"1\"          ,           \"W\",           \"P\",           \"2\",           \"3\",           \"5\",           \"R\",           \"0\",           \"Q\",           \"4\",           \"6\",           \"7\",           \"S\"],\n",
    "    geoname=\"cmeus\",\n",
    "    force=force,\n",
    "    description=[\"Atlanta Hartsfield\", \"Boston Logan\", \"Burbank-Glendale-Pasadena\", \"Chicago O'Hare\", \"Cincinnati (Covington)\",\"Dallas-Fort Worth\", \"Houston-George Bush\", \"Las Vegas McCarran\", \"Minneapolis-StPaul\", \"New York La Guardia\",\"Philadelphia\", \"Portland\", \"Sacramento Exec\"],\n",
    "))\n",
    "# fmt: on\n",
    "stations = loc.load_location_file()\n",
    "print(stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull precomputed skill\n",
    "\n",
    "Salient pre-calculates skill metrics as part of our internal validation and model improvement process. Use the `hindcast_summary` api endpoint to request pre-calculated skill scores. This is the \"easy\" way to validate Salient's forecasts: we've already done all the work for you.\n",
    "\n",
    "The remainder of this notebook will show you how to reproduce this skill calculation by requesting historical forecasts, historical data, and calculating a skill score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Reference CRPS (°C)  Salient CRPS (°C)  Salient CRPS Skill Score (%)\n",
      "Location Lead                                                                        \n",
      "ATL      Week 1                1.522              0.476                        68.705\n",
      "         Week 2                1.521              1.063                        30.122\n",
      "         Week 3                1.528              1.361                        10.951\n",
      "         Week 4                1.525              1.410                         7.512\n",
      "         Week 5                1.522              1.408                         7.504\n",
      "...                              ...                ...                           ...\n",
      "SAC      Week 1                1.218              0.487                        59.950\n",
      "         Week 2                1.225              0.889                        27.396\n",
      "         Week 3                1.225              1.087                        11.314\n",
      "         Week 4                1.228              1.119                         8.881\n",
      "         Week 5                1.231              1.118                         9.194\n",
      "\n",
      "[65 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "skill_summ = (\n",
    "    pd.read_csv(\n",
    "        sk.hindcast_summary(\n",
    "            loc=loc,\n",
    "            interp_method=\"linear\",\n",
    "            metric=\"crps\",\n",
    "            variable=var,\n",
    "            timescale=timescale,\n",
    "            reference=ref_model,\n",
    "            split_set=\"test\" if split_set == \"sample\" else split_set,\n",
    "            verbose=False,\n",
    "            force=force,\n",
    "        )\n",
    "    )\n",
    "    .round(decimals=3)\n",
    "    .drop(columns=[\"Reference Model\"])\n",
    "    .set_index([\"Location\", \"Lead\"])\n",
    "    .sort_index(level=[0, 1])\n",
    ")\n",
    "print(skill_summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_skill(\n",
    "    df: pd.DataFrame, col: str = \"Salient CRPS Skill Score (%)\", title: str = \"Skill\"\n",
    ") -> None:\n",
    "    \"\"\"Plot skill scores in a table.\"\"\"\n",
    "    df = df.reset_index()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for location in df[\"Location\"].unique():\n",
    "        subset = df[df[\"Location\"] == location]\n",
    "        plt.plot(subset[\"Lead\"], subset[col], label=location)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Lead\")\n",
    "    plt.ylabel(col)\n",
    "    plt.legend(title=\"Location\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_skill(skill_summ, title=f\"hindcast_summary crps {model} vs {ref_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical Data\n",
    "\n",
    "To calculate forecast skill, we will want to compare forecasts made in the past with actuals. There are two flavors of actual data: (1) The ERA5 reanalysis dataset and (2) point weather station observations.\n",
    "\n",
    "Salient's forecast natively predicts (1) ERA5, but contains a debiasing function to remove bias between ERA5 and (2) station observations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Historical ERA5 Data\n",
    "\n",
    "Download daily historical values from [`data_timeseries`](https://sdk.salientpredictions.com/api/#salientsdk.data_timeseries) and then aggregate to match the forecasts, so that we can ensure that all forecasts use the same dates.\n",
    "\n",
    "Also, get observed weather station data in the same format by downloading directly from NCEI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 23kB\n",
      "Dimensions:   (time: 198, location: 13)\n",
      "Coordinates:\n",
      "  * time      (time) datetime64[ns] 2kB 2021-03-27 2021-03-28 ... 2021-10-10\n",
      "    lat       (location) float64 104B 33.63 42.36 34.2 ... 39.87 45.6 38.51\n",
      "    lon       (location) float64 104B -84.44 -71.01 -118.4 ... -122.6 -121.5\n",
      "  * location  (location) <U3 156B 'ATL' 'BOS' 'BUR' 'ORD' ... 'PHL' 'PDX' 'SAC'\n",
      "Data variables:\n",
      "    vals      (time, location) float64 21kB 21.77 10.66 14.5 ... 12.31 16.97\n",
      "Attributes:\n",
      "    long_name:   2 metre temperature\n",
      "    units:       degC\n",
      "    clim_start:  1990-01-01\n",
      "    clim_end:    2019-12-31\n"
     ]
    }
   ],
   "source": [
    "# Get additional historical data beyond end_date to make sure we have enough\n",
    "# observed days to compare with the final forecast.\n",
    "duration = {\"sub-seasonal\": 8 * 5, \"seasonal\": 31 * 3, \"long-range\": 95 * 4}[timescale]\n",
    "hist = sk.data_timeseries(\n",
    "    loc=loc,\n",
    "    variable=var,\n",
    "    field=fld,\n",
    "    start=np.datetime64(start_date) - np.timedelta64(5, \"D\"),\n",
    "    end=np.datetime64(end_date) + np.timedelta64(duration, \"D\"),\n",
    "    frequency=\"daily\",\n",
    "    # reference_clim=\"30_yr\",  implicitly uses 30 yr climatology\n",
    "    verbose=False,\n",
    "    force=force,\n",
    ")\n",
    "print(xr.load_dataset(hist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast\n",
    "\n",
    "The [`forecast_timeseries`](https://sdk.salientpredictions.com/api/#salientsdk.forecast_timeseries) API endpoint and SDK function returns Salient's native temporally granular weekly/monthly/quarterly forecasts.\n",
    "\n",
    "This is the most heavyweight call in the notebook, since it's getting multiple historical forecasts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             file_name        date  model\n",
      "0    validation_example/forecast_timeseries_2080b77...  2021-04-01  blend\n",
      "1    validation_example/forecast_timeseries_d2f085b...  2021-04-01   clim\n",
      "2    validation_example/forecast_timeseries_3e8ae2d...  2021-04-04  blend\n",
      "3    validation_example/forecast_timeseries_cbd0d20...  2021-04-04   clim\n",
      "4    validation_example/forecast_timeseries_f8f2b29...  2021-04-07  blend\n",
      "..                                                 ...         ...    ...\n",
      "129  validation_example/forecast_timeseries_c8001f4...  2021-08-25   clim\n",
      "130  validation_example/forecast_timeseries_cce5434...  2021-08-28  blend\n",
      "131  validation_example/forecast_timeseries_b1e01ed...  2021-08-28   clim\n",
      "132  validation_example/forecast_timeseries_dcbf551...  2021-08-31  blend\n",
      "133  validation_example/forecast_timeseries_0547de0...  2021-08-31   clim\n",
      "\n",
      "[134 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# get_hindcast_dates is a utility that returns all valid hindcast initializations.\n",
    "date_range = sk.get_hindcast_dates(start_date=start_date, end_date=end_date, timescale=timescale)\n",
    "\n",
    "fcst = sk.forecast_timeseries(\n",
    "    loc=loc,\n",
    "    variable=var,\n",
    "    field=fld,\n",
    "    date=date_range,\n",
    "    timescale=timescale,\n",
    "    model=[model, ref_model],\n",
    "    reference_clim=\"30_yr\",  # this is the same climatology used by data_timeseries\n",
    "    debias=False,\n",
    "    verbose=False,\n",
    "    force=force,\n",
    "    strict=False,  # There is missing data in 2020.  Work around it.\n",
    ")\n",
    "print(fcst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 7kB\n",
      "Dimensions:                 (lead_weekly: 5, location: 13, quantiles: 23,\n",
      "                             nbnds: 2)\n",
      "Coordinates:\n",
      "    forecast_period_weekly  (lead_weekly, nbnds) datetime64[ns] 80B 2021-04-0...\n",
      "    forecast_date_weekly    datetime64[ns] 8B 2021-04-01\n",
      "  * lead_weekly             (lead_weekly) int64 40B 1 2 3 4 5\n",
      "  * quantiles               (quantiles) float64 184B 0.01 0.025 ... 0.975 0.99\n",
      "    lat                     (location) float64 104B 33.63 42.36 ... 45.6 38.51\n",
      "    lon                     (location) float64 104B -84.44 -71.01 ... -121.5\n",
      "  * location                (location) <U3 156B 'ATL' 'BOS' ... 'PDX' 'SAC'\n",
      "Dimensions without coordinates: nbnds\n",
      "Data variables:\n",
      "    vals_weekly             (lead_weekly, location, quantiles) float32 6kB 9....\n",
      "Attributes:\n",
      "    clim_period:  ['1990-01-01', '2019-12-31']\n",
      "    region:       north-america\n",
      "    short_name:   temp\n",
      "    timescale:    sub-seasonal\n"
     ]
    }
   ],
   "source": [
    "# Check to see if there are any missing forecasts:\n",
    "fcst_na = fcst[fcst[\"file_name\"].isna()]\n",
    "if not fcst_na.empty:\n",
    "    print(\"Missing forecast dates:\")\n",
    "    print(fcst_na)\n",
    "\n",
    "# Example forecast file is for a single model and a single forecast_date\n",
    "print(xr.load_dataset(fcst[\"file_name\"].values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Skill Metrics\n",
    "\n",
    "Compare the forecast and ERA5 datasets to see how well they match. Here we will calculate the same \"Continuous Ranked Probability Score\" that resulted from the call to `hindcast_summary` earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 42kB\n",
      "Dimensions:                 (forecast_date_weekly: 67, lead_weekly: 5,\n",
      "                             location: 13, nbnds: 2)\n",
      "Coordinates:\n",
      "    lat                     (location) float64 104B 33.63 42.36 ... 45.6 38.51\n",
      "    lon                     (location) float64 104B -84.44 -71.01 ... -121.5\n",
      "  * location                (location) <U3 156B 'ATL' 'BOS' ... 'PDX' 'SAC'\n",
      "  * lead_weekly             (lead_weekly) int64 40B 1 2 3 4 5\n",
      "  * forecast_date_weekly    (forecast_date_weekly) datetime64[ns] 536B 2021-0...\n",
      "    forecast_period_weekly  (forecast_date_weekly, lead_weekly, nbnds) datetime64[ns] 5kB ...\n",
      "Dimensions without coordinates: nbnds\n",
      "Data variables:\n",
      "    crps_weekly_all         (forecast_date_weekly, lead_weekly, location) float64 35kB ...\n",
      "    crps_weekly             (lead_weekly, location) float64 520B 0.3575 ... 0...\n"
     ]
    }
   ],
   "source": [
    "skill_model = sk.skill.crps(\n",
    "    observations=hist,\n",
    "    forecasts=fcst[fcst[\"model\"] == model],\n",
    ")\n",
    "print(skill_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `crps_weekly` value shows the average of all error values over the full date range. `crps_weekly_all` preserves the crps for each `forecast_date`, so we can also show that CRPS varies over time and has a seasonal component:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_model[f\"crps_{frequency}_all\"].mean(dim=f\"lead_{frequency}\").rolling(\n",
    "    **{\n",
    "        f\"forecast_date_{frequency}\": max(\n",
    "            1, int(len(skill_model[f\"forecast_date_{frequency}\"]) * 0.1)\n",
    "        )\n",
    "    },\n",
    "    center=True,\n",
    ").mean().plot(x=f\"forecast_date_{frequency}\", hue=\"location\", figsize=(12, 6))\n",
    "\n",
    "units = xr.load_dataset(hist).attrs[\"units\"]\n",
    "plt.title(\"Error varies over time\")\n",
    "plt.ylabel(f\"{model} crps {var} [{units}]\")\n",
    "plt.xlabel(\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also calculate the skill of the \"reference\" model for purposes of comparison:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 42kB\n",
      "Dimensions:                 (forecast_date_weekly: 67, lead_weekly: 5,\n",
      "                             location: 13, nbnds: 2)\n",
      "Coordinates:\n",
      "    lat                     (location) float64 104B 33.63 42.36 ... 45.6 38.51\n",
      "    lon                     (location) float64 104B -84.44 -71.01 ... -121.5\n",
      "  * location                (location) <U3 156B 'ATL' 'BOS' ... 'PDX' 'SAC'\n",
      "  * lead_weekly             (lead_weekly) int64 40B 1 2 3 4 5\n",
      "  * forecast_date_weekly    (forecast_date_weekly) datetime64[ns] 536B 2021-0...\n",
      "    forecast_period_weekly  (forecast_date_weekly, lead_weekly, nbnds) datetime64[ns] 5kB ...\n",
      "Dimensions without coordinates: nbnds\n",
      "Data variables:\n",
      "    crps_weekly_all         (forecast_date_weekly, lead_weekly, location) float64 35kB ...\n",
      "    crps_weekly             (lead_weekly, location) float64 520B 0.787 ... 1.147\n"
     ]
    }
   ],
   "source": [
    "skill_ref = sk.skill.crps(\n",
    "    observations=hist,\n",
    "    forecasts=fcst[fcst[\"model\"] == ref_model],\n",
    ")\n",
    "print(skill_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 77kB\n",
      "Dimensions:                 (source: 2, forecast_date_weekly: 67,\n",
      "                             lead_weekly: 5, location: 13, nbnds: 2)\n",
      "Coordinates:\n",
      "    lat                     (location) float64 104B 33.63 42.36 ... 45.6 38.51\n",
      "    lon                     (location) float64 104B -84.44 -71.01 ... -121.5\n",
      "  * location                (location) <U3 156B 'ATL' 'BOS' ... 'PDX' 'SAC'\n",
      "  * lead_weekly             (lead_weekly) int64 40B 1 2 3 4 5\n",
      "  * forecast_date_weekly    (forecast_date_weekly) datetime64[ns] 536B 2021-0...\n",
      "    forecast_period_weekly  (forecast_date_weekly, lead_weekly, nbnds) datetime64[ns] 5kB ...\n",
      "  * source                  (source) <U5 40B 'clim' 'blend'\n",
      "Dimensions without coordinates: nbnds\n",
      "Data variables:\n",
      "    crps_weekly_all         (source, forecast_date_weekly, lead_weekly, location) float64 70kB ...\n",
      "    crps_weekly             (source, lead_weekly, location) float64 1kB 0.787...\n"
     ]
    }
   ],
   "source": [
    "skills = xr.concat(\n",
    "    [\n",
    "        skill_ref.assign_coords(source=ref_model),\n",
    "        skill_model.assign_coords(source=model),\n",
    "    ],\n",
    "    dim=\"source\",\n",
    ")\n",
    "print(skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_model_skill(skills: xr.Dataset):\n",
    "    \"\"\"Show CRPS by lead, for 2 or more models.\"\"\"\n",
    "    skills[f\"crps_{frequency}\"].plot.line(\n",
    "        x=f\"lead_{frequency}\", hue=\"source\", col=\"location\", col_wrap=3, figsize=(10, 10)\n",
    "    )\n",
    "    plt.suptitle(f\"{var} CRPS\", fontsize=16)\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "compare_model_skill(skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Relative Skill\n",
    "\n",
    "CRPS shows skill without context. A \"skill score\" will compare two different skills to generate relative value. In the example below, we will compare the Salient blend with climatology (historical averages).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Reference CRPS  Salient CRPS  Salient CRPS Skill Score (%)\n",
      "Location Lead                                                              \n",
      "ATL      Week 1            0.79          0.36                          54.6\n",
      "         Week 2            0.73          0.69                           6.2\n",
      "         Week 3            0.69          0.75                          -8.2\n",
      "         Week 4            0.66          0.73                          -9.4\n",
      "         Week 5            0.66          0.77                         -15.7\n",
      "...                         ...           ...                           ...\n",
      "SAC      Week 1            1.13          0.44                          60.7\n",
      "         Week 2            1.19          0.91                          23.8\n",
      "         Week 3            1.18          1.03                          12.6\n",
      "         Week 4            1.17          0.97                          17.1\n",
      "         Week 5            1.15          0.97                          15.8\n",
      "\n",
      "[65 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "skill_score = sk.skill.crpss(forecast=skill_model, reference=skill_ref)\n",
    "\n",
    "# Represent the skill scores as a human-readable table of the same format as we generated\n",
    "# for the hindcast_summary results.\n",
    "skill_table = (\n",
    "    xr.merge(\n",
    "        [\n",
    "            (skill_ref[f\"crps_{frequency}\"].rename(\"Reference CRPS\")).round(2),\n",
    "            skill_model[f\"crps_{frequency}\"].rename(\"Salient CRPS\").round(2),\n",
    "            (skill_score[f\"crpss_{frequency}\"] * 100)\n",
    "            .rename(\"Salient CRPS Skill Score (%)\")\n",
    "            .round(1),\n",
    "        ]\n",
    "    )\n",
    "    .to_dataframe()\n",
    "    .reset_index()\n",
    "    .dropna(how=\"any\")\n",
    "    .drop(columns=[\"lat\", \"lon\"])\n",
    "    .rename(columns={\"location\": \"Location\", f\"lead_{frequency}\": \"Lead\"})\n",
    ")\n",
    "skill_table[\"Lead\"] = \"Week \" + skill_table[\"Lead\"].astype(str)\n",
    "skill_table.set_index([\"Location\", \"Lead\"], inplace=True)\n",
    "\n",
    "print(skill_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_skill(skill_summ, title=f\"manually-calculated crps {model} vs {ref_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare manually-calculated to pre-computed skill\n",
    "\n",
    "Now that we have a CRPS calculated manually as well as downloaded from `hindcast_summary` we can evaluate how close the two values are.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_merge = pd.merge(\n",
    "    skill_summ.add_prefix(\"Summary \"),\n",
    "    skill_table.add_prefix(\"Manual \"),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")\n",
    "\n",
    "print(skill_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize the manually-calculated skill score with the precomputed skill scores published by `hindcast_summary`.\n",
    "\n",
    "Note that when using `split_set = sample` the values won't match exactly. In this case we are plotting skill scores calculated from a single year of forecasts against the skill scores from the `test` set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_cols(col_name: str) -> None:\n",
    "    \"\"\"Plot manual and precalculated skill columns.\"\"\"\n",
    "    summary_col = f\"Summary {col_name}\"\n",
    "    manual_col = f\"Manual {col_name}\"\n",
    "\n",
    "    df = skill_merge.reset_index()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for location in df[\"Location\"].unique():\n",
    "        subset = df[df[\"Location\"] == location]\n",
    "        plt.scatter(subset[summary_col], subset[manual_col], label=location, s=100)\n",
    "\n",
    "    # Same limits for both axes\n",
    "    min_limit = min(df[summary_col].min(), df[manual_col].min())\n",
    "    max_limit = max(df[summary_col].max(), df[manual_col].max())\n",
    "    plt.xlim(min_limit, max_limit)\n",
    "    plt.ylim(min_limit, max_limit)\n",
    "    plt.plot(\n",
    "        [min_limit, max_limit], [min_limit, max_limit], color=\"gray\", linestyle=\"--\", linewidth=1\n",
    "    )\n",
    "    plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "    plt.title(f\"Summary vs Manual {col_name}\")\n",
    "    plt.xlabel(summary_col)\n",
    "    plt.ylabel(manual_col)\n",
    "    plt.legend(title=\"Location\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "\n",
    "    if split_set == \"sample\":\n",
    "        plt.text(\n",
    "            min_limit,\n",
    "            max_limit,\n",
    "            \"Results not expected to match for split_set = 'summary'.\\nUse split_set = 'test' for a full comparison.\",\n",
    "            fontsize=10,\n",
    "            verticalalignment=\"top\",\n",
    "            horizontalalignment=\"left\",\n",
    "            color=\"red\",\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "compare_cols(\"Salient CRPS Skill Score (%)\")\n",
    "# compare_cols(\"Salient CRPS\")\n",
    "# compare_cols(\"Reference CRPS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating vs Observation Station Data\n",
    "\n",
    "Get observed historical data from meteorological stations. In this case, we'll write a `get_ghcnd` function that downloads observed station data and returns a list of pandas `DataFrame`s. If you have observed data from a proprietary source, you can substitute a function here that returns a vector of `DataFrame`s. Make sure that the `DataFrame`s have a column that matches the `variable` of interest (such as `temp`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 12kB\n",
      "Dimensions:   (time: 198, location: 13)\n",
      "Coordinates:\n",
      "  * time      (time) datetime64[ns] 2kB 2021-03-27 2021-03-28 ... 2021-10-10\n",
      "  * location  (location) <U3 156B 'ATL' 'BOS' 'BUR' 'ORD' ... 'PHL' 'PDX' 'SAC'\n",
      "Data variables:\n",
      "    vals      (time, location) float32 10kB 22.8 10.55 16.1 ... 11.65 16.95\n",
      "Attributes:\n",
      "    long_name:   Average temperature at 2m\n",
      "    units:       degC\n",
      "    short_name:  temp\n"
     ]
    }
   ],
   "source": [
    "if validate_obs:\n",
    "    duration = {\"sub-seasonal\": 8 * 5, \"seasonal\": 31 * 3, \"long-range\": 95 * 4}[timescale]\n",
    "    obs_src = sk.met_observations(\n",
    "        loc=loc,\n",
    "        variables=var,\n",
    "        start=np.datetime64(start_date) - np.timedelta64(5, \"D\"),\n",
    "        end=np.datetime64(end_date) + np.timedelta64(duration, \"D\"),\n",
    "        verbose=False,\n",
    "        force=force,\n",
    "    )\n",
    "    # Reformat observations to match the output of data_timeseries:\n",
    "    obs = xr.load_dataset(obs_src).rename({var: \"vals\"})\n",
    "    obs = obs.assign_attrs(**obs.vals.attrs, short_name=var)\n",
    "\n",
    "    # Make sure that we found the expected set of stations:\n",
    "    assert obs.station.values.tolist() == stations.ghcnd.to_list()\n",
    "    # Lat-lon differences may complicate merging later:\n",
    "    obs = obs.reset_coords(drop=True)\n",
    "    print(obs)\n",
    "else:\n",
    "    print(\"skipped: not comparing to observed data\")\n",
    "    obs = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare observed and ERA5 datasets\n",
    "\n",
    "Via `make_observed_ds`, the observed station data (`obs`) is formatted the same as the ERA5 historical data (`hist`). This means we can easily compare one to the other and see the degree of bias that exists between the two.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 74kB\n",
      "Dimensions:    (time: 198, location: 13)\n",
      "Coordinates:\n",
      "  * time       (time) datetime64[ns] 2kB 2021-03-27 2021-03-28 ... 2021-10-10\n",
      "  * location   (location) <U3 156B 'ATL' 'BOS' 'BUR' 'ORD' ... 'PHL' 'PDX' 'SAC'\n",
      "    lat        (location) float64 104B 33.63 42.36 34.2 ... 39.87 45.6 38.51\n",
      "    lon        (location) float64 104B -84.44 -71.01 -118.4 ... -122.6 -121.5\n",
      "Data variables:\n",
      "    obs        (time, location) float32 10kB 22.8 10.55 16.1 ... 11.65 16.95\n",
      "    hist       (time, location) float64 21kB 21.77 10.66 14.5 ... 12.31 16.97\n",
      "    delta_raw  (time, location) float64 21kB 1.03 -0.1126 ... -0.662 -0.02339\n",
      "    delta      (time, location) float64 21kB nan nan nan nan ... nan nan nan nan\n",
      "Attributes:\n",
      "    long_name:   Average temperature at 2m\n",
      "    units:       degC\n",
      "    short_name:  temp\n"
     ]
    }
   ],
   "source": [
    "if validate_obs:\n",
    "    # Pull observed and ERA5 into a single dataset for easy comparison:\n",
    "    merged = xr.merge(\n",
    "        [\n",
    "            obs.rename({\"vals\": \"obs\"}),\n",
    "            xr.load_dataset(hist).rename({\"vals\": \"hist\"}),\n",
    "        ],\n",
    "        join=\"inner\",\n",
    "    )\n",
    "    merged[\"delta_raw\"] = merged[\"obs\"] - merged[\"hist\"]\n",
    "    # Daily bias is noisy.  Smooth it out to make trends clearer.\n",
    "    # This will induce nans at the beginning and end of the timeseries.\n",
    "    merged[\"delta\"] = (\n",
    "        merged[\"delta_raw\"]\n",
    "        .rolling(time=max(1, int(len(merged[\"time\"]) * 0.1)), center=True)\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "    print(merged)\n",
    "else:\n",
    "    print(\"skipped: not comparing to observed data\")\n",
    "    merged = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validate_obs:\n",
    "    # Visualize obs-era5 bias over time at each station\n",
    "    merged[\"delta\"].plot.line(x=\"time\", hue=\"location\")\n",
    "    plt.axhline(y=0, color=\"k\", linestyle=\"--\", alpha=0.5)\n",
    "    plt.title(\"Delta of Observed to Historical Values\")\n",
    "    plt.ylabel(f'{merged.attrs[\"long_name\"]} obs - hist [{merged.attrs[\"units\"]}]')\n",
    "    plt.xlabel(\"\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrate the need for station debiasing\n",
    "\n",
    "Salient's forecasts are trained to predict the ERA5 reanalysis. The bias between station observations and ERA5 means that native forecast skill will be lower than desired when compared to station observations. Let's calculate that undebiased skill so we can quantify the magnitude of the effect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validate_obs:\n",
    "    # Explicitly flag the native forecasts as undebiased:\n",
    "    fcst[\"debias\"] = False\n",
    "    skill_undebiased_obs = sk.skill.crps(\n",
    "        observations=obs,  # note that we're using observation stations as \"truth\"\n",
    "        forecasts=fcst[(fcst[\"model\"] == model) & (fcst[\"debias\"] == False)],\n",
    "    ).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases where there is not much bias between ERA5 and the observation station (Philadelphia, Cincinnati) we see that there is also not much difference in skill depending on the source of truth. In other locations like Boston or New York (LGA) we see that the difference between the observation station and ERA5 induces nontrivial skill degradation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validate_obs:\n",
    "    skills_obs = xr.concat(\n",
    "        [\n",
    "            skill_undebiased_obs.assign_coords(source=\"undebiased vs obs\"),\n",
    "            skill_model.assign_coords(source=\"undebiased vs ERA5\"),\n",
    "        ],\n",
    "        dim=\"source\",\n",
    "        coords=\"minimal\",\n",
    "    )\n",
    "\n",
    "    compare_model_skill(skills_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get debiased forecasts\n",
    "\n",
    "Salient's models natively predict ERA5 values, not observation station values. The `forecast_timeseries`, `data_timeseries`, and `downscale` functions have a `debias` option that adjusts ERA5-based data to more closely match obserations. Let's get a set of forecasts with debiasing on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get debiased hindcasts, if we are validating vs observations\n",
    "if validate_obs:\n",
    "    fcst_debias = sk.forecast_timeseries(\n",
    "        loc=loc,\n",
    "        variable=var,\n",
    "        field=fld,\n",
    "        date=date_range,\n",
    "        timescale=timescale,\n",
    "        model=model,  # debias only avilable for model blend\n",
    "        reference_clim=\"30_yr\",\n",
    "        debias=True,  # Note debias\n",
    "        verbose=False,\n",
    "        force=force,\n",
    "        strict=False,\n",
    "    )\n",
    "    # Add synthetic columns so that the two forecast tables can concatenate:\n",
    "    fcst_debias[\"model\"] = model\n",
    "    fcst_debias[\"debias\"] = True\n",
    "\n",
    "    fcst = pd.concat([fcst, fcst_debias], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare undebiased forecast skill to debiased\n",
    "\n",
    "Now quantify the effect of debiasing by calculating the skill of the debiased forecast against observation station data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validate_obs:\n",
    "    skill_debiased_obs = sk.skill.crps(\n",
    "        observations=obs,\n",
    "        forecasts=fcst[(fcst[\"model\"] == model) & (fcst[\"debias\"] == True)],\n",
    "    ).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of debiasing is to bring the debiased-obs forecast skill (green) as close as possible to the undebiased-era5 skill (orange).\n",
    "\n",
    "- Atlanta, Portland, Minneapolis, Philadelphia, and Sacramento have consistent offsets that result in near-perfect debiasing.\n",
    "- Boston, Burbank, and New York (LGA) see a significant reduction in error as a result of debiasing, but there is still some residual skill loss.\n",
    "- Chicago (ORD)'s observation-ERA5 offset is inconsistent, so the debiaser recovers limited skill.\n",
    "- Cincinnati (CVG) had little bias to begin with, so the debiaser doesn't change the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validate_obs:\n",
    "    skills_obs = xr.concat(\n",
    "        [\n",
    "            skill_undebiased_obs.assign_coords(source=\"undebiased vs obs\"),\n",
    "            skill_model.assign_coords(source=\"undebiased vs ERA5\"),\n",
    "            skill_debiased_obs.assign_coords(source=\"debiased vs obs\"),\n",
    "        ],\n",
    "        dim=\"source\",\n",
    "        coords=\"minimal\",\n",
    "    )\n",
    "\n",
    "    compare_model_skill(skills_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can attribute the incremental error of debiasing against observations. The relatively small size of the orange bars indicates that debiased (vs obs) forecasts are only slightly less skillful than the native (vs era5) forecasts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_skills = xr.concat(\n",
    "    [\n",
    "        skill_model.assign_coords(source=\"era5 forecast\"),\n",
    "        (skill_debiased_obs - skill_model).assign_coords(source=\"obs-era5\"),\n",
    "    ],\n",
    "    dim=\"source\",\n",
    "    coords=\"minimal\",\n",
    ").mean(dim=f\"lead_{frequency}\")[f\"crps_{frequency}\"]\n",
    "\n",
    "location_order = (\n",
    "    skill_debiased_obs.mean(dim=f\"lead_{frequency}\")\n",
    "    .sortby(f\"crps_{frequency}\", ascending=False)\n",
    "    .location\n",
    ")\n",
    "\n",
    "combined_skills.reindex(location=location_order).T.to_pandas().plot(\n",
    "    kind=\"bar\", stacked=True, figsize=(12, 6)\n",
    ")\n",
    "\n",
    "plt.ylabel(f\"CRPS {var} (all leads)\")\n",
    "plt.title(\"Error Contribution by Source\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salientsdk-54A4kIpb-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
