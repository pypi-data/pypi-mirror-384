# JEPA Configuration for Computer Vision Tasks
# Optimized for image data processing

# Model configuration
model:
  encoder_type: "cnn"              # CNN encoder for image data
  encoder_dim: 256                 # Reduced dimension for vision tasks
  predictor_type: "mlp"            # MLP predictor
  predictor_hidden_dim: 512        # Hidden dimension
  predictor_output_dim: 256        # Output dimension
  dropout: 0.1                     # Dropout rate

# Training configuration
training:
  batch_size: 64                   # Larger batch size for images
  learning_rate: 0.001             # Learning rate
  weight_decay: 0.0001             # Weight decay
  num_epochs: 100                  # Training epochs
  warmup_epochs: 5                 # Warmup epochs
  gradient_clip_norm: 1.0          # Gradient clipping
  save_every: 10                   # Save frequency
  early_stopping_patience: 15      # Early stopping patience
  log_interval: 50                 # Log every 50 batches

# Data configuration for images
data:
  train_data_path: ""              # Path to training images
  val_data_path: ""                # Path to validation images
  test_data_path: ""               # Path to test images
  num_workers: 8                   # More workers for image loading
  pin_memory: true                 # Pin memory for GPU efficiency
  sequence_length: 1               # Single images (no temporal sequence)
  input_dim: [3, 224, 224]         # RGB images, 224x224 resolution

# Weights & Biases logging configuration
wandb:
  enabled: false                   # Enable wandb logging
  project: "jepa-vision"           # Project name for vision tasks
  entity: null                     # Wandb entity
  name: null                       # Run name
  tags: ["vision", "cnn"]          # Tags for vision experiments
  notes: "JEPA for computer vision tasks"
  log_model: true                  # Log model artifacts
  log_gradients: false             # Log gradients
  log_freq: 50                     # More frequent logging for vision
  watch_model: true                # Watch model

# General configuration
device: "auto"                     # Auto-detect GPU/CPU
seed: 42                          # Random seed
output_dir: "./outputs"           # Output directory
checkpoint_dir: "./checkpoints"   # Checkpoint directory
experiment_name: "vision_jepa"    # Experiment name
