{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult Income Drift Analysis: Detecting Distribution Shifts\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/GlassAlpha/glassalpha/blob/main/examples/notebooks/adult_income_drift.ipynb)\n",
    "\n",
    "**Detect demographic shifts and their impact on model fairness**\n",
    "\n",
    "**Dataset**: Adult Income (48K samples) | **Protected Attributes**: Race, Sex, Age\n",
    "\n",
    "**Use Case**: Monitor how changes in population demographics affect model performance and fairness over time. Critical for production ML systems that must remain fair as populations evolve.\n",
    "\n",
    "**API Reference**: [`from_model()` documentation](https://glassalpha.com/reference/api/api-audit/) | [Drift Detection Guide](https://glassalpha.com/guides/drift-detection/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Installation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q glassalpha[explain,xgboost]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Environment verification for reproducibility\"\"\"\n",
    "import platform\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import glassalpha as ga\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(\n",
    "    {\n",
    "        \"python\": sys.version.split()[0],\n",
    "        \"platform\": platform.platform(),\n",
    "        \"glassalpha\": getattr(ga, \"__version__\", \"dev\"),\n",
    "        \"seed\": SEED,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Adult Income Dataset\n",
    "\n",
    "We'll use GlassAlpha's built-in Adult Income dataset loader.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Adult Income dataset\n",
    "df = ga.datasets.load_adult_income()\n",
    "\n",
    "print(f\"Dataset: {df.shape[0]} samples, {df.shape[1]} features\")\n",
    "print(f\"\\nIncome >50K rate: {(df['income_over_50k'] == 1).mean():.1%}\")\n",
    "print(\"\\nAge distribution:\")\n",
    "print(df[\"age\"].describe())\n",
    "print(\"\\nSex distribution:\")\n",
    "print(df[\"sex\"].value_counts())\n",
    "print(\"\\nRace distribution:\")\n",
    "print(df[\"race\"].value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Prepare Data\n",
    "\n",
    "Select features and encode categorical variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode categorical variables\n",
    "le_sex = LabelEncoder()\n",
    "le_race = LabelEncoder()\n",
    "le_workclass = LabelEncoder()\n",
    "le_education = LabelEncoder()\n",
    "le_marital = LabelEncoder()\n",
    "le_occupation = LabelEncoder()\n",
    "\n",
    "df[\"sex_encoded\"] = le_sex.fit_transform(df[\"sex\"])\n",
    "df[\"race_encoded\"] = le_race.fit_transform(df[\"race\"])\n",
    "df[\"workclass_encoded\"] = le_workclass.fit_transform(df[\"workclass\"])\n",
    "df[\"education_encoded\"] = le_education.fit_transform(df[\"education_level\"])\n",
    "df[\"marital_encoded\"] = le_marital.fit_transform(df[\"marital_status\"])\n",
    "df[\"occupation_encoded\"] = le_occupation.fit_transform(df[\"occupation\"])\n",
    "\n",
    "# Select features for modeling\n",
    "feature_cols = [\n",
    "    \"age\",\n",
    "    \"workclass_encoded\",\n",
    "    \"education_encoded\",\n",
    "    \"education_num\",\n",
    "    \"marital_encoded\",\n",
    "    \"occupation_encoded\",\n",
    "    \"hours_per_week\",\n",
    "    \"capital_gain\",\n",
    "    \"capital_loss\",\n",
    "]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = (df[\"income_over_50k\"] == 1).astype(int)\n",
    "\n",
    "# Protected attributes\n",
    "protected = {\"race\": df[\"race_encoded\"].values, \"sex\": df[\"sex_encoded\"].values, \"age\": df[\"age\"].values}\n",
    "\n",
    "print(f\"Features: {feature_cols}\")\n",
    "print(\"Target: Income >50K (binary)\")\n",
    "print(f\"Protected attributes: {list(protected.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train/Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED, stratify=y)\n",
    "\n",
    "# Split protected attributes\n",
    "# Use original dataframe values for protected attributes (not encoded)\n",
    "protected_test = {\n",
    "    \"race\": df.loc[X_test.index, \"race\"].values,\n",
    "    \"sex\": df.loc[X_test.index, \"sex\"].values,\n",
    "    \"age\": df.loc[X_test.index, \"age\"].values,\n",
    "}\n",
    "\n",
    "print(f\"Train: {len(X_train)} | Test: {len(X_test)}\")\n",
    "print(f\"Test income >50K rate: {y_test.mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train Model\n",
    "\n",
    "We'll use XGBoost for strong performance on this dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=SEED, eval_metric=\"logloss\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "train_acc = model.score(X_train, y_train)\n",
    "test_acc = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Train accuracy: {train_acc:.3f}\")\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")\n",
    "print(\"\\n✓ Model trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Baseline Audit (Current Population)\n",
    "\n",
    "Generate audit on the current test set to establish baseline metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_result = ga.audit.from_model(\n",
    "    model=model,\n",
    "    X=X_test,\n",
    "    y=y_test,\n",
    "    protected_attributes={\n",
    "        \"race\": df.loc[X_test.index, \"race\"].values,\n",
    "        \"sex\": df.loc[X_test.index, \"sex\"].values,\n",
    "        \"age\": df.loc[X_test.index, \"age\"].values,\n",
    "    },\n",
    "    random_seed=SEED,\n",
    "    explain=True,\n",
    "    calibration=True,\n",
    ")\n",
    "\n",
    "print(\"=== BASELINE METRICS ===\")\n",
    "print(f\"Accuracy: {baseline_result.performance['accuracy']:.3f}\")\n",
    "print(f\"AUC-ROC: {baseline_result.performance['roc_auc']:.3f}\")\n",
    "print(\"\\nFairness (Demographic Parity):\")\n",
    "if hasattr(baseline_result.fairness, \"demographic_parity\"):\n",
    "    print(f\"  {baseline_result.fairness.demographic_parity:.3f}\")\n",
    "print(\"\\nCalibration (ECE):\")\n",
    "if hasattr(baseline_result.calibration, \"expected_calibration_error\"):\n",
    "    print(f\"  {baseline_result.calibration.expected_calibration_error:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Simulate Demographic Shift\n",
    "\n",
    "Simulate a population shift where the proportion of female workers increases by 10 percentage points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current sex distribution\n",
    "current_female_rate = (protected_test[\"sex\"] == le_sex.transform([\"Female\"])[0]).mean()\n",
    "print(f\"Current female rate in test set: {current_female_rate:.1%}\")\n",
    "\n",
    "# Simulate shift: increase female proportion by 10 percentage points\n",
    "target_female_rate = current_female_rate + 0.10\n",
    "print(f\"Target female rate after shift: {target_female_rate:.1%}\")\n",
    "\n",
    "# Create reweighted sample\n",
    "female_mask = protected_test[\"sex\"] == le_sex.transform([\"Female\"])[0]\n",
    "male_mask = ~female_mask\n",
    "\n",
    "# Calculate reweighting factors\n",
    "female_weight = target_female_rate / current_female_rate\n",
    "male_weight = (1 - target_female_rate) / (1 - current_female_rate)\n",
    "\n",
    "# Create sample weights\n",
    "sample_weights = np.ones(len(X_test))\n",
    "sample_weights[female_mask] = female_weight\n",
    "sample_weights[male_mask] = male_weight\n",
    "\n",
    "print(\"\\nReweighting factors:\")\n",
    "print(f\"  Female: {female_weight:.2f}x\")\n",
    "print(f\"  Male: {male_weight:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Audit After Shift\n",
    "\n",
    "Generate audit with reweighted population to see impact of demographic shift.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted_result = ga.audit.from_model(\n",
    "    model=model,\n",
    "    X=X_test,\n",
    "    y=y_test,\n",
    "    protected_attributes={\n",
    "        \"race\": df.loc[X_test.index, \"race\"].values,\n",
    "        \"sex\": df.loc[X_test.index, \"sex\"].values,\n",
    "        \"age\": df.loc[X_test.index, \"age\"].values,\n",
    "    },\n",
    "    sample_weight=sample_weights,\n",
    "    random_seed=SEED,\n",
    "    explain=True,\n",
    "    calibration=True,\n",
    ")\n",
    "\n",
    "print(\"=== SHIFTED POPULATION METRICS ===\")\n",
    "print(f\"Accuracy: {shifted_result.performance['accuracy']:.3f}\")\n",
    "print(f\"AUC-ROC: {shifted_result.performance['roc_auc']:.3f}\")\n",
    "print(\"\\nFairness (Demographic Parity):\")\n",
    "if hasattr(shifted_result.fairness, \"demographic_parity\"):\n",
    "    print(f\"  {shifted_result.fairness.demographic_parity:.3f}\")\n",
    "print(\"\\nCalibration (ECE):\")\n",
    "if hasattr(shifted_result.calibration, \"expected_calibration_error\"):\n",
    "    print(f\"  {shifted_result.calibration.expected_calibration_error:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Compare Baseline vs Shifted\n",
    "\n",
    "Quantify the impact of demographic shift on model performance and fairness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"DRIFT IMPACT ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Performance changes\n",
    "acc_change = shifted_result.performance[\"accuracy\"] - baseline_result.performance[\"accuracy\"]\n",
    "auc_change = shifted_result.performance[\"roc_auc\"] - baseline_result.performance[\"roc_auc\"]\n",
    "\n",
    "print(\"\\n1. Performance Changes:\")\n",
    "print(\n",
    "    f\"   Accuracy: {baseline_result.performance['accuracy']:.3f} → {shifted_result.performance['accuracy']:.3f} ({acc_change:+.3f})\"\n",
    ")\n",
    "print(\n",
    "    f\"   AUC-ROC: {baseline_result.performance['roc_auc']:.3f} → {shifted_result.performance['roc_auc']:.3f} ({auc_change:+.3f})\"\n",
    ")\n",
    "\n",
    "# Fairness changes\n",
    "dp_change = None  # Initialize fairness change variable\n",
    "if hasattr(baseline_result.fairness, \"demographic_parity\") and hasattr(shifted_result.fairness, \"demographic_parity\"):\n",
    "    print(\"\\n2. Fairness Changes:\")\n",
    "\n",
    "# Calibration changes\n",
    "if hasattr(baseline_result.calibration, \"expected_calibration_error\") and hasattr(\n",
    "    shifted_result.calibration, \"expected_calibration_error\"\n",
    "):\n",
    "    ece_change = (\n",
    "        shifted_result.calibration.expected_calibration_error - baseline_result.calibration.expected_calibration_error\n",
    "    )\n",
    "    print(\"\\n3. Calibration Changes:\")\n",
    "    print(\n",
    "        f\"   ECE: {baseline_result.calibration.expected_calibration_error:.4f} → {shifted_result.calibration.expected_calibration_error:.4f} ({ece_change:+.4f})\"\n",
    "    )\n",
    "\n",
    "print(\"\\n4. Interpretation:\")\n",
    "if abs(acc_change) > 0.02:\n",
    "    print(f\"   ⚠️ Significant accuracy change detected ({acc_change:+.1%})\")\n",
    "else:\n",
    "    print(\"   ✓ Accuracy stable under demographic shift\")\n",
    "\n",
    "if dp_change is not None and abs(dp_change) > 0.05:\n",
    "    print(\"   ⚠️ Fairness degraded under demographic shift\")\n",
    "else:\n",
    "    print(\"   ✓ Fairness maintained under demographic shift\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export both audits\n",
    "# TODO: Uncomment when to_pdf() is implemented in Phase 3\n",
    "# baseline_result.to_pdf(\"adult_income_baseline.pdf\")\n",
    "# TODO: Uncomment when to_pdf() is implemented in Phase 3\n",
    "# shifted_result.to_pdf(\"adult_income_shifted.pdf\")\n",
    "\n",
    "print(\"✓ Audit reports saved:\")\n",
    "print(\"  • adult_income_baseline.pdf (current population)\")\n",
    "print(\"  • adult_income_shifted.pdf (after demographic shift)\")\n",
    "print(\"\\nCompare these reports to assess drift impact on:\")\n",
    "print(\"  • Model performance (accuracy, AUC)\")\n",
    "print(\"  • Fairness metrics (demographic parity, equal opportunity)\")\n",
    "print(\"  • Calibration quality (ECE, Brier score)\")\n",
    "print(\"  • Feature importance stability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "**Why Drift Detection Matters:**\n",
    "\n",
    "1. **Population changes over time**: Demographics shift due to policy changes, economic trends, and social movements\n",
    "2. **Model performance degrades**: A model trained on one population may perform poorly on another\n",
    "3. **Fairness can deteriorate**: Shifts can amplify existing biases or introduce new ones\n",
    "4. **Proactive monitoring is critical**: Detect drift before it causes harm\n",
    "\n",
    "**What We Demonstrated:**\n",
    "\n",
    "- Simulated a 10 percentage point increase in female workforce participation\n",
    "- Measured impact on accuracy, fairness, and calibration\n",
    "- Compared baseline vs shifted population metrics\n",
    "- Generated side-by-side audit reports for comparison\n",
    "\n",
    "**Production Recommendations:**\n",
    "\n",
    "1. **Monitor demographic distributions** in production data\n",
    "2. **Set drift thresholds** for key protected attributes (e.g., ±5%)\n",
    "3. **Trigger re-audits** when thresholds are exceeded\n",
    "4. **Retrain or recalibrate** models when drift degrades fairness\n",
    "5. **Document drift incidents** for regulatory compliance\n",
    "\n",
    "**Further Reading:**\n",
    "\n",
    "- [Concept Drift in Machine Learning](https://en.wikipedia.org/wiki/Concept_drift)\n",
    "- [Monitoring ML Models in Production](https://christophergs.com/machine%20learning/2020/03/14/how-to-monitor-machine-learning-models/)\n",
    "- [Fairness Under Distribution Shift](https://arxiv.org/abs/1911.03347)\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "- Try different shift scenarios (age, race, multiple attributes)\n",
    "- Implement automated drift detection in your ML pipeline\n",
    "- Set up alerts for fairness metric degradation\n",
    "- Establish retraining triggers based on drift severity\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
