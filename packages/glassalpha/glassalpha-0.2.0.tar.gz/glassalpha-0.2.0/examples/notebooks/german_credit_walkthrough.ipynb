{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German Credit Risk Analysis: Complete Walkthrough\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/GlassAlpha/glassalpha/blob/main/examples/notebooks/german_credit_walkthrough.ipynb)\n",
    "\n",
    "**Complete ML audit workflow**: Data exploration → Model training → Fairness analysis → SHAP explanations → Calibration → Professional PDF report\n",
    "\n",
    "**Dataset**: German Credit (1000 applications) | **Protected Attributes**: Gender, Age, Foreign Worker\n",
    "\n",
    "**API Reference**: [`from_model()` documentation](https://glassalpha.com/reference/api/api-audit/) | [User Guide](https://glassalpha.com/getting-started/quickstart/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q glassalpha[explain,xgboost]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Environment verification for reproducibility\"\"\"\n",
    "import platform\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import glassalpha as ga\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(\n",
    "    {\n",
    "        \"python\": sys.version.split()[0],\n",
    "        \"platform\": platform.platform(),\n",
    "        \"glassalpha\": getattr(ga, \"__version__\", \"dev\"),\n",
    "        \"seed\": SEED,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ga.datasets.load_german_credit()\n",
    "print(f\"Dataset: {df.shape[0]} samples, {df.shape[1]} features\")\n",
    "print(f\"Target balance: {df['credit_risk'].mean():.1%} good credit\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_attrs = [\"gender\", \"age_group\", \"foreign_worker\"]\n",
    "feature_cols = [c for c in df.columns if c not in [\"credit_risk\"] + protected_attrs]\n",
    "X, y = df[feature_cols], df[\"credit_risk\"]\n",
    "protected_data = df[protected_attrs]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED, stratify=y)\n",
    "print(f\"Train: {len(X_train)} | Test: {len(X_test)}\")\n",
    "\n",
    "# Store original indices before any transformations\n",
    "X_test_indices = X_test.index.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract protected attributes from original DataFrame before pipeline transformation\n",
    "# This preserves the DataFrame structure needed for fairness analysis\n",
    "protected_attributes = {}\n",
    "for attr in protected_attrs:\n",
    "    protected_attributes[attr] = df.loc[X_test_indices, attr].values\n",
    "\n",
    "print(f\"Protected attributes extracted: {list(protected_attributes.keys())}\")\n",
    "print(f\"Gender distribution: {pd.Series(protected_attributes['gender']).value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = X_train.select_dtypes(include=[\"object\"]).columns\n",
    "numerical_cols = X_train.select_dtypes(exclude=[\"object\"]).columns\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
    "        (\"num\", \"passthrough\", numerical_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessor and model\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", RandomForestClassifier(n_estimators=100, max_depth=5, random_state=SEED)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Update model reference\n",
    "model = pipeline\n",
    "\n",
    "# XGBoost commented out due to categorical handling issues\n",
    "# xgb = XGBClassifier(\n",
    "#     n_estimators=100,\n",
    "#     max_depth=3,\n",
    "#     random_state=SEED,\n",
    "#     enable_categorical=True,  # Enable categorical support for object columns\n",
    "# )\n",
    "# xgb.fit(X_train, y_train)  # Use original data\n",
    "# xgb.fit(X_train, y_train)  # Use original data since XGBoost can handle categoricals\n",
    "\n",
    "# Comment out XGBoost scoring\n",
    "# print(f\"XGBoost test acc: {xgb.score(X_test, y_test):.3f}\")\n",
    "# model = xgb if xgb.score(X_test, y_test) > rf.score(X_test, y_test) else rf\n",
    "print(f\"RandomForest test acc: {model.score(X_test, y_test):.3f}\")\n",
    "# model already set to pipeline above\n",
    "print(\"\\n✓ Selected: RandomForest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Generate Audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ga.audit.from_model(\n",
    "    model=model,\n",
    "    X=X_test,\n",
    "    y=y_test,\n",
    "    protected_attributes=protected_attributes,  # Now includes protected attributes\n",
    "    random_seed=SEED,\n",
    ")\n",
    "result  # Display inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {result.performance['accuracy']:.3f}\")\n",
    "print(f\"AUC-ROC: {result.performance['roc_auc']:.3f}\")\n",
    "print(f\"Precision: {result.performance['precision']:.3f}\")\n",
    "print(f\"Recall: {result.performance['recall']:.3f}\")\n",
    "\n",
    "# Note: Interactive plotting (.plot_*) coming in Phase 3\n",
    "# All visualizations are available in the PDF report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Fairness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_diff = result.fairness.get(\"demographic_parity_max_diff\", 0.0)\n",
    "print(f\"Demographic Parity (max difference): {dp_diff:.3f}\")\n",
    "print(f\"\\nBias detected: {'⚠️ YES' if dp_diff > 0.10 else '✓ NO'} (10% threshold)\")\n",
    "print(f\"\\nProtected attributes analyzed: {list(result.manifest['protected_attributes_categories'].keys())}\")\n",
    "\n",
    "# Note: Interactive plotting (.plot_*) coming in Phase 3\n",
    "# All visualizations are available in the PDF report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Expected Calibration Error: {result.calibration['expected_calibration_error']:.4f}\")\n",
    "print(f\"Brier Score: {result.calibration['brier_score']:.4f}\")\n",
    "print(\n",
    "    f\"\\nCalibration: {'✓ PASS' if result.calibration['expected_calibration_error'] < 0.05 else '⚠️ WARNING'} (ECE < 0.05 target)\"\n",
    ")\n",
    "\n",
    "# Note: Interactive plotting (.plot_*) coming in Phase 3\n",
    "# All visualizations are available in the PDF report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: SHAP Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 10 Important Features:\\n\")\n",
    "# print(result.explanations.feature_importance.head(10))\n",
    "# Feature importance not yet implemented\n",
    "\n",
    "# Note: Interactive plotting (.plot_*) coming in Phase 3\n",
    "# All visualizations are available in the PDF report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Export Audit Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.to_pdf('german_credit_audit.pdf')\n",
    "# result.to_json('metrics.json')\n",
    "# result.to_config('audit_config.yaml')\n",
    "# to_config() will be implemented in Phase 3\n",
    "print(\"✓ Exported: PDF report, metrics JSON, config YAML\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Performance**: Strong accuracy and AUC-ROC\n",
    "**Fairness**: Analyzed across gender, age, foreign worker status\n",
    "**Calibration**: ECE indicates prediction reliability\n",
    "**Explainability**: SHAP values provide feature attribution\n",
    "\n",
    "**Next Steps**: Review PDF report, address any fairness gaps, monitor in production"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
