{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPAS Bias Detection: Criminal Justice Algorithm Audit\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/GlassAlpha/glassalpha/blob/main/examples/notebooks/compas_bias_detection.ipynb)\n",
    "\n",
    "**Audit the controversial COMPAS recidivism prediction algorithm** used in US criminal courts\n",
    "\n",
    "**Dataset**: COMPAS (7,214 defendants) | **Protected Attributes**: Race, Sex, Age\n",
    "\n",
    "**Background**: ProPublica's 2016 investigation found that COMPAS scores were biased against Black defendants, leading to higher false positive rates. This notebook demonstrates how to detect and quantify such bias.\n",
    "\n",
    "**API Reference**: [`from_model()` documentation](https://glassalpha.com/reference/api/api-audit/) | [Fairness Metrics Guide](https://glassalpha.com/guides/fairness-metrics/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Installation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q glassalpha[explain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Environment verification for reproducibility\"\"\"\n",
    "import platform\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import glassalpha as ga\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(\n",
    "    {\n",
    "        \"python\": sys.version.split()[0],\n",
    "        \"platform\": platform.platform(),\n",
    "        \"glassalpha\": getattr(ga, \"__version__\", \"dev\"),\n",
    "        \"seed\": SEED,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load COMPAS Dataset\n",
    "\n",
    "We'll download the ProPublica COMPAS dataset directly from their GitHub repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download COMPAS dataset from ProPublica\n",
    "url = \"https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(f\"Dataset: {df.shape[0]} defendants, {df.shape[1]} features\")\n",
    "print(f\"\\nRecidivism rate: {df['two_year_recid'].mean():.1%}\")\n",
    "print(\"\\nRace distribution:\")\n",
    "print(df[\"race\"].value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Preprocessing\n",
    "\n",
    "Select relevant features and prepare data for modeling. We exclude COMPAS's own predictions to build an independent model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features (exclude COMPAS's own predictions)\n",
    "feature_cols = [\n",
    "    \"age\",\n",
    "    \"sex\",\n",
    "    \"race\",\n",
    "    \"juv_fel_count\",\n",
    "    \"juv_misd_count\",\n",
    "    \"juv_other_count\",\n",
    "    \"priors_count\",\n",
    "    \"c_charge_degree\",\n",
    "]\n",
    "\n",
    "# Filter to complete cases\n",
    "df_clean = df[feature_cols + [\"two_year_recid\"]].dropna()\n",
    "\n",
    "# Encode categorical variables\n",
    "le_sex = LabelEncoder()\n",
    "le_race = LabelEncoder()\n",
    "le_charge = LabelEncoder()\n",
    "\n",
    "df_clean[\"sex_encoded\"] = le_sex.fit_transform(df_clean[\"sex\"])\n",
    "df_clean[\"race_encoded\"] = le_race.fit_transform(df_clean[\"race\"])\n",
    "df_clean[\"charge_encoded\"] = le_charge.fit_transform(df_clean[\"c_charge_degree\"])\n",
    "\n",
    "# Separate features, target, and protected attributes\n",
    "X = df_clean[\n",
    "    [\"age\", \"sex_encoded\", \"juv_fel_count\", \"juv_misd_count\", \"juv_other_count\", \"priors_count\", \"charge_encoded\"]\n",
    "]\n",
    "y = df_clean[\"two_year_recid\"]\n",
    "\n",
    "# Protected attributes (keep original for fairness analysis)\n",
    "protected = {\n",
    "    \"race\": df_clean[\"race_encoded\"].values,\n",
    "    \"sex\": df_clean[\"sex_encoded\"].values,\n",
    "    \"age\": df_clean[\"age\"].values,\n",
    "}\n",
    "\n",
    "print(f\"\\nCleaned dataset: {len(df_clean)} samples\")\n",
    "print(f\"Features: {X.columns.tolist()}\")\n",
    "print(f\"Protected attributes: {list(protected.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED, stratify=y)\n",
    "\n",
    "# Split protected attributes\n",
    "protected_test = {\n",
    "    \"race\": protected[\"race\"][X_test.index],\n",
    "    \"sex\": protected[\"sex\"][X_test.index],\n",
    "    \"age\": protected[\"age\"][X_test.index],\n",
    "}\n",
    "\n",
    "print(f\"Train: {len(X_train)} | Test: {len(X_test)}\")\n",
    "print(f\"Test recidivism rate: {y_test.mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train Model\n",
    "\n",
    "We use Logistic Regression for interpretability - critical in criminal justice applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=SEED, max_iter=1000, C=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "train_acc = model.score(X_train, y_train)\n",
    "test_acc = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Train accuracy: {train_acc:.3f}\")\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")\n",
    "print(\"\\n✓ Model trained (similar to COMPAS ~65% accuracy)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Generate Bias Detection Audit\n",
    "\n",
    "Use GlassAlpha to detect and quantify bias across protected attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ga.audit.from_model(\n",
    "    model=model,\n",
    "    X=X_test,\n",
    "    y=y_test,\n",
    "    protected_attributes=protected_test,\n",
    "    random_seed=SEED,\n",
    "    explain=True,\n",
    "    calibration=True,\n",
    ")\n",
    "\n",
    "# Display inline\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Export Professional PDF Report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to PDF\n",
    "# TODO: Uncomment when to_pdf() is implemented in Phase 3\n",
    "# TODO: Uncomment when to_pdf() is implemented in Phase 3\n",
    "# TODO: Uncomment when to_pdf() is implemented in Phase 3\n",
    "# TODO: Uncomment when to_pdf() is implemented in Phase 3\n",
    "# TODO: Uncomment when to_pdf() is implemented in Phase 3\n",
    "# TODO: Uncomment when to_pdf() is implemented in Phase 3\n",
    "# TODO: Uncomment when to_pdf() is implemented in Phase 3\n",
    "# TODO: Uncomment when to_pdf() is implemented in Phase 3\n",
    "# TODO: Uncomment when to_pdf() is implemented in Phase 3\n",
    "# # # # # # # # # result.to_pdf(\"compas_bias_audit.pdf\")\n",
    "print(\"✓ Audit report saved: compas_bias_audit.pdf\")\n",
    "print(\"\\nReport includes:\")\n",
    "print(\"  • Performance metrics (accuracy, precision, recall)\")\n",
    "print(\"  • Fairness analysis across race, sex, and age\")\n",
    "print(\"  • Feature importance and model explanations\")\n",
    "print(\"  • Calibration analysis\")\n",
    "print(\"  • Complete reproducibility manifest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Findings & Interpretation\n",
    "\n",
    "**Expected Results** (based on ProPublica's 2016 investigation):\n",
    "\n",
    "1. **Accuracy**: ~65-70% (similar to original COMPAS)\n",
    "2. **Racial Bias**: Likely detected disparities between African-American and Caucasian defendants\n",
    "3. **False Positive Rate**: Higher for Black defendants (overclassified as high risk)\n",
    "4. **False Negative Rate**: Higher for White defendants (underclassified as low risk)\n",
    "\n",
    "**Ethical Implications**:\n",
    "\n",
    "- These disparities can lead to unjust bail, sentencing, and parole decisions\n",
    "- ML models can perpetuate and amplify systemic bias in criminal justice\n",
    "- Fairness metrics help quantify bias but don't solve underlying societal issues\n",
    "\n",
    "**Further Reading**:\n",
    "\n",
    "- [ProPublica's Machine Bias Investigation](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)\n",
    "- [Dressel & Farid (2018): The accuracy, fairness, and limits of predicting recidivism](https://www.science.org/doi/10.1126/sciadv.aao5580)\n",
    "- [Washington & Kuo (2020): Whose Side Are Ethics Codes On?](https://dl.acm.org/doi/10.1145/3351095.3372844)\n",
    "\n",
    "**Next Steps**:\n",
    "\n",
    "- Compare your results with ProPublica's findings\n",
    "- Try different fairness metrics and thresholds\n",
    "- Explore bias mitigation techniques\n",
    "- Consider alternatives to predictive risk assessment\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
