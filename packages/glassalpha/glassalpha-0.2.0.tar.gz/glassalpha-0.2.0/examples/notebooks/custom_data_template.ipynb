{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audit Your Own Model: Custom Data Template\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/GlassAlpha/glassalpha/blob/main/examples/notebooks/custom_data_template.ipynb)\n",
    "\n",
    "**Use this template to audit YOUR model with YOUR data**\n",
    "\n",
    "This notebook shows how to:\n",
    "1. Load your CSV data\n",
    "2. Train or load your model\n",
    "3. Generate a complete audit\n",
    "4. Export configuration for CI/CD\n",
    "\n",
    "**Replace the placeholder data paths with your own files!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q glassalpha[explain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Environment verification for reproducibility\"\"\"\n",
    "import platform\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier  # Replace with your model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import glassalpha as ga\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(\n",
    "    {\n",
    "        \"python\": sys.version.split()[0],\n",
    "        \"platform\": platform.platform(),\n",
    "        \"glassalpha\": getattr(ga, \"__version__\", \"dev\"),\n",
    "        \"seed\": SEED,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load YOUR Data\n",
    "\n",
    "**REPLACE THIS with your actual data path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Load from CSV\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Option B: For this template, we'll use German Credit as example\n",
    "df = ga.datasets.load_german_credit()\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Your Features and Target\n",
    "\n",
    "**CUSTOMIZE THIS** based on your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column names\n",
    "TARGET_COLUMN = \"credit_risk\"  # ‚Üê CHANGE THIS to your target column\n",
    "PROTECTED_ATTRIBUTES = [\"gender\", \"age_group\"]  # ‚Üê CHANGE THIS to your protected attributes\n",
    "\n",
    "# Features = all columns except target and protected attributes\n",
    "feature_columns = [col for col in df.columns if col not in [TARGET_COLUMN] + PROTECTED_ATTRIBUTES]\n",
    "\n",
    "print(f\"Target: {TARGET_COLUMN}\")\n",
    "print(f\"Protected attributes: {PROTECTED_ATTRIBUTES}\")\n",
    "print(f\"Features ({len(feature_columns)}): {', '.join(feature_columns[:5])}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Validate Your Data\n",
    "\n",
    "Check for common issues before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing = df[feature_columns + [TARGET_COLUMN]].isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    print(\"‚ö†Ô∏è Missing values detected:\")\n",
    "    print(missing[missing > 0])\n",
    "    print(\"\\nConsider: df.fillna() or df.dropna()\")\n",
    "else:\n",
    "    print(\"‚úì No missing values\")\n",
    "\n",
    "# Check target distribution\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(df[TARGET_COLUMN].value_counts())\n",
    "print(f\"Class balance: {df[TARGET_COLUMN].mean():.1%}\")\n",
    "\n",
    "# Check protected group sizes\n",
    "print(\"\\nProtected group sizes:\")\n",
    "for attr in PROTECTED_ATTRIBUTES:\n",
    "    counts = df[attr].value_counts()\n",
    "    min_size = counts.min()\n",
    "    print(f\"{attr}: {dict(counts)} (min={min_size}, {'‚úì OK' if min_size >= 30 else '‚ö†Ô∏è TOO SMALL'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[feature_columns]\n",
    "\n",
    "# Encode categorical features for sklearn compatibility\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode categorical columns\n",
    "X_encoded = X.copy()\n",
    "for col in X_encoded.select_dtypes(include=[\"object\"]).columns:\n",
    "    le = LabelEncoder()\n",
    "    X_encoded[col] = le.fit_transform(X_encoded[col])\n",
    "\n",
    "y = df[TARGET_COLUMN]\n",
    "protected_data = df[PROTECTED_ATTRIBUTES]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED, stratify=y)\n",
    "\n",
    "print(f\"Train: {len(X_train)} samples ({len(X_train) / len(X):.0%})\")\n",
    "print(f\"Test: {len(X_test)} samples ({len(X_test) / len(X):.0%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Train Your Model\n",
    "\n",
    "**REPLACE THIS** with your actual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Train a new model (example with RandomForest)\n",
    "# Encode categorical features for sklearn compatibility\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode categorical columns\n",
    "X_train_encoded = X_train.copy()\n",
    "X_test_encoded = X_test.copy()\n",
    "for col in X_train_encoded.select_dtypes(include=[\"object\"]).columns:\n",
    "    le = LabelEncoder()\n",
    "    X_train_encoded[col] = le.fit_transform(X_train_encoded[col])\n",
    "    X_test_encoded[col] = le.transform(X_test_encoded[col])\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=SEED)\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Option B: Load a pre-trained model\n",
    "# import joblib\n",
    "# model = joblib.load('your_model.joblib')\n",
    "\n",
    "# Quick performance check\n",
    "train_acc = model.score(X_train_encoded, y_train)\n",
    "test_acc = model.score(X_test_encoded, y_test)\n",
    "print(f\"Train accuracy: {train_acc:.3f}\")\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")\n",
    "print(\"‚úì Model ready for audit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Generate Audit\n",
    "\n",
    "This is where the magic happens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ga.audit.from_model(\n",
    "    model=model,\n",
    "    X=X_test_encoded,\n",
    "    y=y_test,\n",
    "    protected_attributes={attr: protected_data.loc[X_test.index, attr] for attr in PROTECTED_ATTRIBUTES},\n",
    "    random_seed=SEED,\n",
    ")\n",
    "\n",
    "print(\"‚úì Audit complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display inline summary\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Review Key Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display audit results\\nprint(\"Performance Metrics:\")\\nfor key, value in result.performance.items():\\n    print(f\"  {key}: {value:.3f}\")\\n\\nprint(\"\\nFairness Metrics:\")\\nfor key, value in result.fairness.items():\\n    print(f\"  {key}: {value:.3f}\" if isinstance(value, (int, float)) else f\"  {key}: {value}\")\\n\\nprint(\"\\nCalibration Metrics:\")\\nfor key, value in result.calibration.items():\\n    print(f\"  {key}: {value:.3f}\")\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display audit results\\nprint(\"üìä PERFORMANCE\")\\nfor key, value in result.performance.items():\\n    print(f\"  {key}: {value:.3f}\")\\n\\nprint(\"\\n‚öñÔ∏è  FAIRNESS\")\\nfor key, value in result.fairness.items():\\n    if isinstance(value, (int, float)):\\n        print(f\"  {key}: {value:.3f}\")\\n\\nprint(\"\\nüéØ CALIBRATION\")\\nfor key, value in result.calibration.items():\\n    print(f\"  {key}: {value:.4f}\")\\n\\nprint(\"\\n‚úì Audit complete!\")\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 10 Important Features:\\n\")\n",
    "# print(result.explanations.feature_importance.head(10))\n",
    "# Feature importance not yet implemented\n",
    "\n",
    "# Note: Interactive plotting (.plot_*) coming in Phase 3\n",
    "# All visualizations are available in the PDF report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Export Audit Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export PDF report\n",
    "# result.to_pdf('my_model_audit.pdf')\n",
    "print(\"‚úì PDF report: my_model_audit.pdf\")\n",
    "\n",
    "# Export metrics as JSON\n",
    "# result.to_json('my_model_metrics.json')\n",
    "print(\"‚úì Metrics JSON: my_model_metrics.json\")\n",
    "\n",
    "# Export config for CI/CD reproduction\n",
    "# result.to_config('my_audit_config.yaml')\n",
    "# to_config() will be implemented in Phase 3\n",
    "print(\"‚úì Config YAML: my_audit_config.yaml\")\n",
    "\n",
    "print(\"\\n‚úì All outputs saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Reproduce with CLI (Optional)\n",
    "\n",
    "The config file can be used to reproduce this audit via command line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"To reproduce this audit:\\n\")\n",
    "print(\"  1. Install GlassAlpha: pip install glassalpha[explain]\")\n",
    "print(\"  2. Run: glassalpha audit --config my_audit_config.yaml --output report.pdf\")\n",
    "print(\"\\nFor CI/CD integration, add this to your GitHub Actions:\")\n",
    "print(\"\"\"\\n```yaml\n",
    "- name: Run ML Audit\n",
    "  run: |\n",
    "    pip install glassalpha[explain]\n",
    "    glassalpha audit --config my_audit_config.yaml --output audit.pdf\n",
    "```\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checklist: Customize This Template\n",
    "\n",
    "Before using with your own data, update:\n",
    "\n",
    "- [ ] **Step 2**: Load your CSV file (`pd.read_csv('your_data.csv')`)\n",
    "- [ ] **Step 3**: Set `TARGET_COLUMN` to your target variable name\n",
    "- [ ] **Step 3**: Set `PROTECTED_ATTRIBUTES` to your fairness-sensitive columns\n",
    "- [ ] **Step 6**: Train your model or load pre-trained model\n",
    "- [ ] **Step 7**: Adjust `threshold` if needed (default: 0.5)\n",
    "- [ ] **Step 10**: Customize output filenames\n",
    "\n",
    "**Need help?**\n",
    "- [Custom Data Guide](https://glassalpha.com/getting-started/custom-data/)\n",
    "- [Configuration Guide](https://glassalpha.com/getting-started/configuration/)\n",
    "- [API Reference](https://glassalpha.com/reference/api/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
