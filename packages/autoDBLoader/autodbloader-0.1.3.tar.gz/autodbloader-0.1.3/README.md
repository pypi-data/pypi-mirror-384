# AutoDBLoader

**AutoDBLoader** √© uma biblioteca Python para automatizar o processo de extra√ß√£o e inser√ß√£o de dados em bancos relacionais a partir de arquivos **CSV**, **Parquet** ou **JSON**, preservando a integridade referencial e respeitando relacionamentos entre tabelas.


## üìå Para que serve


A biblioteca foi desenvolvida para facilitar **extra√ß√£o** e **migra√ß√£o** de dados entre bancos de dados relacionais, garantindo que:

- Os dados sejam inseridos na ordem correta, respeitando as **chaves estrangeiras**;
- Colunas √∫nicas e relacionamentos sejam **validados antes da inser√ß√£o**;
- Dados sejam carregados em **batches** para otimizar performance e uso de mem√≥ria;
- Os dados sejam extra√≠dos e armazenados em **arquivos separados por tabela**;
- **Logs de progresso** sejam mantidos para permitir retomada segura em caso de falhas.



## üöÄ Instala√ß√£o e Utiliza√ß√£o


- No terminal, execute:
    - `pip install autodbloader`

- Ap√≥s a instala√ß√£o, execute `autodbloader` no terminal. Isso iniciar√° uma interface de configura√ß√£o, onde √© poss√≠vel:
    - Configurar a conex√£o com o banco de dados
    - Definir m√©todos de extra√ß√£o ou inser√ß√£o de dados
    - Preencher os formul√°rios de configura√ß√£o referentes √†s tabelas do banco

- Depois de preencher todos os campos, √© poss√≠vel gerar o JSON de configura√ß√£o. A partir da√≠, h√° duas op√ß√µes:
    - Executar diretamente pela interface e acompanhar os logs de execu√ß√£o no terminal
    - Copiar o JSON e utiliz√°-lo em um arquivo Python, instanciando a biblioteca e chamando o m√©todo desejado com a configura√ß√£o criada


### üß© Executar a interface via script

Agora √© poss√≠vel abrir a interface gr√°fica do AutoDBLoader diretamente por um script Python.  
Isso permite utiliz√°-la sem precisar do terminal.

Exemplo de uso:
```python
import autoDBLoader

autoDBLoader.run_interface()
```


## ‚öôÔ∏è Como funciona

A biblioteca opera em tr√™s etapas principais:

1. **Valida√ß√£o**  
   - Verifica a estrutura do dicion√°rio de configura√ß√£o;
   - Confere a exist√™ncia dos arquivos e tabelas;
   - Valida a compatibilidade de tipos entre arquivo e banco;
   - Checa permiss√µes de acesso ao banco;
   - Confere diret√≥rios e arquivos existentes;
   - Valida a execu√ß√£o de queries personalizadas.

2. **Extra√ß√£o**  
   - Executa queries padr√£o ou personalizadas;
   - Extrai os dados do banco de dados;
   - Salva no diret√≥rio e formato informado (**CSV**, **Parquet** ou **JSON**).

3. **Inser√ß√£o ordenada**  
   - Insere os dados respeitando os relacionamentos;
   - Adiciona colunas tempor√°rias para controle dos antigos IDs;
   - Executa inser√ß√£o em lotes para maior performance;
   - Mant√©m logs para garantir continuidade em caso de falhas.

## üìã Requisitos e configura√ß√µes obrigat√≥rias:

### Processo de **inser√ß√£o**:

- O banco de dados **j√° deve estar criado** com a estrutura das tabelas necess√°rias.
- O usu√°rio da conex√£o precisa ter **permiss√£o** para criar, alterar e deletar tabelas (cria√ß√£o de colunas, altera√ß√£o, inser√ß√£o e exclus√£o).
- **SGBDs suportados**:
  - MySQL
  - PostgreSQL
  - Oracle


Para que o **processo de inser√ß√£o** funcione corretamente, os arquivos de dados devem atender aos seguintes crit√©rios:

- Cada arquivo representa **uma tabela** do banco de dados.
- Os nomes das colunas no arquivo devem **corresponder exatamente aos nomes dos atributos** da tabela no banco.
- Os arquivos **devem conter todas as chaves prim√°rias** dos registros.
- As **chaves estrangeiras** tamb√©m devem estar presentes e corretas para garantir a integridade referencial.
- Os arquivos devem estar **completos e consistentes** com a estrutura da tabela, incluindo tipos de dados compat√≠veis.
- Os arquivos devem estar no formato informado no **JSON de configura√ß√£o** e podem ser:
  - CSV (com separador configur√°vel)
  - Parquet
  - JSON (newline-delimited)
- Os arquivos podem conter **atributos extras**, que ser√£o descartados conforme especificado no campo **unwanted_attributes** no JSON de configura√ß√£o.

> ‚ö†Ô∏è Observa√ß√£o: O AutoDBLoader n√£o cria nem adivinha chaves prim√°rias ou estrangeiras. Se algum valor estiver faltando ou incorreto, a inser√ß√£o pode falhar ou gerar inconsist√™ncias no banco.

### Processo de **extra√ß√£o**:

- O usu√°rio da conex√£o precisa ter **permiss√£o** para executar **executar consultas SQL simples** (ex.: `SELECT * FROM tabela`).
- **SGBDs suportados**:
  - MySQL
  - PostgreSQL
  - Oracle
- Os dados de cada tabela ser√£o salvos **em arquivos separados**, onde cada arquivo cont√©m unicamente os dados de uma tabela.
- Os arquivos ser√£o salvos no formato informado no **JSON de configura√ß√£o**, que pode ser:
  - CSV (com separador configur√°vel)
  - Parquet
  - JSON (newline-delimited)
- A extra√ß√£o pode utilizar uma **consultas SQL personalizada**, que deve ser **informada** no **JSON de configura√ß√£o** e cujo resultado ser√° salvo no arquivo da tabela.


## üìÇ Sistema de Logs e Retomada


O **AutoDBLoader** possui um sistema de logs que garante a **continuidade do processo** em caso de falhas, registrando quais tabelas j√° foram processadas.

- **Inser√ß√£o de dados**
  - O log √© salvo em uma **tabela no banco de dados** chamada `log_autodbloader`.
  - Esta tabela **s√≥ √© criada se ocorrer um erro** durante o processo de inser√ß√£o.
  - Ela registra quais tabelas j√° foram inseridas, permitindo que a pr√≥xima execu√ß√£o **retome de onde parou**.

- **Extra√ß√£o de dados**
  - O log √© salvo em um **arquivo JSON** chamado `log_tables_extract.json`.
  - Ele armazena as tabelas que j√° foram extra√≠das.
  - Na pr√≥xima execu√ß√£o, o AutoDBLoader verifica esse arquivo e **retoma apenas as tabelas que ainda n√£o foram extra√≠das**.

> ‚ö†Ô∏è Observa√ß√£o: Manter o arquivo `log_tables_extract.json` ou a tabela `log_autodbloader` √© importante para garantir que o processo seja retomado corretamente ap√≥s falhas.


## üìÑ Formato do JSON de configura√ß√£o

O processo √© orientado por um **JSON de configura√ß√£o** contendo:

### a) Configura√ß√£o de conex√£o ao banco
- `hostname`: Host de conex√£o ao banco.
- `username`: Usu√°rio de conex√£o.
- `password`: Senha do usu√°rio.
- `database`: Banco de dados que ser√° utilizado.
- `port`: Porta de acesso ao banco.
- `sgbd`: Sistema gerenciador de banco de dados (**mysql**, **postgre**, **oracle**, em letras min√∫sculas).

### b) Configura√ß√£o de tabelas (inser√ß√£o)
- `name_table`: Nome da tabela.
- `path_file`: Caminho do arquivo que cont√©m os dados da tabela.
- `type_file`: Tipo do arquivo (**csv**, **parquet**, **json**, em letras min√∫sculas).
- `file_sep`: Usado apenas para arquivos CSV. Informa o caractere separador (ex.: `","` ou `";"`)
- `unwanted_attributes`: Lista de atributos que devem ser ignorados.

### c) Configura√ß√£o de tabelas (extra√ß√£o)
- `name_table`: Nome da tabela.
- `query`: Consultas SQL personalizada para extrair os dados.   
    - Deve conter uma consulta SQL v√°lida.  
    - Se n√£o for necess√°ria, utilize `"query": ""`.  
- `type_file`: Tipo do arquivo (**csv**, **parquet**, **json**, em letras min√∫sculas).
- `file_sep`: Usado apenas para arquivos CSV. Informa o caractere separador (ex.: `","` ou `";"`)

### d) Configura√ß√£o adicional para extra√ß√£o
- `path`: Diret√≥rio onde os arquivos extra√≠dos ser√£o salvos.

---

### üìå Exemplo simplificado de configura√ß√£o para inser√ß√£o de dados:

```json
{
    "db":{
        "hostname":"localhost",
        "username":"root",
        "password":"admin",
        "database":"fraud_analysis",
        "port":3306,
        "sgbd":"mysql"
        },
    "tables":[
        {
            "name_table":"users",
            "path_file":"C:/user/dados/users_data.csv",
            "type_file":"csv",
            "unwanted_attributes":["use_cpf", "use_password"],
            "file_sep":","
        },
        {
            "name_table":"cards",
            "path_file":"C:/user/dados/cards_data.parquet",
            "type_file":"parquet",
            "unwanted_attributes":[]
        },
        {
            "name_table":"transactions",
            "path_file":"C:/user/dados/transactions_data.json",
            "type_file":"json",
            "unwanted_attributes":[],
        },
        {
            "name_table":"mcc",
            "path_file":"C:/user/dados/mcc_codes.csv",
            "type_file":"csv",
            "unwanted_attributes":[],
            "file_sep":";"
        }
    ]
}
```

#### üìù Exemplo de inser√ß√£o utilizando Python:
```python
    from autoDBLoader import insert_date

    config  =  {"db":{ ... },
                "tables":{ ... }}
    insert_date(config)

```

### üìå Exemplo simplificado de configura√ß√£o para extra√ß√£o de dados:

```json
{
    "db":{
        "hostname":"localhost",
        "username":"root",
        "password":"admin",
        "database":"fraud_analysis",
        "port":3306,
        "sgbd":"mysql"
        },
    "path": "C:/user/dados/",
    "tables":[
        {
            "name_table":"users",
            "type_file":"csv",
            "query":"SELECT use_id, use_name, use_age, use_address from fraud_analysis.users
                     WHERE use_age >= 18",
            "file_sep":","
        },
        {
            "name_table":"cards",
            "type_file":"parquet",
            "query":"",
        },
        {
            "name_table":"transactions",
            "type_file":"json",
            "query":"",
        },
        {
            "name_table":"mcc",
            "type_file":"csv",
            "query":"",
            "file_sep":";"
        }
    ]
}
```

#### üìù Exemplo de extra√ß√£o utilizando Python:
```python
    from autoDBLoader import extract_date

    config  =  {"db":{ ... },
                "path": "C:/user/dados",
                "tables":{ ... }}
    extract_date(config)

```


