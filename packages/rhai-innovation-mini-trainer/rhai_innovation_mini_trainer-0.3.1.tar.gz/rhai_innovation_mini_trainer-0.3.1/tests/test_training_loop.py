"""
Test suite for the main training loop and integration.

Tests the full training pipeline including data loading, model training,
checkpointing, and metrics logging.
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import json
import tempfile
from pathlib import Path
from unittest.mock import MagicMock, patch, mock_open

import torch
import pytest

from mini_trainer.train import train, main, validate_training_mode
from mini_trainer.batch_metrics import BatchMetrics
from mini_trainer.training_types import TrainingMode


class TestValidateTrainingMode:
    """Test suite for validate_training_mode function."""
    
    def test_epoch_mode_validation(self):
        """Test EPOCH mode validation."""
        # Should pass with valid max_epochs
        validate_training_mode(TrainingMode.EPOCH, max_epochs=5, max_steps=0, max_tokens=0)
        
        # Should fail without max_epochs
        with pytest.raises(ValueError, match="EPOCH training mode requires max_epochs > 0"):
            validate_training_mode(TrainingMode.EPOCH, max_epochs=0, max_steps=0, max_tokens=0)
    
    def test_step_mode_validation(self):
        """Test STEP mode validation."""
        # Should pass with valid max_steps
        validate_training_mode(TrainingMode.STEP, max_epochs=0, max_steps=100, max_tokens=0)
        
        # Should fail without max_steps
        with pytest.raises(ValueError, match="STEP training mode requires max_steps > 0"):
            validate_training_mode(TrainingMode.STEP, max_epochs=0, max_steps=0, max_tokens=0)
    
    def test_token_mode_validation(self):
        """Test TOKEN mode validation."""
        # Should pass with valid max_tokens
        validate_training_mode(TrainingMode.TOKEN, max_epochs=0, max_steps=0, max_tokens=1000)
        
        # Should fail without max_tokens
        with pytest.raises(ValueError, match="TOKEN training mode requires max_tokens > 0"):
            validate_training_mode(TrainingMode.TOKEN, max_epochs=0, max_steps=0, max_tokens=0)
    
    def test_infinite_mode_validation(self):
        """Test INFINITE mode validation."""
        # Should pass with any parameter values since INFINITE mode doesn't check them
        validate_training_mode(TrainingMode.INFINITE, max_epochs=0, max_steps=0, max_tokens=0)
        validate_training_mode(TrainingMode.INFINITE, max_epochs=5, max_steps=100, max_tokens=1000)


class TestTrainFunction:
    """Test suite for the main train function."""
    
    @pytest.fixture
    def mock_model(self):
        """Create a mock model for training."""
        model = MagicMock()
        model.train = MagicMock()
        
        # Create mock parameter with device attribute
        mock_param = MagicMock()
        mock_param.device = torch.device('cpu')
        model.parameters = MagicMock(return_value=iter([mock_param]))  # Return iterator
        
        # Mock model forward pass - return unreduced losses (per-token)
        output = MagicMock()
        # Return a tensor of losses that will be summed in the training loop
        output.loss = torch.tensor([1.5, 2.0, 3.0, 2.5, 1.0], requires_grad=True)  # 5 token losses
        model.return_value = output
        
        return model
    
    @pytest.fixture
    def mock_optimizer(self):
        """Create a mock optimizer."""
        optimizer = MagicMock()
        optimizer.step = MagicMock()
        optimizer.zero_grad = MagicMock()
        return optimizer
    
    @pytest.fixture
    def mock_scheduler(self):
        """Create a mock scheduler."""
        scheduler = MagicMock()
        scheduler.step = MagicMock()
        scheduler.get_last_lr = MagicMock(return_value=[1e-5])
        return scheduler
    
    @pytest.fixture
    def mock_data_loader(self):
        """Create a mock data loader that produces minibatches."""
        # Create mock minibatch data
        minibatch = {
            'input_ids': torch.tensor([[1, 2, 3, 4, 5]]),
            'labels': torch.tensor([[10, 20, 30, 40, 50]]),
            'position_ids': torch.tensor([[1, 1, 1, 1, 1]]),
            'num_loss_counted_tokens': 5,
            'num_samples': 1,
            'batch_num_loss_counted_tokens': 5
        }
        
        # Create a data loader that yields batches (which are lists of minibatches)
        def data_generator():
            for _ in range(3):  # Yield 3 batches
                yield [minibatch.copy(), minibatch.copy()]  # 2 minibatches per batch
        
        loader = MagicMock()
        loader.__iter__ = data_generator
        # Add sampler with set_epoch method
        loader.sampler = MagicMock()
        loader.sampler.set_epoch = MagicMock()
        return loader
    
    @patch.dict(os.environ, {'WORLD_SIZE': '2', 'RANK': '0', 'LOCAL_WORLD_SIZE': '2'})
    @patch('torch.distributed.is_initialized', return_value=True)
    @patch('torch.distributed.get_world_size', return_value=2)
    @patch('torch.distributed.get_rank', return_value=0)
    @patch('torch.distributed.all_reduce')
    @patch('mini_trainer.train.dist.get_rank', return_value=0)
    @patch('mini_trainer.train.AsyncStructuredLogger')
    @patch('mini_trainer.train.take_gradient_step')
    @patch('mini_trainer.train.save_model')
    @patch('torch.cuda.reset_peak_memory_stats')
    @patch('torch.cuda.empty_cache')
    @patch('torch.cuda.max_memory_allocated', return_value=1e9)
    @patch('torch.distributed.barrier')
    def test_train_basic_loop(self, mock_barrier, mock_memory, mock_empty_cache,
                              mock_reset_stats, mock_save, mock_grad_step,
                              mock_logger_cls, mock_dist_rank, mock_all_reduce, mock_torch_rank,
                              mock_world_size, mock_is_init,
                              mock_model, mock_optimizer, mock_scheduler, mock_data_loader):
        """Test basic training loop execution."""
        # Setup mocks
        mock_logger = MagicMock()
        mock_logger_cls.return_value = mock_logger
        
        mock_grad_step.return_value = torch.tensor(1.0)
        
        with tempfile.TemporaryDirectory() as temp_dir:
            # Run training for a few steps
            with patch('mini_trainer.train.iter', side_effect=lambda x: iter(x)):
                # Use STEP mode with max_steps to ensure termination
                mock_data_loader.__iter__ = lambda self: iter([
                    [{'input_ids': torch.tensor([[1, 2]]),
                      'labels': torch.tensor([[10, 20]]),
                      'position_ids': torch.tensor([5], dtype=torch.long),
                      'num_loss_counted_tokens': 2,
                      'num_samples': 1,
                      'batch_num_loss_counted_tokens': 2}]
                    for _ in range(5)  # Provide enough batches
                ])
                # Add sampler with set_epoch method
                mock_data_loader.sampler = MagicMock()
                mock_data_loader.sampler.set_epoch = MagicMock()
                
                train(
                    model=mock_model,
                    optimizer=mock_optimizer,
                    lr_scheduler=mock_scheduler,
                    data_loader=mock_data_loader,
                    output_dir=temp_dir,
                    min_samples_per_checkpoint=10,
                    model_name_or_path="test/model",
                    training_mode=TrainingMode.STEP,
                    max_steps=2  # Train for only 2 steps
                )
        
        # Verify model was set to training mode
        mock_model.train.assert_called_once()
        
        # Verify gradient steps were taken
        assert mock_grad_step.call_count >= 1
        
        # Verify metrics were logged
        assert mock_logger.log_sync.call_count >= 1
    
    @patch.dict(os.environ, {'WORLD_SIZE': '2', 'RANK': '0', 'LOCAL_WORLD_SIZE': '2'})
    @patch('torch.distributed.is_initialized', return_value=True)
    @patch('torch.distributed.get_world_size', return_value=2)
    @patch('torch.distributed.get_rank', return_value=0)
    @patch('torch.distributed.all_reduce')
    @patch('mini_trainer.train.dist.get_rank', return_value=0)
    @patch('mini_trainer.train.AsyncStructuredLogger')
    @patch('mini_trainer.train.take_gradient_step')
    @patch('mini_trainer.train.save_model')
    @patch('torch.cuda.reset_peak_memory_stats')
    @patch('torch.cuda.empty_cache')
    @patch('torch.distributed.barrier')
    def test_train_checkpoint_saving(self, mock_barrier, mock_empty_cache,
                                    mock_reset_stats, mock_save, mock_grad_step,
                                    mock_logger_cls, mock_dist_rank, mock_all_reduce, mock_torch_rank,
                                    mock_world_size, mock_is_init,
                                    mock_model, mock_optimizer, mock_scheduler):
        """Test checkpoint saving based on samples processed."""
        mock_logger = MagicMock()
        mock_logger_cls.return_value = mock_logger
        mock_grad_step.return_value = torch.tensor(1.0)
        
        # Create data loader with enough samples to trigger checkpoint
        batches = []
        for _ in range(5):
            batch = [{
                'input_ids': torch.tensor([[1, 2, 3]]),
                'labels': torch.tensor([[10, 20, 30]]),
                'num_loss_counted_tokens': 3,
                'num_samples': 3,  # 3 samples per batch
                'position_ids': torch.tensor([1, 1, 1], dtype=torch.long),
                'batch_num_loss_counted_tokens': 3
            }]
            batches.append(batch)
        
        mock_data_loader = MagicMock()
        mock_data_loader.__iter__ = lambda self: iter(batches)
        # Add sampler with set_epoch method
        mock_data_loader.sampler = MagicMock()
        mock_data_loader.sampler.set_epoch = MagicMock()
        
        with tempfile.TemporaryDirectory() as temp_dir:
            train(
                model=mock_model,
                optimizer=mock_optimizer,
                lr_scheduler=mock_scheduler,
                data_loader=mock_data_loader,
                output_dir=temp_dir,
                min_samples_per_checkpoint=10,  # Save after 10 samples
                model_name_or_path="test/model",
                training_mode=TrainingMode.STEP,
                max_steps=5  # Train for 5 steps to accumulate enough samples
            )
        
        # Should save checkpoint when samples exceed threshold
        assert mock_save.call_count >= 1
        
        # Check that save was called with correct arguments
        save_call = mock_save.call_args_list[0]
        assert save_call[0][0] == mock_model
        # Due to the current implementation, save happens after first batch
        # when accumulated_samples > last_saved_samples (3 > 0)
        # This saves at 3 samples rather than waiting for min_samples_per_checkpoint
        samples_seen = save_call[0][1]
        assert samples_seen >= 3, f"Expected at least 3 samples, got {samples_seen}"
    
    @patch.dict(os.environ, {'WORLD_SIZE': '4', 'RANK': '1', 'LOCAL_WORLD_SIZE': '4'})
    @patch('torch.distributed.is_initialized', return_value=True)
    @patch('torch.distributed.get_world_size', return_value=4)
    @patch('torch.distributed.get_rank', return_value=1)
    @patch('torch.distributed.all_reduce')
    @patch('mini_trainer.train.dist.get_rank', return_value=1)
    @patch('mini_trainer.train.AsyncStructuredLogger')
    @patch('mini_trainer.train.take_gradient_step')
    @patch('mini_trainer.train.save_model')
    @patch('torch.cuda.reset_peak_memory_stats')
    @patch('torch.cuda.empty_cache')
    @patch('torch.distributed.barrier')
    def test_train_non_main_process(self, mock_barrier, mock_empty_cache, mock_reset_stats, mock_save,
                                   mock_grad_step, mock_logger_cls, mock_dist_rank, mock_all_reduce,
                                   mock_torch_rank, mock_world_size, mock_is_init,
                                   mock_model, mock_optimizer, mock_scheduler):
        """Test training on non-main process (rank != 0)."""
        mock_logger = MagicMock()
        mock_logger_cls.return_value = mock_logger
        mock_grad_step.return_value = torch.tensor(1.0)
        
        # Simple data loader
        mock_data_loader = MagicMock()
        mock_data_loader.__iter__ = lambda self: iter([[{
            'input_ids': torch.tensor([[1, 2]]),
            'labels': torch.tensor([[10, 20,]], dtype=torch.long),
            'position_ids': torch.tensor([[1, 1,]], dtype=torch.long),
            'num_loss_counted_tokens': 2,
            'num_samples': 1,
            'batch_num_loss_counted_tokens': 2
        }]] * 2)  # Provide 2 batches
        # Add sampler with set_epoch method
        mock_data_loader.sampler = MagicMock()
        mock_data_loader.sampler.set_epoch = MagicMock()
        
        with tempfile.TemporaryDirectory() as temp_dir:
            train(
                model=mock_model,
                optimizer=mock_optimizer,
                lr_scheduler=mock_scheduler,
                data_loader=mock_data_loader,
                output_dir=temp_dir,
                min_samples_per_checkpoint=100,
                model_name_or_path="test/model",
                training_mode=TrainingMode.STEP,
                max_steps=1  # Train for only 1 step
            )
        
        # Non-main process should still train
        mock_model.train.assert_called_once()
        
        # But shouldn't log metrics (only rank 0 logs in the if statement)
        # The logger is created but log_sync is only called if is_main_process
        if mock_logger.log_sync.called:
            # If it was called, verify it was not for metrics logging
            for call_args in mock_logger.log_sync.call_args_list:
                # This would be empty or different for non-main process
                pass


class TestMainCLI:
    """Test suite for the main CLI function."""
    
    @patch('torch.distributed.get_world_size', return_value=1)
    @patch('mini_trainer.train.get_node_rank', return_value=0)
    @patch('mini_trainer.train.destroy_distributed_environment')
    @patch('mini_trainer.train.init_distributed_environment')
    @patch('mini_trainer.train.setup_logger')
    @patch('mini_trainer.train.setup_model')
    @patch('mini_trainer.train.setup_training_components')
    @patch('mini_trainer.train.get_data_loader', return_value=(MagicMock(), None))
    @patch('mini_trainer.train.train')
    @patch('mini_trainer.train.dist.get_rank', return_value=0)
    @patch.dict(os.environ, {'WORLD_SIZE': '1'})
    def test_main_basic(self, mock_rank, mock_train_fn, mock_get_loader,
                        mock_setup_components, mock_setup_model,
                        mock_setup_logger, mock_init_dist, mock_destroy_dist, mock_get_node_rank, mock_world_size):
        """Test basic main function execution."""
        # Setup mocks
        mock_model = MagicMock()
        mock_setup_model.return_value = mock_model
        
        mock_optimizer = MagicMock()
        mock_scheduler = MagicMock()
        mock_setup_components.return_value = (mock_model, mock_optimizer, mock_scheduler)
        
        
        with tempfile.TemporaryDirectory() as temp_dir:
            main(
                model_name_or_path="test/model",
                data_path="test.jsonl",
                batch_size=32,
                max_tokens_per_gpu=1000,
                learning_rate=1e-5,
                num_warmup_steps=10,
                lr_scheduler="constant",
                seed=42,
                use_liger_kernels=False,
                osft=False,
                output_dir=temp_dir,
                min_samples_per_checkpoint=1000
            )
        
        # Verify initialization
        mock_init_dist.assert_called_once()
        mock_setup_logger.assert_called_once_with(level="INFO")
        
        # Verify model setup
        mock_setup_model.assert_called_once()
        mock_setup_components.assert_called_once()
        
        # Verify data loader creation
        mock_get_loader.assert_called_once()
        
        # Verify training was started
        mock_train_fn.assert_called_once()
    
    @patch('torch.distributed.get_world_size', return_value=1)
    @patch('mini_trainer.train.get_node_rank', return_value=0)
    @patch('mini_trainer.train.destroy_distributed_environment')
    @patch('mini_trainer.train.init_distributed_environment')
    @patch('mini_trainer.train.setup_logger')
    @patch('mini_trainer.train.setup_model')
    @patch('mini_trainer.train.setup_training_components')
    @patch('mini_trainer.train.get_data_loader', return_value=(MagicMock(), MagicMock()))
    @patch('mini_trainer.train.train')
    @patch('mini_trainer.train.dist.get_rank', return_value=0)
    @patch.dict(os.environ, {'WORLD_SIZE': '1'})
    @patch('builtins.open', new_callable=mock_open)
    def test_main_saves_parameters(self, mock_file, mock_rank, mock_train_fn,
                                  mock_get_loader, mock_setup_components,
                                  mock_setup_model, mock_setup_logger, mock_init_dist, mock_destroy_dist,
                                  mock_get_node_rank, mock_world_size):
        """Test that main saves training parameters."""
        mock_model = MagicMock()
        mock_setup_model.return_value = mock_model
        mock_setup_components.return_value = (mock_model, MagicMock(), MagicMock())
        
        with tempfile.TemporaryDirectory() as temp_dir:
            main(
                model_name_or_path="test/model",
                data_path="test.jsonl",
                batch_size=32,
                max_tokens_per_gpu=1000,
                learning_rate=1e-5,
                num_warmup_steps=10,
                lr_scheduler="constant",
                seed=42,
                use_liger_kernels=True,
                osft=True,
                osft_unfreeze_rank_ratio=0.5,
                output_dir=temp_dir,
                min_samples_per_checkpoint=500
            )
        
        # Check that parameters were saved
        mock_file.assert_called()
        
        # Extract what was written
        written_content = ''.join(c.args[0] for c in mock_file().write.call_args_list)
        if written_content:
            params = json.loads(written_content)
            assert params['model_name_or_path'] == "test/model"
            assert params['batch_size'] == 32
            assert params['learning_rate'] == 1e-5
            assert params['use_liger_kernels'] is True
            assert params['osft'] is True
            assert params['osft_unfreeze_rank_ratio'] == 0.5
    
    @patch.dict(os.environ, {'WORLD_SIZE': '2', 'LOCAL_RANK': '1'})
    @patch('mini_trainer.train.train')
    @patch('mini_trainer.train.get_data_loader', return_value=(MagicMock(), None))
    @patch('mini_trainer.train.setup_training_components', return_value=(MagicMock(), MagicMock(), MagicMock()))
    @patch('mini_trainer.train.setup_model', return_value=MagicMock())
    @patch('mini_trainer.train.setup_logger')
    @patch('builtins.open', new_callable=mock_open)
    @patch('mini_trainer.train.dist.get_rank', return_value=1)
    @patch('mini_trainer.train.init_distributed_environment')
    @patch('mini_trainer.train.destroy_distributed_environment')
    @patch('mini_trainer.train.get_node_rank', return_value=0)
    @patch('torch.distributed.get_rank', return_value=1)
    @patch('torch.distributed.get_world_size', return_value=2)
    def test_main_non_rank_0_no_params_save(self, mock_world_size, mock_torch_get_rank, mock_get_node_rank,
                                           mock_destroy_dist, mock_init_dist, mock_rank, mock_file, 
                                           mock_setup_logger, mock_setup_model, mock_setup_comp,
                                           mock_get_data_loader, mock_train):
        """Test that non-rank-0 processes don't save parameters."""
        with tempfile.TemporaryDirectory() as temp_dir:
            main(
                model_name_or_path="test/model",
                data_path="test.jsonl",
                batch_size=32,
                max_tokens_per_gpu=1000,
                learning_rate=1e-5,
                num_warmup_steps=10,
                lr_scheduler="constant",
                seed=42,
                use_liger_kernels=False,
                osft=False,
                output_dir=temp_dir,
                min_samples_per_checkpoint=1000
            )
        
        # Check that open was not called for writing params
        # (it might be called for other purposes)
        param_file_written = any(
            'training_params.json' in str(call)
            for call in mock_file.call_args_list
        )
        assert not param_file_written


class TestBatchProcessing:
    """Test suite for batch processing within training loop."""
    
    def test_minibatch_accumulation(self):
        """Test accumulation of metrics across minibatches."""
        batch_metrics = BatchMetrics()
        
        # Simulate processing 3 minibatches in a batch
        minibatches = [
            {'num_samples': 2, 'loss': 2.5, 'tokens': 100},
            {'num_samples': 3, 'loss': 3.0, 'tokens': 150},
            {'num_samples': 1, 'loss': 1.5, 'tokens': 50}
        ]
        
        for mb in minibatches:
            batch_metrics.accumulate_minibatch_metrics(
                num_samples=mb['num_samples'],
                loss=mb['loss'],
                num_total_tokens=mb['tokens']
            )
        
        # Check accumulated values
        assert batch_metrics.minibatch_metrics['num_samples'] == 6
        assert batch_metrics.minibatch_metrics['loss'] == 7.0
        assert batch_metrics.minibatch_metrics['num_total_tokens'] == 300
    
    @patch('torch.distributed.all_reduce')
    def test_batch_reduction_across_ranks(self, mock_all_reduce):
        """Test reduction of batch metrics across distributed ranks."""
        batch_metrics = BatchMetrics()
        
        # Setup metrics
        batch_metrics.minibatch_metrics['num_samples'] = 4
        batch_metrics.minibatch_metrics['loss'] = 10.0
        
        # Mock all_reduce to simulate 4 GPUs
        def all_reduce_effect(tensor, op):
            tensor.mul_(4)
        mock_all_reduce.side_effect = all_reduce_effect
        
        device = torch.device('cpu')
        batch_metrics.reduce_batch_metrics(device)
        
        # Check reduced totals
        assert batch_metrics.totals['num_samples'] == 16
        assert batch_metrics.totals['loss'] == 40.0
        
        # Check minibatch metrics were cleared
        assert len(batch_metrics.minibatch_metrics) == 0


class TestErrorHandling:
    """Test suite for error handling in training."""
    
    @patch.dict(os.environ, {'WORLD_SIZE': '1', 'RANK': '0', 'LOCAL_WORLD_SIZE': '1'})
    @patch('torch.distributed.is_initialized', return_value=True)
    @patch('torch.distributed.get_world_size', return_value=1)
    @patch('torch.distributed.get_rank', return_value=0)
    @patch('torch.distributed.all_reduce')
    @patch('mini_trainer.train.dist.get_rank', return_value=0)
    @patch('mini_trainer.train.AsyncStructuredLogger')
    @patch('mini_trainer.train.save_model')
    @patch('torch.cuda.reset_peak_memory_stats')
    @patch('torch.cuda.empty_cache')
    @patch('torch.distributed.barrier')
    def test_train_handles_empty_batch(self, mock_barrier, mock_empty_cache, mock_reset_stats,
                                       mock_save, mock_logger_cls, mock_dist_rank, mock_all_reduce,
                                       mock_torch_rank, mock_world_size, mock_is_init):
        """Test handling of batches with minimal data."""
        mock_model = MagicMock()
        mock_model.train = MagicMock()
        mock_param = MagicMock()
        mock_param.device = torch.device('cpu')
        mock_model.parameters = MagicMock(return_value=iter([mock_param]))
        
        # Mock model output - return unreduced loss for 1 token
        output = MagicMock()
        output.loss = torch.tensor([2.5], requires_grad=True)  # 1 token loss
        mock_model.return_value = output
        
        # Data loader with minimal batch
        mock_data_loader = MagicMock()
        mock_data_loader.__iter__ = lambda self: iter([
            [{'input_ids': torch.tensor([[1]]),
              'labels': torch.tensor([[10]]),
              'position_ids': torch.tensor([1], dtype=torch.long),
              'num_loss_counted_tokens': 1,
              'num_samples': 1,
              'batch_num_loss_counted_tokens': 1}]
        ] * 2)  # Provide 2 batches
        # Add sampler with set_epoch method
        mock_data_loader.sampler = MagicMock()
        mock_data_loader.sampler.set_epoch = MagicMock()
        
        mock_optimizer = MagicMock()
        mock_scheduler = MagicMock()
        
        with tempfile.TemporaryDirectory() as temp_dir:
            # Should handle minimal batch without crashing
            with patch('mini_trainer.train.take_gradient_step') as mock_grad_step:
                mock_grad_step.return_value = torch.tensor(1.0)
                
                train(
                    model=mock_model,
                    optimizer=mock_optimizer,
                    lr_scheduler=mock_scheduler,
                    data_loader=mock_data_loader,
                    output_dir=temp_dir,
                    min_samples_per_checkpoint=100,
                    model_name_or_path="test/model",
                    training_mode=TrainingMode.STEP,
                    max_steps=1  # Train for only 1 step
                )
                
                # Should have processed one batch
                assert mock_grad_step.call_count == 1


class TestTrainingModes:
    """Test suite for different training modes."""
    
    @patch.dict(os.environ, {'WORLD_SIZE': '1', 'RANK': '0', 'LOCAL_WORLD_SIZE': '1'})
    @patch('torch.distributed.is_initialized', return_value=True)
    @patch('torch.distributed.get_world_size', return_value=1)
    @patch('torch.distributed.get_rank', return_value=0)
    @patch('torch.distributed.all_reduce')
    @patch('mini_trainer.train.dist.get_rank', return_value=0)
    @patch('mini_trainer.train.AsyncStructuredLogger')
    @patch('mini_trainer.train.take_gradient_step')
    @patch('mini_trainer.train.save_model')
    @patch('torch.cuda.reset_peak_memory_stats')
    @patch('torch.cuda.empty_cache')
    @patch('torch.cuda.max_memory_allocated', return_value=1e9)
    @patch('torch.distributed.barrier')
    def test_step_mode(self, mock_barrier, mock_memory, mock_empty_cache,
                      mock_reset_stats, mock_save, mock_grad_step, mock_logger_cls,
                      mock_dist_rank, mock_all_reduce, mock_torch_rank,
                      mock_world_size, mock_is_init):
        """Test STEP training mode stops after max_steps."""
        mock_logger = MagicMock()
        mock_logger_cls.return_value = mock_logger
        mock_grad_step.return_value = torch.tensor(1.0)
        
        # Setup model
        mock_model = MagicMock()
        mock_model.train = MagicMock()
        mock_param = MagicMock()
        mock_param.device = torch.device('cpu')
        mock_model.parameters = MagicMock(return_value=iter([mock_param]))
        output = MagicMock()
        # Return unreduced losses for 2 tokens
        output.loss = torch.tensor([2.5, 3.0], requires_grad=True)  # 2 token losses
        mock_model.return_value = output
        
        # Create data loader with more batches than we'll use
        mock_data_loader = MagicMock()
        mock_data_loader.__iter__ = lambda self: iter([[{
            'input_ids': torch.tensor([[1, 2]]),
            'labels': torch.tensor([[10, 20]]),
            'position_ids': torch.tensor([2], dtype=torch.long),
            'num_loss_counted_tokens': 2,
            'num_samples': 1,
            'batch_num_loss_counted_tokens': 2
        }]] * 10)  # 10 batches available
        mock_data_loader.sampler = MagicMock()
        mock_data_loader.sampler.set_epoch = MagicMock()
        
        with tempfile.TemporaryDirectory() as temp_dir:
            train(
                model=mock_model,
                optimizer=MagicMock(),
                lr_scheduler=MagicMock(),
                data_loader=mock_data_loader,
                output_dir=temp_dir,
                min_samples_per_checkpoint=100,
                model_name_or_path="test/model",
                training_mode=TrainingMode.STEP,
                max_steps=3  # Train for exactly 3 steps
            )
        
        # Should have taken exactly 3 gradient steps
        assert mock_grad_step.call_count == 3
    
    @patch.dict(os.environ, {'WORLD_SIZE': '1', 'RANK': '0', 'LOCAL_WORLD_SIZE': '1'})
    @patch('torch.distributed.is_initialized', return_value=True)
    @patch('torch.distributed.get_world_size', return_value=1)
    @patch('torch.distributed.get_rank', return_value=0)
    @patch('torch.distributed.all_reduce')
    @patch('mini_trainer.train.dist.get_rank', return_value=0)
    @patch('mini_trainer.train.AsyncStructuredLogger')
    @patch('mini_trainer.train.take_gradient_step')
    @patch('mini_trainer.train.save_model')
    @patch('torch.cuda.reset_peak_memory_stats')
    @patch('torch.cuda.empty_cache')
    @patch('torch.cuda.max_memory_allocated', return_value=1e9)
    @patch('torch.distributed.barrier')
    def test_token_mode(self, mock_barrier, mock_memory, mock_empty_cache,
                       mock_reset_stats, mock_save, mock_grad_step, mock_logger_cls,
                       mock_dist_rank, mock_all_reduce, mock_torch_rank,
                       mock_world_size, mock_is_init):
        """Test TOKEN training mode stops after max_tokens."""
        mock_logger = MagicMock()
        mock_logger_cls.return_value = mock_logger
        mock_grad_step.return_value = torch.tensor(1.0)
        
        # Setup model
        mock_model = MagicMock()
        mock_model.train = MagicMock()
        mock_param = MagicMock()
        mock_param.device = torch.device('cpu')
        mock_model.parameters = MagicMock(return_value=iter([mock_param]))
        output = MagicMock()
        # Return unreduced losses for 5 tokens
        output.loss = torch.tensor([2.5, 3.0, 1.5, 2.0, 3.5], requires_grad=True)  # 5 token losses
        mock_model.return_value = output
        
        # Create data loader with batches containing specific token counts
        mock_data_loader = MagicMock()
        mock_data_loader.__iter__ = lambda self: iter([[{
            'input_ids': torch.tensor([[1, 2, 3, 4, 5]]),  # 5 tokens
            'labels': torch.tensor([[10, 20, 30, 40, 50]]),
            'position_ids': torch.tensor([5], dtype=torch.long),
            'num_loss_counted_tokens': 5,
            'num_samples': 1,
            'batch_num_loss_counted_tokens': 5  # 5 tokens counted per batch
        }]] * 10)  # 10 batches available
        mock_data_loader.sampler = MagicMock()
        mock_data_loader.sampler.set_epoch = MagicMock()
        
        with tempfile.TemporaryDirectory() as temp_dir:
            train(
                model=mock_model,
                optimizer=MagicMock(),
                lr_scheduler=MagicMock(),
                data_loader=mock_data_loader,
                output_dir=temp_dir,
                min_samples_per_checkpoint=100,
                model_name_or_path="test/model",
                training_mode=TrainingMode.TOKEN,
                max_tokens=12  # Stop after 12 tokens (will process 3 batches = 15 tokens),

            )
        
        # Should have processed 3 batches (15 tokens total, stopped after reaching 12)
        assert mock_grad_step.call_count == 3


class TestMemoryManagement:
    """Test suite for memory management during training."""
    
    @patch.dict(os.environ, {'WORLD_SIZE': '1', 'RANK': '0', 'LOCAL_WORLD_SIZE': '1'})
    @patch('torch.distributed.is_initialized', return_value=True)
    @patch('torch.distributed.get_world_size', return_value=1)
    @patch('torch.distributed.get_rank', return_value=0)
    @patch('torch.distributed.all_reduce')
    @patch('mini_trainer.train.dist.get_rank', return_value=0)
    @patch('mini_trainer.train.AsyncStructuredLogger')
    @patch('mini_trainer.train.save_model')
    @patch('torch.cuda.reset_peak_memory_stats')
    @patch('torch.cuda.empty_cache')
    @patch('torch.cuda.max_memory_allocated', return_value=2e9)
    @patch('torch.distributed.barrier')
    def test_memory_tracking(self, mock_barrier, mock_max_mem, mock_empty_cache,
                            mock_reset_stats, mock_save, mock_logger_cls, mock_dist_rank,
                            mock_all_reduce, mock_torch_rank, mock_world_size, mock_is_init):
        """Test memory tracking and management."""
        mock_logger = MagicMock()
        mock_logger_cls.return_value = mock_logger
        
        mock_model = MagicMock()
        mock_model.train = MagicMock()
        mock_param = MagicMock()
        mock_param.device = torch.device('cpu')
        mock_model.parameters = MagicMock(return_value=iter([mock_param]))
        output = MagicMock()
        # Return unreduced losses for 2 tokens
        output.loss = torch.tensor([2.5, 3.0], requires_grad=True)  # 2 token losses
        mock_model.return_value = output
        
        mock_data_loader = MagicMock()
        mock_data_loader.__iter__ = lambda self: iter([[{
            'input_ids': torch.tensor([[1, 2]]),
            'labels': torch.tensor([[10, 20]]),
            'position_ids': torch.tensor([1, 1], dtype=torch.long),
            'num_loss_counted_tokens': 2,
            'num_samples': 1,
            'batch_num_loss_counted_tokens': 2
        }]] * 2)  # Provide 2 batches
        # Add sampler with set_epoch method
        mock_data_loader.sampler = MagicMock()
        mock_data_loader.sampler.set_epoch = MagicMock()
        
        with patch('mini_trainer.train.take_gradient_step') as mock_grad_step:
            mock_grad_step.return_value = torch.tensor(1.0)
            
            with tempfile.TemporaryDirectory() as temp_dir:
                train(
                    model=mock_model,
                    optimizer=MagicMock(),
                    lr_scheduler=MagicMock(),
                    data_loader=mock_data_loader,
                    output_dir=temp_dir,
                    min_samples_per_checkpoint=100,
                    model_name_or_path="test/model",
                    training_mode=TrainingMode.STEP,
                    max_steps=1  # Train for only 1 step
                )
        
        # Verify memory management calls
        mock_reset_stats.assert_called()
        mock_empty_cache.assert_called()
        
        # Verify memory was tracked in metrics
        logged_metrics = mock_logger.log_sync.call_args[0][0]
        assert 'peak_memory_usage_GB' in logged_metrics
        assert logged_metrics['peak_memory_usage_GB'] == 2.0  # 2e9 / 1e9


class TestSaveModel:
    """Test suite for save_model function."""
    
    @patch('safetensors.torch.save_file')
    @patch('huggingface_hub.split_torch_state_dict_into_shards', return_value=MagicMock(filename_to_tensors={'model.safetensors': []}, is_sharded=False))
    @patch('transformers.AutoTokenizer.from_pretrained', return_value=MagicMock())
    @patch('torch.distributed.checkpoint.state_dict.get_model_state_dict', return_value={})
    @patch('mini_trainer.train.torch.distributed.barrier')
    @patch('mini_trainer.train.torch.distributed.get_rank', return_value=0)
    @patch.dict(os.environ, {'RANK': '0', 'LOCAL_WORLD_SIZE': '1'})
    def test_save_model_rank_0_saves_files(self, mock_rank, mock_barrier, mock_state_dict,
                                           mock_tokenizer, mock_split, mock_save):
        """Test that rank 0 creates model files."""
        from mini_trainer.train import save_model
        
        model = MagicMock()
        model.module.config.torch_dtype = torch.bfloat16
        
        with tempfile.TemporaryDirectory() as temp_dir:
            save_model(model, samples_seen=1000, output_dir=temp_dir, model_name_or_path="test")
            
            # Verify files are saved on rank 0
            mock_save.assert_called_once()

    @patch('safetensors.torch.save_file')
    @patch('torch.distributed.checkpoint.state_dict.get_model_state_dict', return_value={})
    @patch('mini_trainer.train.torch.distributed.barrier')
    @patch('mini_trainer.train.torch.distributed.get_rank', return_value=1)
    @patch.dict(os.environ, {'RANK': '1', 'LOCAL_WORLD_SIZE': '2'})
    def test_save_model_non_rank_0_no_save(self, mock_rank, mock_barrier, mock_state_dict, mock_save):
        """Test that non-rank 0 processes don't save files."""
        from mini_trainer.train import save_model
        
        model = MagicMock()
        model.module.config.torch_dtype = torch.bfloat16
        
        with tempfile.TemporaryDirectory() as temp_dir:
            save_model(model, samples_seen=1000, output_dir=temp_dir, model_name_or_path="test")
            
            # Non-rank 0 should not save
            mock_save.assert_not_called()

    @patch('safetensors.torch.save_file')
    @patch('huggingface_hub.split_torch_state_dict_into_shards')
    @patch('transformers.AutoTokenizer.from_pretrained', return_value=MagicMock())
    @patch('torch.distributed.checkpoint.state_dict.get_model_state_dict', return_value={'original': torch.tensor([2.0])})
    @patch('mini_trainer.train.torch.distributed.barrier')
    @patch('mini_trainer.train.torch.distributed.get_rank', return_value=0)
    @patch.dict(os.environ, {'RANK': '0', 'LOCAL_WORLD_SIZE': '1'})
    def test_save_model_calls_osft_prepare(self, mock_rank, mock_barrier, mock_state_dict,
                                          mock_tokenizer, mock_split, mock_save):
        """Test that OSFT models get their prepare_state_dict_for_save called."""
        from mini_trainer.train import save_model
        
        model = MagicMock()
        model.module.config.torch_dtype = torch.bfloat16
        model.module.prepare_state_dict_for_save = MagicMock(return_value={'weight': torch.tensor([1.0])})
        
        mock_split.return_value = MagicMock(filename_to_tensors={'model.safetensors': ['weight']}, is_sharded=False)
        
        with tempfile.TemporaryDirectory() as temp_dir:
            save_model(model, samples_seen=1000, output_dir=temp_dir, model_name_or_path="test")
            
            # Verify OSFT prepare method was called
            model.module.prepare_state_dict_for_save.assert_called_once()

    @patch('safetensors.torch.save_file')
    @patch('huggingface_hub.split_torch_state_dict_into_shards')
    @patch('transformers.AutoTokenizer.from_pretrained', return_value=MagicMock())
    @patch('torch.distributed.checkpoint.state_dict.get_model_state_dict')
    @patch('mini_trainer.train.torch.distributed.barrier')
    @patch('mini_trainer.train.torch.distributed.get_rank', return_value=0)
    @patch.dict(os.environ, {'RANK': '0', 'LOCAL_WORLD_SIZE': '1'})
    def test_save_model_dtype_casting(self, mock_rank, mock_barrier, mock_state_dict,
                                     mock_tokenizer, mock_split, mock_save):
        """Test that tensors get cast to save_dtype."""
        from mini_trainer.train import save_model
        
        model = MagicMock()
        model.module.config.torch_dtype = torch.bfloat16
        
        # Start with fp32 tensor
        original_tensor = torch.tensor([1.0, 2.0], dtype=torch.float32)
        state_dict = {'weight': original_tensor}
        mock_state_dict.return_value = state_dict
        
        mock_split.return_value = MagicMock(filename_to_tensors={'model.safetensors': ['weight']}, is_sharded=False)
        
        with tempfile.TemporaryDirectory() as temp_dir:
            save_model(model, samples_seen=1000, output_dir=temp_dir, model_name_or_path="test")
            
            # Check that save_file was called (the dtype casting happens inside save_model)
            mock_save.assert_called_once()
            # We can check the call args contain a tensor (this verifies the dtype conversion logic runs)
            call_args = mock_save.call_args[0][0]
            assert 'weight' in call_args

    @patch('safetensors.torch.save_file')
    @patch('huggingface_hub.split_torch_state_dict_into_shards', return_value=MagicMock(filename_to_tensors={'model.safetensors': []}, is_sharded=False))
    @patch('transformers.AutoTokenizer.from_pretrained', return_value=MagicMock())
    @patch('torch.distributed.checkpoint.state_dict.get_model_state_dict', return_value={})
    @patch('mini_trainer.train.torch.distributed.barrier')
    @patch('mini_trainer.train.torch.distributed.get_rank', return_value=0)
    @patch.dict(os.environ, {'RANK': '0', 'LOCAL_WORLD_SIZE': '1'})
    def test_save_model_creates_directory(self, mock_rank, mock_barrier, mock_state_dict,
                                         mock_tokenizer, mock_split, mock_save):
        """Test that save_model creates the expected directory structure."""
        from mini_trainer.train import save_model
        
        model = MagicMock()
        model.module.config.torch_dtype = torch.bfloat16
        
        with tempfile.TemporaryDirectory() as temp_dir:
            save_model(model, samples_seen=1000, output_dir=temp_dir, model_name_or_path="test")
            
            # Check directory was created
            expected_dir = Path(temp_dir) / "hf_format" / "samples_1000"
            assert expected_dir.exists()


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
