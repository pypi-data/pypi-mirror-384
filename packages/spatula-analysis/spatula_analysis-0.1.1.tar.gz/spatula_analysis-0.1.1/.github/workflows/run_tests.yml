name: Run Unit Tests

concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

on:
  # trigger on pull requests
  pull_request:

  # trigger on all commits to trunk branches
  push:
    branches:
      - "main"

  # trigger on request
  workflow_dispatch:

jobs:
  run_tests:
    name: Unit test [py${{ matrix.python }} ${{ matrix.os }}]
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-24.04]
        python: ['3.12', '3.13', '3.14']
        include:
          - os: 'macos-15'
            python: '3.14'
          - os: 'windows-2025'
            python: '3.14'

    steps:
      - name: Checkout Code
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0
        with:
          submodules: true
      - name: Set up Python
        uses: actions/setup-python@e797f83bcb11b83ae66e0230d6156d7c80228e7c # v6.0.0
        with:
          python-version: ${{ matrix.python }}
      - name: Set up Python environment
        uses: glotzerlab/workflows/setup-uv@894d9678188a02b06560fdeb2b9ba98d016cd371 # 0.10.0
        with:
          lockfile: ".github/workflows/requirements-test.txt"
      - name: Build and Install
        run: |
          uv pip install . --no-build-isolation --no-deps --system -v
      - name: Run Tests (Unix/macOS)
        if: runner.os != 'Windows'
        run: pytest tests/ -v
      - name: Run Tests (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          $ErrorActionPreference = 'Continue'
          $PSNativeCommandUseErrorActionPreference = $false
          $xmlPath = Join-Path $env:GITHUB_WORKSPACE 'pytest-report.xml'
          pytest tests/ -v --junitxml="$xmlPath"
          $code = $LASTEXITCODE
          Write-Host "pytest exit code: $code"
          Write-Host "pwd: $(Get-Location)"
          Write-Host "xml exists: $(Test-Path -LiteralPath $xmlPath)"

          if ($code -eq 0) { exit 0 }

          if ($code -ne 0 -and (Test-Path -LiteralPath $xmlPath)) {
            [xml]$j = Get-Content -LiteralPath $xmlPath -ErrorAction Stop

            $suites = @()
            if ($j.testsuite) { $suites = @($j.testsuite) }
            elseif ($j.testsuites) { $suites = @($j.testsuites.testsuite) }

            $failures = ($suites | ForEach-Object { [int]$_.failures } | Measure-Object -Sum).Sum
            $errors   = ($suites | ForEach-Object { [int]$_.errors }   | Measure-Object -Sum).Sum
            $tests    = ($suites | ForEach-Object { [int]$_.tests }    | Measure-Object -Sum).Sum

            Write-Host ("second JUnit aggregate: tests={0} failures={1} errors={2}" -f $tests, $failures, $errors)
            $suites | % {
              $name = if ($_.name) { $_.name } else { "<unnamed>" }
              Write-Host (" - suite {0}: tests={1} failures={2} errors={3}" -f $name, $_.tests, $_.failures, $_.errors)
            }

            if ($tests -gt 0 -and $failures -eq 0 -and $errors -eq 0) {
              Write-Host "Non-zero process exit ($code) but JUnit shows 0 failures and 0 errors across $tests tests. Overriding to success."
              exit 0
            }
          }

          # In every other case, return the original pytest exit code.
          exit $code

  tests_complete:
    name: All tests
    if: always()
    needs: [run_tests]
    runs-on: ubuntu-latest

    steps:
    - run: jq --exit-status 'all(.result == "success")' <<< '${{ toJson(needs) }}'
    - name: Done
      run: echo "Done."
