jinx_name: "ots"
description: "Take screenshot and analyze with vision model"
inputs:
  - image_paths_args: "" # Optional comma-separated paths to image files for analysis.
  - prompt: "" # The prompt for the LLM about the image(s).
  - vmodel: "" # Vision model to use. Defaults to NPCSH_VISION_MODEL or NPC's model.
  - vprovider: "" # Vision model provider. Defaults to NPCSH_VISION_PROVIDER or NPC's provider.
  - stream: False # Whether to stream the output from the LLM.
  - api_url: "" # API URL for the LLM.
  - api_key: "" # API key for the LLM.
steps:
  - name: "analyze_screenshot_or_image"
    engine: "python"
    code: |
      import os
      import traceback
      from npcpy.llm_funcs import get_llm_response
      from npcpy.data.image import capture_screenshot
      # Assuming NPCSH_VISION_MODEL and NPCSH_VISION_PROVIDER are accessible through _state or defaults
      # For simplicity in Jinx, we'll use fallbacks or assume context will provide
      
      image_paths_args_str = context.get('image_paths_args')
      user_prompt = context.get('prompt')
      vision_model = context.get('vmodel')
      vision_provider = context.get('vprovider')
      stream_output = context.get('stream')
      api_url = context.get('api_url')
      api_key = context.get('api_key')
      output_messages = context.get('messages', [])
      current_npc = context.get('npc')

      image_paths = []
      if image_paths_args_str and image_paths_args_str.strip():
          for img_path_arg in image_paths_args_str.split(','):
              full_path = os.path.abspath(os.path.expanduser(img_path_arg.strip()))
              if os.path.exists(full_path):
                  image_paths.append(full_path)
              else:
                  context['output'] = f"Error: Image file not found at {full_path}"
                  context['messages'] = output_messages
                  exit()
      
      if not image_paths:
          screenshot_info = capture_screenshot(full=False)
          if screenshot_info and "file_path" in screenshot_info:
              image_paths.append(screenshot_info["file_path"])
              print(f"Screenshot captured: {screenshot_info.get('filename', os.path.basename(screenshot_info['file_path']))}")
          else:
               context['output'] = "Error: Failed to capture screenshot."
               context['messages'] = output_messages
               exit()

      if not image_paths:
          context['output'] = "No valid images found or captured."
          context['messages'] = output_messages
          exit()

      if not user_prompt or not user_prompt.strip():
          # In a non-interactive Jinx, a default prompt is better than waiting for input
          user_prompt = "Describe the image(s)."

      # Fallback for model/provider if not explicitly set in Jinx inputs
      if not vision_model and current_npc and current_npc.model:
          vision_model = current_npc.model
      if not vision_provider and current_npc and current_npc.provider:
          vision_provider = current_npc.provider
      
      # Final fallbacks (these would ideally come from npcsh._state config)
      if not vision_model: vision_model = "gemini-1.5-pro-vision" # Example default
      if not vision_provider: vision_provider = "gemini" # Example default

      try:
          response_data = get_llm_response(
              prompt=user_prompt,
              model=vision_model,
              provider=vision_provider,
              messages=output_messages, # Pass current messages to LLM
              images=image_paths,
              stream=stream_output,
              npc=current_npc,
              api_url=api_url,
              api_key=api_key
          )
          context['output'] = response_data.get('response')
          context['messages'] = response_data.get('messages', output_messages)
          context['model'] = vision_model
          context['provider'] = vision_provider

      except Exception as e:
          traceback.print_exc()
          context['output'] = f"Error during /ots command: {e}"
          context['messages'] = output_messages