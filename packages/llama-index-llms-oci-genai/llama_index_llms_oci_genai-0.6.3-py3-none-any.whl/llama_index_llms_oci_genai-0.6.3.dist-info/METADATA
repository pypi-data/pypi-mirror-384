Metadata-Version: 2.4
Name: llama-index-llms-oci-genai
Version: 0.6.3
Summary: llama-index llms OCI GenAI integration
Author-email: Arthur Cheng <arthur.cheng@oracle.com>, Pan Xia <pan.xia@oracle.com>, Rave Harpaz <rave.harpaz@oracle.com>
License-Expression: MIT
License-File: LICENSE
Requires-Python: <4.0,>=3.9
Requires-Dist: llama-index-core<0.15,>=0.13.0
Requires-Dist: oci<3,>=2.134.0
Description-Content-Type: text/markdown

# LlamaIndex Llms Integration: Oracle Cloud Infrastructure (OCI) Generative AI

> Oracle Cloud Infrastructure (OCI) [Generative AI](https://docs.oracle.com/en-us/iaas/Content/generative-ai/home.htm) is a fully managed service that provides a set of state-of-the-art,
> customizable large language models (LLMs) that cover a wide range of use cases, and which are available through a single API.
> Using the OCI Generative AI service you can access ready-to-use pretrained models, or create and host your own fine-tuned
> custom models based on your own data on dedicated AI clusters.

## Installation

```bash
pip install llama-index-llms-oci-genai
```

You will also need to install the OCI sdk

```bash
pip install -U oci
```

## Usage

```bash
from llama_index.llms.oci_genai import OCIGenAI

llm = OCIGenAI(
    model="MY_MODEL",
    service_endpoint="https://inference.generativeai.us-chicago-1.oci.oraclecloud.com",
    compartment_id="MY_OCID",
)
```
