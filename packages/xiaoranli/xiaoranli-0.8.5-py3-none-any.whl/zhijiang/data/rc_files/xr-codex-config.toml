# Set the default model and provider
model = "gpt-5-codex"                 # IMPORTANT: This must be your Azure *deployment name* (not the base model family). Replace if different.
model_provider = "azure"
preferred_auth_method = "apikey"

# Configure the Azure provider
[model_providers.azure]
name = "Azure OpenAI"
# Base URL: include ONLY the portion up to /openai (no trailing /v1). See issue #1552.
base_url = "https://xiaoranli-gpt4omini.openai.azure.com/openai"
# base_url = "http://127.0.0.1:8787"  # Proxy fallback if direct connection fails
env_key = "AZURE_OPENAI_API_KEY"   # export this in your shell profile
wire_api = "responses"             # Azure Responses API
query_params = { api-version = "2025-04-01-preview" }
model_reasoning_effort = "high"
# If calls fail, doubleâ€‘check: (1) deployment exists & matches `model` above, (2) key exported, (3) api-version valid for your region, (4) correct endpoint domain.

# Optional: List your Azure deployment names for quick switching
# Fill in the RIGHT-HAND side with your exact deployment names in Azure.
# Left-hand keys are just aliases; change them as you like.
[azure_deployments]
# examples (replace with YOUR deployment names):
# gpt-5      = "gpt-5"                    # e.g., a custom alias you created
# codex-mini     = "codex-mini"       # if your deployment is named like the base model
# gpt-5-codex = "gpt-5-codex"

# Example of configuring an MCP server for Playwright
