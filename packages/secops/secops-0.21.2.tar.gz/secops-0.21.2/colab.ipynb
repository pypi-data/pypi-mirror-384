{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "introduction"
   },
   "source": [
    "This notebook demonstrates the capabilities of the Chronicle Security Operations SDK. We'll explore:\n",
    "* Authentication with Google Cloud\n",
    "* Querying security events\n",
    "* Analyzing alerts and cases\n",
    "* Visualizing security data\n",
    "* Working with IoCs\n",
    "\n",
    "## Setup\n",
    "First, let's install the required packages and authenticate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup"
   },
   "outputs": [],
   "source": [
    "!pip uninstall secops -y\n",
    "!pip install secops\n",
    "!pip install pandas plotly\n",
    "\n",
    "from google.colab import auth\n",
    "from google.auth import default\n",
    "import google.auth.transport.requests\n",
    "\n",
    "# Authenticate\n",
    "auth.authenticate_user()\n",
    "creds, _ = google.auth.default()\n",
    "auth_req = google.auth.transport.requests.Request()\n",
    "creds.refresh(auth_req)\n",
    "\n",
    "print(\"‚úÖ Authentication successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "client-setup"
   },
   "source": [
    "## Initialize the Chronicle Client\n",
    "\n",
    "Now that we're authenticated, let's set up our Chronicle client. We'll use a demo tenant for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init-client"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "from secops import SecOpsClient\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Initialize client\n",
    "client = SecOpsClient()\n",
    "chronicle = client.chronicle(\n",
    "    customer_id=\"c3c6260c1c9340dcbbb802603bbfffff\",  # not a real customer id\n",
    "    project_id=\"725716779999\",\n",
    "    region=\"us\",\n",
    ")\n",
    "\n",
    "# Set time range for queries\n",
    "end_time = datetime.now(timezone.utc)\n",
    "start_time = end_time - timedelta(hours=24)\n",
    "\n",
    "print(\"üìä Analyzing security data from:\")\n",
    "print(\n",
    "    f\"   {start_time.strftime('%Y-%m-%d %H:%M:%S')} to {end_time.strftime('%Y-%m-%d %H:%M:%S')} UTC\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alerts-section"
   },
   "source": [
    "## üö® Alert Analysis\n",
    "\n",
    "Let's start by analyzing recent alerts. We'll create visualizations to understand:\n",
    "* Alert severity distribution\n",
    "* Top alert rules\n",
    "* Alert status breakdown\n",
    "* Timeline of alert creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "get-alerts"
   },
   "outputs": [],
   "source": [
    "# Get alerts\n",
    "print(\"Fetching alerts...\")\n",
    "alerts = chronicle.get_alerts(start_time=start_time, end_time=end_time, max_alerts=1000)\n",
    "\n",
    "alert_list = alerts.get(\"alerts\", {}).get(\"alerts\", [])\n",
    "print(f\"Found {len(alert_list)} alerts\")\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "alert_data = []\n",
    "for alert in alert_list:\n",
    "    alert_data.append(\n",
    "        {\n",
    "            \"id\": alert.get(\"id\"),\n",
    "            \"rule_name\": alert.get(\"detection\", [{}])[0].get(\"ruleName\"),\n",
    "            \"severity\": alert.get(\"feedbackSummary\", {}).get(\n",
    "                \"severityDisplay\", \"Unknown\"\n",
    "            ),\n",
    "            \"status\": alert.get(\"feedbackSummary\", {}).get(\"status\", \"Unknown\"),\n",
    "            \"created_time\": pd.to_datetime(alert.get(\"createdTime\")),\n",
    "            \"risk_score\": alert.get(\"feedbackSummary\", {}).get(\"riskScore\", 0),\n",
    "        }\n",
    "    )\n",
    "\n",
    "df_alerts = pd.DataFrame(alert_data)\n",
    "\n",
    "# Create visualizations\n",
    "fig1 = px.pie(df_alerts, names=\"severity\", title=\"Alert Severity Distribution\")\n",
    "fig1.show()\n",
    "\n",
    "fig2 = px.bar(\n",
    "    df_alerts[\"rule_name\"].value_counts().head(10),\n",
    "    title=\"Top 10 Alert Rules\",\n",
    "    labels={\"index\": \"Rule Name\", \"value\": \"Count\"},\n",
    ")\n",
    "fig2.show()\n",
    "\n",
    "fig3 = px.histogram(\n",
    "    df_alerts,\n",
    "    x=\"created_time\",\n",
    "    title=\"Alert Timeline\",\n",
    "    labels={\"created_time\": \"Creation Time\", \"count\": \"Number of Alerts\"},\n",
    ")\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cases-section"
   },
   "source": [
    "## üìÅ Case Analysis\n",
    "\n",
    "Now let's examine the cases associated with these alerts. We'll create an interactive dashboard showing:\n",
    "* Case priority levels\n",
    "* Case stages\n",
    "* Alerts per case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "analyze-cases"
   },
   "outputs": [],
   "source": [
    "# Get cases from alerts\n",
    "case_ids = {alert.get(\"caseName\") for alert in alert_list if alert.get(\"caseName\")}\n",
    "\n",
    "if case_ids:\n",
    "    print(f\"Analyzing {len(case_ids)} cases...\")\n",
    "    cases = chronicle.get_cases(list(case_ids))\n",
    "\n",
    "    # Prepare case data\n",
    "    case_data = []\n",
    "    for case in cases.cases:\n",
    "        case_alerts = [a for a in alert_list if a.get(\"caseName\") == case.id]\n",
    "        high_sev_alerts = [\n",
    "            a\n",
    "            for a in case_alerts\n",
    "            if a.get(\"feedbackSummary\", {}).get(\"severityDisplay\") == \"HIGH\"\n",
    "        ]\n",
    "\n",
    "        case_data.append(\n",
    "            {\n",
    "                \"id\": case.id,\n",
    "                \"name\": case.display_name,\n",
    "                \"priority\": case.priority,\n",
    "                \"stage\": case.stage,\n",
    "                \"status\": case.status,\n",
    "                \"alert_count\": len(case_alerts),\n",
    "                \"high_sev_count\": len(high_sev_alerts),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df_cases = pd.DataFrame(case_data)\n",
    "\n",
    "    # Create case dashboard\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Priority distribution\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=df_cases[\"priority\"].value_counts().index,\n",
    "            y=df_cases[\"priority\"].value_counts().values,\n",
    "            name=\"Priority Distribution\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add alerts per case\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_cases[\"name\"],\n",
    "            y=df_cases[\"alert_count\"],\n",
    "            mode=\"markers\",\n",
    "            name=\"Alerts per Case\",\n",
    "            marker=dict(size=df_cases[\"high_sev_count\"] * 5 + 10),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Case Analysis Dashboard\",\n",
    "        xaxis_title=\"Cases\",\n",
    "        yaxis_title=\"Count\",\n",
    "        showlegend=True,\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    # Print summary statistics\n",
    "    print(\"\\nüìä Case Summary:\")\n",
    "    print(f\"Total Cases: {len(df_cases)}\")\n",
    "    print(\n",
    "        f\"High Priority Cases: {len(df_cases[df_cases['priority'] == 'PRIORITY_HIGH'])}\"\n",
    "    )\n",
    "    print(f\"Average Alerts per Case: {df_cases['alert_count'].mean():.1f}\")\n",
    "else:\n",
    "    print(\"No cases found in the current time range\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "entity-section"
   },
   "source": [
    "## üîç Entity Investigation\n",
    "\n",
    "Let's investigate some entities from our alerts. We'll create a network graph of related entities and their relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "analyze-entities"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Extract entities from alerts\n",
    "entities = set()\n",
    "relationships = []\n",
    "\n",
    "for alert in alert_list:\n",
    "    # Get IPs and hostnames from alert events\n",
    "    for elem in alert.get(\"collectionElements\", []):\n",
    "        for ref in elem.get(\"references\", []):\n",
    "            event = ref.get(\"event\", {})\n",
    "\n",
    "            # Get principal IPs\n",
    "            principal_ips = event.get(\"principal\", {}).get(\"ip\", [])\n",
    "            for ip in principal_ips:\n",
    "                entities.add((\"ip\", ip))\n",
    "\n",
    "            # Get target IPs\n",
    "            target_ips = event.get(\"target\", {}).get(\"ip\", [])\n",
    "            for tip in target_ips:\n",
    "                entities.add((\"ip\", tip))\n",
    "\n",
    "                # Create relationship between source and target\n",
    "                for sip in principal_ips:\n",
    "                    relationships.append((sip, tip))\n",
    "\n",
    "# Create network graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes and edges\n",
    "for entity_type, entity_value in entities:\n",
    "    G.add_node(entity_value, type=entity_type)\n",
    "\n",
    "for source, target in relationships:\n",
    "    G.add_edge(source, target)\n",
    "\n",
    "# Create interactive network visualization\n",
    "pos = nx.spring_layout(G)\n",
    "\n",
    "edge_trace = go.Scatter(\n",
    "    x=[], y=[], line=dict(width=0.5, color=\"#888\"), hoverinfo=\"none\", mode=\"lines\"\n",
    ")\n",
    "\n",
    "for edge in G.edges():\n",
    "    x0, y0 = pos[edge[0]]\n",
    "    x1, y1 = pos[edge[1]]\n",
    "    edge_trace[\"x\"] += (x0, x1, None)\n",
    "    edge_trace[\"y\"] += (y0, y1, None)\n",
    "\n",
    "node_trace = go.Scatter(\n",
    "    x=[],\n",
    "    y=[],\n",
    "    text=[],\n",
    "    mode=\"markers+text\",\n",
    "    hoverinfo=\"text\",\n",
    "    marker=dict(size=10, line_width=2),\n",
    ")\n",
    "\n",
    "for node in G.nodes():\n",
    "    x, y = pos[node]\n",
    "    node_trace[\"x\"] += (x,)\n",
    "    node_trace[\"y\"] += (y,)\n",
    "    node_trace[\"text\"] += (node,)\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[edge_trace, node_trace],\n",
    "    layout=go.Layout(\n",
    "        title=\"Entity Relationship Network\",\n",
    "        showlegend=False,\n",
    "        hovermode=\"closest\",\n",
    "        margin=dict(b=20, l=5, r=5, t=40),\n",
    "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(f\"\\nüîç Entity Analysis:\")\n",
    "print(f\"Unique Entities: {len(entities)}\")\n",
    "print(f\"Relationships: {len(relationships)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iocs-section"
   },
   "source": [
    "## üéØ IoC Analysis\n",
    "\n",
    "Let's analyze Indicators of Compromise (IoCs) that have matched against events in our environment. We'll look at:\n",
    "* IoC types and their distribution\n",
    "* Match counts and trends\n",
    "* Sources and categories\n",
    "* Associated threat actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "analyze-iocs"
   },
   "outputs": [],
   "source": [
    "print(\"Fetching IoC matches...\")\n",
    "iocs = chronicle.list_iocs(\n",
    "    start_time=start_time,\n",
    "    end_time=end_time,\n",
    "    max_matches=1000,\n",
    "    add_mandiant_attributes=True,\n",
    ")\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "ioc_data = []\n",
    "for match in iocs.get(\"matches\", []):\n",
    "    # Get the IoC type and value\n",
    "    ioc_type = next(iter(match.get(\"artifactIndicator\", {}).keys()), \"Unknown\")\n",
    "    ioc_value = next(iter(match.get(\"artifactIndicator\", {}).values()), \"Unknown\")\n",
    "\n",
    "    ioc_data.append(\n",
    "        {\n",
    "            \"type\": ioc_type,\n",
    "            \"value\": ioc_value,\n",
    "            \"sources\": \", \".join(match.get(\"sources\", [])),\n",
    "            \"categories\": \", \".join(match.get(\"categories\", [])),\n",
    "            \"first_seen\": pd.to_datetime(match.get(\"firstSeenTime\")),\n",
    "            \"last_seen\": pd.to_datetime(match.get(\"lastSeenTime\")),\n",
    "            \"confidence\": match.get(\"confidenceScore\", 0),\n",
    "            \"severity\": match.get(\"severityScore\", 0),\n",
    "        }\n",
    "    )\n",
    "\n",
    "df_iocs = pd.DataFrame(ioc_data)\n",
    "\n",
    "if not df_iocs.empty:\n",
    "    # Create visualizations\n",
    "    fig1 = px.pie(df_iocs, names=\"type\", title=\"IoC Type Distribution\")\n",
    "    fig1.show()\n",
    "\n",
    "    # Confidence vs Severity scatter plot\n",
    "    fig2 = px.scatter(\n",
    "        df_iocs,\n",
    "        x=\"confidence\",\n",
    "        y=\"severity\",\n",
    "        color=\"type\",\n",
    "        hover_data=[\"value\"],\n",
    "        title=\"IoC Confidence vs Severity\",\n",
    "    )\n",
    "    fig2.show()\n",
    "\n",
    "    # Timeline of IoC matches\n",
    "    fig3 = px.histogram(\n",
    "        df_iocs, x=\"first_seen\", color=\"type\", title=\"IoC First Seen Timeline\"\n",
    "    )\n",
    "    fig3.show()\n",
    "\n",
    "    # Print summary statistics\n",
    "    print(\"\\nüéØ IoC Summary:\")\n",
    "    print(f\"Total IoCs: {len(df_iocs)}\")\n",
    "    print(\"\\nTop IoC Types:\")\n",
    "    print(df_iocs[\"type\"].value_counts())\n",
    "    print(\"\\nTop Categories:\")\n",
    "    print(df_iocs[\"categories\"].value_counts().head())\n",
    "\n",
    "    # High severity IoCs\n",
    "    high_sev = df_iocs[df_iocs[\"severity\"] > 7]\n",
    "    if not high_sev.empty:\n",
    "        print(\"\\n‚ö†Ô∏è High Severity IoCs:\")\n",
    "        for _, ioc in high_sev.iterrows():\n",
    "            print(f\"\\nType: {ioc['type']}\")\n",
    "            print(f\"Value: {ioc['value']}\")\n",
    "            print(f\"Severity: {ioc['severity']}\")\n",
    "            print(f\"Sources: {ioc['sources']}\")\n",
    "else:\n",
    "    print(\"No IoC matches found in the specified time range\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion"
   },
   "source": [
    "## üéØ Summary\n",
    "\n",
    "In this notebook, we've demonstrated the power of the Chronicle Security Operations SDK by:\n",
    "* Analyzing alert patterns and severity distributions\n",
    "* Investigating cases and their relationships to alerts\n",
    "* Visualizing entity relationships and network connections\n",
    "\n",
    "The SDK provides a powerful interface for security analysis and investigation, making it easy to:\n",
    "* Query security events\n",
    "* Track alerts and cases\n",
    "* Investigate entities\n",
    "* Visualize security data\n",
    "\n",
    "For more information, visit the [Chronicle Security Operations documentation](https://cloud.google.com/chronicle/docs)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Chronicle Security Operations SDK Demo",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
