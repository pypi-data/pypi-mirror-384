[
{
  "name": "Audio Metadata",
  "description": "Extract title and metadata from audio files (MP3, FLAC, OGG, etc.)",
  "license": "GPL-3.0",
  "mimetype_re": "audio/(mpeg|flac|ogg|wav|aac|m4a|wma|opus)",
  "timeout": 30,
  "enabled": true,
  "dependencies": [
    "ffmpeg",
    "jq"
  ],
  "builtin": true,
  "script": "#!/bin/bash\nset -e\n\nINPUT_FILE=\"$(jq -r .content_file \"$1\")\"\n\n# Extract title from audio metadata\nTITLE=\"\"\n\nif command -v ffprobe >/dev/null 2>&1; then\n  # Extract metadata as JSON (both format and stream tags)\n  METADATA=\"$(ffprobe -v quiet -print_format json -show_entries format_tags:stream_tags \"$INPUT_FILE\" 2>/dev/null || echo '{}')\"\n  \n  # Extract artist and title metadata\n  ARTIST=\"$(echo \"$METADATA\" | jq -r '(.format.tags // {}) + (.streams[0].tags // {}) | to_entries | map(select(.key | ascii_downcase == \"artist\")) | .[0].value // \"\"' 2>/dev/null || true)\"\n  TRACK_TITLE=\"$(echo \"$METADATA\" | jq -r '(.format.tags // {}) + (.streams[0].tags // {}) | to_entries | map(select(.key | ascii_downcase == \"title\")) | .[0].value // \"\"' 2>/dev/null || true | head -n 1)\"\n  TRACK_NAME=\"$(echo \"$METADATA\" | jq -r '(.format.tags // {}) + (.streams[0].tags // {}) | to_entries | map(select(.key | ascii_downcase == \"track\")) | .[0].value // \"\"' 2>/dev/null || true)\"\n  \n  # Clean up metadata fields\n  if [ -n \"$ARTIST\" ]; then\n    ARTIST=\"$(echo \"$ARTIST\" | tr '\\n\\r' ' ' | head -c 100 | sed 's/[[:space:]]*$//' | sed 's/^[[:space:]]*//')\"\n  fi\n  if [ -n \"$TRACK_TITLE\" ]; then\n    TRACK_TITLE=\"$(echo \"$TRACK_TITLE\" | tr '\\n\\r' ' ' | head -c 100 | sed 's/[[:space:]]*$//' | sed 's/^[[:space:]]*//')\"\n  fi\n  if [ -n \"$TRACK_NAME\" ]; then\n    TRACK_NAME=\"$(echo \"$TRACK_NAME\" | tr '\\n\\r' ' ' | head -c 100 | sed 's/[[:space:]]*$//' | sed 's/^[[:space:]]*//')\"\n  fi\n  \n  # Combine artist and title information (prioritize artist + title combination)\n  if [ -n \"$ARTIST\" ] && [ -n \"$TRACK_TITLE\" ]; then\n    TITLE=\"$ARTIST - $TRACK_TITLE\"\n  elif [ -n \"$ARTIST\" ] && [ -n \"$TRACK_NAME\" ]; then\n    TITLE=\"$ARTIST - $TRACK_NAME\"\n  elif [ -n \"$TRACK_TITLE\" ]; then\n    TITLE=\"$TRACK_TITLE\"\n  elif [ -n \"$ARTIST\" ]; then\n    TITLE=\"$ARTIST\"\n  elif [ -n \"$TRACK_NAME\" ]; then\n    TITLE=\"$TRACK_NAME\"\n  fi\nfi\n\n# Final cleanup of title\nif [ -n \"$TITLE\" ]; then\n  TITLE=\"$(echo \"$TITLE\" | tr '\\n\\r' ' ' | head -c 200 | sed 's/[[:space:]]*$//' | sed 's/^[[:space:]]*//')\"\nfi\n\n# Fallback to URL if no title found\nif [ -z \"$TITLE\" ]; then\n  TITLE=\"$(jq -r .url \"$1\")\"\nfi\n\n# Output JSON\njq -n --arg title \"$TITLE\" '{\n    title: $title\n}'\n\n"
}
,
{
  "name": "DOCX Document",
  "description": "Extract text content and metadata from Microsoft Word DOCX documents",
  "license": "GPL-3.0",
  "mimetype_re": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
  "timeout": 60,
  "enabled": true,
  "dependencies": [
    "unzip",
    "xmlstarlet",
    "pandoc",
    "python3-langdetect",
    "jq"
  ],
  "builtin": true,
  "script": "#!/bin/bash\nset -e\n\nINPUT_FILE=\"$(jq -r .content_file \"$1\")\"\n\n# Extract title from document properties using unzip and xmlstarlet\nTITLE=\"\"\nif unzip -l \"$INPUT_FILE\" docProps/core.xml >/dev/null 2>&1; then\n    TITLE=\"$(unzip -p \"$INPUT_FILE\" docProps/core.xml 2>/dev/null | xmlstarlet sel -t -v \"//dc:title\" 2>/dev/null || true | head -n 1)\"\nfi\n\n# If no title found, try to get first paragraph\nif [ -z \"$TITLE\" ] && unzip -l \"$INPUT_FILE\" word/document.xml >/dev/null 2>&1; then\n    TITLE=\"$(unzip -p \"$INPUT_FILE\" word/document.xml 2>/dev/null | xmlstarlet sel -t -v \"//w:t[1]\" 2>/dev/null | head -n 1 || true)\"\nfi\n\n# Fallback to URL\nif [ -z \"$TITLE\" ]; then\n    TITLE=\"$(jq -r .url \"$1\")\"\nfi\n\n# Extract content using pandoc if available, otherwise try unzip + xmlstarlet\nif command -v pandoc >/dev/null 2>&1; then\n    CONTENT=\"$(pandoc \"$INPUT_FILE\" -t plain --wrap=none 2>/dev/null || true)\"\nelse\n    # Fallback: extract text from document.xml\n    CONTENT=\"\"\n    if unzip -l \"$INPUT_FILE\" word/document.xml >/dev/null 2>&1; then\n        CONTENT=\"$(unzip -p \"$INPUT_FILE\" word/document.xml 2>/dev/null | xmlstarlet sel -t -v \"//w:t\" -n 2>/dev/null | sed '/^$/d' || true)\"\n    fi\nfi\n\n# Language detection if content available\nDETECTED_LANG=\"en\"\nif [ -n \"$CONTENT\" ] && [ \"$(echo \"$CONTENT\" | wc -c)\" -gt 100 ] && command -v python3 >/dev/null 2>&1; then\n    DETECTED_LANG=\"$(echo \"$CONTENT\" | head -c 10000 | python3 -c \"\nimport sys\ntry:\n    from langdetect import detect\n    text = sys.stdin.read().strip()\n    if text:\n        print(detect(text))\n    else:\n        print('en')\nexcept:\n    print('en')\n\" 2>/dev/null || echo 'en')\"\nfi\n\n# Output JSON\njq -n --arg title \"$TITLE\" --arg content \"$CONTENT\" --arg lang \"$DETECTED_LANG\" '{\n    title: $title,\n    content: $content,\n    lang_iso_639_1: $lang\n}'"
}
,
{
  "name": "EPUB eBook",
  "description": "Process EPUB eBook files to extract text content and metadata with OCR fallback",
  "license": "GPL-3.0",
  "mimetype_re": "application/epub\\+zip",
  "timeout": 300,
  "enabled": true,
  "dependencies": [
    "unzip",
    "xmlstarlet",
    "pandoc",
    "tesseract-ocr",
    "python3-langdetect",
    "jq"
  ],
  "builtin": true,
  "script": "#!/bin/bash\nset -e\n\nINPUT_FILE=\"$(jq -r .content_file \"$1\")\"\n\n# Extract metadata and content from EPUB\nTITLE=\"\"\nCONTENT=\"\"\n\n# EPUB is a ZIP archive, extract metadata from META-INF/container.xml and content.opf\nif command -v unzip >/dev/null 2>&1 && command -v xmlstarlet >/dev/null 2>&1; then\n    # Extract container.xml to find the OPF file\n    OPF_PATH=\"\"\n    if unzip -l \"$INPUT_FILE\" META-INF/container.xml >/dev/null 2>&1; then\n        OPF_PATH=\"$(unzip -p \"$INPUT_FILE\" META-INF/container.xml 2>/dev/null | xmlstarlet sel -t -v \"//rootfile/@full-path\" 2>/dev/null || true)\"\n    fi\n    \n    # Extract title from OPF metadata\n    if [ -n \"$OPF_PATH\" ] && unzip -l \"$INPUT_FILE\" \"$OPF_PATH\" >/dev/null 2>&1; then\n        TITLE=\"$(unzip -p \"$INPUT_FILE\" \"$OPF_PATH\" 2>/dev/null | xmlstarlet sel -N dc=http://purl.org/dc/elements/1.1/ -t -v \"//dc:title\" 2>/dev/null | head -1 || true)\"\n    fi\n    \n    # Extract HTML/XHTML content files\n    HTML_FILES=\"$(unzip -l \"$INPUT_FILE\" 2>/dev/null | grep -E '\\.(x?html?|xml)$' | awk '{print $NF}' | head -20 || true)\"\n    \n    TEMP_CONTENT=\"\"\n    for HTML_FILE in $HTML_FILES; do\n        if unzip -l \"$INPUT_FILE\" \"$HTML_FILE\" >/dev/null 2>&1; then\n            # Extract text content from HTML, removing tags\n            FILE_CONTENT=\"$(unzip -p \"$INPUT_FILE\" \"$HTML_FILE\" 2>/dev/null | sed 's/<[^>]*>//g' | sed 's/&[^;]*;//g' | sed '/^$/d' | head -100 || true)\"\n            if [ -n \"$FILE_CONTENT\" ]; then\n                TEMP_CONTENT=\"$TEMP_CONTENT\n$FILE_CONTENT\"\n            fi\n        fi\n    done\n    CONTENT=\"$(echo \"$TEMP_CONTENT\" | head -2000)\"\n    \nelif command -v pandoc >/dev/null 2>&1; then\n    # Fallback: use pandoc to convert EPUB to plain text\n    CONTENT=\"$(pandoc \"$INPUT_FILE\" -t plain --wrap=none 2>/dev/null | head -2000 || true)\"\n    \n    # Try to extract title from first lines if not found\n    if [ -z \"$TITLE\" ] && [ -n \"$CONTENT\" ]; then\n        TITLE=\"$(echo \"$CONTENT\" | head -5 | grep -v '^[[:space:]]*$' | head -1 | head -c 100 || true)\"\n    fi\nfi\n\n# If content extraction failed, try OCR on images (like PDF-OCR plugin)\nif [ -z \"$CONTENT\" ] || [ \"$(echo \"$CONTENT\" | wc -c)\" -lt 100 ]; then\n    echo \"Text content too short, attempting OCR on embedded images\" >&2\n    \n    # Extract images from EPUB\n    IMAGE_FILES=\"$(unzip -l \"$INPUT_FILE\" 2>/dev/null | grep -iE '\\.(png|jpg|jpeg|gif|bmp)$' | awk '{print $NF}' | head -10 || true)\"\n    \n    if [ -n \"$IMAGE_FILES\" ]; then\n        # Language detection using first few images\n        echo \"Language detection from images\" >&2\n        DETECTED_LANG=\"$(\n        COUNT=0\n        for IMG_PATH in $IMAGE_FILES; do\n            if [ \"$COUNT\" -ge 3 ]; then break; fi\n            if unzip -l \"$INPUT_FILE\" \"$IMG_PATH\" >/dev/null 2>&1; then\n                unzip -p \"$INPUT_FILE\" \"$IMG_PATH\" > \"temp_img_$COUNT.png\" 2>/dev/null\n                if [ -f \"temp_img_$COUNT.png\" ]; then\n                    tesseract \"temp_img_$COUNT.png\" stdout -l osd 2>/dev/null || true\n                    echo -e \"\\n\\n\"\n                    rm -f \"temp_img_$COUNT.png\"\n                    COUNT=$((COUNT + 1))\n                fi\n            fi\n        done | python3 -c \"\nimport sys\ntry:\n    from langdetect import detect\n    text = sys.stdin.read().strip()\n    if text:\n        print(detect(text))\n    else:\n        print('en')\nexcept:\n    print('en')\n\" 2>/dev/null || echo 'en')\"\n        \n        echo \"Detected language: $DETECTED_LANG\" >&2\n        \n        # Map language to tesseract language code\n        TESSERACT_DETECTED_LANG=eng\n        case \"$DETECTED_LANG\" in\n            ar) TESSERACT_DETECTED_LANG=\"ara\" ;;\n            da) TESSERACT_DETECTED_LANG=\"dan\" ;;\n            nl) TESSERACT_DETECTED_LANG=\"nld\" ;;\n            en) TESSERACT_DETECTED_LANG=\"eng\" ;;\n            fi) TESSERACT_DETECTED_LANG=\"fin\" ;;\n            fr) TESSERACT_DETECTED_LANG=\"fra\" ;;\n            de) TESSERACT_DETECTED_LANG=\"deu\" ;;\n            el) TESSERACT_DETECTED_LANG=\"ell\" ;;\n            hu) TESSERACT_DETECTED_LANG=\"hun\" ;;\n            id) TESSERACT_DETECTED_LANG=\"ind\" ;;\n            ga) TESSERACT_DETECTED_LANG=\"gle\" ;;\n            it) TESSERACT_DETECTED_LANG=\"ita\" ;;\n            ne) TESSERACT_DETECTED_LANG=\"nep\" ;;\n            no) TESSERACT_DETECTED_LANG=\"nor\" ;;\n            pt) TESSERACT_DETECTED_LANG=\"por\" ;;\n            ro) TESSERACT_DETECTED_LANG=\"ron\" ;;\n            ru) TESSERACT_DETECTED_LANG=\"rus\" ;;\n            ca) TESSERACT_DETECTED_LANG=\"spa\" ;;\n            es) TESSERACT_DETECTED_LANG=\"spa\" ;;\n            sv) TESSERACT_DETECTED_LANG=\"swe\" ;;\n            ta) TESSERACT_DETECTED_LANG=\"tam\" ;;\n            tr) TESSERACT_DETECTED_LANG=\"tur\" ;;\n        esac\n        \n        # Verify tesseract language is available\n        if [ \"$(tesseract --list-langs 2>/dev/null | grep \"$TESSERACT_DETECTED_LANG\")\" == \"\" ]; then\n            TESSERACT_DETECTED_LANG=eng\n        fi\n        \n        echo \"OCR starting with language: $TESSERACT_DETECTED_LANG\" >&2\n        \n        # Perform OCR on images\n        OCR_CONTENT=\"\"\n        COUNT=0\n        for IMG_PATH in $IMAGE_FILES; do\n            if [ \"$COUNT\" -ge 20 ]; then break; fi\n            if unzip -l \"$INPUT_FILE\" \"$IMG_PATH\" >/dev/null 2>&1; then\n                unzip -p \"$INPUT_FILE\" \"$IMG_PATH\" > \"temp_img_$COUNT.png\" 2>/dev/null\n                if [ -f \"temp_img_$COUNT.png\" ]; then\n                    IMG_TEXT=\"$(tesseract \"temp_img_$COUNT.png\" stdout -l \"$TESSERACT_DETECTED_LANG\" 2>/dev/null || true)\"\n                    if [ -n \"$IMG_TEXT\" ]; then\n                        OCR_CONTENT=\"$OCR_CONTENT\n$IMG_TEXT\"\n                    fi\n                    rm -f \"temp_img_$COUNT.png\"\n                    COUNT=$((COUNT + 1))\n                fi\n            fi\n        done\n        \n        if [ -n \"$OCR_CONTENT\" ]; then\n            CONTENT=\"$OCR_CONTENT\"\n            \n            # 2nd pass language detection on OCR text\n            if [ \"$(echo \"$CONTENT\" | wc -c)\" -gt 100 ]; then\n                DETECTED_LANG=\"$(echo \"$CONTENT\" | head -c 10000 | python3 -c \"\nimport sys\ntry:\n    from langdetect import detect\n    text = sys.stdin.read().strip()\n    if text:\n        print(detect(text))\n    else:\n        print('en')\nexcept:\n    print('en')\n\" 2>/dev/null || echo 'en')\"\n                echo \"2nd pass language detected: $DETECTED_LANG\" >&2\n            fi\n        fi\n        \n        echo \"OCR completed\" >&2\n    fi\nfi\n\n# Language detection on extracted content\nif [ -z \"$DETECTED_LANG\" ] && [ -n \"$CONTENT\" ] && [ \"$(echo \"$CONTENT\" | wc -c)\" -gt 100 ]; then\n    DETECTED_LANG=\"$(echo \"$CONTENT\" | head -c 10000 | python3 -c \"\nimport sys\ntry:\n    from langdetect import detect\n    text = sys.stdin.read().strip()\n    if text:\n        print(detect(text))\n    else:\n        print('en')\nexcept:\n    print('en')\n\" 2>/dev/null || echo 'en')\"\nelse\n    DETECTED_LANG=\"${DETECTED_LANG:-en}\"\nfi\n\n# Clean up language code (convert fr_FR.UTF-8 to fr, etc.)\nif [ -n \"$DETECTED_LANG\" ]; then\n    DETECTED_LANG=\"$(echo \"$DETECTED_LANG\" | cut -d'_' -f1 | cut -d'.' -f1)\"\nfi\n\n# Clean up title\nif [ -n \"$TITLE\" ]; then\n    TITLE=\"$(echo \"$TITLE\" | tr '\\n\\r' ' ' | head -c 200 | sed 's/[[:space:]]*$//')\"\nfi\n\n# Fallback to URL if no title found\nif [ -z \"$TITLE\" ]; then\n    TITLE=\"$(jq -r .url \"$1\")\"\nfi\n\n# Clean up temporary files\nrm -f temp_img_*.png\n\n# Output JSON\njq -n --arg title \"$TITLE\" --arg content \"$CONTENT\" --arg lang \"$DETECTED_LANG\" '{\n    title: $title,\n    content: $content,\n    lang_iso_639_1: $lang\n}'\n\necho \"EPUB processing done\" >&2"
}
,
{
  "name": "Excel Spreadsheet",
  "description": "Extract content and metadata from Excel spreadsheet files (XLS, XLSX)",
  "license": "GPL-3.0",
  "mimetype_re": "application/(vnd.ms-excel|vnd.openxmlformats-officedocument.spreadsheetml.sheet)",
  "timeout": 60,
  "enabled": true,
  "dependencies": [
    "python3-openpyxl",
    "unzip",
    "xmlstarlet",
    "file",
    "jq"
  ],
  "builtin": true,
  "script": "#!/bin/bash\nset -e\n\nINPUT_FILE=\"$(jq -r .content_file \"$1\")\"\n\n# Try to extract title from document properties\nTITLE=\"\"\n\n# For xlsx files, try to extract from docProps/core.xml\nif file \"$INPUT_FILE\" | grep -q \"Microsoft Excel 2007+\"; then\n    if unzip -l \"$INPUT_FILE\" docProps/core.xml >/dev/null 2>&1; then\n        TITLE=\"$(unzip -p \"$INPUT_FILE\" docProps/core.xml 2>/dev/null | xmlstarlet sel -t -v \"//dc:title\" 2>/dev/null || true | head -n 1)\"\n    fi\nfi\n\n# Fallback to filename or URL\nif [ -z \"$TITLE\" ]; then\n    TITLE=\"$(jq -r .url \"$1\")\"\nfi\n\n# Extract content using python3-openpyxl\nCONTENT=\"\"\nif command -v python3 >/dev/null 2>&1; then\n    CONTENT=\"$(/usr/bin/python3 -c \"\nimport sys\ntry:\n    from openpyxl import load_workbook\n    wb = load_workbook('$INPUT_FILE', data_only=True)\n    content = []\n    for sheet in wb.worksheets:\n        for row in sheet.iter_rows(values_only=True):\n            if any(cell for cell in row):\n                content.append(' '.join(str(cell or '') for cell in row))\n        if len(content) > 1000:\n            break\n    print('\\n'.join(content[:1000]))\nexcept Exception as e:\n    print('', file=sys.stderr)\n\" 2>/dev/null || true)\"\nfi\n\n# Language detection - spreadsheets are usually language-neutral, default to English\nDETECTED_LANG=\"en\"\n\n# Output JSON\njq -n --arg title \"$TITLE\" --arg content \"$CONTENT\" --arg lang \"$DETECTED_LANG\" '{\n    title: $title,\n    content: $content,\n    lang_iso_639_1: $lang\n}'"
}
,
{
  "name": "Image Metadata",
  "description": "Extract title and metadata from image files (JPEG, PNG, GIF, etc.)",
  "license": "GPL-3.0",
  "mimetype_re": "image/(jpeg|png|gif|webp|bmp|tiff|svg\\+xml)",
  "timeout": 30,
  "enabled": true,
  "dependencies": [
    "exiftool",
    "imagemagick",
    "jq"
  ],
  "builtin": true,
  "script": "#!/bin/bash\nset -e\n\nINPUT_FILE=\"$(jq -r .content_file \"$1\")\"\n\n# Extract title from EXIF metadata\nTITLE=\"\"\n\n# Try exiftool first (most comprehensive)\nif command -v exiftool >/dev/null 2>&1; then\n    TITLE=\"$(exiftool -s -s -s -Title \"$INPUT_FILE\" 2>/dev/null || true | head -n 1)\"\n    if [ -z \"$TITLE\" ]; then\n        TITLE=\"$(exiftool -s -s -s -Subject \"$INPUT_FILE\" 2>/dev/null || true | head -n 1)\"\n    fi\n    if [ -z \"$TITLE\" ]; then\n        TITLE=\"$(exiftool -s -s -s -Description \"$INPUT_FILE\" 2>/dev/null || true | head -n 1)\"\n    fi\n    if [ -z \"$TITLE\" ]; then\n        TITLE=\"$(exiftool -s -s -s -Comment \"$INPUT_FILE\" 2>/dev/null || true | head -n 1)\"\n    fi\n    if [ -z \"$TITLE\" ]; then\n        TITLE=\"$(exiftool -s -s -s -Caption-Abstract \"$INPUT_FILE\" 2>/dev/null || true | head -n 1)\"\n    fi\nelif command -v identify >/dev/null 2>&1; then\n    # Fallback to ImageMagick identify\n    TITLE=\"$(identify -verbose \"$INPUT_FILE\" 2>/dev/null | grep -E \"^\\s*(comment|title|subject):\" | head -1 | cut -d: -f2- | sed 's/^[[:space:]]*//' || true)\"\nfi\n\n# Clean up title (remove newlines, limit length)\nif [ -n \"$TITLE\" ]; then\n    TITLE=\"$(echo \"$TITLE\" | tr '\\n\\r' ' ' | head -c 200 | sed 's/[[:space:]]*$//')\"\nfi\n\n# Fallback to URL if no title found\nif [ -z \"$TITLE\" ]; then\n    TITLE=\"$(jq -r .url \"$1\")\"\nfi\n\n# Output JSON (images typically don't have extractable text content)\njq -n --arg title \"$TITLE\" '{\n    title: $title\n}'"
}
,
{
  "name": "Image OCR",
  "description": "Extract text from image files using OCR with automatic language detection",
  "license": "GPL-3.0",
  "mimetype_re": "image/(jpeg|png|gif|webp|bmp|tiff)",
  "timeout": 120,
  "enabled": false,
  "dependencies": [
    "tesseract-ocr-all",
    "exiftool",
    "python3-langdetect",
    "jq"
  ],
  "builtin": true,
  "script": "#!/bin/bash\nset -e\n\nINPUT_FILE=\"$(jq -r .content_file \"$1\")\"\n\n\n# Language detection on image content using tesseract\necho \"Language detection\" >&2\nDETECTED_LANG=\"$(tesseract \"$INPUT_FILE\" stdout -l osd 2>/dev/null | python3 -c \"\nimport sys\ntry:\n    from langdetect import detect\n    text = sys.stdin.read().strip()\n    if text:\n        print(detect(text))\n    else:\n        print('en')\nexcept:\n    print('en')\n\" 2>/dev/null || echo 'en')\"\n\necho \"Detected language: $DETECTED_LANG\" >&2\n\n# Map language to tesseract language code\nTESSERACT_DETECTED_LANG=eng\ncase \"$DETECTED_LANG\" in\n  ar) TESSERACT_DETECTED_LANG=\"ara\" ;;\n  da) TESSERACT_DETECTED_LANG=\"dan\" ;;\n  nl) TESSERACT_DETECTED_LANG=\"nld\" ;;\n  en) TESSERACT_DETECTED_LANG=\"eng\" ;;\n  fi) TESSERACT_DETECTED_LANG=\"fin\" ;;\n  fr) TESSERACT_DETECTED_LANG=\"fra\" ;;\n  de) TESSERACT_DETECTED_LANG=\"deu\" ;;\n  el) TESSERACT_DETECTED_LANG=\"ell\" ;;\n  hu) TESSERACT_DETECTED_LANG=\"hun\" ;;\n  id) TESSERACT_DETECTED_LANG=\"ind\" ;;\n  ga) TESSERACT_DETECTED_LANG=\"gle\" ;;\n  it) TESSERACT_DETECTED_LANG=\"ita\" ;;\n  ne) TESSERACT_DETECTED_LANG=\"nep\" ;;\n  no) TESSERACT_DETECTED_LANG=\"nor\" ;;\n  pt) TESSERACT_DETECTED_LANG=\"por\" ;;\n  ro) TESSERACT_DETECTED_LANG=\"ron\" ;;\n  ru) TESSERACT_DETECTED_LANG=\"rus\" ;;\n  ca) TESSERACT_DETECTED_LANG=\"spa\" ;;\n  es) TESSERACT_DETECTED_LANG=\"spa\" ;;\n  sv) TESSERACT_DETECTED_LANG=\"swe\" ;;\n  ta) TESSERACT_DETECTED_LANG=\"tam\" ;;\n  tr) TESSERACT_DETECTED_LANG=\"tur\" ;;\nesac\n\n# Verify tesseract language is available\nif [ \"$(tesseract --list-langs 2>/dev/null | grep \"$TESSERACT_DETECTED_LANG\")\" == \"\" ]; then\n    TESSERACT_DETECTED_LANG=eng\nfi\n\necho \"OCR starting with language: $TESSERACT_DETECTED_LANG\" >&2\n\n# Perform OCR\nCONTENT=\"$(tesseract \"$INPUT_FILE\" stdout -l \"$TESSERACT_DETECTED_LANG\" 2>/dev/null || true)\"\n\n# 2nd pass language detection on extracted text\nif [ -n \"$CONTENT\" ] && [ \"$(echo \"$CONTENT\" | wc -c)\" -gt 50 ]; then\n    DETECTED_LANG=\"$(echo \"$CONTENT\" | python3 -c \"\nimport sys\ntry:\n    from langdetect import detect\n    text = sys.stdin.read().strip()\n    if text:\n        print(detect(text))\n    else:\n        print('en')\nexcept:\n    print('en')\n\" 2>/dev/null || echo 'en')\"\n    echo \"2nd pass language detected: $DETECTED_LANG\" >&2\nfi\n\n# Output JSON\njq -n --arg content \"$CONTENT\" --arg lang \"$DETECTED_LANG\" '{\n    content: $content,\n    lang_iso_639_1: $lang\n}'\n\necho \"OCR Done\" >&2"
}
,
{
  "name": "PDF OCR",
  "description": "OCR plugin for PDF documents that extracts text using tesseract and pdftotext, with automatic language detection",
  "license": "GPL-3.0",
  "mimetype_re": "application/pdf",
  "timeout": 300,
  "enabled": true,
  "dependencies": [
    "tesseract-ocr-all",
    "ghostscript",
    "poppler-utils",
    "imagemagick",
    "python3-langdetect",
    "jq",
    "file"
  ],
  "builtin": true,
  "script": "#!/bin/bash\nset -e\necho \"Arguments: $*\" >&2\necho \"Current dir: $PWD\" >&2\n\nINPUT_FILE=\"$(jq -r .content_file \"$1\")\"\necho \"Input file:\" >&2\nls -lh \"$INPUT_FILE\" >&2\nfile \"$INPUT_FILE\" >&2\n\nTITLE=\"$(pdfinfo \"$INPUT_FILE\" | awk -F': ' '/^Title:/ {print $2}' | sed 's/^[[:space:]]*//;s/[[:space:]]*$//' | grep -i '[a-z0-9]' | head -n 1 || :)\"\n\nif [ -z \"$TITLE\" ]; then\n  TITLE=\"$(jq -r .url \"$1\")\"\nfi\n\necho \"Title: $TITLE\" >&2\n\necho -e '\\n\\n' >&2\n\npdftotext -layout -eol unix -enc UTF-8 \"$INPUT_FILE\" content\nMETA_TXT_LINES=\"$(wc -l <content)\"\nif [ \"$META_TXT_LINES\" -gt 5 ]; then\n  DETECTED_LANG=\"$(head -n 500 content | python3 -c \"import sys; from langdetect import detect; print(detect(sys.stdin.read()))\")\"\n  echo \"Language detected: $DETECTED_LANG\" >&2\n  convert-im6.q16 -density 200 -define pdf:use-cropbox=true -alpha remove -alpha off -background white -strip \"${INPUT_FILE}[0]\" \"preview.png\" >&2\n  jq --arg lang \"$DETECTED_LANG\" --arg title \"$TITLE\" -Rs '{lang_iso_639_1: $lang, content: .,title: $title, preview: \"preview.png\"}' <content\n  exit 0\nfi\n\necho \"Converting to image\" >&2\nCOUNT=0\nwhile true; do\n  SUFFIX=\"$(printf \"%05d\" \"$COUNT\")\"\n  convert-im6.q16 -density 200 -define pdf:use-cropbox=true -alpha remove -alpha off -background white -strip \"${INPUT_FILE}[$COUNT]\" \"page-$SUFFIX.png\" >&2 || break\n  COUNT=\"$(($COUNT + 1))\"\ndone\n\necho \"Conversion done: $COUNT pages\" >&2\n\necho -e '\\n\\n' >&2\n\necho \"Language detection\" >&2\nDETECTED_LANG=\"$(\n  (for IMG in page-{00000..00004}.png; do\n    test -e \"$IMG\" || break\n    tesseract \"$IMG\" stdout -l osd\n    echo -e \"\\n\\n\"\n  done) |\n    python3 -c \"import sys; from langdetect import detect; print(detect(sys.stdin.read()))\"\n)\"\n\necho \"Detected language: $DETECTED_LANG\" >&2\n\nTESSERACT_DETECTED_LANG=eng\ncase \"$DETECTED_LANG\" in\nar) TESSERACT_DETECTED_LANG=\"ara\" ;;\nda) TESSERACT_DETECTED_LANG=\"dan\" ;;\nnl) TESSERACT_DETECTED_LANG=\"nld\" ;;\nen) TESSERACT_DETECTED_LANG=\"eng\" ;;\nfi) TESSERACT_DETECTED_LANG=\"fin\" ;;\nfr) TESSERACT_DETECTED_LANG=\"fra\" ;;\nde) TESSERACT_DETECTED_LANG=\"deu\" ;;\nel) TESSERACT_DETECTED_LANG=\"ell\" ;;\nhu) TESSERACT_DETECTED_LANG=\"hun\" ;;\nid) TESSERACT_DETECTED_LANG=\"ind\" ;;\nga) TESSERACT_DETECTED_LANG=\"gle\" ;;\nit) TESSERACT_DETECTED_LANG=\"ita\" ;;\nne) TESSERACT_DETECTED_LANG=\"nep\" ;;\nno) TESSERACT_DETECTED_LANG=\"nor\" ;;\npt) TESSERACT_DETECTED_LANG=\"por\" ;;\nro) TESSERACT_DETECTED_LANG=\"ron\" ;;\nru) TESSERACT_DETECTED_LANG=\"rus\" ;;\nca) TESSERACT_DETECTED_LANG=\"spa\" ;;\nes) TESSERACT_DETECTED_LANG=\"spa\" ;;\nsv) TESSERACT_DETECTED_LANG=\"swe\" ;;\nta) TESSERACT_DETECTED_LANG=\"tam\" ;;\ntr) TESSERACT_DETECTED_LANG=\"tur\" ;;\nesac\n\nif [ \"$(tesseract --list-langs | grep \"$TESSERACT_DETECTED_LANG\")\" == \"\" ]; then\n  TESSERACT_DETECTED_LANG=eng\nfi\n\nHEADER=\"$(\n  for IMG in page-{00000..00004}.png; do\n    test -e \"$IMG\" || break\n    tesseract \"$IMG\" stdout -l \"$TESSERACT_DETECTED_LANG\"\n    echo -e \"\\n\\n\"\n  done\n)\"\n\necho \"OCR starting\" >&2\n\n# Language 2nd pass\nDETECTED_LANG=\"$(\n  echo \"$HEADER\" |\n    python3 -c \"import sys; from langdetect import detect; print(detect(sys.stdin.read()))\"\n)\"\n\necho \"2nd pass language detected: $DETECTED_LANG\" >&2\nPREVIEW_FILE=page-00000.png\n\n(\n  echo \"$HEADER\"\n  test ! -e page-00005.png ||\n    for IMG in page-{00005..99999}.png; do\n      test -e \"$IMG\" || break\n      tesseract \"$IMG\" stdout -l \"$TESSERACT_DETECTED_LANG\"\n      echo -e \"\\n\\n\"\n    done\n) |\n  jq --arg lang \"$DETECTED_LANG\" --arg title \"$TITLE\" --arg preview \"$PREVIEW_FILE\" -Rs '{lang_iso_639_1: $lang, content: .,title: $title, preview: $preview}'\n\necho \"Done\" >&2\n\n"
}
,
{
  "name": "Video Metadata",
  "description": "Extract metadata from video files and generate smart preview thumbnails",
  "license": "GPL-3.0",
  "mimetype_re": "video/(mp4|avi|mov|mkv|wmv|flv|webm|m4v|3gp)",
  "timeout": 120,
  "enabled": true,
  "dependencies": [
    "ffmpeg",
    "bc",
    "jq"
  ],
  "builtin": true,
  "script": "#!/bin/bash\nset -e\n\nINPUT_FILE=\"$(jq -r .content_file \"$1\")\"\n\n# Extract title from video metadata\nTITLE=\"\"\n\nif command -v ffprobe >/dev/null 2>&1; then\n  # Extract metadata as JSON (both format and stream tags)\n  METADATA=\"$(ffprobe -v quiet -print_format json -show_entries format_tags:stream_tags \"$INPUT_FILE\" 2>/dev/null || echo '{}')\"\n  \n  # Extract artist and title metadata\n  ARTIST=\"$(echo \"$METADATA\" | jq -r '(.format.tags // {}) + (.streams[0].tags // {}) | to_entries | map(select(.key | ascii_downcase == \"artist\")) | .[0].value // \"\"' 2>/dev/null || true)\"\n  TRACK_TITLE=\"$(echo \"$METADATA\" | jq -r '(.format.tags // {}) + (.streams[0].tags // {}) | to_entries | map(select(.key | ascii_downcase == \"title\")) | .[0].value // \"\"' 2>/dev/null || true | head -n 1)\"\n  TRACK_NAME=\"$(echo \"$METADATA\" | jq -r '(.format.tags // {}) + (.streams[0].tags // {}) | to_entries | map(select(.key | ascii_downcase == \"track\")) | .[0].value // \"\"' 2>/dev/null || true)\"\n  \n  # Clean up metadata fields\n  if [ -n \"$ARTIST\" ]; then\n    ARTIST=\"$(echo \"$ARTIST\" | tr '\\n\\r' ' ' | head -c 100 | sed 's/[[:space:]]*$//' | sed 's/^[[:space:]]*//')\"\n  fi\n  if [ -n \"$TRACK_TITLE\" ]; then\n    TRACK_TITLE=\"$(echo \"$TRACK_TITLE\" | tr '\\n\\r' ' ' | head -c 100 | sed 's/[[:space:]]*$//' | sed 's/^[[:space:]]*//')\"\n  fi\n  if [ -n \"$TRACK_NAME\" ]; then\n    TRACK_NAME=\"$(echo \"$TRACK_NAME\" | tr '\\n\\r' ' ' | head -c 100 | sed 's/[[:space:]]*$//' | sed 's/^[[:space:]]*//')\"\n  fi\n  \n  # Combine artist and title information (prioritize artist + title combination)\n  if [ -n \"$ARTIST\" ] && [ -n \"$TRACK_TITLE\" ]; then\n    TITLE=\"$ARTIST - $TRACK_TITLE\"\n  elif [ -n \"$ARTIST\" ] && [ -n \"$TRACK_NAME\" ]; then\n    TITLE=\"$ARTIST - $TRACK_NAME\"\n  elif [ -n \"$TRACK_TITLE\" ]; then\n    TITLE=\"$TRACK_TITLE\"\n  elif [ -n \"$ARTIST\" ]; then\n    TITLE=\"$ARTIST\"\n  elif [ -n \"$TRACK_NAME\" ]; then\n    TITLE=\"$TRACK_NAME\"\n  fi\nfi\n\n# Final cleanup of title\nif [ -n \"$TITLE\" ]; then\n  TITLE=\"$(echo \"$TITLE\" | tr '\\n\\r' ' ' | head -c 200 | sed 's/[[:space:]]*$//' | sed 's/^[[:space:]]*//')\"\nfi\n\n# Fallback to URL if no title found\nif [ -z \"$TITLE\" ]; then\n    TITLE=\"$(jq -r .url \"$1\")\"\nfi\n\n# Generate preview thumbnail at a meaningful timestamp (not just first frame)\nPREVIEW=\"\"\nif command -v ffmpeg >/dev/null 2>&1; then\n    # Get video duration\n    DURATION=\"$(ffprobe -v quiet -show_entries format=duration -of csv=p=0 \"$INPUT_FILE\" 2>/dev/null || echo \"0\")\"\n    \n    # Calculate thumbnail timestamp (10% into the video, minimum 5 seconds)\n    if [ -n \"$DURATION\" ] && [ \"$(echo \"$DURATION > 50\" | bc -l 2>/dev/null || echo \"0\")\" -eq 1 ]; then\n        TIMESTAMP=\"$(echo \"$DURATION * 0.1\" | bc -l 2>/dev/null || echo \"5\")\"\n    elif [ -n \"$DURATION\" ] && [ \"$(echo \"$DURATION > 10\" | bc -l 2>/dev/null || echo \"0\")\" -eq 1 ]; then\n        TIMESTAMP=\"5\"\n    else\n        TIMESTAMP=\"1\"\n    fi\n    \n    # Generate thumbnail\n    if ffmpeg -i \"$INPUT_FILE\" -ss \"$TIMESTAMP\" -vframes 1 -q:v 2 -f image2 preview.jpg >/dev/null 2>&1; then\n        PREVIEW=\"preview.jpg\"\n    fi\nfi\n\n# Output JSON\nif [ -n \"$PREVIEW\" ]; then\n    jq -n --arg title \"$TITLE\" --arg preview \"$PREVIEW\" '{\n        title: $title,\n        preview: $preview\n    }'\nelse\n    jq -n --arg title \"$TITLE\" '{\n        title: $title\n    }'\nfi"
}
]
