# balance.py
"""
Data and feature balancing module for imbalanced datasets.

This module provides a unified interface for various balancing techniques
including over-sampling, under-sampling, and combination methods.
"""

import pandas as pd
import numpy as np
from nkululeko.utils.util import Util
import nkululeko.glob_conf as glob_conf


class DataBalancer:
    """Class to handle data and feature balancing operations."""

    def __init__(self, random_state=42):
        """
        Initialize the DataBalancer.

        Args:
            random_state (int): Random state for reproducible results
        """
        self.util = Util("data_balancer")
        self.random_state = random_state

        # Supported balancing algorithms
        self.oversampling_methods = [
            "ros",  # RandomOverSampler
            "smote",  # SMOTE
            "adasyn",  # ADASYN
            "borderlinesmote",  # BorderlineSMOTE
            "svmsmote",  # SVMSMOTE
        ]

        self.undersampling_methods = [
            "clustercentroids",  # ClusterCentroids
            "randomundersampler",  # RandomUnderSampler
            "editednearestneighbours",  # EditedNearestNeighbours
            "tomeklinks",  # TomekLinks
        ]

        self.combination_methods = ["smoteenn", "smotetomek"]  # SMOTEENN  # SMOTETomek

    def get_supported_methods(self):
        """Get all supported balancing methods."""
        return {
            "oversampling": self.oversampling_methods,
            "undersampling": self.undersampling_methods,
            "combination": self.combination_methods,
        }

    def is_valid_method(self, method):
        """Check if a balancing method is supported."""
        all_methods = (
            self.oversampling_methods
            + self.undersampling_methods
            + self.combination_methods
        )
        return method.lower() in all_methods

    def balance_features(self, df_train, feats_train, target_column, method):
        """
        Balance features using the specified method.

        Args:
            df_train (pd.DataFrame): Training dataframe with target labels
            feats_train (np.ndarray or pd.DataFrame): Training features
            target_column (str): Name of the target column
            method (str): Balancing method to use

        Returns:
            tuple: (balanced_df, balanced_features)
        """
        if not self.is_valid_method(method):
            available_methods = (
                self.oversampling_methods
                + self.undersampling_methods
                + self.combination_methods
            )
            self.util.error(
                f"Unknown balancing algorithm: {method}. "
                f"Available methods: {available_methods}"
            )
            return df_train, feats_train

        orig_size = len(df_train)
        self.util.debug(f"Balancing features with: {method}")
        self.util.debug(f"Original dataset size: {orig_size}")

        # Get original class distribution
        orig_dist = df_train[target_column].value_counts().to_dict()
        self.util.debug(f"Original class distribution: {orig_dist}")

        try:
            # Apply the specified balancing method
            X_res, y_res = self._apply_balancing_method(
                feats_train, df_train[target_column], method
            )

            # Create new balanced dataframe
            balanced_df = pd.DataFrame({target_column: y_res})

            # If original dataframe has an index, try to preserve it
            if hasattr(X_res, "index"):
                balanced_df.index = X_res.index

            new_size = len(balanced_df)
            new_dist = balanced_df[target_column].value_counts().to_dict()

            self.util.debug(f"Balanced dataset size: {new_size} (was {orig_size})")
            self.util.debug(f"New class distribution: {new_dist}")

            # Log class distribution with label names if encoder is available
            self._log_class_distribution(y_res, method)

            return balanced_df, X_res

        except Exception as e:
            self.util.debug(f"Error applying {method} balancing: {str(e)}")
            # Don't call sys.exit() in tests, just return original data
            return df_train, feats_train

    def _apply_balancing_method(self, features, targets, method):
        """Apply the specific balancing method."""
        method = method.lower()

        # Over-sampling methods
        if method == "ros":
            from imblearn.over_sampling import RandomOverSampler

            sampler = RandomOverSampler(random_state=self.random_state)

        elif method == "smote":
            from imblearn.over_sampling import SMOTE

            sampler = SMOTE(random_state=self.random_state)

        elif method == "adasyn":
            from imblearn.over_sampling import ADASYN

            sampler = ADASYN(random_state=self.random_state)

        elif method == "borderlinesmote":
            from imblearn.over_sampling import BorderlineSMOTE

            sampler = BorderlineSMOTE(random_state=self.random_state)

        elif method == "svmsmote":
            from imblearn.over_sampling import SVMSMOTE

            sampler = SVMSMOTE(random_state=self.random_state)

        # Under-sampling methods
        elif method == "clustercentroids":
            from imblearn.under_sampling import ClusterCentroids

            sampler = ClusterCentroids(random_state=self.random_state)

        elif method == "randomundersampler":
            from imblearn.under_sampling import RandomUnderSampler

            sampler = RandomUnderSampler(random_state=self.random_state)

        elif method == "editednearestneighbours":
            from imblearn.under_sampling import EditedNearestNeighbours

            sampler = EditedNearestNeighbours()

        elif method == "tomeklinks":
            from imblearn.under_sampling import TomekLinks

            sampler = TomekLinks()

        # Combination methods
        elif method == "smoteenn":
            from imblearn.combine import SMOTEENN

            sampler = SMOTEENN(random_state=self.random_state)

        elif method == "smotetomek":
            from imblearn.combine import SMOTETomek

            sampler = SMOTETomek(random_state=self.random_state)

        else:
            raise ValueError(f"Unsupported balancing method: {method}")

        # Apply the balancing
        X_res, y_res = sampler.fit_resample(features, targets)
        return X_res, y_res

    def _log_class_distribution(self, y_res, method):
        """Log class distribution with label names if possible."""
        # Check if label encoder is available for pretty printing
        if hasattr(glob_conf, "label_encoder") and glob_conf.label_encoder is not None:
            try:
                le = glob_conf.label_encoder
                res = pd.Series(y_res).value_counts()
                resd = {}
                for i, label_idx in enumerate(res.index.values):
                    label_name = le.inverse_transform([label_idx])[0]
                    resd[label_name] = res.values[i]
                self.util.debug(f"Class distribution after {method} balancing: {resd}")
            except Exception as e:
                self.util.debug(
                    f"Could not decode class labels: {e}. "
                    f"Showing numeric distribution: {pd.Series(y_res).value_counts().to_dict()}"
                )
        else:
            self.util.debug(
                f"Label encoder not available. "
                f"Class distribution after {method} balancing: {pd.Series(y_res).value_counts().to_dict()}"
            )


class LegacyDataBalancer:
    """Legacy data balancer for backward compatibility."""

    def __init__(self):
        self.util = Util("legacy_data_balancer")

    def balance_data(self, df_train, df_test):
        """
        Legacy method for data balancing (kept for backward compatibility).

        This method should be replaced by the new DataBalancer class.
        """
        self.util.debug("Using legacy data balancing method")
        # Implementation for legacy balance_data method would go here
        # For now, just return the original data unchanged
        return df_train, df_test
