Metadata-Version: 2.4
Name: prt-rl
Version: 0.5.4
Summary: Python Research Toolkit - Reinforcement Learning
Author-email: Gavin Strunk <gavin.strunk@gmail.com>
License-File: LICENSE
Requires-Python: >=3.11
Requires-Dist: boto3>=1.38.3
Requires-Dist: gymnasium>=1.1.1
Requires-Dist: imageio>=2.37.0
Requires-Dist: inputs>=0.5
Requires-Dist: matplotlib>=3.10.1
Requires-Dist: mlflow>=2.20.4
Requires-Dist: numpy>=2.2.3
Requires-Dist: optuna>=4.3.0
Requires-Dist: prt-sim>=0.1.0
Requires-Dist: psutil>=7.0.0
Requires-Dist: pygame>=2.6.1
Requires-Dist: pynput>=1.8.0
Requires-Dist: pynvml>=12.0.0
Requires-Dist: scipy>=1.15.2
Requires-Dist: tensordict==0.6.2
Requires-Dist: torch>=2.6.0
Requires-Dist: tqdm>=4.67.1
Requires-Dist: vmas>=1.5.0
Description-Content-Type: text/markdown

<p align="center">
<picture>
<img src="docs/_static/prt-rl-logo-title.png" width="1024" style="max-width: 100%;">
</picture>
</p>

My code related to learning and using RL outside of a specific project

The documentation website is at [https://prt-rl.readthedocs.io](https://prt-rl.readthedocs.io/en/latest/)

# Installation
Installing prt-rl from pypi as:
```shell
pip install prt-rl
```

# Getting Started

# Related Libraries
* [Stable Baselines 3](https://stable-baselines3.readthedocs.io/en/master/index.html)
* openai spinup
* TorchRL
* RLlib
* Tianshou
* [CleanRL](https://docs.cleanrl.dev/)
* [SKRL](https://github.com/Toni-SM/skrl/tree/main)

# Reference RL Repositories



# Contributing
Contributions are welcome, but please submit an issue prior to submitting a PR so the feature or bug can be discussed. 
This repository follows semantic versioning with the format major.minor.patch. The patch version bumping is automatically handled by the action workflow, and major/minor bumps can be performed by adding #major or #minor to the commit message. The tag must be in the commit short message for the action to correctly pick it up.