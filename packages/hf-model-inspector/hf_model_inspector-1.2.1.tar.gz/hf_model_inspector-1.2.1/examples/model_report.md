# Model Report: moonshotai/Kimi-K2-Instruct-0905

## Basic Information

- **Repository**: moonshotai/Kimi-K2-Instruct-0905
- **Architecture**: DeepseekV3ForCausalLM
- **Model Type**: kimi_k2

## Metadata

- **Downloads**: 22,079
- **Likes**: 488
- **Library**: transformers
- **Pipeline Tag**: text-generation
- **Tags**: transformers, safetensors, kimi_k2, text-generation, conversational, custom_code, license:other, autotrain_compatible, endpoints_compatible, fp8

## Parameters

- **Total Parameters**: 38,784,729,088
  - 38784.73M parameters
  - 38.785B parameters
- **Estimation Method**: config_heuristic

## Quantization & Precision

- **Quantized**: Yes
- **Quantization Methods**: fp8
- **Precision**: bf16

## Architecture Details

- **Intermediate Size**: 18432
- **Rope Theta**: 50000.0
- **Rope Scaling**: {'beta_fast': 1.0, 'beta_slow': 1.0, 'factor': 64.0, 'mscale': 1.0, 'mscale_all_dim': 1.0, 'original_max_position_embeddings': 4096, 'type': 'yarn'}
- **Use Cache**: True
- **Tie Word Embeddings**: False
- **Num Key Value Heads**: 64

## Tokenizer

- **Type**: TikTokenTokenizer
- **Max Length**: 1000000000000000019884624838656
- **Special Tokens**: 163584, 163585, 163586, 163587, 163588, 163590, 163591, 163593, 163594, 163595

---
*Report generated by HF Model Inspector*