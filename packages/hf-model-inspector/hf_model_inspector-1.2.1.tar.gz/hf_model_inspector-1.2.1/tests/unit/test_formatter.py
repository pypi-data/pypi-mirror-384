import builtins
import io
import os

import pytest

from hf_model_inspector import format_markdown, save_outputs


def test_format_markdown_basic_info_minimal():
    report = {"repo_id": "parag/test-model"}
    md = format_markdown(report)

    assert "# Model Report: parag/test-model" in md
    assert "## Basic Information" in md
    assert "- **Repository**: parag/test-model" in md
    # Unknown defaults
    assert "- **Architecture**: Unknown" in md
    assert "- **Model Type**: Unknown" in md
    # Footer should exist
    assert "Report generated by HF Model Inspector" in md


def test_format_markdown_full_report():
    report = {
        "repo_id": "parag/full-model",
        "architecture": "TransformerX",
        "model_type": "causal",
        "metadata": {
            "downloads": 1234567,
            "likes": 8901,
            "library": "transformers",
            "pipeline_tag": "text-generation",
            # create 12 tags to ensure it truncates to 10
            "tags": [f"tag{i}" for i in range(12)],
        },
        "parameters": {
            "total": 987654321,
            "total_millions": 987.65,
            "total_billions": 0.98765,
            "estimation_method": "heuristic",
        },
        "quantization": {
            "quantized": True,
            "quant_methods": ["q8", "q4"],
            "precision": "fp16",
        },
        "architecture_extras": {
            "num_hidden_layers": 24,
            "embedding_size": "1024-dim",
            "maybe_none": None,
        },
        "tokenizer": {
            "present": True,
            "type": "ByteLevelBPETokenizer",
            "vocab_size": 50257,
            "model_max_length": 2048,
            "special_tokens": ["<s>", "</s>", "<pad>"],
        },
        "architecture_details": {
            "hidden_size": 12288,
            "num_layers": 24,
            "num_attention_heads": 96,
            "intermediate_size": None,  # should be skipped
            "max_position_embeddings": 2048,
            "vocab_size": 50257,
            "hidden_act": "gelu_new",
        },
    }

    md = format_markdown(report)

    # Basic fields present
    assert "## Metadata" in md
    # comma formatting for large ints
    assert "- **Downloads**: 1,234,567" in md
    assert "- **Likes**: 8,901" in md
    assert "- **Library**: transformers" in md
    assert "- **Pipeline Tag**: text-generation" in md

    # tags truncated to first 10 (there should be 10 tags printed)
    assert "tag0" in md and "tag9" in md
    assert "tag10" not in md

    # parameters section content
    assert "## Parameters" in md
    assert "- **Total Parameters**: 987,654,321" in md
    assert "987.65M parameters" in md
    # total_billions < 1 so it should not use "B parameters" branch requiring billions >= 1
    assert "B parameters" not in md

    # quantization
    assert "## Quantization & Precision" in md
    assert "- **Quantized**: Yes" in md
    assert "- **Quantization Methods**: q8, q4" in md
    assert "- **Precision**: fp16" in md

    # architecture_extras keys formatted
    assert "- **Num Hidden Layers**: 24" in md
    assert "- **Embedding Size**: 1024-dim" in md
    # tokenizer
    assert "## Tokenizer" in md
    assert "- **Type**: ByteLevelBPETokenizer" in md
    assert "- **Vocabulary Size**: 50,257" in md
    assert "- **Max Length**: 2048" in md
    assert "- **Special Tokens**: <s>, </s>, <pad>" in md

    # model configuration (ints should be comma-formatted)
    assert "## Model Configuration" in md
    assert "- **Hidden Size**: 12,288" in md
    assert "- **Num Layers**: 24" in md
    assert "- **Num Attention Heads**: 96" in md
    assert "- **Max Position Embeddings**: 2,048" in md
    assert "- **Vocab Size**: 50,257" in md
    assert "- **Hidden Activation**: gelu_new" in md


def test_format_markdown_tokenizer_special_tokens_string_and_inf_max_length():
    report = {
        "repo_id": "parag/tokenizer-test",
        "tokenizer": {
            "present": True,
            "tokenizer_class": "SomeTokenizer",
            "special_tokens": "<unk>",
            "model_max_length": float("inf"),  # should be ignored
        },
    }

    md = format_markdown(report)

    assert "## Tokenizer" in md
    # picks tokenizer_class if type missing
    assert "- **Type**: SomeTokenizer" in md
    # special_tokens printed as given string
    assert "- **Special Tokens**: <unk>" in md
    # Max Length should NOT be included because it's inf
    assert "Max Length" not in md


def test_save_outputs_success_creates_dirs_and_writes(tmp_path):
    content = "hello world"
    out_dir = tmp_path / "some" / "nested"
    out_file = out_dir / "report.md"

    # ensure directory does not exist before call
    assert not out_dir.exists()

    save_outputs(content, str(out_file))

    # directory created and file exists with correct content
    assert out_dir.exists()
    assert out_file.exists()
    read = out_file.read_text(encoding="utf-8")
    assert read == content


def test_save_outputs_failure_raises_oserror(monkeypatch, tmp_path):
    # monkeypatch builtins.open to simulate a write error
    def fake_open(*args, **kwargs):
        raise PermissionError("cannot write")

    monkeypatch.setattr(builtins, "open", fake_open)

    target = tmp_path / "wont_write.md"
    with pytest.raises(OSError):
        save_outputs("irrelevant", str(target))
