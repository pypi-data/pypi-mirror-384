source_id: time_ticks # raw source alias (see config/sources)
stream_id: time_linear # this stream id used by recipes

mapper: # normalize/reshape DTO -> TemporalRecord if not implemented will give you idenitymapper
  entrypoint: encode_time
  args: { mode: linear }
# partition_by: station_id      # optional: add partition suffixes to feature ids

# record:                       # record-level transforms (run before partitioning)
#   - filter: { operator: ge, field: time, comparand: "${start_time}" }
#   - filter: { operator: le, field: time, comparand: "${end_time}" }
#   - floor_time: { resolution: 10m }          # snap timestamps to resolution
#   - lag: { lag: 10m }                         # shift timestamps backwards

# stream:                       # per-feature stream transforms (input sorted by id,time)
#   - ensure_ticks: { tick: 10m }               # insert missing ticks (value=None)
#   - granularity: { mode: first }              # aggregate duplicates within a tick
#   - fill: { statistic: median, window: 6, min_samples: 1 }  # impute gaps

# debug:                        # optional validation-only transforms
#   - lint: { mode: warn, tick: 10m }           # flag gaps/duplicates/order issues

# sort_batch_size: 100000       # in-memory chunk size used by internal sorting
