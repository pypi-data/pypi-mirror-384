
# Autogenerated by mlir-tblgen; don't manually edit.

from enum import IntEnum, auto, IntFlag
from ._ods_common import _cext as _ods_cext
from ..ir import register_attribute_builder
_ods_ir = _ods_cext.ir

class ComputeBitwidths(IntFlag):
    """Supported bitwidths for compute"""

    FP64 = 1
    FP32 = 2
    FP16 = 4
    Int64 = 8
    Int32 = 16
    Int16 = 32
    Int8 = 64
    FP8 = 128
    FP6 = 256
    FP4 = 512

    def __iter__(self):
        return iter([case for case in type(self) if (self & case) is case and self is not case])
    def __len__(self):
        return bin(self).count("1")

    def __str__(self):
        if len(self) > 1:
            return "|".join(map(str, self))
        if self is ComputeBitwidths.FP64:
            return "fp64"
        if self is ComputeBitwidths.FP32:
            return "fp32"
        if self is ComputeBitwidths.FP16:
            return "fp16"
        if self is ComputeBitwidths.Int64:
            return "int64"
        if self is ComputeBitwidths.Int32:
            return "int32"
        if self is ComputeBitwidths.Int16:
            return "int16"
        if self is ComputeBitwidths.Int8:
            return "int8"
        if self is ComputeBitwidths.FP8:
            return "fp8"
        if self is ComputeBitwidths.FP6:
            return "fp6"
        if self is ComputeBitwidths.FP4:
            return "fp4"
        raise ValueError("Unknown ComputeBitwidths enum entry.")



@register_attribute_builder("IREEGPU_ComputeBitwidths")
def _ireegpu_computebitwidths(x, context):
    return _ods_ir.IntegerAttr.get(_ods_ir.IntegerType.get_signless(32, context=context), int(x))

class DotProductOps(IntFlag):
    """Supported dot product ops"""

    None_ = 0
    DP4xI8ToI32 = 1

    def __iter__(self):
        return iter([case for case in type(self) if (self & case) is case and self is not case])
    def __len__(self):
        return bin(self).count("1")

    def __str__(self):
        if len(self) > 1:
            return "|".join(map(str, self))
        if self is DotProductOps.None_:
            return "none"
        if self is DotProductOps.DP4xI8ToI32:
            return "dp4xi8toi32"
        raise ValueError("Unknown DotProductOps enum entry.")



@register_attribute_builder("IREEGPU_DotProductOps")
def _ireegpu_dotproductops(x, context):
    return _ods_ir.IntegerAttr.get(_ods_ir.IntegerType.get_signless(32, context=context), int(x))

class MMAFragment(IntEnum):
    """Descriptor for a particular fragment of an MMA operation"""

    Lhs = 0
    Rhs = 1
    Acc = 2

    def __str__(self):
        if self is MMAFragment.Lhs:
            return "Lhs"
        if self is MMAFragment.Rhs:
            return "Rhs"
        if self is MMAFragment.Acc:
            return "Acc"
        raise ValueError("Unknown MMAFragment enum entry.")



@register_attribute_builder("IREEGPU_MMAFragment")
def _ireegpu_mmafragment(x, context):
    return _ods_ir.IntegerAttr.get(_ods_ir.IntegerType.get_signless(32, context=context), int(x))

class MMAIntrinsic(IntEnum):
    """Descriptor for different MMA intrinsics"""

    MFMA_F32_16x16x4_F32 = 4112
    MFMA_F32_16x16x16_F16 = 4128
    MFMA_F32_32x32x8_F16 = 4129
    MFMA_I32_16x16x16_I8 = 4288
    MFMA_I32_32x32x8_I8 = 4289
    MFMA_F32_16x16x8_BF16 = 4384
    MFMA_F32_32x32x4_BF16 = 4385
    MFMA_F64_16x16x4_F64 = 4352
    MFMA_F32_16x16x16_BF16 = 4640
    MFMA_F32_32x32x8_BF16 = 4641
    MFMA_F32_16x16x32_F8E5M2FNUZ = 4656
    MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ = 4657
    MFMA_F32_16x16x32_F8E4M3FNUZ = 4658
    MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ = 4659
    MFMA_F32_32x32x16_F8E5M2FNUZ = 4660
    MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ = 4661
    MFMA_F32_32x32x16_F8E4M3FNUZ = 4662
    MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ = 4663
    MFMA_I32_16x16x32_I8 = 4800
    MFMA_I32_32x32x16_I8 = 4801
    MFMA_F32_16x16x32_F16 = 4896
    MFMA_F32_32x32x16_F16 = 4897
    MFMA_F32_16x16x32_BF16 = 4898
    MFMA_F32_32x32x16_BF16 = 4899
    MFMA_F32_16x16x32_F8E5M2 = 4912
    MFMA_F32_16x16x32_F8E5M2_F8E4M3FN = 4913
    MFMA_F32_16x16x32_F8E4M3FN = 4914
    MFMA_F32_16x16x32_F8E4M3FN_F8E5M2 = 4915
    MFMA_F32_32x32x16_F8E5M2 = 4916
    MFMA_F32_32x32x16_F8E5M2_F8E4M3FN = 4917
    MFMA_F32_32x32x16_F8E4M3FN = 4918
    MFMA_F32_32x32x16_F8E4M3FN_F8E5M2 = 4919
    MFMA_F32_16x16x128_F8E5M2 = 4920
    MFMA_F32_16x16x128_F8E5M2_F8E4M3FN = 4921
    MFMA_F32_16x16x128_F8E4M3FN = 4922
    MFMA_F32_16x16x128_F8E4M3FN_F8E5M2 = 4923
    MFMA_F32_32x32x64_F8E5M2 = 4924
    MFMA_F32_32x32x64_F8E5M2_F8E4M3FN = 4925
    MFMA_F32_32x32x64_F8E4M3FN = 4926
    MFMA_F32_32x32x64_F8E4M3FN_F8E5M2 = 4927
    MFMA_I32_16x16x64_I8 = 5056
    MFMA_I32_32x32x32_I8 = 5057
    WMMAR3_F32_16x16x16_F16 = 6176
    WMMAR3_F16_16x16x16_F16 = 6177
    WMMAR3_F32_16x16x16_BF16 = 6178
    WMMAR3_BF16_16x16x16_BF16 = 6179
    WMMAR3_I32_16x16x16_I8 = 6336
    WMMAR4_F32_16x16x16_F16 = 6432
    WMMAR4_F16_16x16x16_F16 = 6433
    WMMAR4_F32_16x16x16_BF16 = 6434
    WMMAR4_BF16_16x16x16_BF16 = 6435
    WMMAR4_F32_16x16x16_F8E5M2 = 6448
    WMMAR4_F32_16x16x16_F8E5M2_F8E4M3FN = 6449
    WMMAR4_F32_16x16x16_F8E4M3FN = 6450
    WMMAR4_F32_16x16x16_F8E4M3FN_F8E5M2 = 6451
    WMMAR4_I32_16x16x16_I8 = 6592
    NV_WMMA_F32_16x16x16_F16 = 8224
    NV_WMMA_F16_16x16x16_F16 = 8225

    def __str__(self):
        if self is MMAIntrinsic.MFMA_F32_16x16x4_F32:
            return "MFMA_F32_16x16x4_F32"
        if self is MMAIntrinsic.MFMA_F32_16x16x16_F16:
            return "MFMA_F32_16x16x16_F16"
        if self is MMAIntrinsic.MFMA_F32_32x32x8_F16:
            return "MFMA_F32_32x32x8_F16"
        if self is MMAIntrinsic.MFMA_I32_16x16x16_I8:
            return "MFMA_I32_16x16x16_I8"
        if self is MMAIntrinsic.MFMA_I32_32x32x8_I8:
            return "MFMA_I32_32x32x8_I8"
        if self is MMAIntrinsic.MFMA_F32_16x16x8_BF16:
            return "MFMA_F32_16x16x8_BF16"
        if self is MMAIntrinsic.MFMA_F32_32x32x4_BF16:
            return "MFMA_F32_32x32x4_BF16"
        if self is MMAIntrinsic.MFMA_F64_16x16x4_F64:
            return "MFMA_F64_16x16x4_F64"
        if self is MMAIntrinsic.MFMA_F32_16x16x16_BF16:
            return "MFMA_F32_16x16x16_BF16"
        if self is MMAIntrinsic.MFMA_F32_32x32x8_BF16:
            return "MFMA_F32_32x32x8_BF16"
        if self is MMAIntrinsic.MFMA_F32_16x16x32_F8E5M2FNUZ:
            return "MFMA_F32_16x16x32_F8E5M2FNUZ"
        if self is MMAIntrinsic.MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ:
            return "MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ"
        if self is MMAIntrinsic.MFMA_F32_16x16x32_F8E4M3FNUZ:
            return "MFMA_F32_16x16x32_F8E4M3FNUZ"
        if self is MMAIntrinsic.MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ:
            return "MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ"
        if self is MMAIntrinsic.MFMA_F32_32x32x16_F8E5M2FNUZ:
            return "MFMA_F32_32x32x16_F8E5M2FNUZ"
        if self is MMAIntrinsic.MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ:
            return "MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ"
        if self is MMAIntrinsic.MFMA_F32_32x32x16_F8E4M3FNUZ:
            return "MFMA_F32_32x32x16_F8E4M3FNUZ"
        if self is MMAIntrinsic.MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ:
            return "MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ"
        if self is MMAIntrinsic.MFMA_I32_16x16x32_I8:
            return "MFMA_I32_16x16x32_I8"
        if self is MMAIntrinsic.MFMA_I32_32x32x16_I8:
            return "MFMA_I32_32x32x16_I8"
        if self is MMAIntrinsic.MFMA_F32_16x16x32_F16:
            return "MFMA_F32_16x16x32_F16"
        if self is MMAIntrinsic.MFMA_F32_32x32x16_F16:
            return "MFMA_F32_32x32x16_F16"
        if self is MMAIntrinsic.MFMA_F32_16x16x32_BF16:
            return "MFMA_F32_16x16x32_BF16"
        if self is MMAIntrinsic.MFMA_F32_32x32x16_BF16:
            return "MFMA_F32_32x32x16_BF16"
        if self is MMAIntrinsic.MFMA_F32_16x16x32_F8E5M2:
            return "MFMA_F32_16x16x32_F8E5M2"
        if self is MMAIntrinsic.MFMA_F32_16x16x32_F8E5M2_F8E4M3FN:
            return "MFMA_F32_16x16x32_F8E5M2_F8E4M3FN"
        if self is MMAIntrinsic.MFMA_F32_16x16x32_F8E4M3FN:
            return "MFMA_F32_16x16x32_F8E4M3FN"
        if self is MMAIntrinsic.MFMA_F32_16x16x32_F8E4M3FN_F8E5M2:
            return "MFMA_F32_16x16x32_F8E4M3FN_F8E5M2"
        if self is MMAIntrinsic.MFMA_F32_32x32x16_F8E5M2:
            return "MFMA_F32_32x32x16_F8E5M2"
        if self is MMAIntrinsic.MFMA_F32_32x32x16_F8E5M2_F8E4M3FN:
            return "MFMA_F32_32x32x16_F8E5M2_F8E4M3FN"
        if self is MMAIntrinsic.MFMA_F32_32x32x16_F8E4M3FN:
            return "MFMA_F32_32x32x16_F8E4M3FN"
        if self is MMAIntrinsic.MFMA_F32_32x32x16_F8E4M3FN_F8E5M2:
            return "MFMA_F32_32x32x16_F8E4M3FN_F8E5M2"
        if self is MMAIntrinsic.MFMA_F32_16x16x128_F8E5M2:
            return "MFMA_F32_16x16x128_F8E5M2"
        if self is MMAIntrinsic.MFMA_F32_16x16x128_F8E5M2_F8E4M3FN:
            return "MFMA_F32_16x16x128_F8E5M2_F8E4M3FN"
        if self is MMAIntrinsic.MFMA_F32_16x16x128_F8E4M3FN:
            return "MFMA_F32_16x16x128_F8E4M3FN"
        if self is MMAIntrinsic.MFMA_F32_16x16x128_F8E4M3FN_F8E5M2:
            return "MFMA_F32_16x16x128_F8E4M3FN_F8E5M2"
        if self is MMAIntrinsic.MFMA_F32_32x32x64_F8E5M2:
            return "MFMA_F32_32x32x64_F8E5M2"
        if self is MMAIntrinsic.MFMA_F32_32x32x64_F8E5M2_F8E4M3FN:
            return "MFMA_F32_32x32x64_F8E5M2_F8E4M3FN"
        if self is MMAIntrinsic.MFMA_F32_32x32x64_F8E4M3FN:
            return "MFMA_F32_32x32x64_F8E4M3FN"
        if self is MMAIntrinsic.MFMA_F32_32x32x64_F8E4M3FN_F8E5M2:
            return "MFMA_F32_32x32x64_F8E4M3FN_F8E5M2"
        if self is MMAIntrinsic.MFMA_I32_16x16x64_I8:
            return "MFMA_I32_16x16x64_I8"
        if self is MMAIntrinsic.MFMA_I32_32x32x32_I8:
            return "MFMA_I32_32x32x32_I8"
        if self is MMAIntrinsic.WMMAR3_F32_16x16x16_F16:
            return "WMMAR3_F32_16x16x16_F16"
        if self is MMAIntrinsic.WMMAR3_F16_16x16x16_F16:
            return "WMMAR3_F16_16x16x16_F16"
        if self is MMAIntrinsic.WMMAR3_F32_16x16x16_BF16:
            return "WMMAR3_F32_16x16x16_BF16"
        if self is MMAIntrinsic.WMMAR3_BF16_16x16x16_BF16:
            return "WMMAR3_BF16_16x16x16_BF16"
        if self is MMAIntrinsic.WMMAR3_I32_16x16x16_I8:
            return "WMMAR3_I32_16x16x16_I8"
        if self is MMAIntrinsic.WMMAR4_F32_16x16x16_F16:
            return "WMMAR4_F32_16x16x16_F16"
        if self is MMAIntrinsic.WMMAR4_F16_16x16x16_F16:
            return "WMMAR4_F16_16x16x16_F16"
        if self is MMAIntrinsic.WMMAR4_F32_16x16x16_BF16:
            return "WMMAR4_F32_16x16x16_BF16"
        if self is MMAIntrinsic.WMMAR4_BF16_16x16x16_BF16:
            return "WMMAR4_BF16_16x16x16_BF16"
        if self is MMAIntrinsic.WMMAR4_F32_16x16x16_F8E5M2:
            return "WMMAR4_F32_16x16x16_F8E5M2"
        if self is MMAIntrinsic.WMMAR4_F32_16x16x16_F8E5M2_F8E4M3FN:
            return "WMMAR4_F32_16x16x16_F8E5M2_F8E4M3FN"
        if self is MMAIntrinsic.WMMAR4_F32_16x16x16_F8E4M3FN:
            return "WMMAR4_F32_16x16x16_F8E4M3FN"
        if self is MMAIntrinsic.WMMAR4_F32_16x16x16_F8E4M3FN_F8E5M2:
            return "WMMAR4_F32_16x16x16_F8E4M3FN_F8E5M2"
        if self is MMAIntrinsic.WMMAR4_I32_16x16x16_I8:
            return "WMMAR4_I32_16x16x16_I8"
        if self is MMAIntrinsic.NV_WMMA_F32_16x16x16_F16:
            return "NV_WMMA_F32_16x16x16_F16"
        if self is MMAIntrinsic.NV_WMMA_F16_16x16x16_F16:
            return "NV_WMMA_F16_16x16x16_F16"
        raise ValueError("Unknown MMAIntrinsic enum entry.")



@register_attribute_builder("IREEGPU_MMAIntrinsic")
def _ireegpu_mmaintrinsic(x, context):
    return _ods_ir.IntegerAttr.get(_ods_ir.IntegerType.get_signless(32, context=context), int(x))

class ReorderWorkgroupsStrategy(IntEnum):
    """Strategy for workgroup reordering"""

    None_ = 0
    Transpose = 1

    def __str__(self):
        if self is ReorderWorkgroupsStrategy.None_:
            return "None"
        if self is ReorderWorkgroupsStrategy.Transpose:
            return "Transpose"
        raise ValueError("Unknown ReorderWorkgroupsStrategy enum entry.")



@register_attribute_builder("IREEGPU_ReorderWorkgroupsStrategy")
def _ireegpu_reorderworkgroupsstrategy(x, context):
    return _ods_ir.IntegerAttr.get(_ods_ir.IntegerType.get_signless(32, context=context), int(x))

class ScaledMMAIntrinsic(IntEnum):
    """Descriptor for different scaled MMA intrinsics"""

    MFMA_SCALE_F32_16x16x128_B32 = 4096
    MFMA_SCALE_F32_32x32x64_B32 = 4097

    def __str__(self):
        if self is ScaledMMAIntrinsic.MFMA_SCALE_F32_16x16x128_B32:
            return "MFMA_SCALE_F32_16x16x128_B32"
        if self is ScaledMMAIntrinsic.MFMA_SCALE_F32_32x32x64_B32:
            return "MFMA_SCALE_F32_32x32x64_B32"
        raise ValueError("Unknown ScaledMMAIntrinsic enum entry.")



class StorageBitwidths(IntFlag):
    """Supported bitwidths for storage"""

    B64 = 1
    B32 = 2
    B16 = 4
    B8 = 8

    def __iter__(self):
        return iter([case for case in type(self) if (self & case) is case and self is not case])
    def __len__(self):
        return bin(self).count("1")

    def __str__(self):
        if len(self) > 1:
            return "|".join(map(str, self))
        if self is StorageBitwidths.B64:
            return "b64"
        if self is StorageBitwidths.B32:
            return "b32"
        if self is StorageBitwidths.B16:
            return "b16"
        if self is StorageBitwidths.B8:
            return "b8"
        raise ValueError("Unknown StorageBitwidths enum entry.")



@register_attribute_builder("IREEGPU_StorageBitwidths")
def _ireegpu_storagebitwidths(x, context):
    return _ods_ir.IntegerAttr.get(_ods_ir.IntegerType.get_signless(32, context=context), int(x))

class SubgroupOps(IntFlag):
    """Supported subgroup ops"""

    None_ = 0
    Shuffle = 1
    Arithmetic = 2

    def __iter__(self):
        return iter([case for case in type(self) if (self & case) is case and self is not case])
    def __len__(self):
        return bin(self).count("1")

    def __str__(self):
        if len(self) > 1:
            return "|".join(map(str, self))
        if self is SubgroupOps.None_:
            return "none"
        if self is SubgroupOps.Shuffle:
            return "shuffle"
        if self is SubgroupOps.Arithmetic:
            return "arithmetic"
        raise ValueError("Unknown SubgroupOps enum entry.")



@register_attribute_builder("IREEGPU_SubgroupOps")
def _ireegpu_subgroupops(x, context):
    return _ods_ir.IntegerAttr.get(_ods_ir.IntegerType.get_signless(32, context=context), int(x))

class TilingLevel(IntEnum):
    """Descriptor for tiling levels for GPU lowering configs"""

    Workgroup = 0
    Reduction = 1
    PartialReduction = 2
    Thread = 3
    Subgroup = 4
    Lane = 5

    def __str__(self):
        if self is TilingLevel.Workgroup:
            return "Workgroup"
        if self is TilingLevel.Reduction:
            return "Reduction"
        if self is TilingLevel.PartialReduction:
            return "PartialReduction"
        if self is TilingLevel.Thread:
            return "Thread"
        if self is TilingLevel.Subgroup:
            return "Subgroup"
        if self is TilingLevel.Lane:
            return "Lane"
        raise ValueError("Unknown TilingLevel enum entry.")



@register_attribute_builder("IREEGPU_TilingLevel")
def _ireegpu_tilinglevel(x, context):
    return _ods_ir.IntegerAttr.get(_ods_ir.IntegerType.get_signless(32, context=context), int(x))

class VirtualMMAIntrinsic(IntEnum):
    """Descriptor for different Virtual MMA intrinsics"""

    VMFMA_F32_16x16x32_F16 = 0
    VMFMA_F32_32x32x16_F16 = 1
    VMFMA_F32_16x16x32_F8E4M3FNUZ = 2
    VMFMA_F32_32x32x16_F8E4M3FNUZ = 3

    def __str__(self):
        if self is VirtualMMAIntrinsic.VMFMA_F32_16x16x32_F16:
            return "VMFMA_F32_16x16x32_F16"
        if self is VirtualMMAIntrinsic.VMFMA_F32_32x32x16_F16:
            return "VMFMA_F32_32x32x16_F16"
        if self is VirtualMMAIntrinsic.VMFMA_F32_16x16x32_F8E4M3FNUZ:
            return "VMFMA_F32_16x16x32_F8E4M3FNUZ"
        if self is VirtualMMAIntrinsic.VMFMA_F32_32x32x16_F8E4M3FNUZ:
            return "VMFMA_F32_32x32x16_F8E4M3FNUZ"
        raise ValueError("Unknown VirtualMMAIntrinsic enum entry.")



@register_attribute_builder("IREEGPU_VirtualMMAIntrinsic")
def _ireegpu_virtualmmaintrinsic(x, context):
    return _ods_ir.IntegerAttr.get(_ods_ir.IntegerType.get_signless(32, context=context), int(x))

class IteratorType(IntEnum):
    """Iterator type"""

    parallel = 0
    reduction = 1

    def __str__(self):
        if self is IteratorType.parallel:
            return "parallel"
        if self is IteratorType.reduction:
            return "reduction"
        raise ValueError("Unknown IteratorType enum entry.")



@register_attribute_builder("IteratorType")
def _iteratortype(x, context):
    return _ods_ir.IntegerAttr.get(_ods_ir.IntegerType.get_signless(32, context=context), int(x))

@register_attribute_builder("IREEGPU_ComputeBitwidthsAttr")
def _ireegpu_computebitwidthsattr(x, context):
    return _ods_ir.Attribute.parse(f'#iree_gpu<compute_bitwidths {str(x)}>', context=context)

@register_attribute_builder("IREEGPU_DotProductOpsAttr")
def _ireegpu_dotproductopsattr(x, context):
    return _ods_ir.Attribute.parse(f'#iree_gpu<dotproduct_ops {str(x)}>', context=context)

@register_attribute_builder("IREEGPU_MMAIntrinsicAttr")
def _ireegpu_mmaintrinsicattr(x, context):
    return _ods_ir.Attribute.parse(f'#iree_gpu<mma_intrinsic {str(x)}>', context=context)

@register_attribute_builder("IREEGPU_ReorderWorkgroupsStrategyAttr")
def _ireegpu_reorderworkgroupsstrategyattr(x, context):
    return _ods_ir.Attribute.parse(f'#iree_gpu.reorder_workgroups_strategy<{str(x)}>', context=context)

@register_attribute_builder("IREEGPU_StorageBitwidthsAttr")
def _ireegpu_storagebitwidthsattr(x, context):
    return _ods_ir.Attribute.parse(f'#iree_gpu<storage_bitwidths {str(x)}>', context=context)

@register_attribute_builder("IREEGPU_SubgroupOpsAttr")
def _ireegpu_subgroupopsattr(x, context):
    return _ods_ir.Attribute.parse(f'#iree_gpu<subgroup_ops {str(x)}>', context=context)

@register_attribute_builder("IREEGPU_VirtualMMAIntrinsicAttr")
def _ireegpu_virtualmmaintrinsicattr(x, context):
    return _ods_ir.Attribute.parse(f'#iree_gpu<virtual_mma_intrinsic {str(x)}>', context=context)

