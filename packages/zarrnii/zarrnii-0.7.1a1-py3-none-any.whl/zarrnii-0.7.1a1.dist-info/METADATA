Metadata-Version: 2.4
Name: zarrnii
Version: 0.7.1a1
Summary: Package for working with OME-Zarr and NIFTI images in a unified manner, with a focus on spatial transformations
Project-URL: Homepage, https://github.com/khanlab/zarrnii
Project-URL: Documentation, https://www.khanlab.ca/zarrnii
Project-URL: Repository, https://github.com/khanlab/zarrnii
Project-URL: Issues, https://github.com/khanlab/zarrnii/issues
Author-email: Ali Khan <alik@robarts.ca>
License: MIT
Keywords: biomedical,imaging,microscopy,mri,neuroimaging,nifti,ome-zarr
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Image Processing
Classifier: Topic :: Scientific/Engineering :: Medical Science Apps.
Requires-Python: >=3.11
Requires-Dist: dask>=2025.5.1
Requires-Dist: h5py>=3.14.0
Requires-Dist: ngff-zarr[all]>=0.13.1
Requires-Dist: nibabel>=5.2.0
Requires-Dist: numpy>=1.26.4
Requires-Dist: pandas>=2.2.0
Requires-Dist: pyyaml>=6.0
Requires-Dist: scikit-image>=0.22.0
Requires-Dist: scipy>=1.12.0
Requires-Dist: zarr>=3.0.8
Provides-Extra: dev
Requires-Dist: black>=24.10.0; extra == 'dev'
Requires-Dist: bokeh>=3.4.1; extra == 'dev'
Requires-Dist: flake8-bugbear>=24.12.12; extra == 'dev'
Requires-Dist: flake8-docstrings>=1.7.0; extra == 'dev'
Requires-Dist: flake8-import-order>=0.18.2; extra == 'dev'
Requires-Dist: flake8>=7.3.0; extra == 'dev'
Requires-Dist: isort>=5.13.2; extra == 'dev'
Requires-Dist: jupyterlab>=4.2.1; extra == 'dev'
Requires-Dist: matplotlib>=3.9.0; extra == 'dev'
Requires-Dist: mkdocs-material>=9.5.50; extra == 'dev'
Requires-Dist: mkdocs>=1.6.1; extra == 'dev'
Requires-Dist: mkdocstrings-python>=1.13.0; extra == 'dev'
Requires-Dist: mkdocstrings>=0.27.0; extra == 'dev'
Requires-Dist: pre-commit>=4.0.0; extra == 'dev'
Requires-Dist: pytest-cov>=6.0.0; extra == 'dev'
Requires-Dist: pytest>=8.2.0; extra == 'dev'
Provides-Extra: imaris
Requires-Dist: h5py>=3.8.0; extra == 'imaris'
Provides-Extra: n4
Requires-Dist: antspyx>=0.5.0; extra == 'n4'
Provides-Extra: templateflow
Requires-Dist: templateflow>=0.8.0; extra == 'templateflow'
Description-Content-Type: text/markdown

# zarrnii

 **ZarrNii** is a Python library for working with OME-Zarr, NIfTI, and Imaris formats. ZarrNii bridges the gap between these popular formats, enabling seamless data transformation, metadata preservation, and efficient processing of biomedical images. The motivating application is for whole brain lightsheet microscopy and ultra-high field MRI, but it can generally be used for any 3D+[channel,time] datasets.

ZarrNii allows you to:

 - Read and write OME-Zarr, NIfTI, and Imaris datasets
 - Perform transformations like cropping, downsampling, and interpolation.
 - Preserve and manipulate metadata from OME-Zarr (e.g., axes, coordinate transformations, OME annotations).

---

## Installation

### Using pip (recommended)
```bash
pip install zarrnii
```

### Optional Dependencies
For additional format support:
```bash
# For Imaris (.ims) file support
pip install zarrnii[imaris]
```

### Development installation  
For contributing or development, clone the repository and install with [uv](https://docs.astral.sh/uv/):

```bash
git clone https://github.com/khanlab/zarrnii.git
cd zarrnii
uv sync --dev
```

---

## Key Features

 - **Seamless Format Conversion**: Easily convert between OME-Zarr, NIfTI, and Imaris while preserving spatial metadata.
 - **ZipStore Support**: Read and write OME-Zarr files in compressed ZIP format (.ome.zarr.zip) for efficient storage and sharing.
 - **Transformations**: Apply common operations like affine transformations, downsampling, and upsampling.
 - **Multiscale Support**: Work with multiscale OME-Zarr pyramids.
 - **Metadata Handling**: Access and modify OME-Zarr metadata like axes and transformations.
 - **Lazy Loading**: Leverage Dask arrays for efficient processing of large datasets.
 - **Segmentation Plugins**: Extensible plugin architecture for image segmentation algorithms.

---

## Advanced Topics

### Orientation Metadata Backwards Compatibility

Starting from version 0.2.0, ZarrNii implements improved orientation metadata handling with backwards compatibility for existing OME-Zarr files:

#### New Format (v0.2.0+)
- **Metadata Key**: `xyz_orientation`
- **Axis Order**: Always in XYZ axes order for consistency
- **Example**: `"RAS"` means Right-to-left, Anterior-to-posterior, Superior-to-inferior in XYZ space

#### Legacy Format (pre-v0.2.0)
- **Metadata Key**: `orientation` 
- **Axis Order**: ZYX axes order (reversed from XYZ)
- **Example**: `"SAR"` in ZYX order is equivalent to `"RAS"` in XYZ order

#### Automatic Conversion
ZarrNii automatically handles both formats when loading OME-Zarr files:

```python
# Loading prioritizes xyz_orientation, falls back to orientation (with reversal)
znimg = ZarrNii.from_ome_zarr("legacy_file.zarr")  # Works with both formats

# New files always use xyz_orientation format
znimg.to_ome_zarr("new_file.zarr")  # Saves with xyz_orientation
```

#### Migration Guide
- **Existing files**: Continue to work without modification
- **New files**: Use the improved `xyz_orientation` format automatically  
- **API**: The `orientation` property maintains backwards compatibility

---

## Segmentation Plugin System

ZarrNii includes a plugin architecture for image segmentation algorithms, starting with Otsu thresholding:

```python
from zarrnii import ZarrNii, OtsuSegmentation

# Load your image
znimg = ZarrNii.from_ome_zarr("image.ome.zarr")

# Apply Otsu thresholding segmentation
segmented = znimg.segment_otsu(nbins=256)

# Or use the generic plugin interface
plugin = OtsuSegmentation(nbins=128)
segmented = znimg.segment(plugin)

# Save segmented results
segmented.to_ome_zarr("segmented_image.ome.zarr")
```

### Custom Plugins

Create your own segmentation algorithms by extending the `SegmentationPlugin` base class:

```python
from zarrnii.plugins.segmentation import SegmentationPlugin

class CustomSegmentation(SegmentationPlugin):
    def segment(self, image, metadata=None):
        # Your segmentation logic here
        return binary_mask.astype(np.uint8)
    
    @property
    def name(self):
        return "Custom Algorithm"
    
    @property 
    def description(self):
        return "Description of your algorithm"
```

---

## Quick Start

```python
from zarrnii import ZarrNii

# Load an OME-Zarr dataset
znimg = ZarrNii.from_ome_zarr("path/to/zarr_dataset.ome.zarr")

<<<<<<< HEAD
# Or load from Imaris (requires zarrnii[imaris])
# znimg = ZarrNii.from_imaris("path/to/microscopy_data.ims")
=======
# Load from compressed ZIP format
znimg_zip = ZarrNii.from_ome_zarr("path/to/dataset.ome.zarr.zip")
>>>>>>> main

# Perform a transformation (e.g., downsample)
downsampled_znimg = znimg.downsample(level=2)

# Save as NIfTI
downsampled_znimg.to_nifti("output_dataset.nii")

# Save as compressed OME-Zarr ZIP file
downsampled_znimg.to_ome_zarr("compressed_output.ome.zarr.zip")
```

---

## Development

For development, this project uses:

- **[uv](https://docs.astral.sh/uv/)** for fast dependency management
- **[pytest](https://pytest.org/)** for testing
- **[black](https://black.readthedocs.io/)** for code formatting  
- **[flake8](https://flake8.pycqa.org/)** for linting
- **[mkdocs](https://www.mkdocs.org/)** for documentation

### Available commands (using `uv run`):
```bash
# Run tests
uv run pytest

# Format code
uv run black .

# Check linting  
uv run flake8 .

# Build documentation
uv run mkdocs build

# Serve docs locally
uv run mkdocs serve
```

### Using the justfile:
If you have [just](https://just.systems/) installed:
```bash
# See all available tasks
just help

# Run tests
just test

# Format and lint
just format
just lint
```

---

## Learn More

Explore the [documentation](https://www.khanlab.ca/zarrnii) to get started.

## Contributing

Contributions are welcome! Please read our contributing guidelines and ensure all tests pass before submitting pull requests.
