{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud Environment with Re-imaging\n",
    "This tutorial demonstrates the configuration and use of a BSK-RL environment considering cloud coverage and re-imaging capabilities. Two reward functions are presented: a single-picture binary case (where targets are deemed occluded by clouds or not and no re-imaging is allowed) and a re-imaging case where the problem is formulated in terms of the targets' probability of being successfully observed. Still, the satellite cannot observe the true cloud coverage of each target, only its forecast. The satellite has to image targets while keeping a positive battery level. This example script is part of an upcoming publication.\n",
    "\n",
    "## Loading Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bsk_rl import ConstellationTasking\n",
    "import numpy as np\n",
    "from typing import Optional, Callable, Union\n",
    "\n",
    "from Basilisk.architecture import bskLogging\n",
    "from Basilisk.utilities import orbitalMotion\n",
    "from bsk_rl import act, obs, sats\n",
    "from bsk_rl.sim import dyn, fsw, world\n",
    "from bsk_rl.scene.targets import UniformTargets\n",
    "from bsk_rl.data.base import Data, DataStore, GlobalReward\n",
    "from bsk_rl.data.unique_image_data import (\n",
    "    UniqueImageData,\n",
    "    UniqueImageStore,\n",
    "    UniqueImageReward,\n",
    ")\n",
    "\n",
    "bskLogging.setDefaultLogLevel(bskLogging.BSK_WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a Scenario with Cloud Covered Targets\n",
    "\n",
    "To account for clouds in the simulation process, we can associate a cloud coverage value to each target that represents the percentage of cloud coverage over that area. Cloud coverage can be randomly generated or derived from real data. Here, we have an example on how to use a stochastic cloud model using UniformTargets as a base and attach the following information to each target:\n",
    "\n",
    "* `cloud_cover_true` represents the true cloud coverage. Information from external sources, such as historical cloud data, can be used here based on each target's position.\n",
    "\n",
    "* `cloud_cover_forecast` represents the cloud coverage forecast. Forecast from external sources can be plugged in here.\n",
    "\n",
    "* `cloud_cover_sigma` represents the standard deviation of the cloud coverage forecast.\n",
    "\n",
    "* `belief` represents the probability that the target was successfully observed.\n",
    "\n",
    "* `prev_obs` time at which the last picture of the target was taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudTargets(UniformTargets):\n",
    "    mu_data = 0.6740208166434426  # Average global cloud coverage\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_targets: Union[int, tuple[int, int]],\n",
    "        priority_distribution: Optional[Callable] = None,\n",
    "        radius: float = orbitalMotion.REQ_EARTH * 1e3,\n",
    "        sigma_levels: tuple[float, float] = (0.01, 0.05),\n",
    "        reward_thresholds: Union[float, tuple[float, float]] = 0.95,\n",
    "        belief_init: tuple[float, float] = (0.0, 0.94),\n",
    "        prev_obs_init: tuple[float, float] = (0.0, 5700.0),\n",
    "    ) -> None:\n",
    "        super().__init__(n_targets, priority_distribution, radius)\n",
    "        self.reward_thresholds = reward_thresholds\n",
    "        self.sigma_levels = sigma_levels\n",
    "        self.belief_init = belief_init\n",
    "        self.prev_obs_init = prev_obs_init\n",
    "\n",
    "    def regenerate_targets(self) -> None:\n",
    "        super().regenerate_targets()\n",
    "        for target in self.targets:\n",
    "            # Initialize true cloud coverage\n",
    "            cloud_cover_true = np.random.uniform(\n",
    "                0.0, self.mu_data * 2\n",
    "            )  # Instead, true cloud coverage can be obtained by historical data based on the target's position\n",
    "            cloud_cover_true = np.clip(cloud_cover_true, 0.0, 1.0)\n",
    "            target.cloud_cover_true = cloud_cover_true\n",
    "\n",
    "            # Initialize cloud coverage forecast\n",
    "            target.cloud_cover_sigma = np.random.uniform(\n",
    "                self.sigma_levels[0], self.sigma_levels[1]\n",
    "            )\n",
    "            cloud_cover_forecast = np.random.normal(\n",
    "                target.cloud_cover_true, target.cloud_cover_sigma\n",
    "            )\n",
    "            target.cloud_cover_forecast = np.clip(cloud_cover_forecast, 0.0, 1.0)\n",
    "\n",
    "            # Set reward threshold\n",
    "            if isinstance(self.reward_thresholds, float):\n",
    "                target.reward_threshold = self.reward_thresholds\n",
    "            else:\n",
    "                target.reward_threshold = np.random.uniform(\n",
    "                    self.reward_thresholds[0], self.reward_thresholds[1]\n",
    "                )\n",
    "\n",
    "            # Initialize beliefs and previous observations\n",
    "            b_S1 = np.random.uniform(self.belief_init[0], self.belief_init[1])\n",
    "            b_S0 = 1 - b_S1\n",
    "            target.belief = np.array([b_S0, b_S1])\n",
    "            target.prev_obs = -np.random.uniform(\n",
    "                self.prev_obs_init[0], self.prev_obs_init[0]\n",
    "            )\n",
    "            target.belief_update_var = 0.0\n",
    "\n",
    "\n",
    "# Define the randomization interval for the number of targets\n",
    "n_targets = (1000, 10000)\n",
    "scenario = CloudTargets(n_targets=n_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a Rewarder Considering Cloud Coverage for the Single-picture Case\n",
    "\n",
    "When considering targets potentially covered by clouds, we can use a binary reward model where the reward is proportional to the target priority if the target's cloud coverage is below its `reward_threshold` (how much cloud coverage is acceptable). Therefore, we create a modified rewarder `CloudImageBinaryRewarder`; it has similar settings as the [UniqueImageReward](../api_reference/data/index.rst) class, but `cloud_covered` and `cloud_free` information is added. Additionally, the `calculate_reward` function is modified for the binary reward model. \n",
    "\n",
    "For this case, the reward function is given by\n",
    "\n",
    "$$\n",
    "R = \\begin{cases}\n",
    "\\rho_i & \\text{if } c_{p_i} \\leq c_{\\text{thr}_i} \\\\\n",
    "0 & \\text{otherwise.}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where $\\rho_i$ is priority, $c_{p_i}$ is the true cloud coverage, and $c_{\\text{thr}_i}$ is the `reward_threshold` for target $i$. For a case where the reward is linearly proportional to the cloud coverage, see [Cloud Environment](../examples/cloud_environment.rst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TYPE_CHECKING\n",
    "\n",
    "if TYPE_CHECKING:  # pragma: no cover\n",
    "    from bsk_rl.scene.targets import (\n",
    "        Target,\n",
    "    )\n",
    "\n",
    "\n",
    "class CloudImageBinaryData(UniqueImageData):\n",
    "    \"\"\"DataType for unique images of targets.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        imaged: Optional[set[\"Target\"]] = None,\n",
    "        duplicates: int = 0,\n",
    "        known: Optional[set[\"Target\"]] = None,\n",
    "        cloud_covered: Optional[set[\"Target\"]] = None,\n",
    "        cloud_free: Optional[set[\"Target\"]] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Construct unit of data to record unique images.\n",
    "\n",
    "        Keeps track of ``imaged`` targets, a count of ``duplicates`` (i.e. images that\n",
    "        were not rewarded due to the target already having been imaged), and all\n",
    "        ``known`` targets in the environment. It also keeps track of which targets are considered\n",
    "        ``cloud_covered`` and ``cloud_free`` based on the specified threshold.\n",
    "\n",
    "        Args:\n",
    "            imaged: Set of targets that are known to be imaged.\n",
    "            duplicates: Count of target imaging duplication.\n",
    "            known: Set of targets that are known to exist (imaged and unimaged).\n",
    "            cloud_covered: Set of imaged targets that are known to be cloud covered.\n",
    "            cloud_free: Set of imaged targets that are known to be cloud free.\n",
    "        \"\"\"\n",
    "        super().__init__(imaged=imaged, duplicates=duplicates, known=known)\n",
    "        if cloud_covered is None:\n",
    "            cloud_covered = set()\n",
    "        if cloud_free is None:\n",
    "            cloud_free = set()\n",
    "        self.cloud_covered = set(cloud_covered)\n",
    "        self.cloud_free = set(cloud_free)\n",
    "\n",
    "    def __add__(self, other: \"CloudImageBinaryData\") -> \"CloudImageBinaryData\":\n",
    "        \"\"\"Combine two units of data.\n",
    "\n",
    "        Args:\n",
    "            other: Another unit of data to combine with this one.\n",
    "\n",
    "        Returns:\n",
    "            Combined unit of data.\n",
    "        \"\"\"\n",
    "\n",
    "        imaged = self.imaged | other.imaged\n",
    "        duplicates = (\n",
    "            self.duplicates\n",
    "            + other.duplicates\n",
    "            + len(self.imaged)\n",
    "            + len(other.imaged)\n",
    "            - len(imaged)\n",
    "        )\n",
    "        known = self.known | other.known\n",
    "        cloud_covered = self.cloud_covered | other.cloud_covered\n",
    "        cloud_free = self.cloud_free | other.cloud_free\n",
    "\n",
    "        return self.__class__(\n",
    "            imaged=imaged,\n",
    "            duplicates=duplicates,\n",
    "            known=known,\n",
    "            cloud_covered=cloud_covered,\n",
    "            cloud_free=cloud_free,\n",
    "        )\n",
    "\n",
    "\n",
    "class CloudImageBinaryDataStore(UniqueImageStore):\n",
    "    \"\"\"DataStore for unique images of targets.\"\"\"\n",
    "\n",
    "    data_type = CloudImageBinaryData\n",
    "\n",
    "    def compare_log_states(\n",
    "        self, old_state: np.ndarray, new_state: np.ndarray\n",
    "    ) -> CloudImageBinaryData:\n",
    "        \"\"\"Check for an increase in logged data to identify new images.\n",
    "\n",
    "        Args:\n",
    "            old_state: older storedData from satellite storage unit\n",
    "            new_state: newer storedData from satellite storage unit\n",
    "\n",
    "        Returns:\n",
    "            list: Targets imaged at new_state that were unimaged at old_state\n",
    "        \"\"\"\n",
    "        data_increase = new_state - old_state\n",
    "        if data_increase <= 0:\n",
    "            return UniqueImageData()\n",
    "        else:\n",
    "            assert self.satellite.latest_target is not None\n",
    "            self.update_target_colors([self.satellite.latest_target])\n",
    "            cloud_coverage = self.satellite.latest_target.cloud_cover_true\n",
    "            cloud_threshold = self.satellite.latest_target.reward_threshold\n",
    "            if cloud_coverage > cloud_threshold:\n",
    "                cloud_covered = [self.satellite.latest_target]\n",
    "                cloud_free = []\n",
    "            else:\n",
    "                cloud_covered = []\n",
    "                cloud_free = [self.satellite.latest_target]\n",
    "            return CloudImageBinaryData(\n",
    "                imaged={self.satellite.latest_target},\n",
    "                cloud_covered=cloud_covered,\n",
    "                cloud_free=cloud_free,\n",
    "            )\n",
    "\n",
    "\n",
    "class CloudImageBinaryRewarder(UniqueImageReward):\n",
    "    \"\"\"DataManager for rewarding unique images.\"\"\"\n",
    "\n",
    "    data_store_type = CloudImageBinaryDataStore\n",
    "\n",
    "    def calculate_reward(\n",
    "        self, new_data_dict: dict[str, CloudImageBinaryData]\n",
    "    ) -> dict[str, float]:\n",
    "        \"\"\"Reward new each unique image once using self.reward_fn().\n",
    "\n",
    "        Args:\n",
    "            new_data_dict: Record of new images for each satellite\n",
    "\n",
    "        Returns:\n",
    "            reward: Cumulative reward across satellites for one step\n",
    "        \"\"\"\n",
    "        reward = {}\n",
    "        imaged_counts = {}\n",
    "        for new_data in new_data_dict.values():\n",
    "            for target in new_data.imaged:\n",
    "                if target not in imaged_counts:\n",
    "                    imaged_counts[target] = 0\n",
    "                imaged_counts[target] += 1\n",
    "\n",
    "        for sat_id, new_data in new_data_dict.items():\n",
    "            reward[sat_id] = 0.0\n",
    "            for target in new_data.cloud_free:\n",
    "                if target not in self.data.imaged:\n",
    "                    reward[sat_id] += (\n",
    "                        self.reward_fn(target.priority) / imaged_counts[target]\n",
    "                    )\n",
    "        return reward\n",
    "\n",
    "\n",
    "# Define the reward function as a function of the priority of the target and the cloud cover\n",
    "def reward_function_binary(priority):\n",
    "    return priority\n",
    "\n",
    "\n",
    "# Uncomment this line and comment the reward in the cell below to use the binary reward function\n",
    "# rewarder = CloudImageBinaryRewarder(reward_fn=reward_function_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a Rewarder Considering Cloud Coverage for the Re-imaging Case\n",
    "\n",
    "If the target is deemed occluded by clouds, it won't be tasked again in the single-picture case. However, the problem can be formulated in terms of the probability of observing the target ($\\text{P}(S=1)$, represented by the variable `belief` in the code) given the number of pictures and time difference between pictures ($\\delta t_i$). Thus, a new rewarder named `CloudImageProbabilityRewarder` is created to accommodate this new formulation, as well as a new reward function. \n",
    "\n",
    "The reward function accounts for the desired success probability threshold for each target ($\\theta_{\\text{thr}_i}$, represented by `reward_threshold` in the code) and has a tunable parameter $\\alpha\\in[0,1]$:\n",
    "\n",
    "$$\n",
    "R = \\begin{cases}\n",
    "\\rho_i\\alpha_i\\Delta \\text{P}(S=1) + \\rho_i(1 - \\alpha) & \\text{ if }  \\text{P}_i(S=1) \\geq \\theta_{\\text{thr}_i} \\\\\n",
    "\\rho_i\\alpha_i\\Delta \\text{P}(S=1) & \\text{ otherwise.}\n",
    "\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudImageProbabilityData(Data):\n",
    "    \"\"\"DataType for unique images of targets.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        imaged: Optional[list[\"Target\"]] = None,\n",
    "        imaged_complete: Optional[set[\"Target\"]] = None,\n",
    "        list_belief_update_var: Optional[list[float]] = None,\n",
    "        known: Optional[set[\"Target\"]] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Construct unit of data to record unique images.\n",
    "\n",
    "        Keeps track of ``imaged`` targets and completely imaged targets (those with a success probability\n",
    "        higher than the ``reward_threshold``).\n",
    "\n",
    "        Args:\n",
    "            imaged: List of targets that are known to be imaged.\n",
    "            imaged_complete: Set of targets that are known to be completely imaged (P(S=1) >= reward_threshold).\n",
    "            list_belief_update_var: List of belief update variations for each target after each picture.\n",
    "            known: List of targets that are known to exist (imaged and not imaged)\n",
    "        \"\"\"\n",
    "        if imaged is None:\n",
    "            imaged = []\n",
    "        if imaged_complete is None:\n",
    "            imaged_complete = set()\n",
    "        if list_belief_update_var is None:\n",
    "            list_belief_update_var = []\n",
    "        if known is None:\n",
    "            known = set()\n",
    "        self.known = set(known)\n",
    "\n",
    "        self.imaged = imaged\n",
    "        self.imaged_complete = imaged_complete\n",
    "        self.list_belief_update_var = list(list_belief_update_var)\n",
    "\n",
    "    def __add__(\n",
    "        self, other: \"CloudImageProbabilityData\"\n",
    "    ) -> \"CloudImageProbabilityData\":\n",
    "        \"\"\"Combine two units of data.\n",
    "\n",
    "        Args:\n",
    "            other: Another unit of data to combine with this one.\n",
    "\n",
    "        Returns:\n",
    "            Combined unit of data.\n",
    "        \"\"\"\n",
    "\n",
    "        imaged = self.imaged + other.imaged\n",
    "        imaged_complete = self.imaged_complete | other.imaged_complete\n",
    "        list_belief_update_var = (\n",
    "            self.list_belief_update_var + other.list_belief_update_var\n",
    "        )\n",
    "\n",
    "        known = self.known | other.known\n",
    "        return self.__class__(\n",
    "            imaged=imaged,\n",
    "            imaged_complete=imaged_complete,\n",
    "            list_belief_update_var=list_belief_update_var,\n",
    "            known=known,\n",
    "        )\n",
    "\n",
    "\n",
    "class CloudImageProbabilityDataStore(DataStore):\n",
    "    \"\"\"DataStore for unique images of targets.\"\"\"\n",
    "\n",
    "    data_type = CloudImageProbabilityData\n",
    "\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        \"\"\"DataStore for unique images.\n",
    "\n",
    "        Detects new images by watching for an increase in data in each target's corresponding\n",
    "        buffer.\n",
    "        \"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def get_log_state(self) -> np.ndarray:\n",
    "        \"\"\"Log the instantaneous storage unit state at the end of each step.\n",
    "\n",
    "        Returns:\n",
    "            array: storedData from satellite storage unit\n",
    "        \"\"\"\n",
    "        msg = self.satellite.dynamics.storageUnit.storageUnitDataOutMsg.read()\n",
    "        return msg.storedData[0]\n",
    "\n",
    "    def compare_log_states(\n",
    "        self, old_state: np.ndarray, new_state: np.ndarray\n",
    "    ) -> CloudImageProbabilityData:\n",
    "        \"\"\"Check for an increase in logged data to identify new images.\n",
    "\n",
    "        This method also performs the belief update (new probability of success) for each target\n",
    "        based on the cloud coverage forecast and the time difference between the current time and\n",
    "        the previous observation time. It also keeps track of the variation in the belief update.\n",
    "\n",
    "        Args:\n",
    "            old_state: older storedData from satellite storage unit\n",
    "            new_state: newer storedData from satellite storage unit\n",
    "\n",
    "        Returns:\n",
    "            list: Targets imaged at new_state that were unimaged at old_state\n",
    "        \"\"\"\n",
    "\n",
    "        data_increase = new_state - old_state\n",
    "        if data_increase <= 0:\n",
    "            return CloudImageProbabilityData()\n",
    "        else:\n",
    "            assert self.satellite.latest_target is not None\n",
    "            # return UniqueImageData(imaged={self.satellite.latest_target})\n",
    "\n",
    "            target = self.satellite.latest_target\n",
    "            current_sim_time = self.satellite.simulator.sim_time\n",
    "            belief_update_func = self.satellite.belief_update_func\n",
    "\n",
    "            target_prev_obs = (\n",
    "                target.prev_obs\n",
    "            )  # Time at which the target was previously observed\n",
    "            target_time_diff = (\n",
    "                current_sim_time - target_prev_obs\n",
    "            )  # Time difference between the current time and the previous observation time\n",
    "            target_belief = (\n",
    "                target.belief\n",
    "            )  # Belief of the target before the current picture\n",
    "\n",
    "            target_cloud_cover_forecast = target.cloud_cover_forecast\n",
    "            updated_belief = belief_update_func(\n",
    "                target_belief, target_cloud_cover_forecast, target_time_diff\n",
    "            )\n",
    "\n",
    "            target.belief = updated_belief  # Update the belief of the target\n",
    "            target.belief_update_var = updated_belief[1] - target_belief[1]\n",
    "            target.prev_obs = current_sim_time  # Update the previous observation time\n",
    "\n",
    "            if updated_belief[1] > target.reward_threshold:\n",
    "                list_imaged_complete = [target]\n",
    "            else:\n",
    "                list_imaged_complete = []\n",
    "            list_belief_update_var = target.belief_update_var\n",
    "\n",
    "            return CloudImageProbabilityData(\n",
    "                imaged=[target],\n",
    "                imaged_complete=set(list_imaged_complete),\n",
    "                list_belief_update_var=[list_belief_update_var],\n",
    "            )\n",
    "\n",
    "\n",
    "class CloudImageProbabilityRewarder(GlobalReward):\n",
    "    data_store_type = CloudImageProbabilityDataStore\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        reward_fn: Callable,\n",
    "        alpha: float = 0.5,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "\n",
    "        Modifies the constructor to include the alpha parameter to tune the reward function and\n",
    "        the reward function.\n",
    "        Args:\n",
    "            reward_fn: Reward as function of priority, targets belief, and alpha.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.reward_fn = reward_fn\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def initial_data(self, satellite: \"sats.Satellite\") -> \"UniqueImageData\":\n",
    "        \"\"\"Furnish data to the scenario.\n",
    "\n",
    "        Currently, it is assumed that all targets are known a priori, so the initial data\n",
    "        given to the data store is the list of all targets.\n",
    "        \"\"\"\n",
    "        return self.data_type(known=self.scenario.targets)\n",
    "\n",
    "    def calculate_reward(\n",
    "        self, new_data_dict: dict[str, CloudImageProbabilityData]\n",
    "    ) -> dict[str, float]:\n",
    "        \"\"\"Reward new each unique image once using self.reward_fn().\n",
    "\n",
    "        Args:\n",
    "            new_data_dict: Record of new images for each satellite\n",
    "\n",
    "        Returns:\n",
    "            reward: Cumulative reward across satellites for one step\n",
    "        \"\"\"\n",
    "\n",
    "        reward = {}\n",
    "\n",
    "        for sat_id, new_data in new_data_dict.items():\n",
    "            reward[sat_id] = 0.0\n",
    "            for target, belief_variation in zip(\n",
    "                new_data.imaged, new_data.list_belief_update_var\n",
    "            ):\n",
    "                reward[sat_id] += self.reward_fn(\n",
    "                    target.priority, belief_variation, self.alpha, reach_threshold=False\n",
    "                )\n",
    "            for target in new_data.imaged_complete:\n",
    "                reward[sat_id] += self.reward_fn(\n",
    "                    target.priority, None, self.alpha, reach_threshold=True\n",
    "                )\n",
    "        return reward\n",
    "\n",
    "\n",
    "# Define the reward function as a function of the priority of the target, the cloud cover, and the number of times the target has been imaged\n",
    "def reward_function_probability(\n",
    "    priority: float, belief_variation: float, alpha: float, reach_threshold: bool\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "\n",
    "    Rewards based on the priority of the target, the belief variation, and the alpha parameter.\n",
    "\n",
    "    Args:\n",
    "        priority: Priority of the target.\n",
    "        belief_variation: Variation in the belief of the target after the picture.\n",
    "        alpha: Tuning parameter between 0 and 1.\n",
    "        reach_threshold: Boolean indicating whether the target has reached the reward threshold.\n",
    "\n",
    "    Returns:\n",
    "        float: Reward for the target.\n",
    "    \"\"\"\n",
    "    if reach_threshold:\n",
    "        return priority * (1 - alpha)\n",
    "    else:\n",
    "        return priority * belief_variation * alpha\n",
    "\n",
    "\n",
    "rewarder = CloudImageProbabilityRewarder(\n",
    "    reward_fn=reward_function_probability, alpha=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CloudImageProbabilityDataStore` requires a function `belief_update_func` that returns the updated success probability for target $i$ ($\\text{P}^{(k+1)}_i(S=1)$) given its current success probability ($\\text{P}^{(k)}_i(S=1)$), cloud coverage forecast ($c_{f_i}$), and the time different between the current and previous image ($\\delta t_i$).\n",
    "\n",
    "The update in the success probability is given by:\n",
    "\n",
    "$$\n",
    "\\text{P}^{(k+1)}(S=1) = 1 - \\text{P}^{(k)}(S=1)\\bar{c}_{f_i}\n",
    "$$\n",
    "\n",
    "To penalize two consecutive pictures without enough elapsed time (and not enough shift in clouds' position), a new cloud-free probability variable $g_{f_i}$ is introduced such that\n",
    "\n",
    "$$\n",
    "g^{(k)}_{f_i} = (1-c^{(k)}_{f_i})\\beta(\\delta t_i)\n",
    "$$\n",
    "\n",
    "where $\\beta$ is given by a sigmoid\n",
    "\n",
    "$$\n",
    "\\beta(\\delta t) = \\frac{1}{\\eta_3+e^{-\\eta_1(\\frac{\\delta t}{\\tau}-\\eta_2)}}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\bar{c}_{f_i} = 1 - g_{f_i}^{(k)}\n",
    "$$\n",
    "\n",
    "leading to:\n",
    "\n",
    "$$\n",
    "\\text{P}^{(k+1)}(S=1) = \\text{P}^{(k)}(S=1) + (1-\\text{P}^{(k)}(S=1))(1-c^{(k)}_{f_i})\\beta(\\delta t_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_variation(\n",
    "    delta_t: float, t_const: float, k_1: float = 2.5, k_2: float = 2.5, k_3: float = 1.0\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Time variation function based on sigmoid function.\n",
    "\n",
    "    Args:\n",
    "        delta_t (float): Time difference between the current time and the previous observation time.\n",
    "        t_const (float): Time constant for the sigmoid function.\n",
    "        k_1 (float): Sigmoid function parameter.\n",
    "        k_2 (float): Sigmoid function parameter.\n",
    "        k_3 (float): Sigmoid function parameter.\n",
    "\n",
    "    Returns:\n",
    "        float: Time variation value.\n",
    "    \"\"\"\n",
    "    if delta_t <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 / (k_3 + np.exp(-k_1 * (delta_t / t_const - k_2)))\n",
    "\n",
    "\n",
    "def belief_update(\n",
    "    b: list[float], cloud_cover_forecast: float, delta_t: float, t_const: float\n",
    ") -> np.array:\n",
    "    \"\"\"\n",
    "    Update the belief based on the cloud forecast and the time variation.\n",
    "\n",
    "    Args:\n",
    "        b (np.array): Belief array (b(S=0), b(S=1)).\n",
    "        cloud_forecast (float): Cloud coverage forecast.\n",
    "        delta_t (float): Time difference between the current time and the previous observation time.\n",
    "        t_const (float): Time constant for the sigmoid function.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Updated belief array\n",
    "    \"\"\"\n",
    "\n",
    "    cloud_time_variation = time_variation(delta_t, t_const)\n",
    "    cloud_free = (1 - cloud_cover_forecast) * cloud_time_variation\n",
    "    cloud_cover_bar = 1 - cloud_free\n",
    "    b_0 = b[0] * cloud_cover_bar\n",
    "    b_1 = 1 - b_0\n",
    "    return np.array([b_0, b_1])\n",
    "\n",
    "\n",
    "def belief_update_func(\n",
    "    b: list[float], cloud_cover_forecast: float, delta_t: float\n",
    ") -> np.array:\n",
    "    \"\"\"\n",
    "    Belief update function for the satellite.\n",
    "\n",
    "    Args:\n",
    "        b (np.array): Belief array (b(S=0), b(S=1)).\n",
    "        cloud_forecast (float): Cloud coverage forecast.\n",
    "        delta_t (float): Time difference between the current time and the previous observation time.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Updated belief array\n",
    "    \"\"\"\n",
    "    time_constant = 30 * 60 / 5  # 30 minutes\n",
    "    return belief_update(b, cloud_cover_forecast, delta_t, time_constant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the Satellite to Have Access to Cloud Information\n",
    "\n",
    "The satellite has observations and actions associated with it that are relevant to the decision-making process. The observation space can be modified to include information about the targets and the weather (cloud coverage forecast, reward threshold, success probability, etc) which allows better informed decision-making.\n",
    "\n",
    "* [Observations](../api_reference/obs/index.rst): \n",
    "    - SatProperties: Body angular velocity, instrument pointing direction, body position, body velocity, battery charge (properties in [flight software model](../api_reference/sim/fsw/index.rst) or [dynamics model](../api_reference/sim/dyn/index.rst)). Also, customized dynamics property in CustomDynModel below: Angle between the sun and the solar panel.\n",
    "    - OpportunityProperties: Target's priority, cloud coverage forecast, standard deviation of cloud coverage forecast, probability of being successfully imaged, and last time it was imaged (upcoming 32 targets). \n",
    "    - Time: Simulation time.\n",
    "    - Eclipse: Next eclipse start and end times. \n",
    "* [Actions](../api_reference/act/index.rst):\n",
    "    - Charge: Enter a sun-pointing charging mode for 60 seconds.\n",
    "    - Image: Image target from upcoming 32 targets\n",
    "* [Dynamics model](../api_reference/sim/dyn/index.rst): FullFeaturedDynModel is used and a property, angle between sun and solar panel, is added.\n",
    "* [Flight software model](../api_reference/sim/fsw/index.rst): SteeringImagerFSWModel is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSatComposed(sats.ImagingSatellite):\n",
    "    observation_spec = [\n",
    "        obs.SatProperties(\n",
    "            dict(prop=\"omega_BP_P\", norm=0.03),\n",
    "            dict(prop=\"c_hat_P\"),\n",
    "            dict(prop=\"r_BN_P\", norm=orbitalMotion.REQ_EARTH * 1e3),\n",
    "            dict(prop=\"v_BN_P\", norm=7616.5),\n",
    "            dict(prop=\"battery_charge_fraction\"),\n",
    "            dict(prop=\"solar_angle_norm\"),\n",
    "        ),\n",
    "        obs.Eclipse(),\n",
    "        obs.OpportunityProperties(\n",
    "            dict(prop=\"priority\"),\n",
    "            dict(\n",
    "                fn=lambda sat, opp: opp[\"object\"].cloud_cover_forecast\n",
    "            ),  # Cloud coverage forecast (percentage of the area covered by clouds)\n",
    "            dict(\n",
    "                fn=lambda sat, opp: opp[\"object\"].cloud_cover_sigma\n",
    "            ),  # Confidence on the cloud coverage forecast\n",
    "            # dict(fn=lambda sat, opp: opp[\"object\"].reward_threshold),   #Reward threshold for each target. Uncomment if using variable threshold\n",
    "            dict(\n",
    "                fn=lambda sat, opp: opp[\"object\"].belief[1]\n",
    "            ),  # Probability of successfully imaging the target. Used only in the re-imaging case\n",
    "            dict(\n",
    "                fn=lambda sat, opp: opp[\"object\"].prev_obs, norm=5700\n",
    "            ),  # Previous observation time. Used only in the re-imaging case\n",
    "            type=\"target\",\n",
    "            n_ahead_observe=32,\n",
    "        ),\n",
    "        obs.Time(),\n",
    "    ]\n",
    "\n",
    "    action_spec = [\n",
    "        act.Charge(duration=60.0),\n",
    "        act.Image(n_ahead_image=32),\n",
    "    ]\n",
    "\n",
    "    # Modified the constructor to include the belief update function\n",
    "    def __init__(self, *args, belief_update_func=None, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.belief_update_func = belief_update_func\n",
    "\n",
    "    class CustomDynModel(dyn.FullFeaturedDynModel):\n",
    "        @property\n",
    "        def solar_angle_norm(self) -> float:\n",
    "            sun_vec_N = (\n",
    "                self.world.gravFactory.spiceObject.planetStateOutMsgs[\n",
    "                    self.world.sun_index\n",
    "                ]\n",
    "                .read()\n",
    "                .PositionVector\n",
    "            )\n",
    "            sun_vec_N_hat = sun_vec_N / np.linalg.norm(sun_vec_N)\n",
    "            solar_panel_vec_B = np.array([0, 0, -1])  # Not default configuration\n",
    "            mat = np.transpose(self.BN)\n",
    "            solar_panel_vec_N = np.matmul(mat, solar_panel_vec_B)\n",
    "            error_angle = np.arccos(np.dot(solar_panel_vec_N, sun_vec_N_hat))\n",
    "\n",
    "            return error_angle / np.pi\n",
    "\n",
    "    dyn_type = CustomDynModel\n",
    "    fsw_type = fsw.SteeringImagerFSWModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is necessary to add a filter to remove targets that reached the success threshold from the targets list when re-imaging is allowed such that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def belief_threshold_filter(opportunity):\n",
    "    if opportunity[\"type\"] == \"target\":\n",
    "        return (\n",
    "            True\n",
    "            if opportunity[\"object\"].belief[1] < opportunity[\"object\"].reward_threshold\n",
    "            else False\n",
    "        )\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When instantiating a satellite, these parameters can be overriden with a constant or \n",
    "rerandomized every time the environment is reset using the ``sat_args`` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataStorageCapacity = 20 * 8e6 * 100\n",
    "sat_args = CustomSatComposed.default_sat_args(\n",
    "    imageAttErrorRequirement=0.01,\n",
    "    imageRateErrorRequirement=0.01,\n",
    "    batteryStorageCapacity=80.0 * 3600 * 2,\n",
    "    storedCharge_Init=lambda: np.random.uniform(0.4, 1.0) * 80.0 * 3600 * 2,\n",
    "    u_max=0.2,\n",
    "    K1=0.5,\n",
    "    nHat_B=np.array([0, 0, -1]),\n",
    "    imageTargetMinimumElevation=np.radians(45),\n",
    "    rwBasePower=20,\n",
    "    maxWheelSpeed=1500,\n",
    "    storageInit=lambda: np.random.randint(\n",
    "        0 * dataStorageCapacity,\n",
    "        0.01 * dataStorageCapacity,\n",
    "    ),  # Initialize storage use close to zero\n",
    "    wheelSpeeds=lambda: np.random.uniform(\n",
    "        -1, 1, 3\n",
    "    ),  # Initialize reaction wheel speeds close to zero\n",
    "    dataStorageCapacity=dataStorageCapacity,  # Large storage to avoid filling up in three orbits\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing and Interacting with the Environment\n",
    "For this example, we will be using the multi-agent [ConstellationTasking](../api_reference/index.rst) \n",
    "environment. Along with passing the satellite that we configured, the environment takes\n",
    "a [scenario](../api_reference/scene/index.rst), which defines the environment the\n",
    "satellite is acting in, and a [rewarder](../api_reference/data/index.rst), which defines\n",
    "how data collected from the scenario is rewarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bsk_rl.utils.orbital import walker_delta_args\n",
    "\n",
    "sat_arg_randomizer = walker_delta_args(\n",
    "    altitude=500.0, n_planes=1, inc=45, clustersize=5, clusterspacing=72\n",
    ")\n",
    "\n",
    "satellites = [\n",
    "    CustomSatComposed(f\"EO-{i}\", sat_args, belief_update_func=belief_update_func)\n",
    "    for i in range(5)\n",
    "]\n",
    "\n",
    "# Add filter to satellites to remove targets that have already reached the belief threshold\n",
    "for sat in satellites:\n",
    "    sat.add_access_filter(belief_threshold_filter)\n",
    "\n",
    "env = ConstellationTasking(\n",
    "    satellites=satellites,\n",
    "    world_type=world.GroundStationWorldModel,\n",
    "    world_args=world.GroundStationWorldModel.default_world_args(),\n",
    "    scenario=scenario,\n",
    "    rewarder=rewarder,\n",
    "    sat_arg_randomizer=sat_arg_randomizer,\n",
    "    sim_rate=0.5,\n",
    "    max_step_duration=300.0,\n",
    "    time_limit=95 * 60 / 2,  # half orbit\n",
    "    log_level=\"INFO\",\n",
    "    failure_penalty=0.0,\n",
    "    # disable_env_checker=True,  # For debugging\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, reset the environment. It is possible to specify the seed when resetting the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation, info = env.reset(seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to print out the actions and observations. The composed satellite [action_description](../api_reference/sats/index.rst) returns a human-readable action map each satellite has the same action space and similar observation space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Actions:\", env.satellites[0].action_description, \"\\n\")\n",
    "print(\"States:\", env.unwrapped.satellites[0].observation_description, \"\\n\")\n",
    "\n",
    "# Using the composed satellite features also provides a human-readable state:\n",
    "for satellite in env.unwrapped.satellites:\n",
    "    for k, v in satellite.observation_builder.obs_dict().items():\n",
    "        print(f\"{k}:  {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, run the simulation until timeout or agent failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "while True:\n",
    "    if count == 0:\n",
    "        # Vector with an action for each satellite (we can pass different actions for each satellite)\n",
    "        # Tasking all satellites to charge (tasking None as the first action will raise a warning)\n",
    "        action_dict = {sat_i.name: 0 for sat_i in env.satellites}\n",
    "    else:\n",
    "        # Tasking random actions\n",
    "        action_dict = {sat_i.name: np.random.randint(0, 32) for sat_i in env.satellites}\n",
    "    count += 1\n",
    "\n",
    "    observation, reward, terminated, truncated, info = env.step(action_dict)\n",
    "\n",
    "    if all(terminated.values()) or all(truncated.values()):\n",
    "        print(\"Episode complete.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the running the simulation, we can check the reward, number of imaged targets that were covered by clouds and that were not covered by clouds (according to the threshold set in the rewarder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total reward:\", env.unwrapped.rewarder.cum_reward)\n",
    "print(\"Number of total images taken:\", len(env.unwrapped.rewarder.data.imaged))\n",
    "print(\n",
    "    \"Number of imaged targets (once or more):\",\n",
    "    len(set(env.unwrapped.rewarder.data.imaged)),\n",
    ")\n",
    "print(\n",
    "    \"Number of re-images:\",\n",
    "    len(env.unwrapped.rewarder.data.imaged)\n",
    "    - len(set(env.unwrapped.rewarder.data.imaged)),\n",
    ")\n",
    "print(\n",
    "    \"Number of completely imaged targets:\",\n",
    "    len(env.unwrapped.rewarder.data.imaged_complete),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check [Training with RLlib PPO](../examples/rllib_training.ipynb) for an example on how to train the agent in this environment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_update_cloud_env_JAIS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
