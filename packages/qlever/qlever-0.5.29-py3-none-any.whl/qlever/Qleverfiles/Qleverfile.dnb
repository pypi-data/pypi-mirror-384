# Qleverfile for Olympics, use with https://github.com/ad-freiburg/qlever-control
#
# qlever get-data  # takes ~ 10 mins to download .nt.gz file of size ~ 8 GB
# qlever index     # takes ~ 5 min and ~ 5 GB RAM (on an AMD Ryzen 9 5900X)
# qlever start     # starts the server (instantaneous)
#
# IMPORTANT: The current files contain invalid floating point literals. To make
# QLever ignore them, compile QLever with `invalidLiteralsAreSkipped_ = true`
# in `src/parser/TurtleParserBase.h:55`.
#
# NOTE: https://data.dnb.de/opendata/ is rather confusing becase of the many
# files. This Qleverfile downloads all the datasets named "Gesamtabzug", except
# bib_lds.nt.gz, which contains incorrectly formatted IRIs. The file
# dnb-all_ldsprov.nt.gz contains invalid floating point literals; to ignore
# them, compile QLever with TurtleParserBase::invalidLiteralsAreSkipped_ = true

[data]
NAME              = dnb
BASE_URL          = https://data.dnb.de/opendata
GET_DATA_CMD      = curl -L -C - --remote-name-all --remote-time ${BASE_URL}/authorities-gnd_lds.nt.gz ${BASE_URL}/dnb-all_lds.nt.gz ${BASE_URL}/dnb-all_ldsprov.nt.gz ${BASE_URL}/zdb_lds.nt.gz 2>&1 | tee ${data:NAME}.getdata-log.txt
VERSION           = $$(date -r dnb-all_lds.nt.gz +%d.%m.%Y || echo "NO_DATE")
DESCRIPTION       = DNB data from ${BASE_URL} (authoritities-gnd_lds, dnb_all_lds, dnb-all_ldsprov, zdb_lds), version ${VERSION}

[index]
INPUT_FILES     = *.nt.gz
CAT_INPUT_FILES = zcat ${INPUT_FILES} | sed '/"\$$R0"/d;/"0\.03013\$$D"/d'
SETTINGS_JSON   = { "ascii-prefixes-only": false, "num-triples-per-batch": 1000000 }

[server]
PORT               = 7035
ACCESS_TOKEN       = ${data:NAME}
MEMORY_FOR_QUERIES = 5G
CACHE_MAX_SIZE     = 2G

[runtime]
SYSTEM = docker
IMAGE  = docker.io/adfreiburg/qlever:latest

[ui]
UI_CONFIG = dnb
