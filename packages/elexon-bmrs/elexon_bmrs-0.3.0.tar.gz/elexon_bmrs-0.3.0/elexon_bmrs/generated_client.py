"""
Auto-generated BMRS API client methods with typed Pydantic model returns.

This file is automatically generated from the OpenAPI specification.
Do not edit manually - changes will be overwritten.

All methods return properly typed Pydantic models for type safety and IDE autocomplete.
"""

from typing import Any, Dict, List, Optional, Union
from datetime import date, datetime

# Import all generated models
from elexon_bmrs.generated_models import *

# Import manually created models for endpoints with empty OpenAPI schemas
from elexon_bmrs.untyped_models import (
    HealthCheckResponse,
    CDNResponse,
    DemandResponse,
    InitialDemandOutturn,
    DemandSummaryItem,
    RollingSystemDemandResponse,
    DemandTotalActualResponse,
    GenerationCurrentItem,
    HalfHourlyInterconnectorResponse,
)


class GeneratedBMRSMethods:
    """
    Auto-generated methods for the BMRS API with typed returns.
    
    All methods return Pydantic models instead of Dict[str, Any] for:
    - Type safety
    - IDE autocomplete
    - Validation
    - Better developer experience
    """

    def get_balancing_dynamic(
        self,
        bmUnit: str,
        snapshotAt: str,
        until: Optional[str] = None,
        snapshotAtSettlementPeriod: Optional[int] = None,
        untilSettlementPeriod: Optional[int] = None,
        dataset: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> DynamicData_ResponseWithMetadata:
        """
        Dynamic data per BMU (SEL, SIL, MZT, MNZT, MDV, MDP, NTB, NTO, NDZ)

        This endpoint provides the dynamic data for a requested BMU, excluding physical rate data.
It returns a "snapshot" of data valid at a given time, and optionally a time series of changes over a requested interval.
            
By default, all of the relevant datasets are returned: SIL, SEL, NDZ, NTB, NTO, MZT, MNZT, MDV, MDP.
The results from each dataset are transformed to a common response model, with the common integer field *Value*
mapped from the fields *Level*, *Period*, *Volume* or *Notice* in the original dataset, as relevant.

        Args:
            bmUnit: The BM Unit to query.
            snapshotAt: When to retrieve a snapshot of data at.
That is, the latest datapoint before this time will be returned for each dataset.
            until: When to retrieve data until.
Data from the snapshot until this time will be returned., optional
            snapshotAtSettlementPeriod: The settlement period to retrieve a snapshot of data at.
If provided, the time part of SnapshotAt will be ignored., optional
            untilSettlementPeriod: The settlement period to retrieve data until.
If provided, the time part of Until will be ignored., optional
            dataset: Datasets to filter. If omitted, all datasets will be returned., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DynamicData_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["bmUnit"] = bmUnit
        params["snapshotAt"] = snapshotAt
        if until is not None:
            params["until"] = until
        if snapshotAtSettlementPeriod is not None:
            params["snapshotAtSettlementPeriod"] = snapshotAtSettlementPeriod
        if untilSettlementPeriod is not None:
            params["untilSettlementPeriod"] = untilSettlementPeriod
        if dataset is not None:
            params["dataset"] = dataset
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/dynamic", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DynamicData_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DynamicData_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_balancing_dynamic_all(
        self,
        settlementDate: str,
        settlementPeriod: int,
        bmUnit: Optional[List[str]] = None,
        dataset: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> DynamicData_ResponseWithMetadata:
        """
        Market-wide dynamic data (SEL, SIL, MZT, MNZT, MDV, MDP, NTB, NTO, NDZ)

        This endpoint provides the dynamic data for multiple requested BMUs or all BMUs, excluding dynamic rate data.
It returns the data valid for a single settlement period. This includes a snapshot of data valid at the start
of the settlement period, and any changes published during that settlement period.
            
By default, all of the relevant datasets are returned: SIL, SEL, NDZ, NTB, NTO, MZT, MNZT, MDV & MDP.
The results from each dataset are transformed to a common response model, with the common integer field *Value*
mapped from the fields *Level*, *Period*, *Volume* or *Notice* in the original dataset, as relevant.
            
The settlement period must be specified as a date and settlement period. The date parameter must be provided in the exact format yyyy-MM-dd.

        Args:
            settlementDate: The settlement date or datetime to filter.
            settlementPeriod: The settlement period to filter. This should be an integer from 1-50 inclusive.
            bmUnit: The BM Units to query. Elexon or NGC BMU IDs can be used. If omitted, results for all BM units will be returned., optional
            dataset: Datasets to filter. If omitted, all datasets will be returned., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DynamicData_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["settlementDate"] = settlementDate
        params["settlementPeriod"] = settlementPeriod
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if dataset is not None:
            params["dataset"] = dataset
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/dynamic/all", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DynamicData_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DynamicData_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_balancing_dynamic_rates(
        self,
        bmUnit: str,
        snapshotAt: str,
        until: Optional[str] = None,
        snapshotAtSettlementPeriod: Optional[int] = None,
        untilSettlementPeriod: Optional[int] = None,
        dataset: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> RateData_ResponseWithMetadata:
        """
        Rate data per BMU (RDRE, RURE, RDRI, RURI)

        This endpoint provides the physical rate data for a requested BMU.
It returns a "snapshot" of data valid at a given time, and optionally a time series of changes over a requested interval.
            
By default, all of the relevant datasets are returned: RDRE, RURE, RDRI, RURI.

        Args:
            bmUnit: The BM Unit to query.
            snapshotAt: When to retrieve a snapshot of data at.
That is, the latest datapoint before this time will be returned for each dataset.
            until: When to retrieve data until.
Data from the snapshot until this time will be returned., optional
            snapshotAtSettlementPeriod: The settlement period to retrieve a snapshot of data at.
If provided, the time part of SnapshotAt will be ignored., optional
            untilSettlementPeriod: The settlement period to retrieve data until.
If provided, the time part of Until will be ignored., optional
            dataset: Datasets to filter. If empty, all datasets will be returned., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            RateData_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["bmUnit"] = bmUnit
        params["snapshotAt"] = snapshotAt
        if until is not None:
            params["until"] = until
        if snapshotAtSettlementPeriod is not None:
            params["snapshotAtSettlementPeriod"] = snapshotAtSettlementPeriod
        if untilSettlementPeriod is not None:
            params["untilSettlementPeriod"] = untilSettlementPeriod
        if dataset is not None:
            params["dataset"] = dataset
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/dynamic/rates", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return RateData_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as RateData_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_balancing_dynamic_rates_all(
        self,
        settlementDate: str,
        settlementPeriod: int,
        bmUnit: Optional[List[str]] = None,
        dataset: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> RateData_ResponseWithMetadata:
        """
        Market-wide rate data (RDRE, RURE, RDRI, RURI)

        This endpoint provides market-wide physical rate data, for all BMUs or a requested set of multiple BMUs.
It returns the data valid for a given settlement period. This includes a snapshot of data valid at the start
of the settlement period, and any changes published during that settlement period.
            
The settlement period to query can be specified as a date and settlement period. The settlement date must be provided in the format yyyy-MM-dd.

By default, all of the relevant datasets are returned: RDRE, RURE, RDRI, RURI.

        Args:
            settlementDate: The settlement date to filter.
            settlementPeriod: The settlement period to filter. This should be an integer from 1-50 inclusive.
            bmUnit: The BM Units to query. Elexon or NGC BMU IDs can be used. If omitted, results for all BM units will be returned., optional
            dataset: Datasets to return. If omitted, all datasets will be returned., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            RateData_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["settlementDate"] = settlementDate
        params["settlementPeriod"] = settlementPeriod
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if dataset is not None:
            params["dataset"] = dataset
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/dynamic/rates/all", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return RateData_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as RateData_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_balancing_physical(
        self,
        bmUnit: str,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        dataset: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> PhysicalData_ResponseWithMetadata:
        """
        Physical data per BMU (PN, QPN, MILS, MELS)

        This endpoint provides the physical data for a requested BMU.
It returns the data valid over a given time range.
            
By default, all of the relevant datasets are returned: PN, QPN, MILS, & MELS.
The results from each dataset are transformed to a common response model, with fields not present in all 4 datasets dropped.
            
By default, the from and to parameters filter the data by start time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of start time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /balancing/physical?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /balancing/physical?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /balancing/physical?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /balancing/physical?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            bmUnit: The BM Unit to query.
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            dataset: Datasets to filter. If empty, all datasets will be returned., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            PhysicalData_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["bmUnit"] = bmUnit
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if dataset is not None:
            params["dataset"] = dataset
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/physical", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return PhysicalData_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as PhysicalData_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_balancing_physical_all(
        self,
        dataset: str,
        settlementDate: str,
        settlementPeriod: int,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> PhysicalData_ResponseWithMetadata:
        """
        Market-wide physical data (PN, QPN, MILS, MELS)

        This endpoint provides the physical data for multiple requested BMUs or all BMUs.
It returns the data valid for a single settlement period.
            
Only one dataset can be queried at a time: PN, QPN, MILS, or MELS.
The results from each dataset are transformed to a common response model, with fields not present in all 4 datasets dropped.
            
The settlement period to query must be specified as a date and settlement period. The date must be given in the format yyyy-MM-dd.

        Args:
            dataset: Dataset to query.
            settlementDate: The settlement date for the filter.
            settlementPeriod: The settlement period for the filter. This should be an integer from 1-50 inclusive.
            bmUnit: The BM Units to query. Elexon or NGC BMU IDs can be used. If omitted, results for all BM units will be returned., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            PhysicalData_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["dataset"] = dataset
        params["settlementDate"] = settlementDate
        params["settlementPeriod"] = settlementPeriod
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/physical/all", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return PhysicalData_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as PhysicalData_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_balancing_nonbm_disbsad_summary(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        format: Optional[str] = None
    ) -> DisaggregatedBalancingServicesAdjustmentSummaryResponse_ResponseWithMetadata:
        """
        Disaggregated balancing services adjustment time series (DISBSAD)

        This endpoint provides disaggregated balancing services adjustment data batched by settlement period. Each
batch in the time series contains a summary of all records for that settlement period, detailing the number of
buy and sell actions, price information and volume information.

By default, the from and to parameters filter the data by start time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of start time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /balancing/nonbm/disbsad/summary?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /balancing/nonbm/disbsad/summary?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /balancing/nonbm/disbsad/summary?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /balancing/nonbm/disbsad/summary?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DisaggregatedBalancingServicesAdjustmentSummaryResponse_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/nonbm/disbsad/summary", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DisaggregatedBalancingServicesAdjustmentSummaryResponse_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DisaggregatedBalancingServicesAdjustmentSummaryResponse_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_balancing_nonbm_disbsad_details(
        self,
        settlementDate: str,
        settlementPeriod: int,
        format: Optional[str] = None
    ) -> DisaggregatedBalancingServicesAdjustmentDetailsResponse_ResponseWithMetadata:
        """
        Disaggregated balancing services adjustment per settlement period (DISBSAD)

        This endpoint provides disaggregated balancing services adjustment data for a single settlement period. The
response includes all the buying and selling actions that occurred during that settlement period.
            
Date parameter must be provided in the exact format yyyy-MM-dd.

        Args:
            settlementDate: The settlement date to query.
            settlementPeriod: The settlement period to query. This should be an integer from 1-50 inclusive.
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DisaggregatedBalancingServicesAdjustmentDetailsResponse_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["settlementDate"] = settlementDate
        params["settlementPeriod"] = settlementPeriod
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/nonbm/disbsad/details", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DisaggregatedBalancingServicesAdjustmentDetailsResponse_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DisaggregatedBalancingServicesAdjustmentDetailsResponse_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_balancing_nonbm_netbsad(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        includeZero: Optional[bool] = None,
        format: Optional[str] = None
    ) -> NetBalancingServicesAdjustmentResponse_ResponseWithMetadata:
        """
        Net balancing services adjustment time series (NETBSAD)

        This endpoint provides data about the Net Balancing Services Adjustment (NETBSAD). Each
entry in the time series contains the NETBSAD values for that settlement period.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /balancing/nonbm/netbsad?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /balancing/nonbm/netbsad?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /balancing/nonbm/netbsad?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /balancing/nonbm/netbsad?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            includeZero: Include data points with a generation of zero., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            NetBalancingServicesAdjustmentResponse_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if includeZero is not None:
            params["includeZero"] = includeZero
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/nonbm/netbsad", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return NetBalancingServicesAdjustmentResponse_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as NetBalancingServicesAdjustmentResponse_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_balancing_nonbm_netbsad_events(
        self,
        count: int,
        before: Optional[str] = None,
        settlementPeriodBefore: Optional[int] = None,
        format: Optional[str] = None
    ) -> NetBalancingServicesAdjustmentResponse_ResponseWithMetadata:
        """
        Net balancing services adjustment events (NETBSAD)

        This endpoint provides data about the start of NGESO Net Balancing Services Adjustment (NETBSAD) events.
An event is a point in time where one of the NETBSAD values has changed from 0 to a value.
Each event details the start time of the event and the NETBSAD values associated with the start of the event.
            
By default, the before parameter filters the data by start time. If the settlementPeriodBefore parameter is
provided, the before parameter instead filters on settlement date, allowing for searching by start time or
settlement date & settlement period.
Note: When filtering via settlement date, before is treated as a Date only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering latest 3 events:
            
    /balancing/nonbm/netbsad/events?count=3
            
Filtering latest 3 events before start time:
            
    /balancing/nonbm/netbsad/events?before=2022-08-01T00:00Z&count=3
            
Filtering latest 3 events before settlement date and settlement period:
            
    /balancing/nonbm/netbsad/events?before=2022-08-01T00:00Z&settlementPeriodBefore=48&count=3

        Args:
            count: The number of events to return.
            before: If specified, filters events to those with a start time before or at the date, or a settlement date before the date if
settlementPeriodBefore is also specified.
If omitted, latest events are returned., optional
            settlementPeriodBefore: Filters events to those with a settlement period before or at the value.
Before parameter must be specified if this is specified., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            NetBalancingServicesAdjustmentResponse_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["count"] = count
        if before is not None:
            params["before"] = before
        if settlementPeriodBefore is not None:
            params["settlementPeriodBefore"] = settlementPeriodBefore
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/nonbm/netbsad/events", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return NetBalancingServicesAdjustmentResponse_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as NetBalancingServicesAdjustmentResponse_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_balancing_bid_offer(
        self,
        bmUnit: str,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        format: Optional[str] = None
    ) -> BidOfferResponse_ResponseWithMetadata:
        """
        Bid-offer data per BMU (BOD)

        This endpoint provides the bid-offer data for a requested BMU. It returns the data valid over a given time
range, excluding any results where LevelFrom and LevelTo are both zero.
            
By default, the from and to parameters filter the data inclusively and this endpoint will return any data that
overlaps even at a single instant. If the settlementPeriodFrom or settlementPeriodTo parameters are provided, it
will instead filter to return any data that overlaps with the specified range of settlement periods. It is
possible to search using a combination of time and/or settlement date & settlement period. Note: When
filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For example,
2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering by timeFrom and timeTo:
            
    /balancing/bid-offer?bmUnit=T_DRAXX-1&from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from timeFrom to settlement date and period:
            
    /balancing/bid-offer?bmUnit=T_DRAXX-1&from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to TimeTo:
            
    /balancing/bid-offer?bmUnit=T_DRAXX-1&from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /balancing/bid-offer?bmUnit=T_DRAXX-1&from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            bmUnit: The BM Unit to query.
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            BidOfferResponse_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["bmUnit"] = bmUnit
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/bid-offer", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return BidOfferResponse_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as BidOfferResponse_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_balancing_bid_offer_all(
        self,
        settlementDate: str,
        settlementPeriod: int,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> BidOfferResponse_ResponseWithMetadata:
        """
        Market-wide bid-offer data (BOD)

        This endpoint provides market-wide bid-offer data, for all BMUs or a requested set of multiple BMUs.
It returns the data valid for a given settlement period, excluding any results where LevelFrom and LevelTo are both zero.
            
The settlement period to query must be specified as a date and settlement period. The date should be provided in the format yyyy-MM-dd.

        Args:
            settlementDate: The settlement date to filter.
            settlementPeriod: The settlement period to filter. This should be an integer from 1-50 inclusive.
            bmUnit: The BM Units to query. Elexon or NGC BMU IDs can be used. If omitted, results for all BM units will be returned., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            BidOfferResponse_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["settlementDate"] = settlementDate
        params["settlementPeriod"] = settlementPeriod
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/bid-offer/all", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return BidOfferResponse_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as BidOfferResponse_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_balancing_acceptances(
        self,
        bmUnit: str,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        format: Optional[str] = None
    ) -> BidOfferAcceptancesResponse_ResponseWithMetadata:
        """
        Bid-offer acceptances per BMU (BOALF)

        This endpoint provides the bid-offer acceptance data (BOALF) for a requested BMU.
            
By default, the from and to parameters filter the data by start time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of start time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /balancing/acceptances?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /balancing/acceptances?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /balancing/acceptances?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /balancing/acceptances?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            bmUnit: The BM Unit to query.
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            BidOfferAcceptancesResponse_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["bmUnit"] = bmUnit
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/acceptances", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return BidOfferAcceptancesResponse_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as BidOfferAcceptancesResponse_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_balancing_acceptances_all(
        self,
        settlementDate: str,
        settlementPeriod: int,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> BidOfferAcceptancesResponse_ResponseWithMetadata:
        """
        Market-wide bid-offer acceptances (BOALF)

        This endpoint provides the bid-offer acceptance data (BOALF) for multiple requested BMUs or all BMUs.
It returns the data valid for a single settlement period.
            
The settlement period must be specified as a date and settlement period. The date parameter must be provided in the exact format yyyy-MM-dd.

        Args:
            settlementDate: The settlement date for the filter.
            settlementPeriod: The settlement period for the filter. This should be an integer from 1-50 inclusive.
            bmUnit: The BM Units to query. Elexon or NGC BMU IDs can be used. If omitted, results for all BM units will be returned., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            BidOfferAcceptancesResponse_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["settlementDate"] = settlementDate
        params["settlementPeriod"] = settlementPeriod
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/acceptances/all", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return BidOfferAcceptancesResponse_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as BidOfferAcceptancesResponse_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_balancing_acceptances_all_latest(
        self,
        format: Optional[str] = None
    ) -> BidOfferAcceptancesResponse_ResponseWithMetadata:
        """
        Latest market-wide bid-offer acceptances (BOALF)

        This endpoint provides the latest market-wide bid-offer acceptance data (BOALF). The latest 100 acceptances will be returned.

        Args:
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            BidOfferAcceptancesResponse_ResponseWithMetadata: Typed response object
        """
        params = {}
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/acceptances/all/latest", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return BidOfferAcceptancesResponse_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as BidOfferAcceptancesResponse_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_nonbm(
        self,
        from_: Optional[str] = None,
        to_: Optional[str] = None,
        format: Optional[str] = None
    ) -> NonBmStorData_DatasetResponse:
        """
        Non-BM STOR (NONBM)

        This endpoint provides data about the Short Term Operating Reserves (STOR) that have been made use of
by NGESO. This is activity that is outside of the Balancing Mechanism and takes place to meet the need to
increase generation or decrease demand.
            
To retrieve data from a particular time window, use the optional start and end time parameters.
These times should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
If no time window is chosen, the default output will be the latest published data.

        Args:
            from_: The start of the data publish time window., optional
            to_: The end of the data publish time window., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            NonBmStorData_DatasetResponse: Typed response object
        """
        params = {}
        if from_ is not None:
            params["from"] = from_
        if to_ is not None:
            params["to"] = to_
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/NONBM", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return NonBmStorData_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as NonBmStorData_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_nonbm_stream(
        self,
        from_: Optional[str] = None,
        to_: Optional[str] = None
    ) -> List[NonBmStorData]:
        """
        Non-BM STOR (NONBM) stream

        This endpoint provides data about the Short Term Operating Reserves (STOR) that have been made use of
by NGESO. This is activity that is outside of the Balancing Mechanism and takes place to meet the need to
increase generation or decrease demand.
            
To retrieve data from a particular time window, use the optional start and end time parameters.
These times should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
If no time window is chosen, the default output will be the latest published data.
            
This endpoint has an optimised JSON payload and is aimed at frequent requests for the Non-BM STOR data.

        Args:
            from_: The start of the data publish time window., optional
            to_: The end of the data publish time window., optional

        Returns:
            List[NonBmStorData]: List of NonBmStorData objects
        """
        params = {}
        if from_ is not None:
            params["from"] = from_
        if to_ is not None:
            params["to"] = to_

        response = self._make_request("GET", f"/datasets/NONBM/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [NonBmStorData(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[NonBmStorData]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_pn(
        self,
        settlementDate: str,
        settlementPeriod: int,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> PhysicalNotificationData_DatasetResponse:
        """
        Physical Notifications (PN)

        This endpoint provides Physical Notification data received from NGESO. It returns the data valid for a single settlement period.
A Physical Notification is the best estimate of the level of generation or demand that a participant in the BM expects a BM Unit to export or import, respectively, in a Settlement Period.
            
Physical Notifications are submitted as a series of point MW values.
            
The settlement period to query must be specified as a date and settlement period. The date should be provided in the format yyyy-MM-dd.

        Args:
            settlementDate: The settlement date to query. This must be in the format yyyy-MM-dd.
            settlementPeriod: The settlement period to query. This should be an integer from 1-50 inclusive.
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            PhysicalNotificationData_DatasetResponse: Typed response object
        """
        params = {}
        params["settlementDate"] = settlementDate
        params["settlementPeriod"] = settlementPeriod
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/PN", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return PhysicalNotificationData_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as PhysicalNotificationData_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_pn_stream(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None
    ) -> List[PhysicalNotificationData]:
        """
        Physical Notifications (PN) stream

        This endpoint provides Physical Notification data received from NGESO.
A Physical Notification is the best estimate of the level of generation or demand that a participant in the BM expects a BM Unit to export or import, respectively, in a Settlement Period.
            
Physical Notifications are submitted as a series of point MW values.
            
The settlement period to query can be specified as a date and settlement period, or as a datetime
which will resolve to the settlement period that time falls within.
If a settlement period is provided, it will take precedence over the time portion of the datetime.

Some examples of date parameter combinations are shown below.
            
Filtering from settlement datetime to settlement datetime:
            
     /datasets/PN/stream?from=2022-07-01T00:00Z&to=2022-07-03T06:00Z
            
Filtering from settlement datetime to settlement date and period:
            
     /datasets/PN/stream?from=2022-07-01T00:00Z&to=2022-07-03&settlementPeriodTo=15
            
Filtering from settlement date and period to settlement datetime:
            
     /datasets/PN/stream?from=2022-07-01&settlementPeriodFrom=3&to=2022-07-03T06:00Z
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/PN/stream?from=2022-07-01&settlementPeriodFrom=3&to=2022-07-03&settlementPeriodTo=15

This endpoint has an optimised JSON payload and is aimed at frequent requests for PN data.

        Args:
            from_: The settlement date to query from.
            to_: The settlement date to query up to.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional

        Returns:
            List[PhysicalNotificationData]: List of PhysicalNotificationData objects
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit

        response = self._make_request("GET", f"/datasets/PN/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [PhysicalNotificationData(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[PhysicalNotificationData]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_qpn(
        self,
        settlementDate: str,
        settlementPeriod: int,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> PhysicalNotificationData_DatasetResponse:
        """
        Quiescent Physical Notifications (QPN)

        This endpoint provides Quiescent Physical Notification data received from NGESO. It returns the data valid for a single settlement period.
Quiescent Physical Notifications describe the MW levels to be deducted from the Physical Notification of a BM Unit to determine a resultant operating level.
            
The settlement period to query must be specified as a date and settlement period. The date should be provided in the format yyyy-MM-dd.

        Args:
            settlementDate: The settlement date to query. This must be in the format yyyy-MM-dd.
            settlementPeriod: The settlement period to query. This should be an integer from 1-50 inclusive.
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            PhysicalNotificationData_DatasetResponse: Typed response object
        """
        params = {}
        params["settlementDate"] = settlementDate
        params["settlementPeriod"] = settlementPeriod
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/QPN", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return PhysicalNotificationData_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as PhysicalNotificationData_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_qpn_stream(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None
    ) -> List[PhysicalNotificationData]:
        """
        Quiescent Physical Notifications (QPN) stream

        This endpoint provides Quiescent Physical Notification data received from NGESO.
Quiescent Physical Notifications describe the MW levels to be deducted from the Physical Notification of a BM Unit to determine a resultant operating level.
            
The settlement period to query can be specified as a date and settlement period, or as a datetime
which will resolve to the settlement period that time falls within.
If a settlement period is provided, it will take precedence over the time portion of the datetime.

Some examples of date parameter combinations are shown below.
            
Filtering from settlement datetime to settlement datetime:
            
     /datasets/QPN/stream?from=2022-07-01T00:00Z&to=2022-07-03T06:00Z
            
Filtering from settlement datetime to settlement date and period:
            
     /datasets/QPN/stream?from=2022-07-01T00:00Z&to=2022-07-03&settlementPeriodTo=15
            
Filtering from settlement date and period to settlement datetime:
            
     /datasets/QPN/stream?from=2022-07-01&settlementPeriodFrom=3&to=2022-07-03T06:00Z
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/QPN/stream?from=2022-07-01&settlementPeriodFrom=3&to=2022-07-03&settlementPeriodTo=15

This endpoint has an optimised JSON payload and is aimed at frequent requests for QPN data.

        Args:
            from_: The settlement date to query from.
            to_: The settlement date to query up to.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional

        Returns:
            List[PhysicalNotificationData]: List of PhysicalNotificationData objects
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit

        response = self._make_request("GET", f"/datasets/QPN/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [PhysicalNotificationData(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[PhysicalNotificationData]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_mels(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> DeliveryLimitMaxData_DatasetResponse:
        """
        Maximum Export Limit (MELS)

        This endpoint provides Maximum Export Limit data received from NGESO.

The Maximum Export Limit is the maximum power export level of a particular BM Unit at a particular time.
The data is updated every 30 minutes and within 15 minutes of the end of the effective Settlement Period.
MELs are submitted as a series of MW values and associated times in UTC.

By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/mels?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/mels?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/mels?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/mels?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DeliveryLimitMaxData_DatasetResponse: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/MELS", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DeliveryLimitMaxData_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DeliveryLimitMaxData_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_mels_stream(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None
    ) -> List[DeliveryLimitMaxData]:
        """
        Maximum Export Limit (MELS) stream

        This endpoint provides Maximum Export Limit data received from NGESO.

The Maximum Export Limit is the maximum power export level of a particular BM Unit at a particular time.
The data is updated every 30 minutes and within 15 minutes of the end of the effective Settlement Period.
MELs are submitted as a series of MW values and associated times in UTC.

By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/mels/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/mels/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/mels/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/mels/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1
This endpoint has an optimised JSON payload and is aimed at frequent requests for MELS data.

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional

        Returns:
            List[DeliveryLimitMaxData]: List of DeliveryLimitMaxData objects
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit

        response = self._make_request("GET", f"/datasets/MELS/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [DeliveryLimitMaxData(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[DeliveryLimitMaxData]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_mils(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> DeliveryLimitMaxData_DatasetResponse:
        """
        Maximum Import Limit (MILS)

        This endpoint provides Maximum Import Limit data received from NGESO.

The maximum power import level of a particular BM Unit at a particular time.
The data is updated every 30 minutes and within 15 minutes of the end of the effective Settlement Period.
MILs are submitted as a series of MW values and associated times in UTC.

By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/mils?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/mils?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/mils?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/mils?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DeliveryLimitMaxData_DatasetResponse: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/MILS", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DeliveryLimitMaxData_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DeliveryLimitMaxData_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_mils_stream(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None
    ) -> List[DeliveryLimitMaxData]:
        """
        Maximum Import Limit (MILS) stream

        This endpoint provides Maximum Import Limit data received from NGESO.

The maximum power import level of a particular BM Unit at a particular time.
The data is updated every 30 minutes and within 15 minutes of the end of the effective Settlement Period.
MILs are submitted as a series of MW values and associated times in UTC.

By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/mils/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/mils/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/mils/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/mils/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1
This endpoint has an optimised JSON payload and is aimed at frequent requests for MILS data.

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional

        Returns:
            List[DeliveryLimitMaxData]: List of DeliveryLimitMaxData objects
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit

        response = self._make_request("GET", f"/datasets/MILS/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [DeliveryLimitMaxData(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[DeliveryLimitMaxData]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_qas(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> BalancingServicesVolumeData_DatasetResponse:
        """
        Balancing Services Volume (QAS)

        This endpoint provides Balancing Services Volume data received from NGESO.
            
Balancing Services Volume is a volume which is received from the System Operator, which represents the volume
of energy (MWh) associated with the provision of Applicable Balancing Services for each relevant BM Unit and
Settlement Period.

QAS can be positive or negative and is normally only provided where there is a non-zero volume.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/qas?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/qas?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/qas?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/qas?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            BalancingServicesVolumeData_DatasetResponse: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/QAS", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return BalancingServicesVolumeData_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as BalancingServicesVolumeData_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_qas_stream(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None
    ) -> List[BalancingServicesVolumeData]:
        """
        Balancing Services Volume (QAS) stream

        This endpoint provides Balancing Services Volume data received from NGESO.
            
Balancing Services Volume is a volume which is received from the System Operator, which represents the volume
of energy (MWh) associated with the provision of Applicable Balancing Services for each relevant BM Unit and
Settlement Period.

QAS can be positive or negative and is normally only provided where there is a non-zero volume.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/qas/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/qas/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/qas/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/qas/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

This endpoint has an optimised JSON payload and is aimed at frequent requests for QAS data.

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional

        Returns:
            List[BalancingServicesVolumeData]: List of BalancingServicesVolumeData objects
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit

        response = self._make_request("GET", f"/datasets/QAS/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [BalancingServicesVolumeData(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[BalancingServicesVolumeData]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_netbsad(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        format: Optional[str] = None
    ) -> NetBalancingServicesAdjustmentData_DatasetResponse:
        """
        Net Balancing Services Adjustment Data (NETBSAD)

        This endpoint provides Net Balancing Services Adjustment data received from NGESO.
            
Net Balancing Services Adjustment data covers the buy/sell price, cost and volume adjustments for each
settlement period. 
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/netbsad?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/netbsad?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/netbsad?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/netbsad?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            NetBalancingServicesAdjustmentData_DatasetResponse: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/NETBSAD", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return NetBalancingServicesAdjustmentData_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as NetBalancingServicesAdjustmentData_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_netbsad_stream(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None
    ) -> List[NetBalancingServicesAdjustmentData]:
        """
        Net Balancing Services Adjustment Data (NETBSAD)

        This endpoint provides Net Balancing Services Adjustment data received from NGESO.
            
Net Balancing Services Adjustment data covers the buy/sell price, cost and volume adjustments for each
settlement period. 
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/netbsad/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/netbsad/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/netbsad/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/netbsad/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

This endpoint has an optimised JSON payload and is aimed at frequent requests for NETBSAD data.

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional

        Returns:
            List[NetBalancingServicesAdjustmentData]: List of NetBalancingServicesAdjustmentData objects
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo

        response = self._make_request("GET", f"/datasets/NETBSAD/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [NetBalancingServicesAdjustmentData(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[NetBalancingServicesAdjustmentData]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_disbsad(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        format: Optional[str] = None
    ) -> DisaggregatedBalancingServicesAdjustmentData_DatasetResponse:
        """
        Disaggregated Balancing Services Adjustment Data (DISBSAD)

        This endpoint provides Disaggregated Balancing Services Adjustment data received from NGESO.
            
Disaggregated Balancing Services Adjustment data covers a set of adjustment actions, cost and volume values
for each Settlement Period. Adjustment costs are shown in . Adjustment volumes are shown in MWh.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/disbsad?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/disbsad?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/disbsad?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/disbsad?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DisaggregatedBalancingServicesAdjustmentData_DatasetResponse: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/DISBSAD", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DisaggregatedBalancingServicesAdjustmentData_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DisaggregatedBalancingServicesAdjustmentData_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_disbsad_stream(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None
    ) -> List[DisaggregatedBalancingServicesAdjustmentData]:
        """
        Disaggregated Balancing Services Adjustment Data (DISBSAD) stream

        This endpoint provides Disaggregated Balancing Services Adjustment data received from NGESO.
            
Disaggregated Balancing Services Adjustment data covers a set of adjustment actions, cost and volume values
for each Settlement Period. Adjustment costs are shown in . Adjustment volumes are shown in MWh.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/disbsad/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/disbsad/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/disbsad/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/disbsad/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

This endpoint has an optimised JSON payload and is aimed at frequent requests for DISBSAD data.

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional

        Returns:
            List[DisaggregatedBalancingServicesAdjustmentData]: List of DisaggregatedBalancingServicesAdjustmentData objects
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo

        response = self._make_request("GET", f"/datasets/DISBSAD/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [DisaggregatedBalancingServicesAdjustmentData(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[DisaggregatedBalancingServicesAdjustmentData]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_bod(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> BidOfferDatasetResponse_DatasetResponse:
        """
        Bid Offer Data (BOD)

        This endpoint provides bid-offer data.
            
By default, the from and to parameters filter the data inclusively and this endpoint will return any data where
TimeFrom is within the requested time range. If the settlementPeriodFrom or settlementPeriodTo parameters are
provided, it will instead filter to return any data where TimeFrom is within the specified range of settlement
periods. It is possible to search using a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored.
For example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from a datetime to a datetime
            
    /datasets/bod?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from a datetime to a settlement date and period:
            
    /datasets/bod?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from a settlement date and period to a datetime:
            
    /datasets/bod?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from a settlement date and period to a settlement date and period:
            
    /datasets/bod?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            BidOfferDatasetResponse_DatasetResponse: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/BOD", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return BidOfferDatasetResponse_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as BidOfferDatasetResponse_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_bod_stream(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None
    ) -> List[BidOfferDatasetResponse]:
        """
        Bid-Offer Data (BOD) stream

        This endpoint provides bid-offer data.
            
By default, the from and to parameters filter the data inclusively and this endpoint will return any data where
TimeFrom is within the requested time range. If the settlementPeriodFrom or settlementPeriodTo parameters are
provided, it will instead filter to return any data where TimeFrom is within the specified range of settlement
periods. It is possible to search using a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored.
For example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from datetime to datetime
            
    /datasets/bod/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from datetime to settlement date and period:
            
    /datasets/bod/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to datetime:
            
    /datasets/bod/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/bod/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional

        Returns:
            List[BidOfferDatasetResponse]: List of BidOfferDatasetResponse objects
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit

        response = self._make_request("GET", f"/datasets/BOD/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [BidOfferDatasetResponse(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[BidOfferDatasetResponse]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_boalf(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> BidOfferAcceptanceLevelDatasetResponse_DatasetResponse:
        """
        Bid Offer Acceptance Level Flagged (BOALF)

        This endpoint provides bid offer acceptance data.
            
By default, the from and to parameters filter the data inclusively and this endpoint will return any data where
TimeFrom is within the requested time range. If the settlementPeriodFrom or settlementPeriodTo parameters are
provided, it will instead filter to return any data where TimeFrom is within the specified range of settlement
periods. It is possible to search using a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored.
For example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from datetime to datetime
            
    /datasets/boalf?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from datetime to settlement date and period:
            
    /datasets/boalf?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to datetime:
            
    /datasets/boalf?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/boalf?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            BidOfferAcceptanceLevelDatasetResponse_DatasetResponse: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/BOALF", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return BidOfferAcceptanceLevelDatasetResponse_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as BidOfferAcceptanceLevelDatasetResponse_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_boalf_stream(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None
    ) -> List[BidOfferAcceptanceLevelDatasetResponse]:
        """
        Bid Offer Acceptance Level Flagged (BOALF) stream

        This endpoint provides bid offer acceptance data.
            
By default, the from and to parameters filter the data inclusively and this endpoint will return any data where
TimeFrom is within the requested time range. If the settlementPeriodFrom or settlementPeriodTo parameters are
provided, it will instead filter to return any data where TimeFrom is within the specified range of settlement
periods. It is possible to search using a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored.
For example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from datetime to datetime
            
    /datasets/boalf/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from datetime to settlement date and period:
            
    /datasets/boalf/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to datetime:
            
    /datasets/boalf/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/boalf/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional

        Returns:
            List[BidOfferAcceptanceLevelDatasetResponse]: List of BidOfferAcceptanceLevelDatasetResponse objects
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit

        response = self._make_request("GET", f"/datasets/BOALF/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [BidOfferAcceptanceLevelDatasetResponse(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[BidOfferAcceptanceLevelDatasetResponse]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_mid(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        dataProviders: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> MarketIndexDatasetResponse_DatasetResponse:
        """
        Market Index Data (MID)

        This endpoint provides Market Index Data received from NGESO.
            
Market Index Data is a key component in the calculation of System Buy Price and System Sell Price for each
Settlement Period. This data is received from each of the appointed Market Index Data Providers (MIDPs) and
reflects the price of wholesale electricity in Great Britain in the short term markets. The Market Index Data
which is received from each MIDP for each Settlement Period consists of a Market Index Volume and
Market Index Price, representing the volume and price of trading for the relevant period in the market operated
by the MIDP. The Market Price (the volume weighed average Market Index Price) is used to derive
the Reverse Price (SBP or SSP)."
            
The two data providers available to query are N2EX ("N2EXMIDP") and APX ("APXMIDP").

By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/mid?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/mid?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/mid?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/mid?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            dataProviders: The data providers to query. If no data provider is selected both will be displayed., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            MarketIndexDatasetResponse_DatasetResponse: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if dataProviders is not None:
            params["dataProviders"] = dataProviders
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/MID", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return MarketIndexDatasetResponse_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as MarketIndexDatasetResponse_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_mid_stream(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        dataProviders: Optional[List[str]] = None
    ) -> List[MarketIndexDatasetResponse]:
        """
        Market Index Data (MID) stream

        This endpoint provides Market Index Data received from NGESO.
            
Market Index Data is a key component in the calculation of System Buy Price and System Sell Price for each
Settlement Period. This data is received from each of the appointed Market Index Data Providers (MIDPs) and
reflects the price of wholesale electricity in Great Britain in the short term markets. The Market Index Data
which is received from each MIDP for each Settlement Period consists of a Market Index Volume and
Market Index Price, representing the volume and price of trading for the relevant period in the market operated
by the MIDP. The Market Price (the volume weighed average Market Index Price) is used to derive
the Reverse Price (SBP or SSP)."
            
The two data providers available to query are N2EX ("N2EXMIDP") and APX ("APXMIDP").

By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/mid/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/mid/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/mid/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/mid/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

This endpoint has an optimised JSON payload and is aimed at frequent requests for MID data.

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            dataProviders: The data providers to query. If no data provider is selected both will be displayed., optional

        Returns:
            List[MarketIndexDatasetResponse]: List of MarketIndexDatasetResponse objects
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if dataProviders is not None:
            params["dataProviders"] = dataProviders

        response = self._make_request("GET", f"/datasets/MID/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [MarketIndexDatasetResponse(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[MarketIndexDatasetResponse]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_fuelhh(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        settlementDateFrom: Optional[str] = None,
        settlementDateTo: Optional[str] = None,
        settlementPeriod: Optional[List[str]] = None,
        fuelType: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> AugmentedOutturnData_DatasetResponse:
        """
        Half-hourly generation outturn by fuel type (FUELHH)

        This endpoint provides the half-hourly generation outturn (Generation By Fuel type)
to give our users an indication of the generation outturn for Great Britain.
The data is aggregated by Fuel Type category and updated at 30-minute intervals with
average MW values over 30 minutes for each category.
            
This endpoint includes additional settlement parameters such as Settlement Date and Settlement Period.
The Settlement Date fields cannot be set when a Publish Date field is set.
            
Settlement date parameters must be provided in the exact format yyyy-MM-dd.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            settlementDateFrom: , optional
            settlementDateTo: , optional
            settlementPeriod: List of Settlement Periods, optional
            fuelType: Fuel Type e.g. NUCLEAR, optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            AugmentedOutturnData_DatasetResponse: Typed response object
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if settlementDateFrom is not None:
            params["settlementDateFrom"] = settlementDateFrom
        if settlementDateTo is not None:
            params["settlementDateTo"] = settlementDateTo
        if settlementPeriod is not None:
            params["settlementPeriod"] = settlementPeriod
        if fuelType is not None:
            params["fuelType"] = fuelType
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/FUELHH", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return AugmentedOutturnData_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as AugmentedOutturnData_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_fuelhh_stream(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        settlementDateFrom: Optional[str] = None,
        settlementDateTo: Optional[str] = None,
        settlementPeriod: Optional[List[str]] = None,
        fuelType: Optional[List[str]] = None
    ) -> List[AugmentedOutturnData]:
        """
        Half-hourly generation outturn by fuel type (FUELHH) stream

        This endpoint provides the half-hourly generation outturn (Generation By Fuel type)
to give our users an indication of the generation outturn for Great Britain.
The data is aggregated by Fuel Type category and updated at 30-minute intervals with
average MW values over 30 minutes for each category.
            
This endpoint includes additional settlement parameters such as Settlement Date and Settlement Period.
The Settlement Date fields cannot be set when a Publish Date field is set.
            
Settlement date parameters must be provided in the exact format yyyy-MM-dd.
            
This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            settlementDateFrom: , optional
            settlementDateTo: , optional
            settlementPeriod: List of Settlement Periods, optional
            fuelType: Fuel Type e.g. NUCLEAR, optional

        Returns:
            List[AugmentedOutturnData]: List of AugmentedOutturnData objects
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if settlementDateFrom is not None:
            params["settlementDateFrom"] = settlementDateFrom
        if settlementDateTo is not None:
            params["settlementDateTo"] = settlementDateTo
        if settlementPeriod is not None:
            params["settlementPeriod"] = settlementPeriod
        if fuelType is not None:
            params["fuelType"] = fuelType

        response = self._make_request("GET", f"/datasets/FUELHH/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [AugmentedOutturnData(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[AugmentedOutturnData]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_fuelinst(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        settlementDateFrom: Optional[str] = None,
        settlementDateTo: Optional[str] = None,
        settlementPeriod: Optional[List[str]] = None,
        fuelType: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> AugmentedOutturnData_DatasetResponse:
        """
        Instantaneous generation outturn by fuel type (FUELINST)

        This endpoint provides the instantaneous generation outturn (Generation By Fuel type)
to give our users an indication of the generation outturn for Great Britain.
The data is aggregated by Fuel Type category and updated at five-minute intervals
with average MW values over 5 minutes for each category.
            
This endpoint includes additional settlement parameters such as Settlement Date and Settlement Period.
The Settlement Date fields cannot be set when a Publish Date field is set.
            
Settlement date parameters must be provided in the exact format yyyy-MM-dd.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            settlementDateFrom: , optional
            settlementDateTo: , optional
            settlementPeriod: List of Settlement Periods, optional
            fuelType: Fuel Type e.g. NUCLEAR, optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            AugmentedOutturnData_DatasetResponse: Typed response object
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if settlementDateFrom is not None:
            params["settlementDateFrom"] = settlementDateFrom
        if settlementDateTo is not None:
            params["settlementDateTo"] = settlementDateTo
        if settlementPeriod is not None:
            params["settlementPeriod"] = settlementPeriod
        if fuelType is not None:
            params["fuelType"] = fuelType
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/FUELINST", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return AugmentedOutturnData_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as AugmentedOutturnData_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_fuelinst_stream(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        settlementDateFrom: Optional[str] = None,
        settlementDateTo: Optional[str] = None,
        settlementPeriod: Optional[List[str]] = None,
        fuelType: Optional[List[str]] = None
    ) -> List[AugmentedOutturnData]:
        """
        Instantaneous generation outturn by fuel type (FUELINST) stream

        This endpoint provides the instantaneous generation outturn (Generation By Fuel type)
to give our users an indication of the generation outturn for Great Britain.
The data is aggregated by Fuel Type category and updated at five-minute intervals
with average MW values over 5 minutes for each category.
            
This endpoint includes additional settlement parameters such as Settlement Date and Settlement Period.
The Settlement Date fields cannot be set when a Publish Date field is set.
            
Settlement date parameters must be provided in the exact format yyyy-MM-dd.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            settlementDateFrom: , optional
            settlementDateTo: , optional
            settlementPeriod: List of Settlement Periods, optional
            fuelType: Fuel Type e.g. NUCLEAR, optional

        Returns:
            List[AugmentedOutturnData]: List of AugmentedOutturnData objects
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if settlementDateFrom is not None:
            params["settlementDateFrom"] = settlementDateFrom
        if settlementDateTo is not None:
            params["settlementDateTo"] = settlementDateTo
        if settlementPeriod is not None:
            params["settlementPeriod"] = settlementPeriod
        if fuelType is not None:
            params["fuelType"] = fuelType

        response = self._make_request("GET", f"/datasets/FUELINST/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [AugmentedOutturnData(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[AugmentedOutturnData]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_uou2_t14_d(
        self,
        fuelType: Optional[List[str]] = None,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> AvailabilityByBmUnitDaily_DatasetResponse:
        """
        2 to 14 days ahead generation availability aggregated by Balancing Mechanism Units (UOU2T14D)

        This endpoint provides a forward view of availability (also referred to as Output Usable
data under the Grid Code) for generation and interconnector capacity, accounting for planned
outages covering availability data from 2 days ahead to 14 days ahead; it is aggregated by
National Grid Balancing Mechanism Units (NGC BMUs).
            
In the context of this report, BMUs can be considered as generating units.
Elexon BMUs differs from NGC BMUs by including a prefix e.g. 'T_'.
The mapping between NGC and Elexon BMUs can be retrieved via reference data API endpoints.

        Args:
            fuelType: The fuel type to query. Add each fuel type separately. If no fuel types are supplied, all fuel types will be returned., optional
            publishDateTimeFrom: Start of the Publish Time range to query. If specified, PublishDateTimeTo must also be specified.
If both are omitted, latest published data is returned., optional
            publishDateTimeTo: End of the Publish Time range to query. If specified, PublishDateTimeFrom must also be specified.
If both are omitted, latest published data is returned., optional
            bmUnit: The BM units to query. Add each unit separately. Either the Elexon ID or the National Grid ID can be used.
If no BM unit is supplied all BM units will be returned., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            AvailabilityByBmUnitDaily_DatasetResponse: Typed response object
        """
        params = {}
        if fuelType is not None:
            params["fuelType"] = fuelType
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/UOU2T14D", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return AvailabilityByBmUnitDaily_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as AvailabilityByBmUnitDaily_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_uou2_t14_d_stream(
        self,
        fuelType: Optional[List[str]] = None,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        bmUnit: Optional[List[str]] = None
    ) -> List[AvailabilityByBmUnitDaily]:
        """
        2 to 14 days ahead generation availability aggregated by Balancing Mechanism Units (UOU2T14D) stream

        This endpoint provides a forward view of availability (also referred to as Output Usable
data under the Grid Code) for generation and interconnector capacity, accounting for planned
outages covering availability data from 2 days ahead to 14 days ahead; it is aggregated by
National Grid Balancing Mechanism Units (NGC BMUs).
            
In the context of this report, BMUs can be considered as generating units.
Elexon BMUs differs from NGC BMUs by including a prefix e.g. 'T_'.
The mapping between NGC and Elexon BMUs can be retrieved via reference data API endpoints.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            fuelType: The fuel type to query. Add each fuel type separately. If no fuel types are supplied, all fuel types will be returned., optional
            publishDateTimeFrom: Start of the Publish Time range to query. If specified, PublishDateTimeTo must also be specified.
If both are omitted, latest published data is returned., optional
            publishDateTimeTo: End of the Publish Time range to query. If specified, PublishDateTimeFrom must also be specified.
If both are omitted, latest published data is returned., optional
            bmUnit: The BM units to query. Add each unit separately. Either the Elexon ID or the National Grid ID can be used.
If no BM unit is supplied all BM units will be returned., optional

        Returns:
            List[AvailabilityByBmUnitDaily]: List of AvailabilityByBmUnitDaily objects
        """
        params = {}
        if fuelType is not None:
            params["fuelType"] = fuelType
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit

        response = self._make_request("GET", f"/datasets/UOU2T14D/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [AvailabilityByBmUnitDaily(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[AvailabilityByBmUnitDaily]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_uou2_t3_yw(
        self,
        fuelType: Optional[List[str]] = None,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> AvailabilityByBmUnitWeekly_DatasetResponse:
        """
        2 to 156 weeks ahead generation availability aggregated by Balancing Mechanism Units (UOU2T3YW)

        This endpoint forward view of availability (also referred to as Output Usable
data under the Grid Code) for generation and interconnector capacity, accounting for planned
outages covering availability data from 2 weeks ahead to 156 weeks ahead; it is aggregated by
Balancing Mechanism Units (BMUs).
            
In the context of this report, BMUs can be considered as generating units.
Elexon BMUs differs from NGC BMUs by including a prefix e.g. 'T_'.
The mapping between NGC and Elexon BMUs can be retrieved via reference data API endpoints.
            
This endpoint is subject to a limit of 100 requests per minute.
Any requests made beyond this limit may result in a 429 error ("Too Many Requests")

        Args:
            fuelType: The fuel type to query. Add each fuel type separately. If no fuel types are supplied, all fuel types will be returned., optional
            publishDateTimeFrom: Start of the Publish Time range to query. If specified, PublishDateTimeTo must also be specified.
If both are omitted, latest published data is returned., optional
            publishDateTimeTo: End of the Publish Time range to query. If specified, PublishDateTimeFrom must also be specified.
If both are omitted, latest published data is returned., optional
            bmUnit: The BM units to query. Add each unit separately. Either the Elexon ID or the National Grid ID can be used.
If no BM unit is supplied all BM units will be returned., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            AvailabilityByBmUnitWeekly_DatasetResponse: Typed response object
        """
        params = {}
        if fuelType is not None:
            params["fuelType"] = fuelType
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/UOU2T3YW", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return AvailabilityByBmUnitWeekly_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as AvailabilityByBmUnitWeekly_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_uou2_t3_yw_stream(
        self,
        fuelType: Optional[List[str]] = None,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        bmUnit: Optional[List[str]] = None
    ) -> List[AvailabilityByBmUnitWeekly]:
        """
        2 to 156 weeks ahead generation availability aggregated by Balancing Mechanism Units (UOU2T3YW) stream

        This endpoint forward view of availability (also referred to as Output Usable
data under the Grid Code) for generation and interconnector capacity, accounting for planned
outages covering availability data from 2 weeks ahead to 156 weeks ahead; it is aggregated by
Balancing Mechanism Units (BMUs).
            
In the context of this report, BMUs can be considered as generating units.
Elexon BMUs differs from NGC BMUs by including a prefix e.g. 'T_'.
The mapping between NGC and Elexon BMUs can be retrieved via reference data API endpoints.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            fuelType: The fuel type to query. Add each fuel type separately. If no fuel types are supplied, all fuel types will be returned., optional
            publishDateTimeFrom: Start of the Publish Time range to query. If specified, PublishDateTimeTo must also be specified.
If both are omitted, latest published data is returned., optional
            publishDateTimeTo: End of the Publish Time range to query. If specified, PublishDateTimeFrom must also be specified.
If both are omitted, latest published data is returned., optional
            bmUnit: The BM units to query. Add each unit separately. Either the Elexon ID or the National Grid ID can be used.
If no BM unit is supplied all BM units will be returned., optional

        Returns:
            List[AvailabilityByBmUnitWeekly]: List of AvailabilityByBmUnitWeekly objects
        """
        params = {}
        if fuelType is not None:
            params["fuelType"] = fuelType
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit

        response = self._make_request("GET", f"/datasets/UOU2T3YW/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [AvailabilityByBmUnitWeekly(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[AvailabilityByBmUnitWeekly]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_fou2_t14_d(
        self,
        fuelType: Optional[List[str]] = None,
        publishDate: Optional[str] = None,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        biddingZone: Optional[List[str]] = None,
        interconnector: Optional[bool] = None,
        format: Optional[str] = None
    ) -> AvailabilityByFuelTypeDaily_DatasetResponse:
        """
        2 to 14 days ahead generation availability aggregated by fuel type (FOU2T14D)

        This endpoint provides a forward view of availability (also referred to as Output Usable data
under the Grid Code) for generation and interconnector capacity, accounting for planned outages
covering 2 days ahead to 14 days ahead; it is aggregated by Fuel Types categories.
            
Date parameter must be provided in the exact format yyyy-MM-dd.

        Args:
            fuelType: , optional
            publishDate: The publish date for filtering. This must be in the format yyyy-MM-dd., optional
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            biddingZone: , optional
            interconnector: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            AvailabilityByFuelTypeDaily_DatasetResponse: Typed response object
        """
        params = {}
        if fuelType is not None:
            params["fuelType"] = fuelType
        if publishDate is not None:
            params["publishDate"] = publishDate
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if biddingZone is not None:
            params["biddingZone"] = biddingZone
        if interconnector is not None:
            params["interconnector"] = interconnector
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/FOU2T14D", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return AvailabilityByFuelTypeDaily_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as AvailabilityByFuelTypeDaily_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_fou2_t3_yw(
        self,
        fuelType: Optional[List[str]] = None,
        publishDate: Optional[str] = None,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        week: Optional[List[str]] = None,
        year: Optional[List[str]] = None,
        biddingZone: Optional[List[str]] = None,
        interconnector: Optional[bool] = None,
        format: Optional[str] = None
    ) -> AvailabilityByFuelTypeWeekly_DatasetResponse:
        """
        2 to 156 weeks ahead generation availability aggregated by fuel type (FOU2T3YW)

        This endpoint provides a forward view of availability (also referred to as Output Usable data
under the Grid Code) for generation and interconnector capacity, accounting for planned outages
covering availability data from 2 weeks ahead to 156 weeks ahead;
it is aggregated by Fuel Types categories.
            
Date parameter must be provided in the exact format yyyy-MM-dd.

        Args:
            fuelType: , optional
            publishDate: The publish date for filtering. This must be in the format yyyy-MM-dd., optional
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            week: , optional
            year: , optional
            biddingZone: , optional
            interconnector: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            AvailabilityByFuelTypeWeekly_DatasetResponse: Typed response object
        """
        params = {}
        if fuelType is not None:
            params["fuelType"] = fuelType
        if publishDate is not None:
            params["publishDate"] = publishDate
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if week is not None:
            params["week"] = week
        if year is not None:
            params["year"] = year
        if biddingZone is not None:
            params["biddingZone"] = biddingZone
        if interconnector is not None:
            params["interconnector"] = interconnector
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/FOU2T3YW", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return AvailabilityByFuelTypeWeekly_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as AvailabilityByFuelTypeWeekly_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_nou2_t14_d(
        self,
        publishDate: Optional[str] = None,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        format: Optional[str] = None
    ) -> AvailabilityDaily_DatasetResponse:
        """
        2 to 14 days ahead generation availability aggregated data (NOU2T14D)

        This endpoint provides a forward view of availability (also referred to as Output Usable data
under the Grid Code) for generation and interconnector capacity, accounting for planned outages
covering 2 days ahead to 14 days ahead. The data is aggregated at national level.
            
Date parameter must be provided in the exact format yyyy-MM-dd.

        Args:
            publishDate: The publish date for filtering. This must be in the format yyyy-MM-dd., optional
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            AvailabilityDaily_DatasetResponse: Typed response object
        """
        params = {}
        if publishDate is not None:
            params["publishDate"] = publishDate
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/NOU2T14D", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return AvailabilityDaily_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as AvailabilityDaily_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_nou2_t3_yw(
        self,
        publishDate: Optional[str] = None,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        week: Optional[List[str]] = None,
        year: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> AvailabilityWeekly_DatasetResponse:
        """
        2 to 156 weeks ahead generation availability aggregated data (NOU2T3YW)

        This endpoint provides a forward view of availability (also referred to as Output Usable data
under the Grid Code) for generation and interconnector capacity, accounting for planned outages
covering availability data from 2 weeks ahead to 156 weeks ahead.
The data is an aggregation of all Fuel Type categories at national level.
            
Date parameter must be provided in the exact format yyyy-MM-dd.

        Args:
            publishDate: The publish date for filtering. This must be in the format yyyy-MM-dd., optional
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            week: , optional
            year: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            AvailabilityWeekly_DatasetResponse: Typed response object
        """
        params = {}
        if publishDate is not None:
            params["publishDate"] = publishDate
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if week is not None:
            params["week"] = week
        if year is not None:
            params["year"] = year
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/NOU2T3YW", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return AvailabilityWeekly_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as AvailabilityWeekly_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_temp(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        format: Optional[str] = None
    ) -> TemperatureData_DatasetResponse:
        """
        Temperature data (TEMP)

        This endpoint provides the average degree celsius value measured at midday deemed to be
representative of the temperature for Great Britain. Data is gathered from 6 weather stations.
Default output will be the last 31 days. Values are received from 5pm each day.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            TemperatureData_DatasetResponse: Typed response object
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/TEMP", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return TemperatureData_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as TemperatureData_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_indgen(
        self,
        boundary: Optional[str] = None,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        format: Optional[str] = None
    ) -> IndicatedGeneration_DatasetResponse:
        """
        Day and day-ahead indicated generation (INDGEN)

        This endpoint provides the indicated generation received from NGESO. Data is received daily, by
midday. Expressed as an average MW value for each Settlement period. The indicated generation
forecast for each period is the sum of all the PNs submitted for BM Units which are forecast to
be exporting energy, presented as a single average MW value for the settlement period.

This API endpoint provides a maximum data output range of 1 day.

        Args:
            boundary: , optional
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            IndicatedGeneration_DatasetResponse: Typed response object
        """
        params = {}
        if boundary is not None:
            params["boundary"] = boundary
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/INDGEN", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return IndicatedGeneration_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as IndicatedGeneration_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_indgen_stream(
        self,
        boundary: Optional[str] = None,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None
    ) -> List[IndicatedGeneration]:
        """
        Day and day-ahead indicated generation (INDGEN) stream

        This endpoint provides the indicated generation received from NGESO. Data is received daily, by
midday. Expressed as an average MW value for each settlement period. The indicated generation
forecast for each period is the sum of all the PNs submitted for BM Units which are forecast to
be exporting energy, presented as a single average MW value for the settlement period.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            boundary: , optional
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional

        Returns:
            List[IndicatedGeneration]: List of IndicatedGeneration objects
        """
        params = {}
        if boundary is not None:
            params["boundary"] = boundary
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/INDGEN/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [IndicatedGeneration(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[IndicatedGeneration]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_inddem(
        self,
        boundary: Optional[str] = None,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        format: Optional[str] = None
    ) -> IndicatedDemand_DatasetResponse:
        """
        Day and day-ahead indicated demand (INDDEM)

        This endpoint provides the indicated demand forecast for the current day and day-ahead received
from NGESO. The forecast is updated every half hour. The forecast for each period is the sum of
all the PNs submitted for BM Units which are forecast to be importing energy. Data is presented
an average MW for the settlement period.
            
This API endpoint provides a maximum data output range of 1 day.

        Args:
            boundary: , optional
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            IndicatedDemand_DatasetResponse: Typed response object
        """
        params = {}
        if boundary is not None:
            params["boundary"] = boundary
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/INDDEM", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return IndicatedDemand_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as IndicatedDemand_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_inddem_stream(
        self,
        boundary: Optional[str] = None,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None
    ) -> List[IndicatedDemand]:
        """
        Day and day-ahead indicated demand (INDDEM) stream

        This endpoint provides the indicated demand forecast for the current day and day-ahead received
from NGESO. The forecast is updated every half hour. The forecast for each period is the sum of
all the PNs submitted for BM Units which are forecast to be importing energy. Data is presented
an average MW for the settlement period.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            boundary: , optional
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional

        Returns:
            List[IndicatedDemand]: List of IndicatedDemand objects
        """
        params = {}
        if boundary is not None:
            params["boundary"] = boundary
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/INDDEM/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [IndicatedDemand(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[IndicatedDemand]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_melngc(
        self,
        boundary: Optional[str] = None,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        format: Optional[str] = None
    ) -> IndicatedMargin_DatasetResponse:
        """
        Day and day-ahead indicated margin (MELNGC)

        This endpoint provides the indicated margin. Data is received every half an hour from NGESO.
Expressed as an average MW value for each settlement period. The indicated margin forecast for
each settlement period is the difference between the sum of the MELs submitted for that period,
and the National Demand forecast made by the System Operator. The greater the value, the higher
the margin between available generation capacity and forecast demand - that is to say, the more
spare capacity there is forecast to be in the system.
            
This API endpoint provides a maximum data output range of 1 day.

        Args:
            boundary: , optional
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            IndicatedMargin_DatasetResponse: Typed response object
        """
        params = {}
        if boundary is not None:
            params["boundary"] = boundary
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/MELNGC", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return IndicatedMargin_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as IndicatedMargin_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_melngc_stream(
        self,
        boundary: Optional[str] = None,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None
    ) -> List[IndicatedMargin]:
        """
        Day and day-ahead indicated margin (MELNGC) stream

        This endpoint provides the indicated margin. Data is received every half an hour from NGESO.
Expressed as an average MW value for each settlement period. The indicated margin forecast for
each settlement period is the difference between the sum of the MELs submitted for that period,
and the National Demand forecast made by the System Operator. The greater the value, the higher
the margin between available generation capacity and forecast demand - that is to say, the more
spare capacity there is forecast to be in the system.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            boundary: , optional
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional

        Returns:
            List[IndicatedMargin]: List of IndicatedMargin objects
        """
        params = {}
        if boundary is not None:
            params["boundary"] = boundary
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/MELNGC/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [IndicatedMargin(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[IndicatedMargin]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_imbalngc(
        self,
        boundary: Optional[str] = None,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        format: Optional[str] = None
    ) -> IndicatedImbalance_DatasetResponse:
        """
        Day and day-ahead indicated imbalance (IMBALNGC)

        This endpoint provides the indicated imbalance. Data is received by daily by midday from NGESO.
Expressed as an average MW value for each settlement period. The indicated imbalance forecast for
each period is the difference between the sum of the PNs submitted for generation BM Units (i.e.
the indicated generation), and the Transmission System Demand forecast made by the System Operator.
            
This API endpoint provides a maximum data output range of 1 day.

        Args:
            boundary: , optional
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            IndicatedImbalance_DatasetResponse: Typed response object
        """
        params = {}
        if boundary is not None:
            params["boundary"] = boundary
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/IMBALNGC", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return IndicatedImbalance_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as IndicatedImbalance_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_imbalngc_stream(
        self,
        boundary: Optional[str] = None,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None
    ) -> List[IndicatedImbalance]:
        """
        Day and day-ahead indicated imbalance (IMBALNGC) stream

        This endpoint provides the indicated imbalance. Data is received by daily by midday from NGESO.
Expressed as an average MW value for each settlement period. The indicated imbalance forecast for
each period is the difference between the sum of the PNs submitted for generation BM Units (i.e.
the indicated generation), and the National Demand forecast made by the System Operator.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            boundary: , optional
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional

        Returns:
            List[IndicatedImbalance]: List of IndicatedImbalance objects
        """
        params = {}
        if boundary is not None:
            params["boundary"] = boundary
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/IMBALNGC/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [IndicatedImbalance(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[IndicatedImbalance]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_ndf(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        format: Optional[str] = None
    ) -> DemandForecastNationalDayAhead_DatasetResponse:
        """
        Day and day-ahead National Demand forecast (NDF)

        This endpoint provides the National Demand forecast received from NGESO. Data is available
daily and will show values for the day ahead. Expressed as an average MW
value for each settlement period. The forecast is based on historically metered generation
output for Great Britain. This value INCLUDES transmission losses, but EXCLUDES interconnector
flows and demand from station transformers and pumped storage units.
            
This API endpoint provides a maximum data output range of 1 day.
            
Specific publish time filters may be supplied, otherwise this will retrieve the latest published forecast.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DemandForecastNationalDayAhead_DatasetResponse: Typed response object
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/NDF", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DemandForecastNationalDayAhead_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DemandForecastNationalDayAhead_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_ndf_stream(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None
    ) -> List[DemandForecastNationalDayAhead]:
        """
        Day and day-ahead National Demand forecast (NDF) stream

        This endpoint provides the National Demand forecast received from NGESO. Data is available
daily and will show values for the day ahead. Expressed as an average MW
value for each settlement period. The forecast is based on historically metered generation
output for Great Britain. This value INCLUDES transmission losses, but EXCLUDES interconnector
flows and demand from station transformers and pumped storage units.
            
Specific publish time filters may be supplied, otherwise this will retrieve the latest published forecast.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional

        Returns:
            List[DemandForecastNationalDayAhead]: List of DemandForecastNationalDayAhead objects
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/NDF/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [DemandForecastNationalDayAhead(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[DemandForecastNationalDayAhead]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_tsdf(
        self,
        boundary: Optional[str] = None,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        format: Optional[str] = None
    ) -> DemandForecastTransmissionDayAhead_DatasetResponse:
        """
        Day and day-ahead Transmission System Demand forecast (TSDF)

        This endpoint provides the Transmission System Demand forecast.
Data is received daily from NGESO and will show values for the day ahead.
Expressed as an average MW value for each settlement period.
The Transmission System Demand forecast is based on historically metered generation output for Great Britain.
This value INCLUDES interconnector flows and demand from station transformers and pumped storage units.

Specific publish time filters may be supplied, otherwise this will retrieve the latest published forecast.
            
This API endpoint provides a maximum data output range of 1 day.

        Args:
            boundary: , optional
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DemandForecastTransmissionDayAhead_DatasetResponse: Typed response object
        """
        params = {}
        if boundary is not None:
            params["boundary"] = boundary
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/TSDF", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DemandForecastTransmissionDayAhead_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DemandForecastTransmissionDayAhead_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_tsdf_stream(
        self,
        boundary: Optional[str] = None,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None
    ) -> List[DemandForecastTransmissionDayAhead]:
        """
        Day and day-ahead Transmission System Demand forecast (TSDF) stream

        This endpoint provides the Transmission System Demand forecast .
Data is received daily from NGESO and will show values for the day ahead.
Expressed as an average MW value for each settlement period.
The Transmission System Demand forecast is based on historically metered generation output for Great Britain.
This value INCLUDES interconnector flows and demand from station transformers and pumped storage units.

Specific publish time filters may be supplied, otherwise this will retrieve the latest published forecast.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            boundary: , optional
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional

        Returns:
            List[DemandForecastTransmissionDayAhead]: List of DemandForecastTransmissionDayAhead objects
        """
        params = {}
        if boundary is not None:
            params["boundary"] = boundary
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/TSDF/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [DemandForecastTransmissionDayAhead(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[DemandForecastTransmissionDayAhead]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_windfor(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        format: Optional[str] = None
    ) -> WindGenerationForecast_DatasetResponse:
        """
        Wind generation forecast (WINDFOR)

        This endpoint provides wind generation forecast data.

Specific publish time filters may be supplied, otherwise this will retrieve the latest published forecast.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            WindGenerationForecast_DatasetResponse: Typed response object
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/WINDFOR", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return WindGenerationForecast_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as WindGenerationForecast_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_windfor_stream(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None
    ) -> List[WindGenerationForecast]:
        """
        Wind generation forecast (WINDFOR) stream

        This endpoint provides wind generation forecast data.

Specific publish time filters may be supplied, otherwise this will retrieve the latest published forecast.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional

        Returns:
            List[WindGenerationForecast]: List of WindGenerationForecast objects
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/WINDFOR/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [WindGenerationForecast(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[WindGenerationForecast]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_indo(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        format: Optional[str] = None
    ) -> DemandOutturnNational_DatasetResponse:
        """
        Initial National Demand outturn (INDO)

        The endpoint provides data showing the initial National Demand outturn.
Data is updated at 15 min intervals containing the initial demand expressed in MW.
            
Specific publish time filters may be supplied, otherwise this will retrieve the latest published data.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DemandOutturnNational_DatasetResponse: Typed response object
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/INDO", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DemandOutturnNational_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DemandOutturnNational_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_indod(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str,
        format: Optional[str] = None
    ) -> IndodDatasetRow_DatasetResponse:
        """
        Initial National Demand outturn daily (INDOD)

        This endpoint provides initial National Demand outturn daily data. The total daily energy volume is the total
demand volume for the previous day expressed on an initial National Demand outturn (INDO) basis, i.e. excluding
station transformer, pumping and interconnector export demand. It is calculated from summing the half hourly
INDO demands (divided by two to convert to MWh).

This API endpoint has a maximum range of 2 years (731 days).

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            IndodDatasetRow_DatasetResponse: Typed response object
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/INDOD", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return IndodDatasetRow_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as IndodDatasetRow_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_indod_stream(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str
    ) -> List[IndodDatasetRow]:
        """
        Initial National Demand outturn daily (INDOD) stream

        This endpoint provides initial National Demand outturn daily data. The total daily energy volume is the total
demand volume for the previous day expressed on an initial National Demand outturn (INDO) basis, i.e. excluding
station transformer, pumping and interconnector export demand. It is calculated from summing the half hourly
INDO demands (divided by two to convert to MWh).

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 

        Returns:
            List[IndodDatasetRow]: List of IndodDatasetRow objects
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/INDOD/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [IndodDatasetRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[IndodDatasetRow]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_itsdo(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        format: Optional[str] = None
    ) -> DemandOutturnTransmission_DatasetResponse:
        """
        Initial Transmission System Demand outturn (ITSDO)

        The endpoint provides data showing the initial Transmission System Demand outturn.
Data is updated at 15 min intervals containing the initial demand expressed in MW.
            
Specific publish time filters may be supplied, otherwise this will retrieve the latest published forecast.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DemandOutturnTransmission_DatasetResponse: Typed response object
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/ITSDO", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DemandOutturnTransmission_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DemandOutturnTransmission_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_ndfd(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        format: Optional[str] = None
    ) -> DemandForecastNationalDaily_DatasetResponse:
        """
        2-14 days ahead National Demand and surplus forecast (NDFD)

        This endpoint provides the National Demand forecast received from NGESO.
Data is available daily and will show values for the 2 to 14 days ahead.
Expressed as an average MW value for each Settlement period. The forecast is based on historically metered generation output for Great Britain.
This value INCLUDES transmission losses, but EXCLUDES interconnector flows and demand from station.

This API endpoint provides a maximum data output range of 92 days.

Specific publish time filters may be supplied, otherwise this will retrieve the latest published forecast.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DemandForecastNationalDaily_DatasetResponse: Typed response object
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/NDFD", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DemandForecastNationalDaily_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DemandForecastNationalDaily_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_ndfd_stream(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None
    ) -> List[DemandForecastNationalDaily]:
        """
        2-14 days ahead National Demand and surplus forecast (NDFD) stream

        This endpoint provides the National Demand forecast received from NGESO.
Data is available daily and will show values for the 2 to 14 days ahead.
Expressed as an average MW value for each Settlement period. The forecast is based on historically metered generation output for Great Britain.
This value INCLUDES transmission losses, but EXCLUDES Interconnector flows and demand from station

Specific publish time filters may be supplied, otherwise this will retrieve the latest published forecast.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional

        Returns:
            List[DemandForecastNationalDaily]: List of DemandForecastNationalDaily objects
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/NDFD/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [DemandForecastNationalDaily(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[DemandForecastNationalDaily]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_tsdfd(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        format: Optional[str] = None
    ) -> DemandForecastTransmissionDaily_DatasetResponse:
        """
        2-14 days ahead Transmission System Demand and surplus forecast (TSDFD)

        This endpoint provides the Transmission System forecast. Data is available daily and will show values for the 2 to 14 days ahead.
Expressed as an average MW value for each settlement period. The Transmission System Demand forecast is based on historically metered generation output for Great Britain.
This value INCLUDES interconnector flows and demand from station transformers and pumped storage units.
            
Specific publish time filters may be supplied, otherwise this will retrieve the latest published forecast.
            
This API endpoint provides a maximum data output range of 92 days.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DemandForecastTransmissionDaily_DatasetResponse: Typed response object
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/TSDFD", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DemandForecastTransmissionDaily_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DemandForecastTransmissionDaily_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_tsdfd_stream(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None
    ) -> List[DemandForecastTransmissionDaily]:
        """
        2-14 days ahead Transmission System Demand and surplus forecast (TSDFD) stream

        This endpoint provides the Transmission System Demand forecast. Data is available daily and will show values for the 2 to 14 days ahead.
Expressed as an average MW value for each settlement period. The Transmission System Demand forecast is based on historically metered generation output for Great Britain.
This value INCLUDES interconnector flows and demand from station transformers and pumped storage units.
            
Specific publish time filters may be supplied, otherwise this will retrieve the latest published forecast.
            
This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional

        Returns:
            List[DemandForecastTransmissionDaily]: List of DemandForecastTransmissionDaily objects
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/TSDFD/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [DemandForecastTransmissionDaily(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[DemandForecastTransmissionDaily]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_ndfw(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        format: Optional[str] = None
    ) -> DemandForecastNationalWeekly_DatasetResponse:
        """
        2-52 weeks ahead National Demand and surplus forecast (NDFW)

        This endpoint provides the National Demand forecast received from NGESO.
Data is available from 4pm each Thursday and will show values for the 2 to 52 weeks ahead.
Expressed as an average MW value for each week. The forecast is based on historically metered generation output for Great Britain.
This value INCLUDES transmission losses, but EXCLUDES interconnector flows and demand from station.

This API endpoint provides a maximum data output range of 366 days.

Specific publish time filters may be supplied, otherwise this will retrieve the latest published forecast.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DemandForecastNationalWeekly_DatasetResponse: Typed response object
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/NDFW", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DemandForecastNationalWeekly_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DemandForecastNationalWeekly_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_ndfw_stream(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None
    ) -> List[DemandForecastNationalWeekly]:
        """
        2-52 weeks ahead National Demand and surplus forecast (NDFW) stream

        This endpoint provides the National Demand forecast received from NGESO.
Data is available from 4pm each Thursday and will show values for the 2 to 52 weeks ahead.
Expressed as an average MW value for each week. The forecast is based on historically metered generation output for Great Britain.
This value INCLUDES transmission losses, but EXCLUDES interconnector flows and demand from station.

Specific publish time filters may be supplied, otherwise this will retrieve the latest published forecast.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional

        Returns:
            List[DemandForecastNationalWeekly]: List of DemandForecastNationalWeekly objects
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/NDFW/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [DemandForecastNationalWeekly(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[DemandForecastNationalWeekly]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_tsdfw(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        format: Optional[str] = None
    ) -> DemandForecastTransmissionWeekly_DatasetResponse:
        """
        2-52 weeks ahead Transmission System Demand and surplus forecast (TSDFW)

        This endpoint provides the Transmission System Demand forecast received from NGESO.
Data is available from 4pm each Thursday and will show values for the 2 to 52 weeks ahead.
Expressed as an average MW value for each week. The forecast is based on historically metered generation output for Great Britain.
This value INCLUDES transmission losses, but EXCLUDES interconnector flows and demand from station.

This API will provide a maximum data output range of 366 days.

Specific publish time filters may be supplied, otherwise this will retrieve the latest published forecast.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DemandForecastTransmissionWeekly_DatasetResponse: Typed response object
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/TSDFW", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DemandForecastTransmissionWeekly_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DemandForecastTransmissionWeekly_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_tsdfw_stream(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None
    ) -> List[DemandForecastTransmissionWeekly]:
        """
        2-52 weeks ahead Transmission System Demand and surplus forecast (TSDFW) stream

        This endpoint provides the Transmission System Demand forecast received from NGESO.
Data is available from 4pm each Thursday and will show values for the 2 to 52 weeks ahead.
Expressed as an average MW value for each week. The forecast is based on historically metered generation output for Great Britain.
This value INCLUDES transmission losses, but EXCLUDES interconnector flows and demand from station.

Specific publish time filters may be supplied, otherwise this will retrieve the latest published forecast.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional

        Returns:
            List[DemandForecastTransmissionWeekly]: List of DemandForecastTransmissionWeekly objects
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/TSDFW/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [DemandForecastTransmissionWeekly(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[DemandForecastTransmissionWeekly]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_freq(
        self,
        measurementDateTimeFrom: Optional[str] = None,
        measurementDateTimeTo: Optional[str] = None,
        format: Optional[str] = None
    ) -> SystemFrequency_DatasetResponse:
        """
        System frequency (FREQ)

        The endpoint provides data that has been received every 2 minutes the transmission system frequency, expressed as a hertz value for one or more spot times within that 2 minute period.
The default output will be the latest published data.
            
A maximum limit of 24 hours is applied to this endpoint to limit response size. Use the streaming version
for larger response sizes.

        Args:
            measurementDateTimeFrom: , optional
            measurementDateTimeTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            SystemFrequency_DatasetResponse: Typed response object
        """
        params = {}
        if measurementDateTimeFrom is not None:
            params["measurementDateTimeFrom"] = measurementDateTimeFrom
        if measurementDateTimeTo is not None:
            params["measurementDateTimeTo"] = measurementDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/FREQ", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return SystemFrequency_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as SystemFrequency_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_freq_stream(
        self,
        measurementDateTimeFrom: Optional[str] = None,
        measurementDateTimeTo: Optional[str] = None
    ) -> List[SystemFrequency]:
        """
        System frequency (FREQ) stream

        The endpoint provides data that has been received every 2 minutes the transmission system frequency, expressed as a hertz value for one or more spot times within that 2 minute period.
The default output will be the latest published data.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            measurementDateTimeFrom: , optional
            measurementDateTimeTo: , optional

        Returns:
            List[SystemFrequency]: List of SystemFrequency objects
        """
        params = {}
        if measurementDateTimeFrom is not None:
            params["measurementDateTimeFrom"] = measurementDateTimeFrom
        if measurementDateTimeTo is not None:
            params["measurementDateTimeTo"] = measurementDateTimeTo

        response = self._make_request("GET", f"/datasets/FREQ/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [SystemFrequency(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[SystemFrequency]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_ocnmfd(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        format: Optional[str] = None
    ) -> ForecastSurplusDaily_DatasetResponse:
        """
        2-14 days ahead demand surplus forecast (OCNMFD)

        The demand surplus forecast data is received hourly from NGESO.
It shows the daily peak half hour MW value of generating plant demand surplus for each day for the 2 to 14 days ahead.

This API endpoint provides a maximum data output range of 7 days.
            
Specific publish time filters may be supplied, otherwise this will retrieve the latest published forecast.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            ForecastSurplusDaily_DatasetResponse: Typed response object
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/OCNMFD", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return ForecastSurplusDaily_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as ForecastSurplusDaily_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_ocnmfd_stream(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None
    ) -> List[ForecastSurplusDaily]:
        """
        2-14 days ahead demand surplus forecast (OCNMFD) stream

        The demand surplus forecast data is received hourly from NGESO.
It shows the daily peak half hour MW value of generating plant demand surplus for each day for the 2 to 14 days ahead.

Specific publish time filters may be supplied, otherwise this will retrieve the latest published forecast.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional

        Returns:
            List[ForecastSurplusDaily]: List of ForecastSurplusDaily objects
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/OCNMFD/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [ForecastSurplusDaily(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[ForecastSurplusDaily]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_ocnmfd2(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        format: Optional[str] = None
    ) -> ForecastMarginDaily_DatasetResponse:
        """
        2-14 days ahead demand margin forecast (OCNMFD2)

        The demand margin forecast is received hourly from NGESO.
It shows the daily peak half hour MW value of generating plant demand margin for each day for the 2 to 14 days ahead.

This API endpoint provides a maximum data output range of 7 days.
            
Specific publish time filters may be supplied, otherwise this will retrieve the latest published forecast.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            ForecastMarginDaily_DatasetResponse: Typed response object
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/OCNMFD2", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return ForecastMarginDaily_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as ForecastMarginDaily_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_ocnmfd2_stream(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None
    ) -> List[ForecastMarginDaily]:
        """
        2-14 days ahead demand margin forecast (OCNMFD2) stream

        The demand margin forecast is received hourly from NGESO.
It shows the daily peak half hour MW value of generating plant demand margin for each day for the 2 to 14 days ahead.

Specific publish time filters may be supplied, otherwise this will retrieve the latest published forecast.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional

        Returns:
            List[ForecastMarginDaily]: List of ForecastMarginDaily objects
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/OCNMFD2/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [ForecastMarginDaily(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[ForecastMarginDaily]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_ocnmf3_y(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        format: Optional[str] = None
    ) -> ForecastSurplusWeekly_DatasetResponse:
        """
        2-156 weeks ahead demand surplus forecast (OCNMF3Y)

        The demand surplus forecast data is received hourly from NGESO.
It shows the weekly peak half hour MW value of generating plant demand surplus for each day for the 2-156 weeks ahead.

This API endpoint provides a maximum data output range of 7 days.
            
Specific publish time filters may be supplied, otherwise this will retrieve the latest published forecast.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            ForecastSurplusWeekly_DatasetResponse: Typed response object
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/OCNMF3Y", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return ForecastSurplusWeekly_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as ForecastSurplusWeekly_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_ocnmf3_y_stream(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None
    ) -> List[ForecastSurplusWeekly]:
        """
        2-156 weeks ahead demand surplus forecast (OCNMF3Y) stream

        The demand surplus forecast data is received hourly from NGESO.
It shows the weekly peak half hour MW value of generating plant demand surplus for each day for the 2-156 weeks ahead.

Specific publish time filters may be supplied, otherwise this will retrieve the latest published forecast.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional

        Returns:
            List[ForecastSurplusWeekly]: List of ForecastSurplusWeekly objects
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/OCNMF3Y/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [ForecastSurplusWeekly(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[ForecastSurplusWeekly]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_ocnmf3_y2(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        format: Optional[str] = None
    ) -> ForecastMarginWeekly_DatasetResponse:
        """
        2-156 weeks ahead demand margin forecast (OCNMF3Y2)

        The demand margin forecast is received hourly from NGESO.
It shows the weekly peak half hour MW value of generating plant demand margin for each day for the 2 to 156 weeks ahead.
            
This API endpoint has a maximum data output range of 7 days.

Specific publish time filters may be supplied, otherwise this will retrieve the latest published forecast.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            ForecastMarginWeekly_DatasetResponse: Typed response object
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/OCNMF3Y2", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return ForecastMarginWeekly_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as ForecastMarginWeekly_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_ocnmf3_y2_stream(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None
    ) -> List[ForecastMarginWeekly]:
        """
        2-156 weeks ahead demand margin forecast (OCNMF3Y2) stream

        The demand margin forecast is received hourly from NGESO.
It shows the weekly peak half hour MW value of generating plant demand margin for each day for the 2 to 156 weeks ahead.

Specific publish time filters may be supplied, otherwise this will retrieve the latest published forecast.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional

        Returns:
            List[ForecastMarginWeekly]: List of ForecastMarginWeekly objects
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/OCNMF3Y2/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [ForecastMarginWeekly(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[ForecastMarginWeekly]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_metadata_latest(
        self,
        format: Optional[str] = None
    ) -> DatasetMetadataLatestRow_DatasetResponse:
        """
        Returns the time when each dataset was last updated

        Depending on the dataset, this value may be taken from the timestamp on the source datafile, the
publishTime field on the dataset, or the latest available measurement time.

        Args:
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DatasetMetadataLatestRow_DatasetResponse: Typed response object
        """
        params = {}
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/metadata/latest", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DatasetMetadataLatestRow_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DatasetMetadataLatestRow_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_lolpdrm(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str,
        format: Optional[str] = None
    ) -> LossOfLoadProbabilityDeratedMarginData_DatasetResponse:
        """
        Loss of load probability and de-rated margin (LOLPDRM)

        The loss of load probability and de-rated margin data is received half-hourly from NGESO.
            
Loss of load probability (LoLP) is a measure of system reliability, calculated by NGESO for each settlement period,
using the methodology set out in the Loss of Load Probability Calculation Statement.
            
De-rated margin is a forecast of the excess supply on the system, which has been adjusted to take account of the likely availability of electricity generators.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            LossOfLoadProbabilityDeratedMarginData_DatasetResponse: Typed response object
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/LOLPDRM", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return LossOfLoadProbabilityDeratedMarginData_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as LossOfLoadProbabilityDeratedMarginData_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_lolpdrm_stream(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str
    ) -> List[LossOfLoadProbabilityDeratedMarginData]:
        """
        Loss of load probability and de-rated margin (LOLPDRM)

        The loss of load probability and de-rated margin data is received half-hourly from NGESO.
            
Loss of load probability (LoLP) is a measure of system reliability, calculated by NGESO for each settlement period,
using the methodology set out in the Loss of Load Probability Calculation Statement.
            
De-rated margin is a forecast of the excess supply on the system, which has been adjusted to take account of the likely availability of electricity generators.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 

        Returns:
            List[LossOfLoadProbabilityDeratedMarginData]: List of LossOfLoadProbabilityDeratedMarginData objects
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/LOLPDRM/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [LossOfLoadProbabilityDeratedMarginData(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[LossOfLoadProbabilityDeratedMarginData]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_cdn(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str,
        bscPartyId: Optional[str] = None,
        format: Optional[str] = None
    ) -> CreditDefaultNoticeDatasetResponse_DatasetResponse:
        """
        Credit default notices (CDN)

        This endpoint provides CDN (Credit Default Notice) data received from ECVAA (Energy Contract Volume Aggregation Agent).

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 
            bscPartyId: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            CreditDefaultNoticeDatasetResponse_DatasetResponse: Typed response object
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo
        if bscPartyId is not None:
            params["bscPartyId"] = bscPartyId
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/CDN", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return CreditDefaultNoticeDatasetResponse_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as CreditDefaultNoticeDatasetResponse_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_cdn_stream(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str,
        bscPartyId: Optional[str] = None
    ) -> List[CreditDefaultNoticeDatasetResponse]:
        """
        Credit default notices (CDN) stream

        This endpoint provides CDN (Credit Default Notice) data received from ECVAA (Energy Contract Volume Aggregation Agent).
            
This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 
            bscPartyId: , optional

        Returns:
            List[CreditDefaultNoticeDatasetResponse]: List of CreditDefaultNoticeDatasetResponse objects
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo
        if bscPartyId is not None:
            params["bscPartyId"] = bscPartyId

        response = self._make_request("GET", f"/datasets/CDN/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [CreditDefaultNoticeDatasetResponse(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[CreditDefaultNoticeDatasetResponse]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_syswarn(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        format: Optional[str] = None
    ) -> SystemWarningsData_DatasetResponse:
        """
        System warnings (SYSWARN)

        This endpoint provides system warnings data

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            SystemWarningsData_DatasetResponse: Typed response object
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/SYSWARN", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return SystemWarningsData_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as SystemWarningsData_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_syswarn_stream(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None
    ) -> List[SystemWarningsData]:
        """
        System warnings (SYSWARN) stream

        This endpoint provides system warnings data

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional

        Returns:
            List[SystemWarningsData]: List of SystemWarningsData objects
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/SYSWARN/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [SystemWarningsData(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[SystemWarningsData]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_dci(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        format: Optional[str] = None
    ) -> DemandControlInstructionDatasetRow_DatasetResponse:
        """
        Demand control instructions (DCI)

        This endpoint provides demand control instruction data, filtered by publish time.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DemandControlInstructionDatasetRow_DatasetResponse: Typed response object
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/DCI", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DemandControlInstructionDatasetRow_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DemandControlInstructionDatasetRow_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_dci_stream(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None
    ) -> List[DemandControlInstructionDatasetRow]:
        """
        Demand control instructions (DCI) stream

        This endpoint provides demand control instruction data, filtered by publish time.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional

        Returns:
            List[DemandControlInstructionDatasetRow]: List of DemandControlInstructionDatasetRow objects
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/DCI/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [DemandControlInstructionDatasetRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[DemandControlInstructionDatasetRow]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_soso(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str,
        format: Optional[str] = None
    ) -> SoSoPricesDatasetRow_DatasetResponse:
        """
        SO-SO prices (SOSO)

        This endpoint provides system operator to system operator prices data, filtered by publish time.
This API endpoint has a maximum range of 24 hours.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            SoSoPricesDatasetRow_DatasetResponse: Typed response object
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/SOSO", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return SoSoPricesDatasetRow_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as SoSoPricesDatasetRow_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_soso_stream(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str
    ) -> List[SoSoPricesDatasetRow]:
        """
        SO-SO prices (SOSO) stream

        This endpoint provides system operator to system operator prices data, filtered by publish time.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 

        Returns:
            List[SoSoPricesDatasetRow]: List of SoSoPricesDatasetRow objects
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/SOSO/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [SoSoPricesDatasetRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[SoSoPricesDatasetRow]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_tudm(
        self,
        settlementDate: str,
        settlementPeriod: int,
        tradingUnitName: Optional[List[str]] = None,
        tradingUnitType: Optional[str] = None,
        format: Optional[str] = None
    ) -> TudmDatasetRow_DatasetResponse:
        """
        Trading unit data (S0491_TUDM)

        This endpoint provides trading unit data for a settlement period filtered by trading unit name and type.

        Args:
            settlementDate: The settlement date to filter. This must be in the format yyyy-MM-dd.
            settlementPeriod: 
            tradingUnitName: , optional
            tradingUnitType: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            TudmDatasetRow_DatasetResponse: Typed response object
        """
        params = {}
        params["settlementDate"] = settlementDate
        params["settlementPeriod"] = settlementPeriod
        if tradingUnitName is not None:
            params["tradingUnitName"] = tradingUnitName
        if tradingUnitType is not None:
            params["tradingUnitType"] = tradingUnitType
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/TUDM", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return TudmDatasetRow_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as TudmDatasetRow_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_tudm_stream(
        self,
        settlementDateFrom: str,
        settlementPeriodFrom: int,
        settlementDateTo: str,
        settlementPeriodTo: int,
        tradingUnitName: Optional[List[str]] = None,
        tradingUnitType: Optional[str] = None
    ) -> List[TudmDatasetRow]:
        """
        Trading unit data (S0491_TUDM) stream

        This endpoint provides trading unit data filtered by settlement period, trading unit name and type.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            settlementDateFrom: The settlement date to filter from. This must be in the format yyyy-MM-dd.
            settlementPeriodFrom: 
            settlementDateTo: The settlement date to filter to. This must be in the format yyyy-MM-dd.
            settlementPeriodTo: 
            tradingUnitName: , optional
            tradingUnitType: , optional

        Returns:
            List[TudmDatasetRow]: List of TudmDatasetRow objects
        """
        params = {}
        params["settlementDateFrom"] = settlementDateFrom
        params["settlementPeriodFrom"] = settlementPeriodFrom
        params["settlementDateTo"] = settlementDateTo
        params["settlementPeriodTo"] = settlementPeriodTo
        if tradingUnitName is not None:
            params["tradingUnitName"] = tradingUnitName
        if tradingUnitType is not None:
            params["tradingUnitType"] = tradingUnitType

        response = self._make_request("GET", f"/datasets/TUDM/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [TudmDatasetRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[TudmDatasetRow]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_rzdf(
        self,
        submissionDateTimeFrom: str,
        submissionDateTimeTo: str,
        region: Optional[str] = None,
        gspGroupId: Optional[str] = None,
        format: Optional[str] = None
    ) -> RestorationZoneDemandForecastDatasetRow_DatasetResponse:
        """
        Restoration Region Demand Forecast (RZDF)

        This endpoint provides the forecasted peak demand values (60% and 100%) for each restoration region with filtering by submission time, region, and GSP Group ID (when received by NESO).
This API endpoint supports up to 12 months range per request.

        Args:
            submissionDateTimeFrom: The submission date and time to filter from. This should be in the format yyyy-MM-dd HH:mm:ssZ.
            submissionDateTimeTo: The submission date and time to filter to. This should be in the format yyyy-MM-dd HH:mm:ssZ.
            region: The region to filter by., optional
            gspGroupId: The GSP Group ID to filter by., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            RestorationZoneDemandForecastDatasetRow_DatasetResponse: Typed response object
        """
        params = {}
        params["submissionDateTimeFrom"] = submissionDateTimeFrom
        params["submissionDateTimeTo"] = submissionDateTimeTo
        if region is not None:
            params["region"] = region
        if gspGroupId is not None:
            params["gspGroupId"] = gspGroupId
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/RZDF", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return RestorationZoneDemandForecastDatasetRow_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as RestorationZoneDemandForecastDatasetRow_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_rzdf_stream(
        self,
        submissionDateTimeFrom: str,
        submissionDateTimeTo: str,
        region: Optional[str] = None,
        gspGroupId: Optional[str] = None
    ) -> List[RestorationZoneDemandForecastDatasetRow]:
        """
        Restoration Region Demand Forecast (RZDF) stream

        This endpoint provides the forecasted peak demand values (60% and 100%) for each restoration region with filtering by submission time, region, and GSP Group ID (when received by NESO).
This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            submissionDateTimeFrom: The submission date and time to filter from. This should be in the format yyyy-MM-dd HH:mm:ssZ.
            submissionDateTimeTo: The submission date and time to filter to. This should be in the format yyyy-MM-dd HH:mm:ssZ.
            region: The region to filter by., optional
            gspGroupId: The GSP Group ID to filter by., optional

        Returns:
            List[RestorationZoneDemandForecastDatasetRow]: List of RestorationZoneDemandForecastDatasetRow objects
        """
        params = {}
        params["submissionDateTimeFrom"] = submissionDateTimeFrom
        params["submissionDateTimeTo"] = submissionDateTimeTo
        if region is not None:
            params["region"] = region
        if gspGroupId is not None:
            params["gspGroupId"] = gspGroupId

        response = self._make_request("GET", f"/datasets/RZDF/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [RestorationZoneDemandForecastDatasetRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[RestorationZoneDemandForecastDatasetRow]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_rzdr(
        self,
        submissionDateTimeFrom: str,
        submissionDateTimeTo: str,
        region: Optional[str] = None,
        gspGroupId: Optional[str] = None,
        format: Optional[str] = None
    ) -> RestorationZoneDemandRestoredDatasetRow_DatasetResponse:
        """
        Restoration Region Demand Restored (RZDR)

        This endpoint provides the restored demand value for each restoration region with filtering by submission time, region, and GSP Group ID (when received by NESO).
This API endpoint supports up to 12 months range per request.

        Args:
            submissionDateTimeFrom: The submission date and time to filter from. This should be in the format yyyy-MM-dd HH:mm:ssZ.
            submissionDateTimeTo: The submission date and time to filter to. This should be in the format yyyy-MM-dd HH:mm:ssZ.
            region: The region to filter by., optional
            gspGroupId: The GSP Group ID to filter by., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            RestorationZoneDemandRestoredDatasetRow_DatasetResponse: Typed response object
        """
        params = {}
        params["submissionDateTimeFrom"] = submissionDateTimeFrom
        params["submissionDateTimeTo"] = submissionDateTimeTo
        if region is not None:
            params["region"] = region
        if gspGroupId is not None:
            params["gspGroupId"] = gspGroupId
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/RZDR", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return RestorationZoneDemandRestoredDatasetRow_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as RestorationZoneDemandRestoredDatasetRow_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_rzdr_stream(
        self,
        submissionDateTimeFrom: str,
        submissionDateTimeTo: str,
        region: Optional[str] = None,
        gspGroupId: Optional[str] = None
    ) -> List[RestorationZoneDemandRestoredDatasetRow]:
        """
        Restoration Region Demand Restored (RZDR) Stream

        This endpoint provides the restored demand value for each restoration region with filtering by submission time, region, and GSP Group ID (when received by NESO).
This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            submissionDateTimeFrom: The submission date and time to filter from. This should be in the format yyyy-MM-dd HH:mm:ssZ.
            submissionDateTimeTo: The submission date and time to filter to. This should be in the format yyyy-MM-dd HH:mm:ssZ.
            region: The region to filter by., optional
            gspGroupId: The GSP Group ID to filter by., optional

        Returns:
            List[RestorationZoneDemandRestoredDatasetRow]: List of RestorationZoneDemandRestoredDatasetRow objects
        """
        params = {}
        params["submissionDateTimeFrom"] = submissionDateTimeFrom
        params["submissionDateTimeTo"] = submissionDateTimeTo
        if region is not None:
            params["region"] = region
        if gspGroupId is not None:
            params["gspGroupId"] = gspGroupId

        response = self._make_request("GET", f"/datasets/RZDR/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [RestorationZoneDemandRestoredDatasetRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[RestorationZoneDemandRestoredDatasetRow]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_sil(
        self,
        from_: Optional[str] = None,
        to_: Optional[str] = None,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> StablePortageLimitData_DatasetResponse:
        """
        Stable Import Limit (SIL)

        This endpoint provides Stable Import Limit data received from NGESO.
Stable Import Limit is a negative megawatt value, expressing the minimum stable operating level at which a particular BM Unit can import power from the transmission system.
            
If no date window is chosen, the search will default to results from last 24 hours.

        Args:
            from_: The start of the data time window., optional
            to_: The end of the data time window., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            StablePortageLimitData_DatasetResponse: Typed response object
        """
        params = {}
        if from_ is not None:
            params["from"] = from_
        if to_ is not None:
            params["to"] = to_
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/SIL", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return StablePortageLimitData_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as StablePortageLimitData_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_sil_stream(
        self,
        from_: Optional[str] = None,
        to_: Optional[str] = None,
        bmUnit: Optional[List[str]] = None
    ) -> List[StablePortageLimitData]:
        """
        Stable Import Limit (SIL) stream

        This endpoint provides Stable Import Limit data received from NGESO.
Stable Import Limit is a negative megawatt value, expressing the minimum stable operating level at which a particular BM Unit can import power from the transmission system.
            
If no date window is chosen, the search will default to results from last 24 hours.
            
This endpoint has an optimised JSON payload and is aimed at frequent requests for SIL data.

        Args:
            from_: The start of the data time window., optional
            to_: The end of the data time window., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional

        Returns:
            List[StablePortageLimitData]: List of StablePortageLimitData objects
        """
        params = {}
        if from_ is not None:
            params["from"] = from_
        if to_ is not None:
            params["to"] = to_
        if bmUnit is not None:
            params["bmUnit"] = bmUnit

        response = self._make_request("GET", f"/datasets/SIL/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [StablePortageLimitData(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[StablePortageLimitData]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_sel(
        self,
        from_: Optional[str] = None,
        to_: Optional[str] = None,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> StablePortageLimitData_DatasetResponse:
        """
        Stable Export Limit (SEL)

        This endpoint provides Stable Export Limit data received from NGESO.
Stable Export Limit is a positive megawatt value, expressing the minimum stable operating level at which a particular BM Unit can export power to the transmission system.
            
If no date window is chosen, the search will default to results from last 24 hours.

        Args:
            from_: The start of the data time window., optional
            to_: The end of the data time window., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            StablePortageLimitData_DatasetResponse: Typed response object
        """
        params = {}
        if from_ is not None:
            params["from"] = from_
        if to_ is not None:
            params["to"] = to_
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/SEL", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return StablePortageLimitData_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as StablePortageLimitData_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_sel_stream(
        self,
        from_: Optional[str] = None,
        to_: Optional[str] = None,
        bmUnit: Optional[List[str]] = None
    ) -> List[StablePortageLimitData]:
        """
        Stable Export Limit (SEL) stream

        This endpoint provides Stable Export Limit data received from NGESO.
Stable Export Limit is a positive megawatt value, expressing the minimum stable operating level at which a particular BM Unit can export power to the transmission system.
            
If no date window is chosen, the search will default to results from last 24 hours.
            
This endpoint has an optimised JSON payload and is aimed at frequent requests for SEL data.

        Args:
            from_: The start of the data time window., optional
            to_: The end of the data time window., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional

        Returns:
            List[StablePortageLimitData]: List of StablePortageLimitData objects
        """
        params = {}
        if from_ is not None:
            params["from"] = from_
        if to_ is not None:
            params["to"] = to_
        if bmUnit is not None:
            params["bmUnit"] = bmUnit

        response = self._make_request("GET", f"/datasets/SEL/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [StablePortageLimitData(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[StablePortageLimitData]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_mzt(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> DeliveryPeriodMinData_DatasetResponse:
        """
        Minimum Zero Time (MZT)

        This endpoint provides Minimum Zero Time data received from NGESO.

The Minimum Zero Time is the minimum time that a BM Unit which has been exporting must operate at zero or import, before returning to export;
whereas if the BM Unit has been importing, the MZT indicates the minimum time that it must operate at zero or export before returning to import,
if action by the System Operator (i.e. a Bid-Offer Acceptance) places it at such a level.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/MZT?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/MZT?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/MZT?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/MZT?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DeliveryPeriodMinData_DatasetResponse: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/MZT", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DeliveryPeriodMinData_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DeliveryPeriodMinData_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_mzt_stream(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None
    ) -> List[DeliveryPeriodMinData]:
        """
        Minimum Zero Time (MZT) stream

        This endpoint provides Minimum Zero Time data received from NGESO.

The Minimum Zero Time is the minimum time that a BM Unit which has been exporting must operate at zero or import, before returning to export;
whereas if the BM Unit has been importing, the MZT indicates the minimum time that it must operate at zero or export before returning to import,
if action by the System Operator (i.e. a Bid-Offer Acceptance) places it at such a level.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
  /// All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/MZT/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/MZT/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/MZT/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/MZT/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

This endpoint has an optimised JSON payload and is aimed at frequent requests for MZT data.

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional

        Returns:
            List[DeliveryPeriodMinData]: List of DeliveryPeriodMinData objects
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit

        response = self._make_request("GET", f"/datasets/MZT/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [DeliveryPeriodMinData(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[DeliveryPeriodMinData]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_mnzt(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> DeliveryPeriodMinData_DatasetResponse:
        """
        Minimum Non-Zero Time (MNZT)

        This endpoint provides Minimum Non Zero Time data received from NGESO.

The Minimum Non-Zero Time represents the minimum time that a BM Unit can operate at a non-zero level as a result of a Bid-Offer Acceptance.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/MNZT?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/MNZT?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/MNZT?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/MNZT?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DeliveryPeriodMinData_DatasetResponse: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/MNZT", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DeliveryPeriodMinData_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DeliveryPeriodMinData_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_mnzt_stream(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None
    ) -> List[DeliveryPeriodMinData]:
        """
        Minimum Non-Zero Time (MNZT) stream

        This endpoint provides Minimum Non Zero Time data received from NGESO.

The Minimum Non-Zero Time represents the minimum time that a BM Unit can operate at a non-zero level as a result of a Bid-Offer Acceptance.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/MNZT/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/MNZT/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/MNZT/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/MNZT/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1
            
This endpoint has an optimised JSON payload and is aimed at frequent requests for MNZT data.

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional

        Returns:
            List[DeliveryPeriodMinData]: List of DeliveryPeriodMinData objects
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit

        response = self._make_request("GET", f"/datasets/MNZT/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [DeliveryPeriodMinData(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[DeliveryPeriodMinData]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_mdv(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> DeliveryVolumeMaxData_DatasetResponse:
        """
        Maximum Delivery Volume (MDV)

        This endpoint provides Maximum Delivery Volume data received from NGESO.
            
Maximum Delivery Volume is the maximum number of MWh of Offer (or Bid), that a particular BM Unit
may deliver within the associated Maximum Delivery Period.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/MDV?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/MDV?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/MDV?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/MDV?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DeliveryVolumeMaxData_DatasetResponse: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/MDV", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DeliveryVolumeMaxData_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DeliveryVolumeMaxData_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_mdv_stream(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None
    ) -> List[DeliveryVolumeMaxData]:
        """
        Maximum Delivery Volume (MDV) stream

        This endpoint provides Maximum Delivery Volume data received from NGESO.
            
Maximum Delivery Volume is the maximum number of MWh of Offer (or Bid), that a particular BM Unit
may deliver within the associated Maximum Delivery Period.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/MDV/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/MDV/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/MDV/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/MDV/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

This endpoint has an optimised JSON payload and is aimed at frequent requests for MDV data.

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional

        Returns:
            List[DeliveryVolumeMaxData]: List of DeliveryVolumeMaxData objects
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit

        response = self._make_request("GET", f"/datasets/MDV/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [DeliveryVolumeMaxData(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[DeliveryVolumeMaxData]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_mdp(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> DeliveryPeriodMaxData_DatasetResponse:
        """
        Maximum Delivery Period (MDP)

        Maximum Delivery Period (MDP) is the maximum period, expressed in minutes, over which the
Maximum Delivery Volume (MDV) applies. Maximum Delivery Volume is the maximum number of MWh of Offer (or Bid)
that a particular BM Unit may deliver within the associated Maximum Delivery Period.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/MDP?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/MDP?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/MDP?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/MDP?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DeliveryPeriodMaxData_DatasetResponse: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/MDP", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DeliveryPeriodMaxData_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DeliveryPeriodMaxData_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_mdp_stream(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None
    ) -> List[DeliveryPeriodMaxData]:
        """
        Maximum Delivery Period (MDP) stream

        This endpoint provides Maximum Delivery Period data received from NGESO.
            
Maximum Delivery Period (MDP) is the maximum period over which the Maximum Delivery Volume (MDV) applies.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/MDP/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/MDP/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/MDP/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/MDP/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

This endpoint has an optimised JSON payload and is aimed at frequent requests for MDP data.

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional

        Returns:
            List[DeliveryPeriodMaxData]: List of DeliveryPeriodMaxData objects
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit

        response = self._make_request("GET", f"/datasets/MDP/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [DeliveryPeriodMaxData(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[DeliveryPeriodMaxData]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_ntb(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> NoticeData_DatasetResponse:
        """
        Notice to Deliver Bids (NTB)

        This endpoint provides Notice to Deliver Bids data received from NGESO.
            
Notice to Deliver Bids (NTB) indicates the length of time between the issuing of a Bid-Offer Acceptance and the
time when a BM Unit begins to deliver Bid volumes, expressed in minutes.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/NTB?from=2022-06-01T00:00Z&to=2022-06-08T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/NTB?from=2022-06-01T00:00Z&to=2022-06-08T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/NTB?from=2022-06-01T00:00Z&to=2022-06-08T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/NTB?from=2022-06-01T00:00Z&to=2022-06-08T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            NoticeData_DatasetResponse: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/NTB", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return NoticeData_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as NoticeData_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_ntb_stream(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None
    ) -> List[NoticeData]:
        """
        Notice to Deliver Bids (NTB) stream

        This endpoint provides Notice to Deliver Bids data received from NGESO.
            
Notice to Deliver Bids (NTB) indicates the length of time between the issuing of a Bid-Offer Acceptance and the
time when a BM Unit begins to deliver Bid volumes, expressed in minutes.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/NTB/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/NTB/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/NTB/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/NTB/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

This endpoint has an optimised JSON payload and is aimed at frequent requests for NTB data.

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional

        Returns:
            List[NoticeData]: List of NoticeData objects
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit

        response = self._make_request("GET", f"/datasets/NTB/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [NoticeData(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[NoticeData]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_nto(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> NoticeData_DatasetResponse:
        """
        Notice to Deliver Offers (NTO)

        This endpoint provides Notice to Deliver Offers data received from NGESO.
            
Notice to Deliver Offers (NTO) indicates the length of time required for a BM Unit to start delivering Offers
from the time that the Bid-Offer Acceptance is issued, expressed in minutes.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/NTO?from=2022-06-01T00:00Z&to=2022-06-08T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/NTO?from=2022-06-01T00:00Z&to=2022-06-08T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/NTO?from=2022-06-01T00:00Z&to=2022-06-08T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/NTO?from=2022-06-01T00:00Z&to=2022-06-08T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            NoticeData_DatasetResponse: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/NTO", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return NoticeData_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as NoticeData_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_nto_stream(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None
    ) -> List[NoticeData]:
        """
        Notice to Deliver Offers (NTO) stream

        This endpoint provides Notice to Deliver Offers data received from NGESO.
            
Notice to Deliver Offers (NTO) indicates the length of time required for a BM Unit to start delivering Offers
from the time that the Bid-Offer Acceptance is issued, expressed in minutes.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/NTO/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/NTO/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/NTO/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/NTO/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

This endpoint has an optimised JSON payload and is aimed at frequent requests for NTO data.

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional

        Returns:
            List[NoticeData]: List of NoticeData objects
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit

        response = self._make_request("GET", f"/datasets/NTO/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [NoticeData(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[NoticeData]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_ndz(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> NoticeData_DatasetResponse:
        """
        Notice to Deviate from Zero (NDZ)

        This endpoint provides Notice to Deviate from Zero data received from NGESO.
            
Notice to Deviate from Zero (NDZ) indicates the length of time required for a BM Unit to start importing or
exporting energy, from a zero Physical Notification level as a result of a Bid-Offer Acceptance, expressed in
minutes.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/NDZ?from=2022-06-01T00:00Z&to=2022-06-08T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/NDZ?from=2022-06-01T00:00Z&to=2022-06-08T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/NDZ?from=2022-06-01T00:00Z&to=2022-06-08T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/NDZ?from=2022-06-01T00:00Z&to=2022-06-08T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            NoticeData_DatasetResponse: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/NDZ", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return NoticeData_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as NoticeData_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_ndz_stream(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None
    ) -> List[NoticeData]:
        """
        Notice to Deviate from Zero (NDZ) stream

        This endpoint provides Notice to Deviate from Zero data received from NGESO.
            
Notice to Deviate from Zero (NDZ) indicates the length of time required for a BM Unit to start importing or
exporting energy, from a zero Physical Notification level as a result of a Bid-Offer Acceptance, expressed in
minutes.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/NDZ/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/NDZ/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/NDZ/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/NDZ/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

This endpoint has an optimised JSON payload and is aimed at frequent requests for NDZ data.

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional

        Returns:
            List[NoticeData]: List of NoticeData objects
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit

        response = self._make_request("GET", f"/datasets/NDZ/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [NoticeData(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[NoticeData]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_rure(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> RateData_DatasetResponse:
        """
        Run Up Rate Export (RURE)

        This endpoint provides Run Up Rate Export data received from NGESO.
            
Run Up Rate Export (RURE) expresses the rate of increase in active power production (MW/minute)
for a particular BM Unit which is exporting power within a particular operating range.
There can be up to three of these for a given BM Unit.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/rure?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/rure?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/rure?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/rure?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            RateData_DatasetResponse: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/RURE", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return RateData_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as RateData_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_rure_stream(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None
    ) -> List[RateData]:
        """
        Run Up Rate Export (RURE) stream

        This endpoint provides Run Up Rate Export data received from NGESO.
            
Run Up Rate Export (RURE) expresses the rate of increase in active power production (MW/minute)
for a particular BM Unit which is exporting power within a particular operating range.
There can be up to three of these for a given BM Unit.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/rure/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/rure/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/rure/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/rure/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

This endpoint has an optimised JSON payload and is aimed at frequent requests for QAS data.

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional

        Returns:
            List[RateData]: List of RateData objects
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit

        response = self._make_request("GET", f"/datasets/RURE/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [RateData(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[RateData]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_rdre(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> RateData_DatasetResponse:
        """
        Run Down Rate Export (RDRE)

        This endpoint provides Run Down Rate Export data received from NGESO.
            
Run Down Rate Export (RDRE) expresses the rate of decrease in active power production (MW/minute)
for a particular BM Unit which is exporting power within a particular operating range. 
There can be up to three of these for a given BM Unit.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/rdre?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/rdre?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/rdre?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/rdre?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            RateData_DatasetResponse: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/RDRE", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return RateData_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as RateData_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_rdre_stream(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None
    ) -> List[RateData]:
        """
        Run Down Rate Export (RDRE) stream

        This endpoint provides Run Down Rate Export data received from NGESO.
            
Run Down Rate Export (RDRE) expresses the rate of decrease in active power production (MW/minute)
for a particular BM Unit which is exporting power within a particular operating range. 
There can be up to three of these for a given BM Unit.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/rdre/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/rdre/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/rdre/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/rdre/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

This endpoint has an optimised JSON payload and is aimed at frequent requests for QAS data.

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional

        Returns:
            List[RateData]: List of RateData objects
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit

        response = self._make_request("GET", f"/datasets/RDRE/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [RateData(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[RateData]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_ruri(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> RateData_DatasetResponse:
        """
        Run Up Rate Import (RURI)

        This endpoint provides Run Up Rate Import data received from NGESO.
            
Run Up Rate Import (RURI) expresses the rate of decrease in active power consumption (MW/minute)
for a particular BM Unit which is importing power within a particular operating range.
There can be up to three of these for a given BM Unit.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/ruri?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/ruri?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/ruri?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/ruri?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            RateData_DatasetResponse: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/RURI", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return RateData_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as RateData_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_ruri_stream(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None
    ) -> List[RateData]:
        """
        Run Up Rate Import (RURI) stream

        This endpoint provides Run Up Rate Import data received from NGESO.
            
Run Up Rate Import (RURI) expresses the rate of decrease in active power consumption (MW/minute)
for a particular BM Unit which is importing power within a particular operating range. 
There can be up to three of these for a given BM Unit.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/ruri/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/ruri/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/ruri/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/ruri/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

This endpoint has an optimised JSON payload and is aimed at frequent requests for QAS data.

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional

        Returns:
            List[RateData]: List of RateData objects
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit

        response = self._make_request("GET", f"/datasets/RURI/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [RateData(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[RateData]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_rdri(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> RateData_DatasetResponse:
        """
        Run Down Rate Import (RDRI)

        This endpoint provides Run Down Rate Import data received from NGESO.
            
Run Down Rate Import (RDRI) expresses the rate of increase in active power consumption (MW/minute)
for a particular BM Unit which is importing power within a particular operating range.
There can be up to three of these for a given BM Unit.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/rdri?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/rdri?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/rdri?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/rdri?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            RateData_DatasetResponse: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/RDRI", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return RateData_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as RateData_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_rdri_stream(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None
    ) -> List[RateData]:
        """
        Run Down Rate Import (RDRI) stream

        This endpoint provides Run Down Rate Import data received from NGESO.
            
Run Down Rate Import (RDRI) expresses the rate of increase in active power consumption (MW/minute)
for a particular BM Unit which is importing power within a particular operating range. 
There can be up to three of these for a given BM Unit.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /datasets/rdri/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /datasets/rdri/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /datasets/rdri/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /datasets/rdri/stream?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

This endpoint has an optimised JSON payload and is aimed at frequent requests for QAS data.

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional

        Returns:
            List[RateData]: List of RateData objects
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit

        response = self._make_request("GET", f"/datasets/RDRI/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [RateData(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[RateData]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_remit(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str,
        format: Optional[str] = None
    ) -> RemitMessage_DatasetResponse:
        """
        The Regulation on Wholesale Energy Markets Integrity and Transparency (REMIT)

        The Regulation on Wholesale Energy Markets Integrity and Transparency (REMIT) is an EU regulation aimed at preventing market abuse in wholesale energy markets.

This endpoint returns information provided by market participants to comply with Article 4 of Regulation on Wholesale Energy Market Integrity and Transparency (REMIT) Regulation (EU) 1227/2011.
            
Only JSON and XML formats are supported for this endpoint.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            RemitMessage_DatasetResponse: Typed response object
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/REMIT", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return RemitMessage_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as RemitMessage_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_remit_stream(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str
    ) -> List[RemitMessage]:
        """
        The Regulation on Wholesale Energy Markets Integrity and Transparency (REMIT) stream

        The Regulation on Wholesale Energy Markets Integrity and Transparency (REMIT) is an EU regulation aimed at preventing market abuse in wholesale energy markets.

This endpoint returns information provided by market participants to comply with Article 4 of Regulation on Wholesale Energy Market Integrity and Transparency (REMIT) Regulation (EU) 1227/2011.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 

        Returns:
            List[RemitMessage]: List of RemitMessage objects
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/REMIT/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [RemitMessage(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[RemitMessage]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_agws(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str,
        format: Optional[str] = None
    ) -> ActualGenerationWindSolarDatasetRow_DatasetResponse:
        """
        Actual Or Estimated Wind And Solar Power Generation (AGWS / B1630)

        This endpoint provides actual or estimated wind and solar power generation
per settlement period. It returns generation with Power System Resource type
Solar, Wind Onshore or Wind Offshore (Fuel Type categories as defined by
Commission Regulation (EU) No 543/2013).
            
This API endpoint provides a maximum data output range of 7 days.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            ActualGenerationWindSolarDatasetRow_DatasetResponse: Typed response object
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/AGWS", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return ActualGenerationWindSolarDatasetRow_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as ActualGenerationWindSolarDatasetRow_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_agws_stream(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str
    ) -> List[ActualGenerationWindSolarDatasetRow]:
        """
        Actual Or Estimated Wind And Solar Power Generation (AGWS / B1630) stream

        This endpoint provides actual or estimated wind and solar power generation
per settlement period. It returns generation with Power System Resource type
Solar, Wind Onshore or Wind Offshore (Fuel Type categories as defined by
Commission Regulation (EU) No 543/2013).
            
This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 

        Returns:
            List[ActualGenerationWindSolarDatasetRow]: List of ActualGenerationWindSolarDatasetRow objects
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/AGWS/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [ActualGenerationWindSolarDatasetRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[ActualGenerationWindSolarDatasetRow]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_dgws(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str,
        format: Optional[str] = None
    ) -> DayAheadGenerationForWindAndSolarDatasetRow_DatasetResponse:
        """
        Day-Ahead Generation For Wind And Solar (DGWS / B1440)

        This endpoint provides day-ahead generation data for wind and solar.

This API endpoint provides a maximum data output range of 7 days.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DayAheadGenerationForWindAndSolarDatasetRow_DatasetResponse: Typed response object
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/DGWS", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DayAheadGenerationForWindAndSolarDatasetRow_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DayAheadGenerationForWindAndSolarDatasetRow_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_dgws_stream(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str
    ) -> List[DayAheadGenerationForWindAndSolarDatasetRow]:
        """
        Day-Ahead Generation For Wind And Solar (DGWS / B1440) stream

        This endpoint provides day-ahead generation data for wind and solar.
            
This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 

        Returns:
            List[DayAheadGenerationForWindAndSolarDatasetRow]: List of DayAheadGenerationForWindAndSolarDatasetRow objects
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/DGWS/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [DayAheadGenerationForWindAndSolarDatasetRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[DayAheadGenerationForWindAndSolarDatasetRow]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_agpt(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str,
        format: Optional[str] = None
    ) -> ActualAggregatedGenerationPerTypeDatasetRow_DatasetResponse:
        """
        Actual Aggregated Generation Per Type (AGPT / B1620)

        This endpoint provides actual generation data per settlement period aggregated by Power System Resource type (Fuel Type categories as defined by Commission Regulation (EU) No 543/2013).
            
This endpoint filters by publishTime and provides a maximum data output range of 4 days.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            ActualAggregatedGenerationPerTypeDatasetRow_DatasetResponse: Typed response object
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/AGPT", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return ActualAggregatedGenerationPerTypeDatasetRow_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as ActualAggregatedGenerationPerTypeDatasetRow_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_agpt_stream(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str
    ) -> List[ActualAggregatedGenerationPerTypeDatasetRow]:
        """
        Actual Aggregated Generation Per Type (AGPT / B1620) stream

        This endpoint provides actual generation data per settlement period aggregated by Power System Resource type (Fuel Type categories as defined by Commission Regulation (EU) No 543/2013).
            
This endpoint filters by publishTime and has an optimised JSON payload aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 

        Returns:
            List[ActualAggregatedGenerationPerTypeDatasetRow]: List of ActualAggregatedGenerationPerTypeDatasetRow objects
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/AGPT/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [ActualAggregatedGenerationPerTypeDatasetRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[ActualAggregatedGenerationPerTypeDatasetRow]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_b1610(
        self,
        settlementDate: str,
        settlementPeriod: int,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> ActualGenerationOutputPerGenerationUnitDatasetResponse_DatasetResponse:
        """
        Actual Generation Output Per Generation Unit (B1610)

        This endpoint provides the actual metered volume output (MWh) per Settlement Period for all BM units (Positive, Negative or zero MWh values).
            
The settlement period to query must be specified as a date and settlement period. The date must be given in the format yyyy-MM-dd.
            
The information is published five days after the end of the operational period based on the Interim Information (II) Settlement Run and the data is refreshed by subsequent Settlement Runs.
            
The generation output returned by this endpoint is the metered volume and not the instantaneous power output as often appears in other specifications.

        Args:
            settlementDate: 
            settlementPeriod: 
            bmUnit: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            ActualGenerationOutputPerGenerationUnitDatasetResponse_DatasetResponse: Typed response object
        """
        params = {}
        params["settlementDate"] = settlementDate
        params["settlementPeriod"] = settlementPeriod
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/B1610", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return ActualGenerationOutputPerGenerationUnitDatasetResponse_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as ActualGenerationOutputPerGenerationUnitDatasetResponse_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_b1610_stream(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None
    ) -> List[ActualGenerationOutputPerGenerationUnitDatasetResponse]:
        """
        Actual Generation Output Per Generation Unit (B1610) stream

        This endpoint provides the actual metered volume output (MWh) per Settlement Period for all BM units (Positive, Negative or zero MWh values).
            
The information is published five days after the end of the operational period based on the Interim Information (II) Settlement Run and the data is refreshed by subsequent Settlement Runs.
            
The generation output returned by this endpoint is the metered volume and not the instantaneous power output as often appears in other specifications.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: , optional

        Returns:
            List[ActualGenerationOutputPerGenerationUnitDatasetResponse]: List of ActualGenerationOutputPerGenerationUnitDatasetResponse objects
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit

        response = self._make_request("GET", f"/datasets/B1610/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [ActualGenerationOutputPerGenerationUnitDatasetResponse(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[ActualGenerationOutputPerGenerationUnitDatasetResponse]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_igca(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str,
        format: Optional[str] = None
    ) -> IgcaDatasetRow_DatasetResponse:
        """
        Installed Generation Capacity Aggregated (IGCA / B1410)

        This endpoint provides installed generation capacity aggregated data.

This API endpoint provides a maximum data output range of 2 years (731 days).

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            IgcaDatasetRow_DatasetResponse: Typed response object
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/IGCA", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return IgcaDatasetRow_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as IgcaDatasetRow_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_igca_stream(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str
    ) -> List[IgcaDatasetRow]:
        """
        Installed Generation Capacity Aggregated (IGCA / B1410) stream

        This endpoint provides installed generation capacity aggregated data.
            
This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 

        Returns:
            List[IgcaDatasetRow]: List of IgcaDatasetRow objects
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/IGCA/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [IgcaDatasetRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[IgcaDatasetRow]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_igcpu(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str,
        format: Optional[str] = None
    ) -> IgcpuDatasetRow_DatasetResponse:
        """
        Installed Generation Capacity per Unit (IGCPU / B1420)

        This endpoint provides information about production units (existing and planned)
with an installed generation capacity equaling to or exceeding 100 MW. 
            
The database was populated from a data dump lacking publishTime values,
all entries were assigned a default publishTime of 2023-01-01 00:00 during the migration.

This API endpoint provides a maximum data output range of 2 years (731 days).

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            IgcpuDatasetRow_DatasetResponse: Typed response object
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/IGCPU", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return IgcpuDatasetRow_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as IgcpuDatasetRow_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_igcpu_stream(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str
    ) -> List[IgcpuDatasetRow]:
        """
        Installed Generation Capacity per Unit (IGCPU / B1420) stream

        This endpoint provides information about production units (existing and planned)
with an installed generation capacity equaling to or exceeding 100 MW. 
            
The database was populated from a data dump lacking publishTime values,
all entries were assigned a default publishTime of 2023-01-01 00:00 during the migration.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 

        Returns:
            List[IgcpuDatasetRow]: List of IgcpuDatasetRow objects
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/IGCPU/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [IgcpuDatasetRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[IgcpuDatasetRow]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_atl(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str,
        format: Optional[str] = None
    ) -> ActualTotalLoadPerBiddingZoneDatasetRow_DatasetResponse:
        """
        Actual Total Load Per Bidding Zone (ATL / B0610)

        This endpoint provides actual total load per bidding zone data.

This API endpoint provides a maximum data output range of 7 days.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            ActualTotalLoadPerBiddingZoneDatasetRow_DatasetResponse: Typed response object
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/ATL", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return ActualTotalLoadPerBiddingZoneDatasetRow_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as ActualTotalLoadPerBiddingZoneDatasetRow_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_atl_stream(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str
    ) -> List[ActualTotalLoadPerBiddingZoneDatasetRow]:
        """
        Actual Total Load Per Bidding Zone (ATL / B0610) stream

        This endpoint provides actual total load per bidding zone data.
            
This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 

        Returns:
            List[ActualTotalLoadPerBiddingZoneDatasetRow]: List of ActualTotalLoadPerBiddingZoneDatasetRow objects
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/ATL/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [ActualTotalLoadPerBiddingZoneDatasetRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[ActualTotalLoadPerBiddingZoneDatasetRow]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_datl(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str,
        format: Optional[str] = None
    ) -> DayAheadTotalLoadPerBiddingZoneDatasetRow_DatasetResponse:
        """
        Day-Ahead Total Load Forecast Per Bidding Zone (DATL / B0620)

        This endpoint provides day-ahead total load forecast per bidding zone data.

This API endpoint provides a maximum data output range of 7 days.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DayAheadTotalLoadPerBiddingZoneDatasetRow_DatasetResponse: Typed response object
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/DATL", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DayAheadTotalLoadPerBiddingZoneDatasetRow_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DayAheadTotalLoadPerBiddingZoneDatasetRow_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_datl_stream(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str
    ) -> List[DayAheadTotalLoadPerBiddingZoneDatasetRow]:
        """
        Day-Ahead Total Load Forecast Per Bidding Zone (DATL / B0620) stream

        This endpoint provides day-ahead total load forecast per bidding zone data.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 

        Returns:
            List[DayAheadTotalLoadPerBiddingZoneDatasetRow]: List of DayAheadTotalLoadPerBiddingZoneDatasetRow objects
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/DATL/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [DayAheadTotalLoadPerBiddingZoneDatasetRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[DayAheadTotalLoadPerBiddingZoneDatasetRow]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_watl(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str,
        format: Optional[str] = None
    ) -> WeekAheadTotalLoadPerBiddingZoneDatasetRow_DatasetResponse:
        """
        Week-Ahead Total Load Forecast Per Bidding Zone (WATL / B0630)

        This endpoint provides week-ahead total load forecast per bidding zone data with minimum possible
and maximum available loads provided in MW values.

This API endpoint has a maximum range of 367 days.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            WeekAheadTotalLoadPerBiddingZoneDatasetRow_DatasetResponse: Typed response object
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/WATL", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return WeekAheadTotalLoadPerBiddingZoneDatasetRow_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as WeekAheadTotalLoadPerBiddingZoneDatasetRow_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_watl_stream(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str
    ) -> List[WeekAheadTotalLoadPerBiddingZoneDatasetRow]:
        """
        Week-Ahead Total Load Forecast Per Bidding Zone (WATL / B0630) stream

        This endpoint provides week-ahead total load forecast per bidding zone data with minimum possible
and maximum available loads provided in MW values.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 

        Returns:
            List[WeekAheadTotalLoadPerBiddingZoneDatasetRow]: List of WeekAheadTotalLoadPerBiddingZoneDatasetRow objects
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/WATL/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [WeekAheadTotalLoadPerBiddingZoneDatasetRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[WeekAheadTotalLoadPerBiddingZoneDatasetRow]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_dag(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str,
        format: Optional[str] = None
    ) -> DayAheadAggregatedGenerationDatasetRow_DatasetResponse:
        """
        Day-Ahead Aggregated Generation (DAG / B1430)

        This endpoint provides day-ahead aggregated generation data.
            
It has a maximum date range of 7 days.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DayAheadAggregatedGenerationDatasetRow_DatasetResponse: Typed response object
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/DAG", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DayAheadAggregatedGenerationDatasetRow_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DayAheadAggregatedGenerationDatasetRow_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_dag_stream(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str
    ) -> List[DayAheadAggregatedGenerationDatasetRow]:
        """
        Day-Ahead Aggregated Generation (DAG / B1430) stream

        This endpoint provides day-ahead aggregated generation data.
            
This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 

        Returns:
            List[DayAheadAggregatedGenerationDatasetRow]: List of DayAheadAggregatedGenerationDatasetRow objects
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/DAG/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [DayAheadAggregatedGenerationDatasetRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[DayAheadAggregatedGenerationDatasetRow]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_matl(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str,
        format: Optional[str] = None
    ) -> MonthAheadTotalLoadPerBiddingZoneDatasetRow_DatasetResponse:
        """
        Month-Ahead Total Load Forecast Per Bidding Zone (MATL / B0640)

        This endpoint provides month-ahead total load per bidding zone forecast data with minimum possible
and maximum available loads provided in MW values.

This API endpoint has a maximum range of 367 days.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            MonthAheadTotalLoadPerBiddingZoneDatasetRow_DatasetResponse: Typed response object
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/MATL", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return MonthAheadTotalLoadPerBiddingZoneDatasetRow_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as MonthAheadTotalLoadPerBiddingZoneDatasetRow_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_matl_stream(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str
    ) -> List[MonthAheadTotalLoadPerBiddingZoneDatasetRow]:
        """
        Month-Ahead Total Load Forecast Per Bidding Zone (MATL / B0640) stream

        This endpoint provides month-ahead total load per bidding zone forecast data with minimum possible
and maximum available loads provided in MW values.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 

        Returns:
            List[MonthAheadTotalLoadPerBiddingZoneDatasetRow]: List of MonthAheadTotalLoadPerBiddingZoneDatasetRow objects
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/MATL/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [MonthAheadTotalLoadPerBiddingZoneDatasetRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[MonthAheadTotalLoadPerBiddingZoneDatasetRow]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_yatl(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str,
        format: Optional[str] = None
    ) -> YearAheadTotalLoadPerBiddingZoneDatasetRow_DatasetResponse:
        """
        Year-Ahead Total Load Forecast Per Bidding Zone (YATL / B0650)

        This endpoint provides year-ahead total load per bidding zone forecast data with minimum possible
and maximum available loads provided in MW values.

This API endpoint has a maximum range of 367 days.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            YearAheadTotalLoadPerBiddingZoneDatasetRow_DatasetResponse: Typed response object
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/YATL", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return YearAheadTotalLoadPerBiddingZoneDatasetRow_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as YearAheadTotalLoadPerBiddingZoneDatasetRow_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_yatl_stream(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str
    ) -> List[YearAheadTotalLoadPerBiddingZoneDatasetRow]:
        """
        Year-Ahead Total Load Forecast Per Bidding Zone (YATL / B0650) stream

        This endpoint provides year-ahead total load per bidding zone forecast data with minimum possible
and maximum available loads provided in MW values.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 

        Returns:
            List[YearAheadTotalLoadPerBiddingZoneDatasetRow]: List of YearAheadTotalLoadPerBiddingZoneDatasetRow objects
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/YATL/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [YearAheadTotalLoadPerBiddingZoneDatasetRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[YearAheadTotalLoadPerBiddingZoneDatasetRow]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_ccm(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str,
        format: Optional[str] = None
    ) -> CostsOfCongestionManagementDatasetRow_DatasetResponse:
        """
        Cost of Congestion Management (CCM / B1330)

        This endpoint provides cost of congestion management data.

This API endpoint has a maximum range of 2 years (731 days).

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            CostsOfCongestionManagementDatasetRow_DatasetResponse: Typed response object
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/CCM", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return CostsOfCongestionManagementDatasetRow_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as CostsOfCongestionManagementDatasetRow_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_ccm_stream(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str
    ) -> List[CostsOfCongestionManagementDatasetRow]:
        """
        Cost of Congestion Management (CCM / B1330) stream

        This endpoint provides cost of congestion management data.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 

        Returns:
            List[CostsOfCongestionManagementDatasetRow]: List of CostsOfCongestionManagementDatasetRow objects
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/CCM/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [CostsOfCongestionManagementDatasetRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[CostsOfCongestionManagementDatasetRow]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_yafm(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str,
        format: Optional[str] = None
    ) -> YearAheadForecastMarginDatasetRow_DatasetResponse:
        """
        Year Ahead Forecast Margin (YAFM / B0810)

        This endpoint provides year-ahead forecast margin data.
            
A year-ahead forecast margin is defined as the difference between yearly forecast of available generation capacity and yearly forecast of total load,
taking into account the forecast of total generation capacity, forecast of availability of generation and forecast of reserves contracted for system services.

This API endpoint has a maximum range of 20 years (7305 days).

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            YearAheadForecastMarginDatasetRow_DatasetResponse: Typed response object
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/YAFM", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return YearAheadForecastMarginDatasetRow_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as YearAheadForecastMarginDatasetRow_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_yafm_stream(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str
    ) -> List[YearAheadForecastMarginDatasetRow]:
        """
        Year Ahead Forecast Margin (YAFM / B0810) stream

        This endpoint provides year-ahead forecast margin data.

A year-ahead forecast margin is defined as the difference between yearly forecast of available generation capacity and yearly forecast of total load,
taking into account the forecast of total generation capacity, forecast of availability of generation and forecast of reserves contracted for system services.
            
This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 

        Returns:
            List[YearAheadForecastMarginDatasetRow]: List of YearAheadForecastMarginDatasetRow objects
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/YAFM/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [YearAheadForecastMarginDatasetRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[YearAheadForecastMarginDatasetRow]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_abuc(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str,
        format: Optional[str] = None
    ) -> AbucDatasetRow_DatasetResponse:
        """
        Amount Of Balancing Reserves Under Contract (ABUC / B1720)

        This endpoint provides amount of balancing reserves under contract data.

This API endpoint has a maximum range of 2 years (731 days).

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            AbucDatasetRow_DatasetResponse: Typed response object
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/ABUC", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return AbucDatasetRow_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as AbucDatasetRow_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_abuc_stream(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str
    ) -> List[AbucDatasetRow]:
        """
        Amount Of Balancing Reserves Under Contract (ABUC / B1720) stream

        This endpoint provides amount of balancing reserves under contract data.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 

        Returns:
            List[AbucDatasetRow]: List of AbucDatasetRow objects
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/ABUC/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [AbucDatasetRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[AbucDatasetRow]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_ppbr(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str,
        format: Optional[str] = None
    ) -> PpbrDatasetRow_DatasetResponse:
        """
        Prices Of Procured Balancing Reserves (PPBR / B1730)

        This endpoint provides prices of procured balancing reserves.

This API endpoint has a maximum range of 2 years (731 days).

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            PpbrDatasetRow_DatasetResponse: Typed response object
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/PPBR", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return PpbrDatasetRow_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as PpbrDatasetRow_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_ppbr_stream(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str
    ) -> List[PpbrDatasetRow]:
        """
        Prices Of Procured Balancing Reserves (PPBR / B1730) stream

        This endpoint provides prices of procured balancing reserves.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 

        Returns:
            List[PpbrDatasetRow]: List of PpbrDatasetRow objects
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/PPBR/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [PpbrDatasetRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[PpbrDatasetRow]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_feib(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str,
        format: Optional[str] = None
    ) -> FeibDatasetRow_DatasetResponse:
        """
        Financial Expenses and Income for Balancing (FEIB / B1790)

        This endpoint provides financial expenses and income for balancing data.

This API endpoint has a maximum range of 1 year (367 days).

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            FeibDatasetRow_DatasetResponse: Typed response object
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/FEIB", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return FeibDatasetRow_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as FeibDatasetRow_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_feib_stream(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str
    ) -> List[FeibDatasetRow]:
        """
        Financial Expenses and Income for Balancing (FEIB / B1790) stream

        This endpoint provides financial expenses and income for balancing data.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 

        Returns:
            List[FeibDatasetRow]: List of FeibDatasetRow objects
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/FEIB/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [FeibDatasetRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[FeibDatasetRow]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_aobe(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str,
        format: Optional[str] = None
    ) -> AobeDatasetRow_DatasetResponse:
        """
        Accepted Offered Balancing Energy (AOBE)

        This endpoint provides accepted offered balancing energy data.

This API endpoint has a maximum range of 7 days.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            AobeDatasetRow_DatasetResponse: Typed response object
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/AOBE", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return AobeDatasetRow_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as AobeDatasetRow_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_aobe_stream(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str
    ) -> List[AobeDatasetRow]:
        """
        Accepted Offered Balancing Energy (AOBE) stream

        This endpoint provides accepted offered balancing energy data.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 

        Returns:
            List[AobeDatasetRow]: List of AobeDatasetRow objects
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/AOBE/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [AobeDatasetRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[AobeDatasetRow]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_beb(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str,
        format: Optional[str] = None
    ) -> BebDatasetRow_DatasetResponse:
        """
        Balancing Energy Bids (BEB)

        This endpoint provides information on all balancing energy bids, in accordance with the Electricity Balancing Guidelines (EBGL) article 12.3.b.

This API endpoint has a maximum range of 7 days.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            BebDatasetRow_DatasetResponse: Typed response object
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/BEB", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return BebDatasetRow_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as BebDatasetRow_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_beb_stream(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str
    ) -> List[BebDatasetRow]:
        """
        Balancing Energy Bids (BEB) stream

        This endpoint provides information on all balancing energy bids, in accordance with the Electricity Balancing Guidelines (EBGL) article 12.3.b.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 

        Returns:
            List[BebDatasetRow]: List of BebDatasetRow objects
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/BEB/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [BebDatasetRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[BebDatasetRow]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_cbs(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str,
        format: Optional[str] = None
    ) -> CbsDatasetRow_DatasetResponse:
        """
        Current Balancing State (CBS)

        This endpoint provides information on the current system balance, in accordance with the Electricity Balancing Guidelines (EBGL) article 12.3.a.

This API endpoint has a maximum range of 1 day.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            CbsDatasetRow_DatasetResponse: Typed response object
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/CBS", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return CbsDatasetRow_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as CbsDatasetRow_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_cbs_stream(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str
    ) -> List[CbsDatasetRow]:
        """
        Current Balancing State (CBS) stream

        This endpoint provides information on the current system balance, in accordance with the Electricity Balancing Guidelines (EBGL) article 12.3.a.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 

        Returns:
            List[CbsDatasetRow]: List of CbsDatasetRow objects
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/CBS/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [CbsDatasetRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[CbsDatasetRow]: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_pbc(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str,
        format: Optional[str] = None
    ) -> PbcDatasetRow_DatasetResponse:
        """
        Procured Balancing Capacity (PBC)

        This endpoint provides information on the procured balancing capacity, in accordance with the Electricity Balancing Guidelines (EBGL) article 12.3.f.

This API endpoint has a maximum range of 1 day.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            PbcDatasetRow_DatasetResponse: Typed response object
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/datasets/PBC", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return PbcDatasetRow_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as PbcDatasetRow_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_datasets_pbc_stream(
        self,
        publishDateTimeFrom: str,
        publishDateTimeTo: str
    ) -> List[PbcDatasetRow]:
        """
        Procured Balancing Capacity (PBC) stream

        This endpoint provides information on the procured balancing capacity, in accordance with the Electricity Balancing Guidelines (EBGL) article 12.3.f.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            publishDateTimeFrom: 
            publishDateTimeTo: 

        Returns:
            List[PbcDatasetRow]: List of PbcDatasetRow objects
        """
        params = {}
        params["publishDateTimeFrom"] = publishDateTimeFrom
        params["publishDateTimeTo"] = publishDateTimeTo

        response = self._make_request("GET", f"/datasets/PBC/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [PbcDatasetRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[PbcDatasetRow]: {e}. Returning raw data.")
                return response
        return response

    def get_cdn(
        self,
        format: Optional[str] = None
    ) -> CDNResponse:
        """
        [DEPRECATED] Credit default notices (CDN)

        This endpoint has been moved to balancing/settlement/default-notices.

        Args:
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            CDNResponse: Typed response object
        """
        params = {}
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/CDN", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return CDNResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as CDNResponse: {e}. Returning raw data.")
                return response
        return response

    def get_demand_by_restoration_zone_restored_submissions(
        self,
        count: int,
        before: Optional[str] = None,
        region: Optional[str] = None,
        gspGroupId: Optional[str] = None,
        format: Optional[str] = None
    ) -> RestorationZoneDemandRestoredDatasetRow_ResponseWithMetadata:
        """
        Restoration Zone Demand Restored Submissions (RZDR)

        This endpoint provides data about the end of system restoration events. It returns the restored demand value
for each restoration zone at the last submission time of each event. The number of events to return is
determined by the `count` parameter.
            
The data can be filtered by submission date/time, region, and GSP Group ID (when received by NESO).
            
All DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.

Some examples of parameter combinations are shown below.
            
Filtering latest 3 events:
            
    /demand/by-restoration-zone/restored/submissions?count=3
            
Filtering latest 3 events before a given submission time:
            
    /demand/by-restoration-zone/restored/submissions?before=2025-10-01T00:00Z&count=3
            
Filtering latest 10 events for a given region:
            
    /demand/by-restoration-zone/restored/submissions?region=North West&count=10

        Args:
            count: The number of system restoration events to return.
            before: If specified, filters events to those with a submission time before or at the specified date and time.
If omitted, latest events are returned., optional
            region: The region to filter by., optional
            gspGroupId: The GSP Group ID to filter by., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            RestorationZoneDemandRestoredDatasetRow_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["count"] = count
        if before is not None:
            params["before"] = before
        if region is not None:
            params["region"] = region
        if gspGroupId is not None:
            params["gspGroupId"] = gspGroupId
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/demand/by-restoration-zone/restored/submissions", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return RestorationZoneDemandRestoredDatasetRow_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as RestorationZoneDemandRestoredDatasetRow_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_demand_outturn(
        self,
        settlementDateFrom: Optional[str] = None,
        settlementDateTo: Optional[str] = None,
        settlementPeriod: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> DemandOutturn_ResponseWithMetadata:
        """
        Initial National Demand outturn (INDO)

        This endpoint provides data for Initial National Demand Outturn, which measures the
half-hour average MW demand metered by the Transmission Company based on its operational metering.
The data is updated every 30 minutes and within 15 minutes of the end of the effective settlement period. The data is represented with:
- INDO (initial National Demand outturn) which takes into account transmission losses but does not include station transformer load, pumped storage demand or interconnector demand.
- ITSDO (initial Transmission System Demand outturn) which takes into account transmission losses, station transformer load, pumped storage demand and interconnector demand.
            
This endpoint is useful for ad-hoc querying of the data.
            
Settlement date parameters must be provided in the exact format yyyy-MM-dd.

        Args:
            settlementDateFrom: The settlement date from for the filter. This must be in the format yyyy-MM-dd., optional
            settlementDateTo: The settlement date to for the filter. This must be in the format yyyy-MM-dd., optional
            settlementPeriod: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DemandOutturn_ResponseWithMetadata: Typed response object
        """
        params = {}
        if settlementDateFrom is not None:
            params["settlementDateFrom"] = settlementDateFrom
        if settlementDateTo is not None:
            params["settlementDateTo"] = settlementDateTo
        if settlementPeriod is not None:
            params["settlementPeriod"] = settlementPeriod
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/demand/outturn", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DemandOutturn_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DemandOutturn_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_demand_outturn_stream(
        self,
        settlementDateFrom: Optional[str] = None,
        settlementDateTo: Optional[str] = None,
        settlementPeriod: Optional[List[str]] = None
    ) -> List[DemandOutturn]:
        """
        Initial National Demand outturn (INDO) stream

        This endpoint provides data for initial National Demand outturn, which measures the
half-hour average MW demand metered by the Transmission Company based on its operational metering.
The data is updated every 30 minutes and within 15 minutes of the end of the effective settlement period. The data is represented with:
- INDO (initial National Demand outturn) which takes into account transmission losses but does not include station transformer load, pumped storage demand or interconnector demand.
- ITSDO (initial Transmission System Demand outturn) which takes into account transmission losses, station transformer load, pumped storage demand and interconnector demand.
            
This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.
            
Settlement date parameters must be provided in the exact format yyyy-MM-dd.

        Args:
            settlementDateFrom: The settlement date from for the filter. This must be in the format yyyy-MM-dd., optional
            settlementDateTo: The settlement date to for the filter. This must be in the format yyyy-MM-dd., optional
            settlementPeriod: , optional

        Returns:
            List[DemandOutturn]: List of DemandOutturn objects
        """
        params = {}
        if settlementDateFrom is not None:
            params["settlementDateFrom"] = settlementDateFrom
        if settlementDateTo is not None:
            params["settlementDateTo"] = settlementDateTo
        if settlementPeriod is not None:
            params["settlementPeriod"] = settlementPeriod

        response = self._make_request("GET", f"/demand/outturn/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [DemandOutturn(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[DemandOutturn]: {e}. Returning raw data.")
                return response
        return response

    def get_demand_outturn_daily(
        self,
        settlementDateFrom: Optional[str] = None,
        settlementDateTo: Optional[str] = None,
        format: Optional[str] = None
    ) -> IndodRow_ResponseWithMetadata:
        """
        Initial National Demand outturn per day (INDOD)

        This endpoint provides initial National Demand outturn data per day. The total daily energy volume is the total
demand volume for the previous day expressed on an initial National Demand outturn (INDO) basis, i.e. excluding
station transformer, pumping and interconnector export demand. It is calculated from summing the half hourly
INDO demands (divided by two to convert to MWh).
            
If no date window is chosen, the search will default to results from the last 31 days.

This API endpoint has a maximum range of 2 years (731 days).

        Args:
            settlementDateFrom: , optional
            settlementDateTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            IndodRow_ResponseWithMetadata: Typed response object
        """
        params = {}
        if settlementDateFrom is not None:
            params["settlementDateFrom"] = settlementDateFrom
        if settlementDateTo is not None:
            params["settlementDateTo"] = settlementDateTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/demand/outturn/daily", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return IndodRow_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as IndodRow_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_demand_outturn_daily_stream(
        self,
        settlementDateFrom: Optional[str] = None,
        settlementDateTo: Optional[str] = None
    ) -> List[IndodRow]:
        """
        Initial National Demand outturn per day (INDOD) stream

        This endpoint provides initial National Demand outturn daily data. The total daily energy volume is the total
demand volume for the previous day expressed on an initial National Demand outturn (INDO) basis, i.e. excluding
station transformer, pumping and interconnector export demand. It is calculated from summing the half hourly
INDO demands (divided by two to convert to MWh).
            
If no date window is chosen, the search will default to results from the last 31 days.

This endpoint has an optimised JSON payload and is aimed at frequent requests for the data.

        Args:
            settlementDateFrom: , optional
            settlementDateTo: , optional

        Returns:
            List[IndodRow]: List of IndodRow objects
        """
        params = {}
        if settlementDateFrom is not None:
            params["settlementDateFrom"] = settlementDateFrom
        if settlementDateTo is not None:
            params["settlementDateTo"] = settlementDateTo

        response = self._make_request("GET", f"/demand/outturn/daily/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [IndodRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[IndodRow]: {e}. Returning raw data.")
                return response
        return response

    def get_demand_outturn_summary(
        self,
        resolution: Optional[str] = None,
        from_: Optional[str] = None,
        to_: Optional[str] = None,
        format: Optional[str] = None
    ) -> List[RollingSystemDemand]:
        """
        System demand summary (FUELINST)

         This endpoint provides a down-sampled data summary intended for visualisation purposes.
Use datasets endpoints for full dataset access.

        Args:
            resolution: , optional
            from_: , optional
            to_: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            List[RollingSystemDemand]: List of RollingSystemDemand objects
        """
        params = {}
        if resolution is not None:
            params["resolution"] = resolution
        if from_ is not None:
            params["from"] = from_
        if to_ is not None:
            params["to"] = to_
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/demand/outturn/summary", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [RollingSystemDemand(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[RollingSystemDemand]: {e}. Returning raw data.")
                return response
        return response

    def get_demand_peak(
        self,
        from_: Optional[str] = None,
        to_: Optional[str] = None,
        format: Optional[str] = None
    ) -> DemandOutturnPeak_ResponseWithMetadata:
        """
        Peak demand per day (ITSDO)

        This endpoint allows for retrieving peak ITSDO demand for each day from National Grid ESO.
Results are filtered by a range of Date parameters.
Results default to yesterday's peak if no parameters are supplied.
            
Date parameters must be provided in the exact format yyyy-MM-dd.

        Args:
            from_: The start of the requested date range., optional
            to_: The end of the requested date range., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DemandOutturnPeak_ResponseWithMetadata: Typed response object
        """
        params = {}
        if from_ is not None:
            params["from"] = from_
        if to_ is not None:
            params["to"] = to_
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/demand/peak", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DemandOutturnPeak_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DemandOutturnPeak_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_demand_peak_indicative(
        self,
        data: str,
        triadSeasonStartYear: Optional[int] = None,
        from_: Optional[str] = None,
        to_: Optional[str] = None,
        format: Optional[str] = None
    ) -> IndicativeDemandPeak_ResponseWithMetadata:
        """
        Indicative peak demand per day (S0142, ITSDO, FUELHH)

        Indicative demand peaks using operational metering data are daily maxima values determined from
ITSDO and FUELHH data used to determine and visualise Triad.
            
Indicative demand peaks using settlement metering data are daily maxima values determined from
metered volume data from the S0142_bpi file. These peaks are not used for Triad visualisation as
they are always calculated based on the latest run type. Triads for settlement data
remain static after the National Grid report posted at the beginning of April after the Triad season has ended. 
            
If no filters are supplied, results default to the latest or current Triad season.
To specify a custom filter, you can supplier EITHER a Triad season start year, OR a date range, but not both.
If a Triad Season Start year is supplied, data for the Triad season beginning on 1 November
of the specified year will be returned.
If a date range is supplied, data will be returned for settlement dates within the date range inclusively.
            
Date parameters must be provided in the exact format yyyy-MM-dd.

        Args:
            data: The type of data. Supports values of 'operational' or 'settlement'.
            triadSeasonStartYear: A year indicating the Triad season starting on 1 November of the given year, e.g. 2021., optional
            from_: The start of the requested date range., optional
            to_: The end of the requested date range., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            IndicativeDemandPeak_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["data"] = data
        if triadSeasonStartYear is not None:
            params["triadSeasonStartYear"] = triadSeasonStartYear
        if from_ is not None:
            params["from"] = from_
        if to_ is not None:
            params["to"] = to_
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/demand/peak/indicative", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return IndicativeDemandPeak_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as IndicativeDemandPeak_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_demand_peak_indicative_settlement(
        self,
        triadSeason: int,
        format: Optional[str] = None
    ) -> IndicativeDemandPeak_ResponseWithMetadata:
        """
        Settlement data demand peaks for a Triad season (S0142)

        Provides indicative demand peak data for a Triad season from S0142_bpi files that were calculated
during the Triad season. For the data from the latest settlement runs for the Triad season use the
`peak/indicative` endpoint.

        Args:
            triadSeason: A year indicating the Triad season starting on 1 November of the given year
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            IndicativeDemandPeak_ResponseWithMetadata: Typed response object
        """
        params = {}
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/demand/peak/indicative/settlement/{triadSeason}", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return IndicativeDemandPeak_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as IndicativeDemandPeak_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_demand_peak_indicative_operational(
        self,
        triadSeason: int,
        format: Optional[str] = None
    ) -> IndicativeDemandPeak_ResponseWithMetadata:
        """
        Operational data demand peaks for a Triad season (ITSDO, FUELHH)

        Provides indicative demand peak data for a Triad season ITSDO and FUELHH files over a Triad season. For non-Triad
season dates please use the `peak/indicative` endpoint.

        Args:
            triadSeason: A year indicating the Triad season starting on 1 November of the given year
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            IndicativeDemandPeak_ResponseWithMetadata: Typed response object
        """
        params = {}
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/demand/peak/indicative/operational/{triadSeason}", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return IndicativeDemandPeak_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as IndicativeDemandPeak_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_demand_peak_triad(
        self,
        data: str,
        triadSeasonStartYear: Optional[int] = None,
        format: Optional[str] = None
    ) -> IndicativeDemandPeak_ResponseWithMetadata:
        """
        Triad demand peaks (S0142, ITSDO, FUELHH)

        Operational Triad peaks are calculated from the indicative demand peaks data.

Settlement Triad Peaks are calculated from the latest metered volume data available at the point one month following the Triad season's end.
For any Triad season still in progress, the latest run type data is used.
            
All Triad peaks are at least 10 days clear of one another.

        Args:
            data: The type of data. Supports values of 'operational' or 'settlement'.
            triadSeasonStartYear: A year indicating the Triad season starting on 1 November of the given year., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            IndicativeDemandPeak_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["data"] = data
        if triadSeasonStartYear is not None:
            params["triadSeasonStartYear"] = triadSeasonStartYear
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/demand/peak/triad", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return IndicativeDemandPeak_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as IndicativeDemandPeak_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_demand(
        self,
        format: Optional[str] = None
    ) -> DemandResponse:
        """
        This endpoint is obsolete, and this location may be removed with no further notice. 

        This endpoint has been moved to demand/outturn.

        Args:
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DemandResponse: Typed response object
        """
        params = {}
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/demand", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DemandResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DemandResponse: {e}. Returning raw data.")
                return response
        return response

    def get_demand_stream(
        self,
        format: Optional[str] = None
    ) -> List[InitialDemandOutturn]:
        """
        This endpoint is obsolete, and this location may be removed with no further notice. 

        This endpoint has been moved to demand/outturn/stream.

        Args:
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            List[InitialDemandOutturn]: List of InitialDemandOutturn objects
        """
        params = {}
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/demand/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [InitialDemandOutturn(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[InitialDemandOutturn]: {e}. Returning raw data.")
                return response
        return response

    def get_demand_rolling_system_demand(
        self,
        format: Optional[str] = None
    ) -> RollingSystemDemandResponse:
        """
        This endpoint is obsolete, and this location may be removed with no further notice. 

        This endpoint has been moved to generation/outturn.

        Args:
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            RollingSystemDemandResponse: Typed response object
        """
        params = {}
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/demand/rollingSystemDemand", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return RollingSystemDemandResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as RollingSystemDemandResponse: {e}. Returning raw data.")
                return response
        return response

    def get_demand_summary(
        self,
        format: Optional[str] = None
    ) -> List[DemandSummaryItem]:
        """
        This endpoint is obsolete, and this location may be removed with no further notice. 

        This endpoint has been moved to demand/outturn/summary.

        Args:
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            List[DemandSummaryItem]: List of DemandSummaryItem objects
        """
        params = {}
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/demand/summary", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [DemandSummaryItem(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[DemandSummaryItem]: {e}. Returning raw data.")
                return response
        return response

    def get_demand_total_actual(
        self,
        format: Optional[str] = None
    ) -> DemandTotalActualResponse:
        """
        This endpoint is obsolete, and this location may be removed with no further notice. 

        This endpoint has been moved to demand/actual/total.

        Args:
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DemandTotalActualResponse: Typed response object
        """
        params = {}
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/demand/total/actual", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DemandTotalActualResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DemandTotalActualResponse: {e}. Returning raw data.")
                return response
        return response

    def get_demand_actual_total(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        format: Optional[str] = None
    ) -> ActualTotalLoadPerBiddingZone_ResponseWithMetadata:
        """
        Actual total load (ATL/B0610)

        This endpoint provides actual total load data per bidding zone.
It can be filtered by settlement period dates.
            
This API endpoint has a maximum range of 7 days.

        Args:
            from_: 
            to_: 
            settlementPeriodFrom: , optional
            settlementPeriodTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            ActualTotalLoadPerBiddingZone_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/demand/actual/total", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return ActualTotalLoadPerBiddingZone_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as ActualTotalLoadPerBiddingZone_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_demand_day_ahead(
        self,
        boundary: Optional[str] = None,
        format: Optional[str] = None
    ) -> DemandForecastDayAhead_ResponseWithMetadata:
        """
        Day-ahead demand forecast (NDF, TSDF)

        This endpoint provides the day and day ahead demand forecast and are categorized as National Demand Forecast (NDF) and Transmission System Demand Forecast (TSDF);
the forecast values are derived by NGESO and is based on historically metered generation output for Great Britain.
The data is updated every 30 minutes and within 15 minutes of the end of the effective Settlement Period.
NDF takes into account transmission losses but but does not include station transformer load, pumped storage demand or Interconnector demand;
the data is reported only at national level; and TSDF which takes into account transmission losses , station transformer load, pumped storage demand and interconnector demand.
The data is reported both at national and boundary (system zones) level. Boundary data only available for Transmission System Demand Forecast (TSDF).

        Args:
            boundary: Omitting this will return only national data. Specifying boundary=zonal will return only zonal data., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DemandForecastDayAhead_ResponseWithMetadata: Typed response object
        """
        params = {}
        if boundary is not None:
            params["boundary"] = boundary
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/demand/day-ahead", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DemandForecastDayAhead_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DemandForecastDayAhead_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_demand_daily(
        self,
        format: Optional[str] = None
    ) -> DemandForecastDaily_ResponseWithMetadata:
        """
        Fourteen day demand forecast (NDFD, TSDFD)

        Retrieve latest 14-day forecast demand data

        Args:
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DemandForecastDaily_ResponseWithMetadata: Typed response object
        """
        params = {}
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/demand/daily", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DemandForecastDaily_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DemandForecastDaily_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_demand_weekly(
        self,
        format: Optional[str] = None
    ) -> DemandForecastWeekly_ResponseWithMetadata:
        """
        One-year demand forecast (NDFW, TSDFW)

        This endpoint provides the latest weekly forecast demand data

        Args:
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DemandForecastWeekly_ResponseWithMetadata: Typed response object
        """
        params = {}
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/demand/weekly", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DemandForecastWeekly_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DemandForecastWeekly_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_demand_day_ahead_history(
        self,
        publishTime: str,
        boundary: Optional[str] = None,
        format: Optional[str] = None
    ) -> DemandForecastDayAhead_ResponseWithMetadata:
        """
        History of the day-ahead demand forecast (NDF, TSDF)

        This endpoint provides the day and day ahead demand forecast and are categorized as National Demand Forecast (NDF) and Transmission System Demand Forecast (TSDF);
the forecast values are derived by NGESO and is based on historically metered generation output for Great Britain.
The data is updated every 30 minutes and within 15 minutes of the end of the effective Settlement Period.
NDF takes into account transmission losses but but does not include station transformer load, pumped storage demand or Interconnector demand;
the data is reported only at national level; and TSDF which takes into account transmission losses , station transformer load, pumped storage demand and interconnector demand.
The data is reported both at national and boundary (system zones) level. Boundary data only available for Transmission System Demand Forecast (TSDF).

        Args:
            publishTime: 
            boundary: Omitting this will return only national data. Specifying boundary=zonal will return only zonal data., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DemandForecastDayAhead_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["publishTime"] = publishTime
        if boundary is not None:
            params["boundary"] = boundary
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/demand/day-ahead/history", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DemandForecastDayAhead_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DemandForecastDayAhead_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_demand_daily_history(
        self,
        publishTime: str,
        format: Optional[str] = None
    ) -> DemandForecastDaily_ResponseWithMetadata:
        """
        History of the fourteen-day demand forecast (NDFD, TSDFD)

        Retrieve historical daily forecast demand data

        Args:
            publishTime: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DemandForecastDaily_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["publishTime"] = publishTime
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/demand/daily/history", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DemandForecastDaily_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DemandForecastDaily_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_demand_weekly_history(
        self,
        publishTime: str,
        format: Optional[str] = None
    ) -> DemandForecastWeekly_ResponseWithMetadata:
        """
        History of the one-year demand forecast (NDFW, TSDFW)

        Retrieve historical weekly forecast demand data

        Args:
            publishTime: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DemandForecastWeekly_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["publishTime"] = publishTime
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/demand/weekly/history", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DemandForecastWeekly_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DemandForecastWeekly_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_demand_day_ahead_evolution(
        self,
        settlementDate: str,
        settlementPeriod: List[str],
        boundary: Optional[str] = None,
        format: Optional[str] = None
    ) -> DemandForecastDayAhead_ResponseWithMetadata:
        """
        Evolution of the day-ahead demand forecast over time (NDF, TSDF)

        This endpoint provides the day and day ahead demand forecast and are categorized as National Demand Forecast (NDF) and Transmission System Demand Forecast (TSDF);
the forecast values are derived by NGESO and is based on historically metered generation output for Great Britain.
The data is updated every 30 minutes and within 15 minutes of the end of the effective Settlement Period.
NDF takes into account transmission losses but but does not include station transformer load, pumped storage demand or Interconnector demand;
the data is reported only at national level; and TSDF which takes into account transmission losses , station transformer load, pumped storage demand and interconnector demand.
The data is reported both at national and boundary (system zones) level. Boundary data only available for Transmission System Demand Forecast (TSDF).
            
Date parameter must be provided in the exact format yyyy-MM-dd.

        Args:
            settlementDate: The settlement date for the filter. This must be in the format yyyy-MM-dd.
            settlementPeriod: 
            boundary: Omitting this will return only national data. Specifying boundary=zonal will return only zonal data., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DemandForecastDayAhead_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["settlementDate"] = settlementDate
        params["settlementPeriod"] = settlementPeriod
        if boundary is not None:
            params["boundary"] = boundary
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/demand/day-ahead/evolution", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DemandForecastDayAhead_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DemandForecastDayAhead_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_demand_daily_evolution(
        self,
        forecastDate: str,
        format: Optional[str] = None
    ) -> DemandForecastDaily_ResponseWithMetadata:
        """
        Evolution of the fourteen-day demand forecast over time (NDFD, TSDFD)

        This endpoint provides the evolution of all daily demand forecasts over time for a given forecast date.
            
Date parameter must be provided in the exact format yyyy-MM-dd.

        Args:
            forecastDate: The forecast date for the filter. This must be in the format yyyy-MM-dd.
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DemandForecastDaily_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["forecastDate"] = forecastDate
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/demand/daily/evolution", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DemandForecastDaily_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DemandForecastDaily_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_demand_weekly_evolution(
        self,
        forecastYear: int,
        forecastWeek: int,
        format: Optional[str] = None
    ) -> DemandForecastWeekly_ResponseWithMetadata:
        """
        Evolution of the one-year demand forecast over time  (NDFW, TSDFW)

        This endpoint provides all weekly demand forecasts over time for a given forecast Year and Week

        Args:
            forecastYear: 
            forecastWeek: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DemandForecastWeekly_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["forecastYear"] = forecastYear
        params["forecastWeek"] = forecastWeek
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/demand/weekly/evolution", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DemandForecastWeekly_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DemandForecastWeekly_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_demand_day_ahead_latest(
        self,
        from_: str,
        to_: str,
        boundary: Optional[str] = None,
        format: Optional[str] = None
    ) -> DemandForecastDayAhead_ResponseWithMetadata:
        """
        Historic view of the latest forecasted demand (NDF, TSDF)

        This endpoint allows for retrieving latest day-ahead demand forecast data from National Grid ESO.
Results are filtered by settlement time, and only the latest published forecast for each settlement period is shown.

        Args:
            boundary: Omitting this will return only national data. Specifying boundary=zonal will return only zonal data., optional
            from_: 
            to_: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DemandForecastDayAhead_ResponseWithMetadata: Typed response object
        """
        params = {}
        if boundary is not None:
            params["boundary"] = boundary
        params["from"] = from_
        params["to"] = to_
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/demand/day-ahead/latest", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DemandForecastDayAhead_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DemandForecastDayAhead_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_demand_day_ahead_latest_stream(
        self,
        from_: str,
        to_: str,
        boundary: Optional[str] = None
    ) -> List[DayAheadDemandForecastRow]:
        """
        Historic view of the latest forecasted demand (NDF, TSDF) stream

        This endpoint allows for retrieving a stream of latest day-ahead demand forecast data from National Grid ESO.
Results are filtered by settlement time, and only the latest published forecast for each settlement period is shown.
This endpoint has an optimised JSON payload and aimed at frequent request for the day-ahead demand forecast data.

        Args:
            boundary: Omitting this will return only national data. Specifying boundary=zonal will return only zonal data., optional
            from_: 
            to_: 

        Returns:
            List[DayAheadDemandForecastRow]: List of DayAheadDemandForecastRow objects
        """
        params = {}
        if boundary is not None:
            params["boundary"] = boundary
        params["from"] = from_
        params["to"] = to_

        response = self._make_request("GET", f"/forecast/demand/day-ahead/latest/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [DayAheadDemandForecastRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[DayAheadDemandForecastRow]: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_demand_day_ahead_earliest(
        self,
        from_: str,
        to_: str,
        boundary: Optional[str] = None,
        format: Optional[str] = None
    ) -> DemandForecastDayAhead_ResponseWithMetadata:
        """
        Historic view of the earliest forecasted demand (NDF, TSDF)

        This endpoint allows for retrieving earliest day-ahead demand forecast data from National Grid ESO.
Results are filtered by settlement time, and only the earliest published forecast for each settlement period is shown.

        Args:
            boundary: Omitting this will return only national data. Specifying boundary=zonal will return only zonal data., optional
            from_: 
            to_: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DemandForecastDayAhead_ResponseWithMetadata: Typed response object
        """
        params = {}
        if boundary is not None:
            params["boundary"] = boundary
        params["from"] = from_
        params["to"] = to_
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/demand/day-ahead/earliest", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DemandForecastDayAhead_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DemandForecastDayAhead_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_demand_day_ahead_earliest_stream(
        self,
        from_: str,
        to_: str,
        boundary: Optional[str] = None
    ) -> List[DayAheadDemandForecastRow]:
        """
        Historic view of the earliest forecasted demand (NDF, TSDF) stream

        This endpoint allows for retrieving a stream of earliest day-ahead demand forecast data from National Grid ESO.
Results are filtered by settlement time, and only the earliest published forecast for each settlement period is shown.
This endpoint has an optimised JSON payload and aimed at frequent request for the day-ahead demand forecast data.

        Args:
            boundary: Omitting this will return only national data. Specifying boundary=zonal will return only zonal data., optional
            from_: 
            to_: 

        Returns:
            List[DayAheadDemandForecastRow]: List of DayAheadDemandForecastRow objects
        """
        params = {}
        if boundary is not None:
            params["boundary"] = boundary
        params["from"] = from_
        params["to"] = to_

        response = self._make_request("GET", f"/forecast/demand/day-ahead/earliest/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [DayAheadDemandForecastRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[DayAheadDemandForecastRow]: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_demand_day_ahead_peak(
        self,
        boundary: Optional[str] = None,
        from_: Optional[str] = None,
        to_: Optional[str] = None,
        format: Optional[str] = None
    ) -> DemandForecastPeak_ResponseWithMetadata:
        """
        Peak forecasted demand per day (TSDF)

        This endpoint allows for retrieving the peak demand that is forecast for each day from National Grid ESO.
Results are filtered by a range of Date parameters.
Results default to yesterday, today and tomorrow if no parameters are supplied.
            
Date parameters must be provided in the exact format yyyy-MM-dd.

        Args:
            boundary: , optional
            from_: The start of the requested date range., optional
            to_: The end of the requested date range., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DemandForecastPeak_ResponseWithMetadata: Typed response object
        """
        params = {}
        if boundary is not None:
            params["boundary"] = boundary
        if from_ is not None:
            params["from"] = from_
        if to_ is not None:
            params["to"] = to_
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/demand/day-ahead/peak", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DemandForecastPeak_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DemandForecastPeak_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_demand_total_day_ahead(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        format: Optional[str] = None
    ) -> DayAheadTotalLoadPerBiddingZone_ResponseWithMetadata:
        """
        Day-ahead total load forecast (DATL/B0620)

        This endpoint provides day-ahead total load forecast per bidding zone data.
It can be filtered by settlement period dates.
            
This API endpoint has a maximum range of 7 days.

        Args:
            from_: 
            to_: 
            settlementPeriodFrom: , optional
            settlementPeriodTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DayAheadTotalLoadPerBiddingZone_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/demand/total/day-ahead", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DayAheadTotalLoadPerBiddingZone_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DayAheadTotalLoadPerBiddingZone_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_demand_total_week_ahead(
        self,
        from_: str,
        to_: str,
        format: Optional[str] = None
    ) -> WeekAheadTotalLoadPerBiddingZone_ResponseWithMetadata:
        """
        Week-ahead total load forecast (WATL/B0630)

        This endpoint returns week-ahead total load forecast per bidding zone data with the minimum possible
and maximum available total loads in MW values, filtered by forecast week.
            
For a given forecast date, if more than one forecast has been published, only the most recent forecast
is returned.
            
This API endpoint has a maximum range of 367 days.
            
Date parameters must be provided in the exact format yyyy-MM-dd.

        Args:
            from_: The earliest forecast date to include.
            to_: The latest forecast date to include.
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            WeekAheadTotalLoadPerBiddingZone_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/demand/total/week-ahead", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return WeekAheadTotalLoadPerBiddingZone_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as WeekAheadTotalLoadPerBiddingZone_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_demand_total_week_ahead_latest(
        self,
        format: Optional[str] = None
    ) -> WeekAheadTotalLoadPerBiddingZone_ResponseWithMetadata:
        """
        Latest week-ahead total load forecast (WATL/B0630)

        This endpoint returns the most recently published WATL / B0630 forecast.
            
This forecast is the week-ahead total load forecast per bidding zone data,
with minimum possible and maximum available total loads in MW values.

        Args:
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            WeekAheadTotalLoadPerBiddingZone_ResponseWithMetadata: Typed response object
        """
        params = {}
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/demand/total/week-ahead/latest", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return WeekAheadTotalLoadPerBiddingZone_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as WeekAheadTotalLoadPerBiddingZone_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_generation_actual_per_type(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        format: Optional[str] = None
    ) -> ActualGenerationBySettlementPeriod_ResponseWithMetadata:
        """
        Historic actual generation automatically down-sampled (AGPT/B1620)

         This endpoint provides a down-sampled data summary intended for visualisation purposes.
Depending on the quantity of data requested, data returned may be averaged hourly, daily,
weekly or monthly. Quantities are rounded to the nearest MWh.
Use /datasets/AGPT for full access.
            
This endpoint provides actual aggregated generation data per Power System Resource type 
(Fuel Type categories as defined by Commission Regulation (EU) No 543/2013).

This endpoint filters by startTime, and groups results by settlement period.

        Args:
            from_: 
            to_: 
            settlementPeriodFrom: , optional
            settlementPeriodTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            ActualGenerationBySettlementPeriod_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/generation/actual/per-type", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return ActualGenerationBySettlementPeriod_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as ActualGenerationBySettlementPeriod_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_generation_actual_per_type_day_total(
        self,
        format: Optional[str] = None
    ) -> List[AgptSummaryData]:
        """
        Current snapshot of actual generation by fuel type categories (AGPT/B1620)

        This endpoint provides aggregated AGPT (B1620) data. It returns totals and percentages
for the last half hour and 24 hours for each generation type.

        Args:
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            List[AgptSummaryData]: List of AgptSummaryData objects
        """
        params = {}
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/generation/actual/per-type/day-total", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [AgptSummaryData(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[AgptSummaryData]: {e}. Returning raw data.")
                return response
        return response

    def get_generation_actual_per_type_wind_and_solar(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        format: Optional[str] = None
    ) -> ActualGenerationWindSolar_ResponseWithMetadata:
        """
        Historic actual or estimated wind and solar power generation (AGWS/B1630)

        This endpoint provides actual or estimated wind and solar power generation
per settlement period. It returns generation with Power System Resource type
Solar, Wind Onshore or Wind Offshore (Fuel Type categories as defined by
Commission Regulation (EU) No 543/2013).
            
This endpoint filters by startTime and provides a maximum data output range of 7 days.

        Args:
            from_: 
            to_: 
            settlementPeriodFrom: , optional
            settlementPeriodTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            ActualGenerationWindSolar_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/generation/actual/per-type/wind-and-solar", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return ActualGenerationWindSolar_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as ActualGenerationWindSolar_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_generation_outturn_interconnectors(
        self,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        settlementDateFrom: Optional[str] = None,
        settlementDateTo: Optional[str] = None,
        settlementPeriod: Optional[List[str]] = None,
        interconnectorName: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> HalfHourlyInterconnectorOutturn_ResponseWithMetadata:
        """
        Historic half-hourly interconnector flows (FUELINST)

        This endpoint provides the interconnector flows report derived from the Generation by Fuel Type (FUELINST)
data and shows both interconnector imports and exports; the data is updated every five minutes.
            
Settlement date parameters must be provided in the exact format yyyy-MM-dd.

        Args:
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            settlementDateFrom: The settlement date from filter. This must be in the format yyyy-MM-dd., optional
            settlementDateTo: The settlement date to filter. This must be in the format yyyy-MM-dd., optional
            settlementPeriod: , optional
            interconnectorName: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            HalfHourlyInterconnectorOutturn_ResponseWithMetadata: Typed response object
        """
        params = {}
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if settlementDateFrom is not None:
            params["settlementDateFrom"] = settlementDateFrom
        if settlementDateTo is not None:
            params["settlementDateTo"] = settlementDateTo
        if settlementPeriod is not None:
            params["settlementPeriod"] = settlementPeriod
        if interconnectorName is not None:
            params["interconnectorName"] = interconnectorName
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/generation/outturn/interconnectors", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return HalfHourlyInterconnectorOutturn_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as HalfHourlyInterconnectorOutturn_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_generation_outturn_current(
        self,
        fuelType: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> List[GenerationByFuelType]:
        """
        Current snapshot of generation by fuel type categories (FUELINST, FUELHH)

        This endpoint provides a snapshot view of the last 24 hours generation by individual fuel type categories including interconnector.

        Args:
            fuelType: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            List[GenerationByFuelType]: List of GenerationByFuelType objects
        """
        params = {}
        if fuelType is not None:
            params["fuelType"] = fuelType
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/generation/outturn/current", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [GenerationByFuelType(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[GenerationByFuelType]: {e}. Returning raw data.")
                return response
        return response

    def get_generation_outturn_summary(
        self,
        startTime: Optional[str] = None,
        endTime: Optional[str] = None,
        includeNegativeGeneration: Optional[bool] = None,
        format: Optional[str] = None
    ) -> List[OutturnGenerationBySettlementPeriod]:
        """
        Historic generation automatically down-sampled (FUELINST)

         This endpoint provides a down-sampled data summary intended for visualisation purposes.
Use raw dataset endpoints under /datasets for full access.

        Args:
            startTime: , optional
            endTime: , optional
            includeNegativeGeneration: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            List[OutturnGenerationBySettlementPeriod]: List of OutturnGenerationBySettlementPeriod objects
        """
        params = {}
        if startTime is not None:
            params["startTime"] = startTime
        if endTime is not None:
            params["endTime"] = endTime
        if includeNegativeGeneration is not None:
            params["includeNegativeGeneration"] = includeNegativeGeneration
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/generation/outturn/summary", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [OutturnGenerationBySettlementPeriod(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[OutturnGenerationBySettlementPeriod]: {e}. Returning raw data.")
                return response
        return response

    def get_generation_outturn_half_hourly_interconnector(
        self,
        format: Optional[str] = None
    ) -> HalfHourlyInterconnectorResponse:
        """
        This endpoint is obsolete, and this location may be removed with no further notice. 

        This endpoint has been moved to generation/outturn/interconnectors.

        Args:
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            HalfHourlyInterconnectorResponse: Typed response object
        """
        params = {}
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/generation/outturn/halfHourlyInterconnector", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return HalfHourlyInterconnectorResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as HalfHourlyInterconnectorResponse: {e}. Returning raw data.")
                return response
        return response

    def get_generation_outturn_fuelinsthhcur(
        self,
        format: Optional[str] = None
    ) -> List[GenerationCurrentItem]:
        """
        This endpoint is obsolete, and this location may be removed with no further notice. 

        This endpoint has been moved to generation/outturn/current.

        Args:
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            List[GenerationCurrentItem]: List of GenerationCurrentItem objects
        """
        params = {}
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/generation/outturn/FUELINSTHHCUR", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [GenerationCurrentItem(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[GenerationCurrentItem]: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_availability_daily(
        self,
        level: Optional[str] = None,
        bmUnit: Optional[List[str]] = None,
        fuelType: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> AvailabilityDaily_ResponseWithMetadata:
        """
        Fourteen-day generation capacity forecast (FOU2T14D)

        This endpoint provides the latest fourteen-day generation forecast

        Args:
            level: The filter level for the forecast. This can be one of the following:
- `total`: the total forecast for the given time period.
- `bmUnit`: the forecast for each specified BM unit.
- `fuelType`: the forecast aggregated, and optionally filtered by fuel type., optional
            bmUnit: The BM units to query. Add each unit separately. Either the Elexon ID (Eg: `T_CARR-1`) or National Grid ID (Eg: `CARR-1`) can be used.
Between 1 and 10 units should be queried when using the `bmUnit` level., optional
            fuelType: The fuel type to query when using the `fuelType` level. Add each fuel type separately. If no fuel types are supplied, all fuel types will be returned., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            AvailabilityDaily_ResponseWithMetadata: Typed response object
        """
        params = {}
        if level is not None:
            params["level"] = level
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if fuelType is not None:
            params["fuelType"] = fuelType
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/availability/daily", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return AvailabilityDaily_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as AvailabilityDaily_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_availability_weekly(
        self,
        level: Optional[str] = None,
        bmUnit: Optional[List[str]] = None,
        fuelType: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> AvailabilityWeekly_ResponseWithMetadata:
        """
        Three-year generation capacity forecast (FOU2T3YW)

        This endpoint provides the latest three-year generation forecast

        Args:
            level: The filter level for the forecast. This can be one of the following:
- `total`: the total forecast for the given time period.
- `bmUnit`: the forecast for each specified BM unit.
- `fuelType`: the forecast aggregated, and optionally filtered by fuel type., optional
            bmUnit: The BM units to query. Add each unit separately. Either the Elexon ID (Eg: `T_CARR-1`) or National Grid ID (Eg: `CARR-1`) can be used.
Between 1 and 10 units should be queried when using the `bmUnit` level., optional
            fuelType: The fuel type to query when using the `fuelType` level. Add each fuel type separately. If no fuel types are supplied, all fuel types will be returned., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            AvailabilityWeekly_ResponseWithMetadata: Typed response object
        """
        params = {}
        if level is not None:
            params["level"] = level
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if fuelType is not None:
            params["fuelType"] = fuelType
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/availability/weekly", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return AvailabilityWeekly_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as AvailabilityWeekly_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_availability_daily_history(
        self,
        publishTime: str,
        level: Optional[str] = None,
        bmUnit: Optional[List[str]] = None,
        fuelType: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> AvailabilityDaily_ResponseWithMetadata:
        """
        History of the fourteen-day generation capacity forecast (FOU2T14D)

        This endpoint provides the latest fourteen-day generation forecast from a given DateTime

        Args:
            publishTime: The UTC publish time to query. This should be in the format yyyy-MM-ddT:HH:mm:ssZ.
            level: The filter level for the forecast. This can be one of the following:
- `total`: the total forecast for the given time period.
- `bmUnit`: the forecast for each specified BM unit.
- `fuelType`: the forecast aggregated, and optionally filtered by fuel type., optional
            bmUnit: The BM units to query. Add each unit separately. Either the Elexon ID (Eg: `T_CARR-1`) or National Grid ID (Eg: `CARR-1`) can be used.
Between 1 and 10 units should be queried when using the `bmUnit` level., optional
            fuelType: The fuel type to query when using the `fuelType` level. Add each fuel type separately. If no fuel types are supplied, all fuel types will be returned., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            AvailabilityDaily_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["publishTime"] = publishTime
        if level is not None:
            params["level"] = level
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if fuelType is not None:
            params["fuelType"] = fuelType
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/availability/daily/history", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return AvailabilityDaily_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as AvailabilityDaily_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_availability_weekly_history(
        self,
        publishTime: str,
        level: Optional[str] = None,
        bmUnit: Optional[List[str]] = None,
        fuelType: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> AvailabilityWeekly_ResponseWithMetadata:
        """
        History of the three-year generation capacity forecast (FOU2T3YW)

        This endpoint provides the latest three-year forecast from a given DateTime

        Args:
            publishTime: The UTC publish time to query. This should be in the format yyyy-MM-ddT:HH:mm:ssZ.
            level: The filter level for the forecast. This can be one of the following:
- `total`: the total forecast for the given time period.
- `bmUnit`: the forecast for each specified BM unit.
- `fuelType`: the forecast aggregated, and optionally filtered by fuel type., optional
            bmUnit: The BM units to query. Add each unit separately. Either the Elexon ID (Eg: `T_CARR-1`) or National Grid ID (Eg: `CARR-1`) can be used.
Between 1 and 10 units should be queried when using the `bmUnit` level., optional
            fuelType: The fuel type to query when using the `fuelType` level. Add each fuel type separately. If no fuel types are supplied, all fuel types will be returned., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            AvailabilityWeekly_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["publishTime"] = publishTime
        if level is not None:
            params["level"] = level
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if fuelType is not None:
            params["fuelType"] = fuelType
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/availability/weekly/history", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return AvailabilityWeekly_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as AvailabilityWeekly_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_availability_daily_evolution(
        self,
        forecastDate: str,
        level: Optional[str] = None,
        bmUnit: Optional[List[str]] = None,
        fuelType: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> AvailabilityDaily_ResponseWithMetadata:
        """
        Evolution of the fourteen-day generation capacity forecast over time (FOU2T14D)

        This endpoint provides the evolution of all daily generation forecasts over time for a given Forecast Date.
            
Date parameter must be provided in the exact format yyyy-MM-dd.

        Args:
            forecastDate: The forecast date for the filter. This must be in the format yyyy-MM-dd.
            level: The filter level for the forecast. This can be one of the following:
- `total`: the total forecast for the given time period.
- `bmUnit`: the forecast for each specified BM unit.
- `fuelType`: the forecast aggregated, and optionally filtered by fuel type., optional
            bmUnit: The BM units to query. Add each unit separately. Either the Elexon ID (Eg: `T_CARR-1`) or National Grid ID (Eg: `CARR-1`) can be used.
Between 1 and 10 units should be queried when using the `bmUnit` level., optional
            fuelType: The fuel type to query when using the `fuelType` level. Add each fuel type separately. If no fuel types are supplied, all fuel types will be returned., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            AvailabilityDaily_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["forecastDate"] = forecastDate
        if level is not None:
            params["level"] = level
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if fuelType is not None:
            params["fuelType"] = fuelType
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/availability/daily/evolution", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return AvailabilityDaily_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as AvailabilityDaily_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_availability_weekly_evolution(
        self,
        year: int,
        week: int,
        level: Optional[str] = None,
        bmUnit: Optional[List[str]] = None,
        fuelType: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> AvailabilityWeekly_ResponseWithMetadata:
        """
        Evolution of the three-year generation capacity forecast over time (FOU2T3YW)

        This endpoint provides all weekly generation forecasts over time for a given Year and Week

        Args:
            year: The forecast year for the filter.
            week: The forecast week for the filter.
            level: The filter level for the forecast. This can be one of the following:
- `total`: the total forecast for the given time period.
- `bmUnit`: the forecast for each specified BM unit.
- `fuelType`: the forecast aggregated, and optionally filtered by fuel type., optional
            bmUnit: The BM units to query. Add each unit separately. Either the Elexon ID (Eg: `T_CARR-1`) or National Grid ID (Eg: `CARR-1`) can be used.
Between 1 and 10 units should be queried when using the `bmUnit` level., optional
            fuelType: The fuel type to query when using the `fuelType` level. Add each fuel type separately. If no fuel types are supplied, all fuel types will be returned., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            AvailabilityWeekly_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["year"] = year
        params["week"] = week
        if level is not None:
            params["level"] = level
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if fuelType is not None:
            params["fuelType"] = fuelType
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/availability/weekly/evolution", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return AvailabilityWeekly_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as AvailabilityWeekly_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_generation_day_ahead(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        format: Optional[str] = None
    ) -> DayAheadAggregatedGeneration_ResponseWithMetadata:
        """
        Day-ahead aggregated generation (DAG/B1430)

        This endpoint provides day-ahead aggregated generation data filtered by settlement date.
            
This API endpoint has a maximum range of 7 days.

        Args:
            from_: 
            to_: 
            settlementPeriodFrom: , optional
            settlementPeriodTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DayAheadAggregatedGeneration_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/generation/day-ahead", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DayAheadAggregatedGeneration_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DayAheadAggregatedGeneration_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_generation_wind_and_solar_day_ahead(
        self,
        from_: str,
        to_: str,
        processType: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        format: Optional[str] = None
    ) -> DayAheadGenerationForWindAndSolar_ResponseWithMetadata:
        """
        Day-ahead generation forecast for wind and solar (DGWS/B1440)

        This endpoint provides day-ahead forecast generation data for wind and solar.
            
This endpoint filters by startTime and provides a maximum data output range of 7 days.

        Args:
            from_: 
            to_: 
            settlementPeriodFrom: , optional
            settlementPeriodTo: , optional
            processType: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DayAheadGenerationForWindAndSolar_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        params["processType"] = processType
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/generation/wind-and-solar/day-ahead", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DayAheadGenerationForWindAndSolar_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DayAheadGenerationForWindAndSolar_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_generation_wind(
        self,
        format: Optional[str] = None
    ) -> WindGenerationForecast_ResponseWithMetadata:
        """
        Current wind generation forecast (WINDFOR)

        This endpoint provides the latest wind generation forecast data. This provides wind generation forecast for wind farms which are visible to the ESO and have operational metering.
Updated data is published by NGESO up to 8 times a day at 03:30, 05:30, 08:30, 10:30, 12:30, 16:30, 19:30 and 23:30. Results are filtered by a range of DateTime parameters.

        Args:
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            WindGenerationForecast_ResponseWithMetadata: Typed response object
        """
        params = {}
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/generation/wind", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return WindGenerationForecast_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as WindGenerationForecast_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_generation_wind_history(
        self,
        publishTime: str,
        format: Optional[str] = None
    ) -> WindGenerationForecast_ResponseWithMetadata:
        """
        History of the wind generation forecast (WINDFOR)

        This endpoint provides the historical wind generation forecast data. This provides wind generation forecast for wind farms which are visible to the ESO and have operational metering.
Updated data is published by NGESO up to 8 times a day at 03:30, 05:30, 08:30, 10:30, 12:30, 16:30, 19:30 and 23:30.
Results are filtered by a range of DateTime parameters.

        Args:
            publishTime: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            WindGenerationForecast_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["publishTime"] = publishTime
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/generation/wind/history", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return WindGenerationForecast_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as WindGenerationForecast_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_generation_wind_evolution(
        self,
        startTime: str,
        format: Optional[str] = None
    ) -> WindGenerationForecast_ResponseWithMetadata:
        """
        Evolution of the wind generation forecast over time (WINDFOR)

        This endpoint provides the evolution wind generation forecast data.
This provides wind generation forecast for wind farms which are visible to the ESO and have operational metering.
Updated data is published by NGESO up to 8 times a day at 03:30, 05:30, 08:30, 10:30, 12:30, 16:30, 19:30 and 23:30.
Results are filtered by a range of DateTime parameters.

        Args:
            startTime: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            WindGenerationForecast_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["startTime"] = startTime
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/generation/wind/evolution", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return WindGenerationForecast_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as WindGenerationForecast_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_generation_wind_latest(
        self,
        from_: str,
        to_: str,
        format: Optional[str] = None
    ) -> WindGenerationForecast_ResponseWithMetadata:
        """
        Historic view of the latest forecasted wind generation (WINDFOR)

        This endpoint provides the latest wind generation forecast data.
This provides wind generation forecast for wind farms which are visible to the ESO and have operational metering.
Updated data is published by NGESO up to 8 times a day at 03:30, 05:30, 08:30, 10:30, 12:30, 16:30, 19:30 and 23:30.
Results are filtered by a range of DateTime parameters.

        Args:
            from_: 
            to_: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            WindGenerationForecast_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/generation/wind/latest", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return WindGenerationForecast_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as WindGenerationForecast_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_generation_wind_latest_stream(
        self,
        from_: str,
        to_: str
    ) -> List[WindGenerationForecastRow]:
        """
        Historic view of the latest forecasted wind generation (WINDFOR) stream

        This endpoint provides the latest wind generation forecast data.
This provides wind generation forecast for wind farms which are visible to the ESO and have operational metering.
Updated data is published by NGESO up to 8 times a day at 03:30, 05:30, 08:30, 10:30, 12:30, 16:30, 19:30 and 23:30.
Results are filtered by a range of DateTime parameters.
This endpoint has an optimised JSON payload and is aimed at frequent requests for the wind generation forecast data.

        Args:
            from_: 
            to_: 

        Returns:
            List[WindGenerationForecastRow]: List of WindGenerationForecastRow objects
        """
        params = {}
        params["from"] = from_
        params["to"] = to_

        response = self._make_request("GET", f"/forecast/generation/wind/latest/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [WindGenerationForecastRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[WindGenerationForecastRow]: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_generation_wind_earliest(
        self,
        from_: str,
        to_: str,
        format: Optional[str] = None
    ) -> WindGenerationForecast_ResponseWithMetadata:
        """
        Historic view of the earliest forecasted wind generation (WINDFOR)

        This endpoint provides the eariest wind generation forecast data.
This provides wind generation forecast for wind farms which are visible to the ESO and have operational metering.
Updated data is published by NGESO up to 8 times a day at 03:30, 05:30, 08:30, 10:30, 12:30, 16:30, 19:30 and 23:30.
Results are filtered by a range of DateTime parameters.

        Args:
            from_: 
            to_: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            WindGenerationForecast_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/generation/wind/earliest", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return WindGenerationForecast_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as WindGenerationForecast_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_generation_wind_earliest_stream(
        self,
        from_: str,
        to_: str
    ) -> List[WindGenerationForecastRow]:
        """
        Historic view of the earliest forecasted wind generation (WINDFOR) stream

        This endpoint provides the earliest wind generation forecast data.
This provides wind generation forecast for wind farms which are visible to the ESO and have operational metering.
Updated data is published by NGESO up to 8 times a day at 03:30, 05:30, 08:30, 10:30, 12:30, 16:30, 19:30 and 23:30.
Results are filtered by a range of DateTime parameters.
This endpoint has an optimised JSON payload and is aimed at frequent requests for the wind generation forecast data.

        Args:
            from_: 
            to_: 

        Returns:
            List[WindGenerationForecastRow]: List of WindGenerationForecastRow objects
        """
        params = {}
        params["from"] = from_
        params["to"] = to_

        response = self._make_request("GET", f"/forecast/generation/wind/earliest/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [WindGenerationForecastRow(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[WindGenerationForecastRow]: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_generation_wind_peak(
        self,
        from_: Optional[str] = None,
        to_: Optional[str] = None,
        format: Optional[str] = None
    ) -> WindGenerationForecast_ResponseWithMetadata:
        """
        Peak wind generation forecast for each day (WINDFOR)

        This endpoint provides the peak wind generation forecast data.
This provides wind generation forecast for wind farms which are visible to the ESO and have operational metering.
Updated data is published by NGESO up to 8 times a day at 03:30, 05:30, 08:30, 10:30, 12:30, 16:30, 19:30 and 23:30.
Results are filtered by a range of DateTime parameters.
            
Date parameters must be provided in the exact format yyyy-MM-dd.

        Args:
            from_: The start of the requested date range., optional
            to_: The end of the requested date range., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            WindGenerationForecast_ResponseWithMetadata: Typed response object
        """
        params = {}
        if from_ is not None:
            params["from"] = from_
        if to_ is not None:
            params["to"] = to_
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/generation/wind/peak", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return WindGenerationForecast_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as WindGenerationForecast_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_health(
        self
    ) -> HealthCheckResponse:
        """
        Health check

        This endpoint provides a success response code (200) with status code 2 if the service is alive

        Returns:
            HealthCheckResponse: Typed response object
        """
        params = {}

        response = self._make_request("GET", f"/health", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return HealthCheckResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as HealthCheckResponse: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_indicated_day_ahead(
        self,
        boundary: Optional[str] = None,
        format: Optional[str] = None
    ) -> IndicatedForecast_ResponseWithMetadata:
        """
        Latest indicated day-ahead forecast (INDDEM, INDGEN, IMBALNGC, MELNGC)

        This endpoint provides the latest forecast indicated day-ahead data

        Args:
            boundary: Omitting this will return only national data. Specifying boundary=zonal will return only zonal data., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            IndicatedForecast_ResponseWithMetadata: Typed response object
        """
        params = {}
        if boundary is not None:
            params["boundary"] = boundary
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/indicated/day-ahead", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return IndicatedForecast_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as IndicatedForecast_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_indicated_day_ahead_history(
        self,
        publishTime: str,
        boundary: Optional[str] = None,
        format: Optional[str] = None
    ) -> IndicatedForecast_ResponseWithMetadata:
        """
        Historical indicated day-ahead forecast (INDDEM, INDGEN, IMBALNGC, MELNGC)

        Args:
            publishTime: 
            boundary: Omitting this will return only national data. Specifying boundary=zonal will return only zonal data., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            IndicatedForecast_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["publishTime"] = publishTime
        if boundary is not None:
            params["boundary"] = boundary
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/indicated/day-ahead/history", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return IndicatedForecast_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as IndicatedForecast_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_indicated_day_ahead_evolution(
        self,
        settlementDate: str,
        settlementPeriod: List[str],
        boundary: Optional[str] = None,
        format: Optional[str] = None
    ) -> IndicatedForecast_ResponseWithMetadata:
        """
        Evolution indicated day-ahead forecast (INDDEM, INDGEN, IMBALNGC, MELNGC)

        This endpoint provides the forecast indicated day-ahead data over time for the specified settlement date and settlement period.

Date parameter must be provided in the exact format yyyy-MM-dd.

        Args:
            settlementDate: The settlement date for the filter. This must be in the format yyyy-MM-dd.
            settlementPeriod: 
            boundary: Omitting this will return only national data. Specifying boundary=zonal will return only zonal data., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            IndicatedForecast_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["settlementDate"] = settlementDate
        params["settlementPeriod"] = settlementPeriod
        if boundary is not None:
            params["boundary"] = boundary
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/indicated/day-ahead/evolution", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return IndicatedForecast_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as IndicatedForecast_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_balancing_settlement_messages(
        self,
        settlementDate: str,
        format: Optional[str] = None
    ) -> SettlementMessageResponse_ResponseWithMetadata:
        """
        Settlement messages by settlement date (SMSG)

        Returns settlement messages generated by the SAA for a given settlement day, relating to the data
for a settlement run.
            
For each settlement period within the range, only messages generated for the latest settlement run are returned.
            
Settlement date parameter must be provided in the exact format yyyy-MM-dd.

        Args:
            settlementDate: The settlement date to filter. This must be in the format yyyy-MM-dd.
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            SettlementMessageResponse_ResponseWithMetadata: Typed response object
        """
        params = {}
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/settlement/messages/{settlementDate}", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return SettlementMessageResponse_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as SettlementMessageResponse_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_balancing_settlement_stack_all(
        self,
        bidOffer: str,
        settlementDate: str,
        settlementPeriod: int,
        format: Optional[str] = None
    ) -> SettlementStackResponse_ResponseWithMetadata:
        """
        Settlement bid-offer stacks by settlement period (ISPSTACK)

        Returns detailed system prices generated by the latest calculation run for a given settlement period.
            
Settlement date parameter must be provided in the exact format yyyy-MM-dd.

        Args:
            bidOffer: Filter if bid or offer data is to be returned.
            settlementDate: The settlement date for the filter. This must be in the format yyyy-MM-dd.
            settlementPeriod: The settlement period for the filter.
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            SettlementStackResponse_ResponseWithMetadata: Typed response object
        """
        params = {}
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/settlement/stack/all/{bidOffer}/{settlementDate}/{settlementPeriod}", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return SettlementStackResponse_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as SettlementStackResponse_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_balancing_settlement_summary(
        self,
        settlementDate: str,
        settlementPeriod: int,
        format: Optional[str] = None
    ) -> SettlementSummaryResponse:
        """
        Settlement calculation summary (ISPSTACK, DISEBSP, MID, NETBSAD)

        Returns the settlement calculation summary for the requested settlement period.
Data is derived from the following datasets: ISPSTACK, DISEBSP, MID, NETBSAD
            
In JSON format, decimal values are returned as strings to avoid loss of precision.

        Args:
            settlementDate: This must be in the format yyyy-MM-dd.
            settlementPeriod: This should be an integer from 1-50 inclusive.
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            SettlementSummaryResponse: Typed response object
        """
        params = {}
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/settlement/summary/{settlementDate}/{settlementPeriod}", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return SettlementSummaryResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as SettlementSummaryResponse: {e}. Returning raw data.")
                return response
        return response

    def get_balancing_settlement_default_notices(
        self,
        format: Optional[str] = None
    ) -> CreditDefaultNoticeResponse_DatasetResponse:
        """
        Default notices (CDN)

        This endpoint provides a subset of CDN (Credit Default Notice) data received from ECVAA (Energy Contract Volume Aggregation Agent). It returns the defaults that are in force and defaults that have closed within the last 7 days.

        Args:
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            CreditDefaultNoticeResponse_DatasetResponse: Typed response object
        """
        params = {}
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/settlement/default-notices", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return CreditDefaultNoticeResponse_DatasetResponse(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as CreditDefaultNoticeResponse_DatasetResponse: {e}. Returning raw data.")
                return response
        return response

    def get_balancing_settlement_system_prices(
        self,
        settlementDate: str,
        format: Optional[str] = None
    ) -> SystemPriceResponse_ResponseWithMetadata:
        """
        Settlement system prices by settlement date (DISEBSP)

        Returns settlement system buy and sell prices generated by the SAA for a given settlement day, relating to
the data for a settlement run.
            
For each settlement period within the range, only messages generated for the latest settlement run are returned.
            
Settlement date parameter must be provided in the exact format yyyy-MM-dd.

        Args:
            settlementDate: The settlement date to filter. This must be in the format yyyy-MM-dd.
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            SystemPriceResponse_ResponseWithMetadata: Typed response object
        """
        params = {}
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/settlement/system-prices/{settlementDate}", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return SystemPriceResponse_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as SystemPriceResponse_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_balancing_settlement_acceptance_volumes_all(
        self,
        settlementDate: str,
        bidOffer: str,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> AcceptanceVolumeResponse_ResponseWithMetadata:
        """
        Acceptance volumes by settlement date (BOAV)

        Returns the settlement acceptance volumes for the requested settlement date.

For each settlement period within the range, only messages generated for the latest settlement run are returned.
            
Settlement date parameter must be provided in the exact format yyyy-MM-dd.

        Args:
            settlementDate: This must be in the format yyyy-MM-dd.
            bidOffer: 
            bmUnit: Elexon or NGC BMU IDs can be used. If omitted, results for all BM units will be returned., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            AcceptanceVolumeResponse_ResponseWithMetadata: Typed response object
        """
        params = {}
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/settlement/acceptance/volumes/all/{bidOffer}/{settlementDate}", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return AcceptanceVolumeResponse_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as AcceptanceVolumeResponse_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_balancing_settlement_indicative_volumes_all(
        self,
        settlementDate: str,
        bidOffer: str,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> IndicativeVolumeResponse_ResponseWithMetadata:
        """
        Indicative volumes by settlement date (DISPTAV)

        Returns the settlement indicative volumes for the requested settlement date.

For each settlement period within the range, only messages generated for the latest settlement run are returned.
            
Settlement date parameter must be provided in the exact format yyyy-MM-dd.

        Args:
            settlementDate: This must be in the format yyyy-MM-dd.
            bidOffer: 
            bmUnit: Elexon or NGC BMU IDs can be used. If omitted, results for all BM units will be returned., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            IndicativeVolumeResponse_ResponseWithMetadata: Typed response object
        """
        params = {}
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/settlement/indicative/volumes/all/{bidOffer}/{settlementDate}", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return IndicativeVolumeResponse_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as IndicativeVolumeResponse_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_balancing_settlement_indicative_cashflows_all(
        self,
        bidOffer: str,
        settlementDate: str,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> IndicativeCashflowResponse_ResponseWithMetadata:
        """
        Indicative period BMU cashflows by settlement date (EBOCF)

        Returns derived indicative cashflow data generated by the latest calculation run for a given settlement date.
            
For each settlement period within the range, only messages generated for the latest settlement run are returned.
            
Settlement date parameter must be provided in the exact format yyyy-MM-dd.

        Args:
            bidOffer: Filter if bid or offer data is to be returned.
            settlementDate: The settlement date for the filter. This must be in the format yyyy-MM-dd.
            bmUnit: The BM Units to query. Elexon or NGC BMU IDs can be used. If omitted, results for all BM units will be returned., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            IndicativeCashflowResponse_ResponseWithMetadata: Typed response object
        """
        params = {}
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/settlement/indicative/cashflows/all/{bidOffer}/{settlementDate}", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return IndicativeCashflowResponse_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as IndicativeCashflowResponse_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_balancing_settlement_acceptances_all(
        self,
        settlementDate: str,
        settlementPeriod: int,
        format: Optional[str] = None
    ) -> HistoricAcceptanceResponse_ResponseWithMetadata:
        """
        Historic acceptances by settlement period (ISPSTACK, BOALF, BOD)

        Returns the bid and offer prices for acceptances, with the acceptance number and acceptance time. Results are sorted by descending acceptance time.
            
Settlement date parameter must be provided in the exact format yyyy-MM-dd.

        Args:
            settlementDate: The settlement date for the filter. This must be in the format yyyy-MM-dd.
            settlementPeriod: The settlement period to filter. This should be an integer from 1-50 inclusive.
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            HistoricAcceptanceResponse_ResponseWithMetadata: Typed response object
        """
        params = {}
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/settlement/acceptances/all/{settlementDate}/{settlementPeriod}", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return HistoricAcceptanceResponse_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as HistoricAcceptanceResponse_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_balancing_settlement_market_depth(
        self,
        settlementDate: str,
        format: Optional[str] = None
    ) -> MarketDepthResponse_ResponseWithMetadata:
        """
        Market depth by settlement date (IMBALNGC, BOD, DISEBSP, DISPTAV)

        Returns market depth data for a given day.
Imbalance (MW) is retrieved from IMBALNGC.
Bid/offer volumes (MWh) are calculated by summing bid/offer volumes from BOD.
Total acceptance volumes (MWh) are retrieved from DISEBSP.
Priced acceptance volumes (MWh) are calculated by summing bid/offer accepted volumes with data type Original from DISPTAV.
            
Settlement date parameter must be provided in the exact format yyyy-MM-dd.

        Args:
            settlementDate: The settlement date for the filter. This must be in the format yyyy-MM-dd.
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            MarketDepthResponse_ResponseWithMetadata: Typed response object
        """
        params = {}
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/settlement/market-depth/{settlementDate}", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return MarketDepthResponse_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as MarketDepthResponse_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_interop_message_list_retrieval(
        self,
        eventStart: str,
        eventEnd: str
    ) -> Dict[str, Any]:
        """
        This endpoint is obsolete, and this location may be removed with no further notice. Use /remit/* or /datasets/REMIT endpoints instead.

          WARNING: This endpoint returns untyped Dict[str, Any]
        The OpenAPI specification does not define a response schema for this endpoint.
        You will not get type checking or IDE autocomplete for the response.

        Args:
            eventStart: 
            eventEnd: 

        Returns:
            Dict[str, Any]: Untyped response data (no schema available)
        """
        params = {}
        params["eventStart"] = eventStart
        params["eventEnd"] = eventEnd

        response = self._make_request("GET", f"/interop/MessageListRetrieval", params=params)
        return response

    def get_interop_message_detail_retrieval(
        self,
        messageId: str
    ) -> Dict[str, Any]:
        """
        This endpoint is obsolete, and this location may be removed with no further notice. Use /remit/* or /datasets/REMIT endpoints instead.

          WARNING: This endpoint returns untyped Dict[str, Any]
        The OpenAPI specification does not define a response schema for this endpoint.
        You will not get type checking or IDE autocomplete for the response.

        Args:
            messageId: 

        Returns:
            Dict[str, Any]: Untyped response data (no schema available)
        """
        params = {}
        params["messageId"] = messageId

        response = self._make_request("GET", f"/interop/MessageDetailRetrieval", params=params)
        return response

    def get_lolpdrm_forecast_evolution(
        self,
        format: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Loss of load probability and de-rated margin forecast (LOLPDRM)

        This endpoint has been moved to forecast/system/loss-of-load.

          WARNING: This endpoint returns untyped Dict[str, Any]
        The OpenAPI specification does not define a response schema for this endpoint.
        You will not get type checking or IDE autocomplete for the response.

        Args:
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            Dict[str, Any]: Untyped response data (no schema available)
        """
        params = {}
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/lolpdrm/forecast/evolution", params=params)
        return response

    def get_forecast_margin_daily(
        self,
        format: Optional[str] = None
    ) -> ForecastMarginDaily_ResponseWithMetadata:
        """
        Daily margin forecast (OCNMFD2)

        This endpoint provides the Generating Plant Operating Margin covering 2 days ahead to 14 days ahead
in MW values. The Daily API outputs the latest published data for daily margin forecast for D+2 t D+14

        Args:
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            ForecastMarginDaily_ResponseWithMetadata: Typed response object
        """
        params = {}
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/margin/daily", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return ForecastMarginDaily_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as ForecastMarginDaily_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_margin_daily_history(
        self,
        publishTime: str,
        format: Optional[str] = None
    ) -> ForecastMarginDaily_ResponseWithMetadata:
        """
        Historical daily margin forecast (OCNMFD2)

        This endpoint provides the historic Generating Plant Operating Margin covering 2 days ahead to 14 days ahead in MW values.
The historic API outputs the latest published data for historic daily margin forecast for D+2 to D+14

        Args:
            publishTime: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            ForecastMarginDaily_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["publishTime"] = publishTime
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/margin/daily/history", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return ForecastMarginDaily_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as ForecastMarginDaily_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_margin_daily_evolution(
        self,
        forecastDate: str,
        format: Optional[str] = None
    ) -> ForecastMarginDaily_ResponseWithMetadata:
        """
        Evolution daily margin forecast (OCNMFD2)

        This endpoint provides the daily evolution Generating Plant Operating Margin covering 2 days ahead to 14 days ahead in MW values.
The Daily API outputs the latest published data for daily margin forecast for D+2 to D+14.
            
Date parameter must be provided in the exact format yyyy-MM-dd.

        Args:
            forecastDate: The forecast date for the filter. This must be in the format yyyy-MM-dd.
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            ForecastMarginDaily_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["forecastDate"] = forecastDate
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/margin/daily/evolution", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return ForecastMarginDaily_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as ForecastMarginDaily_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_margin_weekly(
        self,
        range: Optional[str] = None,
        format: Optional[str] = None
    ) -> ForecastMarginWeekly_ResponseWithMetadata:
        """
        Weekly margin forecast (OCNMFW2, OCNMF3Y2)

        This endpoint provides the Generating Plant Operating Margin covering 2 weeks ahead to 156 weeks ahead in MW values.
The weekly API outputs the latest published data for weekly margin forecast for W+2 to W+156

        Args:
            range: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            ForecastMarginWeekly_ResponseWithMetadata: Typed response object
        """
        params = {}
        if range is not None:
            params["range"] = range
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/margin/weekly", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return ForecastMarginWeekly_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as ForecastMarginWeekly_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_margin_weekly_history(
        self,
        publishTime: str,
        range: Optional[str] = None,
        format: Optional[str] = None
    ) -> ForecastMarginWeekly_ResponseWithMetadata:
        """
        Historical weekly margin forecast (OCNMFW2, OCNMF3Y2)

        This endpoint provides the weekly historic  Generating Plant Operating Margin.
This historic API output 2 weeks ahead to 156 weeks ahead in MW values

        Args:
            publishTime: 
            range: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            ForecastMarginWeekly_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["publishTime"] = publishTime
        if range is not None:
            params["range"] = range
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/margin/weekly/history", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return ForecastMarginWeekly_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as ForecastMarginWeekly_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_margin_weekly_evolution(
        self,
        year: int,
        week: int,
        range: Optional[str] = None,
        format: Optional[str] = None
    ) -> ForecastMarginWeekly_ResponseWithMetadata:
        """
        Evolution daily margin forecast (OCNMFW2, OCNMF3Y2)

        This endpoint provides the daily evolution Generating Plant Operating Margin covering 2 days ahead to 14 days ahead in MW values.
The Daily API outputs the latest published data for daily margin forecast for D+2 t D+14

        Args:
            year: 
            week: 
            range: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            ForecastMarginWeekly_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["year"] = year
        params["week"] = week
        if range is not None:
            params["range"] = range
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/margin/weekly/evolution", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return ForecastMarginWeekly_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as ForecastMarginWeekly_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_balancing_pricing_market_index(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        dataProviders: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> MarketIndexResponse_ResponseWithMetadata:
        """
        Market Index Data (MID) price time series

        This endpoint provides Market Index Data received from NGESO.
            
Market Index Data is a key component in the calculation of System Buy Price and System Sell Price for each
Settlement Period. This data is received from each of the appointed Market Index Data Providers (MIDPs) and
reflects the price of wholesale electricity in Great Britain in the short term markets. The Market Index Data
which is received from each MIDP for each Settlement Period consists of a Market Index Volume and
Market Index Price, representing the volume and price of trading for the relevant period in the market operated
by the MIDP. The Market Price (the volume weighed average Market Index Price) is used to derive
the Reverse Price (SBP or SSP)."
            
The two data providers available to query are N2EX ("N2EXMIDP") and APX ("APXMIDP").

By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /balancing/pricing/market-index?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /balancing/pricing/market-index?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /balancing/pricing/market-index?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /balancing/pricing/market-index?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            dataProviders: The data providers to query. If no data provider is selected both will be displayed., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            MarketIndexResponse_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if dataProviders is not None:
            params["dataProviders"] = dataProviders
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/pricing/market-index", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return MarketIndexResponse_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as MarketIndexResponse_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_balancing_nonbm_stor(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        includeZero: Optional[bool] = None,
        format: Optional[str] = None
    ) -> NonBmStorResponse_ResponseWithMetadata:
        """
        Non-BM STOR time series (NONBM)

        This endpoint provides data about the Short Term Operating Reserves (STOR) that have been made use of
by NGESO. This is activity that is outside of the Balancing Mechanism and takes place to meet the need to
increase generation or decrease demand.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /balancing/nonbm/stor?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /balancing/nonbm/stor?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /balancing/nonbm/stor?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /balancing/nonbm/stor?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            includeZero: Include data points with a generation of zero., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            NonBmStorResponse_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if includeZero is not None:
            params["includeZero"] = includeZero
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/nonbm/stor", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return NonBmStorResponse_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as NonBmStorResponse_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_balancing_nonbm_stor_events(
        self,
        count: int,
        before: Optional[str] = None,
        settlementPeriodBefore: Optional[int] = None,
        format: Optional[str] = None
    ) -> NonBmStorResponse_ResponseWithMetadata:
        """
        Non-BM STOR events (NONBM)

        This endpoint provides data about the start of NGESO Short Term Operating Reserves (STOR) events. This is
activity that is outside of the Balancing Mechanism and takes place to meet the need to
increase generation or decrease demand. Each result has a non-zero generation value which was preceded by a zero
generation value.
            
By default, the before parameter filters the data by start time. If the settlementPeriodBefore parameter is
provided, the before parameter instead filters on settlement date, allowing for searching by start time or
settlement date & settlement period.
Note: When filtering via settlement date, before is treated as a Date only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering latest 3 events:
            
    /balancing/nonbm/stor/events?count=3
            
Filtering latest 3 events before start time:
            
    /balancing/nonbm/stor/events?before=2022-08-01T00:00Z&count=3
            
Filtering latest 3 events before settlement date and settlement period:
            
    /balancing/nonbm/stor/events?before=2022-08-01T00:00Z&settlementPeriodBefore=48&count=3

        Args:
            count: The number of events to return.
            before: If specified, filters events to those with a start time before or at the date, or a settlement date before the date if
settlementPeriodBefore is also specified.
If omitted, latest events are returned., optional
            settlementPeriodBefore: Filters events to those with a settlement period before or at the value.
Before parameter must be specified if this is specified., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            NonBmStorResponse_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["count"] = count
        if before is not None:
            params["before"] = before
        if settlementPeriodBefore is not None:
            params["settlementPeriodBefore"] = settlementPeriodBefore
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/nonbm/stor/events", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return NonBmStorResponse_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as NonBmStorResponse_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_balancing_nonbm_volumes(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        bmUnit: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> BalancingServicesVolume_ResponseWithMetadata:
        """
        Balancing services volume (QAS)

        This endpoint provides balancing services volume data received from NGESO, with an added computed 'Time' field.
(The time field is calculated from the settlement date & period and represents the earliest possible time for
for which the datapoint applies)
            
Balancing services volume is a volume which is received from the System Operator, which represents the volume
of energy (MWh) associated with the provision of Applicable Balancing Services for each relevant BM Unit and
Settlement Period.

QAS can be positive or negative and is normally only provided where there is a non-zero volume.
            
By default, the from and to parameters filter the data by time inclusively. If the settlementPeriodFrom or
settlementPeriodTo parameters are provided, the corresponding from or to parameter instead filters on settlement
date, allowing for searching by a combination of time and/or settlement date & settlement period.
Note: When filtering via settlement date, from/to are treated as Dates only, with the time being ignored. For
example, 2022-06-01T00:00Z and 2022-06-01T11:11Z are both treated as the settlement date 2022-06-01.
            
All Dates and DateTimes should be expressed as defined within
<a href="https://datatracker.ietf.org/doc/html/rfc3339#section-5.6" target="_blank">RFC 3339</a>.
            
Some examples of date parameter combinations are shown below.
            
Filtering from start time to start time:
            
    /balancing/nonbm/volumes?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z
            
Filtering from start time to settlement date and period:
            
    /balancing/nonbm/volumes?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodTo=1
            
Filtering from settlement date and period to start time:
            
    /balancing/nonbm/volumes?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1
            
Filtering from settlement date and period to settlement date and period:
            
    /balancing/nonbm/volumes?from=2022-06-01T00:00Z&to=2022-07-01T00:00Z&settlementPeriodFrom=1&settlementPeriodTo=1

        Args:
            from_: The "from" start time or settlement date for the filter.
            to_: The "to" start time or settlement date for the filter.
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            bmUnit: The BM units to query. Add each unit separately. If no BM unit is selected all BM units will be displayed., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            BalancingServicesVolume_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if bmUnit is not None:
            params["bmUnit"] = bmUnit
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/balancing/nonbm/volumes", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return BalancingServicesVolume_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as BalancingServicesVolume_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_reference_fueltypes_all(
        self
    ) -> List[str]:
        """
        Fuel types

        This endpoint provides a current list of fuel types

        Returns:
            List[str]: List of string values
        """
        params = {}

        response = self._make_request("GET", f"/reference/fueltypes/all", params=params)
        
        # Parse response into Pydantic model(s)
        # Returns list of strings directly
        return response

    def get_reference_remit_participants_all(
        self
    ) -> List[str]:
        """
        Participants

        This endpoint provides a current list of participant IDs received from REMIT messages

        Returns:
            List[str]: List of string values
        """
        params = {}

        response = self._make_request("GET", f"/reference/remit/participants/all", params=params)
        
        # Parse response into Pydantic model(s)
        # Returns list of strings directly
        return response

    def get_reference_remit_assets_all(
        self
    ) -> List[str]:
        """
        Assets

        This endpoint provides a current list of asset IDs received from REMIT messages

        Returns:
            List[str]: List of string values
        """
        params = {}

        response = self._make_request("GET", f"/reference/remit/assets/all", params=params)
        
        # Parse response into Pydantic model(s)
        # Returns list of strings directly
        return response

    def get_reference_remit_fueltypes_all(
        self
    ) -> List[str]:
        """
        REMIT fuel types

        This endpoint provides a current list of fuel types received from REMIT messages

        Returns:
            List[str]: List of string values
        """
        params = {}

        response = self._make_request("GET", f"/reference/remit/fueltypes/all", params=params)
        
        # Parse response into Pydantic model(s)
        # Returns list of strings directly
        return response

    def get_reference_bmunits_all(
        self
    ) -> List[BmUnitData]:
        """
        BM Units

        This endpoint provides a current list of BM units held by Elexon

        Returns:
            List[BmUnitData]: List of BmUnitData objects
        """
        params = {}

        response = self._make_request("GET", f"/reference/bmunits/all", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [BmUnitData(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[BmUnitData]: {e}. Returning raw data.")
                return response
        return response

    def get_reference_interconnectors_all(
        self
    ) -> List[InterconnectorData]:
        """
        Interconnectors

        This endpoint provides a current list of interconnectors

        Returns:
            List[InterconnectorData]: List of InterconnectorData objects
        """
        params = {}

        response = self._make_request("GET", f"/reference/interconnectors/all", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [InterconnectorData(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[InterconnectorData]: {e}. Returning raw data.")
                return response
        return response

    def get_remit(
        self,
        messageId: List[str],
        format: Optional[str] = None
    ) -> RemitMessageWithId_ResponseWithMetadata:
        """
        Bulk fetch message details by IDs

        This endpoint provides one or more REMIT messages based on the given message IDs.

        Args:
            messageId: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            RemitMessageWithId_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["messageId"] = messageId
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/remit", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return RemitMessageWithId_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as RemitMessageWithId_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_remit_search(
        self,
        mrid: str,
        revisionNumber: Optional[int] = None,
        format: Optional[str] = None
    ) -> RemitMessageWithId_ResponseWithMetadata:
        """
        Fetch message details by mRID

        This endpoint provides one or more REMIT messages based on the given mRID and revision number. If none is given
it returns the REMIT message revision with the latest revision number.

        Args:
            mrid: 
            revisionNumber: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            RemitMessageWithId_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["mrid"] = mrid
        if revisionNumber is not None:
            params["revisionNumber"] = revisionNumber
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/remit/search", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return RemitMessageWithId_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as RemitMessageWithId_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_remit_revisions(
        self,
        mrid: Optional[str] = None,
        messageId: Optional[int] = None,
        format: Optional[str] = None
    ) -> RemitMessageIdentifierWithUrl_ResponseWithMetadata:
        """
        List all message revisions

        This endpoint provides all revisions for a given REMIT message.
The message can be specified in two ways:
- the mRID
- the message ID of a specific revision, which will return the entire list of revisions for that message

        Args:
            mrid: , optional
            messageId: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            RemitMessageIdentifierWithUrl_ResponseWithMetadata: Typed response object
        """
        params = {}
        if mrid is not None:
            params["mrid"] = mrid
        if messageId is not None:
            params["messageId"] = messageId
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/remit/revisions", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return RemitMessageIdentifierWithUrl_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as RemitMessageIdentifierWithUrl_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_remit_list_by_publish(
        self,
        from_: str,
        to_: str,
        participantId: Optional[str] = None,
        assetId: Optional[str] = None,
        messageType: Optional[str] = None,
        unavailabilityType: Optional[str] = None,
        eventType: Optional[List[str]] = None,
        fuelType: Optional[List[str]] = None,
        latestRevisionOnly: Optional[bool] = None,
        profileOnly: Optional[bool] = None,
        format: Optional[str] = None
    ) -> RemitMessageIdentifierWithUrl_ResponseWithMetadata:
        """
        List messages by publish time

        This endpoint provides a list of REMIT message identifiers based on the publish time and other optional parameters.
            
- Filtering by LatestRevisionOnly (default = true):
   if true, include only the latest revision of each message.
            
- Filtering by ProfileOnly (default = false):
    if true, include only messages with an outage profile.

        Args:
            from_: 
            to_: 
            participantId: , optional
            assetId: , optional
            messageType: , optional
            unavailabilityType: , optional
            eventType: , optional
            fuelType: , optional
            latestRevisionOnly: , optional
            profileOnly: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            RemitMessageIdentifierWithUrl_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if participantId is not None:
            params["participantId"] = participantId
        if assetId is not None:
            params["assetId"] = assetId
        if messageType is not None:
            params["messageType"] = messageType
        if unavailabilityType is not None:
            params["unavailabilityType"] = unavailabilityType
        if eventType is not None:
            params["eventType"] = eventType
        if fuelType is not None:
            params["fuelType"] = fuelType
        if latestRevisionOnly is not None:
            params["latestRevisionOnly"] = latestRevisionOnly
        if profileOnly is not None:
            params["profileOnly"] = profileOnly
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/remit/list/by-publish", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return RemitMessageIdentifierWithUrl_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as RemitMessageIdentifierWithUrl_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_remit_list_by_publish_stream(
        self,
        from_: str,
        to_: str,
        participantId: Optional[str] = None,
        assetId: Optional[str] = None,
        messageType: Optional[str] = None,
        unavailabilityType: Optional[str] = None,
        eventType: Optional[List[str]] = None,
        fuelType: Optional[List[str]] = None,
        latestRevisionOnly: Optional[bool] = None,
        profileOnly: Optional[bool] = None
    ) -> List[RemitMessageIdentifierWithUrl]:
        """
        List messages by publish time (stream)

        This endpoint provides a list of REMIT message identifiers based on the publish time and other optional parameters.
            
- Filtering by LatestRevisionOnly (default = true):
   if true, include only the latest revision of each message.
            
- Filtering by ProfileOnly (default = false):
    if true, include only messages with an outage profile.
            
This endpoint has an optimised JSON payload and is aimed at frequent requests for this data.

        Args:
            from_: 
            to_: 
            participantId: , optional
            assetId: , optional
            messageType: , optional
            unavailabilityType: , optional
            eventType: , optional
            fuelType: , optional
            latestRevisionOnly: , optional
            profileOnly: , optional

        Returns:
            List[RemitMessageIdentifierWithUrl]: List of RemitMessageIdentifierWithUrl objects
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if participantId is not None:
            params["participantId"] = participantId
        if assetId is not None:
            params["assetId"] = assetId
        if messageType is not None:
            params["messageType"] = messageType
        if unavailabilityType is not None:
            params["unavailabilityType"] = unavailabilityType
        if eventType is not None:
            params["eventType"] = eventType
        if fuelType is not None:
            params["fuelType"] = fuelType
        if latestRevisionOnly is not None:
            params["latestRevisionOnly"] = latestRevisionOnly
        if profileOnly is not None:
            params["profileOnly"] = profileOnly

        response = self._make_request("GET", f"/remit/list/by-publish/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [RemitMessageIdentifierWithUrl(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[RemitMessageIdentifierWithUrl]: {e}. Returning raw data.")
                return response
        return response

    def get_remit_list_by_event(
        self,
        from_: str,
        to_: str,
        participantId: Optional[str] = None,
        assetId: Optional[str] = None,
        messageType: Optional[str] = None,
        unavailabilityType: Optional[str] = None,
        eventType: Optional[List[str]] = None,
        fuelType: Optional[List[str]] = None,
        latestRevisionOnly: Optional[bool] = None,
        profileOnly: Optional[bool] = None,
        format: Optional[str] = None
    ) -> RemitMessageIdentifierWithUrl_ResponseWithMetadata:
        """
        List messages by event time

        This endpoint provides a list of REMIT message identifiers based on the event start time, end time and other optional parameters.
            
- Filtering by LatestRevisionOnly (default = true):
   if true, include only the latest revision of each message.
            
- Filtering by ProfileOnly (default = false):
    if true, include only messages with an outage profile.

        Args:
            from_: 
            to_: 
            participantId: , optional
            assetId: , optional
            messageType: , optional
            unavailabilityType: , optional
            eventType: , optional
            fuelType: , optional
            latestRevisionOnly: , optional
            profileOnly: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            RemitMessageIdentifierWithUrl_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if participantId is not None:
            params["participantId"] = participantId
        if assetId is not None:
            params["assetId"] = assetId
        if messageType is not None:
            params["messageType"] = messageType
        if unavailabilityType is not None:
            params["unavailabilityType"] = unavailabilityType
        if eventType is not None:
            params["eventType"] = eventType
        if fuelType is not None:
            params["fuelType"] = fuelType
        if latestRevisionOnly is not None:
            params["latestRevisionOnly"] = latestRevisionOnly
        if profileOnly is not None:
            params["profileOnly"] = profileOnly
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/remit/list/by-event", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return RemitMessageIdentifierWithUrl_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as RemitMessageIdentifierWithUrl_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_remit_list_by_event_stream(
        self,
        from_: str,
        to_: str,
        participantId: Optional[str] = None,
        assetId: Optional[str] = None,
        messageType: Optional[str] = None,
        unavailabilityType: Optional[str] = None,
        eventType: Optional[List[str]] = None,
        fuelType: Optional[List[str]] = None,
        latestRevisionOnly: Optional[bool] = None,
        profileOnly: Optional[bool] = None
    ) -> List[RemitMessageIdentifierWithUrl]:
        """
        List messages by event time (stream)

        This endpoint provides a list of REMIT message identifiers based on the event start, end time and other optional parameters.
            
- Filtering by LatestRevisionOnly (default = true):
   if true, include only the latest revision of each message.
            
- Filtering by ProfileOnly (default = false):
    if true, include only messages with an outage profile.
            
This endpoint has an optimised JSON payload and is aimed at frequent requests for this data.

        Args:
            from_: 
            to_: 
            participantId: , optional
            assetId: , optional
            messageType: , optional
            unavailabilityType: , optional
            eventType: , optional
            fuelType: , optional
            latestRevisionOnly: , optional
            profileOnly: , optional

        Returns:
            List[RemitMessageIdentifierWithUrl]: List of RemitMessageIdentifierWithUrl objects
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if participantId is not None:
            params["participantId"] = participantId
        if assetId is not None:
            params["assetId"] = assetId
        if messageType is not None:
            params["messageType"] = messageType
        if unavailabilityType is not None:
            params["unavailabilityType"] = unavailabilityType
        if eventType is not None:
            params["eventType"] = eventType
        if fuelType is not None:
            params["fuelType"] = fuelType
        if latestRevisionOnly is not None:
            params["latestRevisionOnly"] = latestRevisionOnly
        if profileOnly is not None:
            params["profileOnly"] = profileOnly

        response = self._make_request("GET", f"/remit/list/by-event/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [RemitMessageIdentifierWithUrl(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[RemitMessageIdentifierWithUrl]: {e}. Returning raw data.")
                return response
        return response

    def get_generation_outturn(
        self,
        from_: Optional[str] = None,
        to_: Optional[str] = None,
        format: Optional[str] = None
    ) -> RollingSystemDemand_ResponseWithMetadata:
        """
        Total generation outturn (FUELINST)

        This endpoint provides the total generation outturn across all fuel types, derived by summing generation
of all categories from the Generation by Fuel Type report.
            
This data can be used as a proxy for rolling system demand.

        Args:
            from_: , optional
            to_: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            RollingSystemDemand_ResponseWithMetadata: Typed response object
        """
        params = {}
        if from_ is not None:
            params["from"] = from_
        if to_ is not None:
            params["to"] = to_
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/generation/outturn", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return RollingSystemDemand_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as RollingSystemDemand_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_saa_datasets_total_exempt_volume(
        self,
        settlementDate: str,
        settlementRunType: Optional[List[str]] = None,
        format: Optional[str] = None
    ) -> TotalExemptSupplyVolumeResponse_ResponseWithMetadata:
        """
        Total Exempt Supply Volume (S0621)

        Returns the total Import and Export Exempt Metered Volume (in MW) for the requested settlement date and settlement run type.
            
This endpoint will not return any data until S0621 data is first published at the beginning of March 2025.

Settlement date parameter must be provided in the exact format YYYY-MM-dd.

        Args:
            settlementDate: The settlement date for the filter.
            settlementRunType: The settlement run type for the filter.
If one or more run types are specified, only data with those run types is returned.
If no run type is specified, for each settlement period only the single data point with the most recent run type is returned., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            TotalExemptSupplyVolumeResponse_ResponseWithMetadata: Typed response object
        """
        params = {}
        if settlementRunType is not None:
            params["settlementRunType"] = settlementRunType
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/saa/datasets/total-exempt-volume/{settlementDate}", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return TotalExemptSupplyVolumeResponse_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as TotalExemptSupplyVolumeResponse_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_soso_prices(
        self,
        from_: str,
        to_: str,
        format: Optional[str] = None
    ) -> SoSoPrices_ResponseWithMetadata:
        """
        SO-SO prices (SOSO)

        This endpoint provides system operator to system operator prices data.
It can be filtered by start time.
            
This API endpoint has a maximum range of 24 hours.

        Args:
            from_: 
            to_: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            SoSoPrices_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/soso/prices", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return SoSoPrices_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as SoSoPrices_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_surplus_daily(
        self,
        format: Optional[str] = None
    ) -> ForecastSurplusDaily_ResponseWithMetadata:
        """
        Daily surplus forecast (OCNMFD)

        This endpoint provides the Generating Plant Operating Surplus covering 2 days ahead to 14 days ahead in MW values.
The Daily API outputs the latest published data for daily surplus forecast for D+2 t D+14

        Args:
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            ForecastSurplusDaily_ResponseWithMetadata: Typed response object
        """
        params = {}
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/surplus/daily", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return ForecastSurplusDaily_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as ForecastSurplusDaily_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_surplus_daily_history(
        self,
        publishTime: str,
        format: Optional[str] = None
    ) -> ForecastSurplusDaily_ResponseWithMetadata:
        """
        Historical daily surplus forecast (OCNMFD)

        This endpoint provides the historic Generating Plant Operating Surplus covering 2 days ahead to 14 days ahead in MW values.
The historic API outputs the latest published data for historic daily surplus forecast for D+2 to D+14

        Args:
            publishTime: 
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            ForecastSurplusDaily_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["publishTime"] = publishTime
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/surplus/daily/history", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return ForecastSurplusDaily_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as ForecastSurplusDaily_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_surplus_daily_evolution(
        self,
        forecastDate: str,
        format: Optional[str] = None
    ) -> ForecastSurplusDaily_ResponseWithMetadata:
        """
        Evolution daily surplus forecast (OCNMFD)

        This endpoint provides the daily evolution Generating Plant Operating Surplus covering 2 days ahead to 14 days ahead in MW values.
The Daily API outputs the latest published data for daily surplus forecast for D+2 to D+14.
            
Date parameter must be provided in the exact format yyyy-MM-dd.

        Args:
            forecastDate: The forecast date for the filter. This must be in the format yyyy-MM-dd.
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            ForecastSurplusDaily_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["forecastDate"] = forecastDate
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/surplus/daily/evolution", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return ForecastSurplusDaily_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as ForecastSurplusDaily_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_surplus_weekly(
        self,
        range: Optional[str] = None,
        format: Optional[str] = None
    ) -> ForecastSurplusWeekly_ResponseWithMetadata:
        """
        Weekly surplus forecast (OCNMFW, OCNMF3Y)

        This endpoint provides the Generating Plant Operating Surplus covering 2 weeks ahead to 156 weeks ahead in MW values.
The weekly API outputs the latest published data for weekly surplus forecast for W+2 to W+156

        Args:
            range: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            ForecastSurplusWeekly_ResponseWithMetadata: Typed response object
        """
        params = {}
        if range is not None:
            params["range"] = range
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/surplus/weekly", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return ForecastSurplusWeekly_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as ForecastSurplusWeekly_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_surplus_weekly_history(
        self,
        publishTime: str,
        range: Optional[str] = None,
        format: Optional[str] = None
    ) -> ForecastSurplusWeekly_ResponseWithMetadata:
        """
        Historical weekly surplus forecast (OCNMFW, OCNMF3Y)

        This endpoint provides the historic Generating Plant Operating Surplus covering 2 weeks ahead to 156 weeks ahead in MW values.
The weekly API outputs the latest published data for weekly surplus forecast for W+2 to W+156.
Historical published data of weekly surplus forecasts for a given publish date in the 2-156 week dataset.

        Args:
            publishTime: 
            range: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            ForecastSurplusWeekly_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["publishTime"] = publishTime
        if range is not None:
            params["range"] = range
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/surplus/weekly/history", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return ForecastSurplusWeekly_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as ForecastSurplusWeekly_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_surplus_weekly_evolution(
        self,
        year: int,
        week: int,
        range: Optional[str] = None,
        format: Optional[str] = None
    ) -> ForecastSurplusWeekly_ResponseWithMetadata:
        """
        Evolution weekly surplus forecast (OCNMFW, OCNMF3Y)

        This endpoint provides the evolution Generating Plant Operating Surplus  covering 2 weeks ahead to 156 weeks ahead in MW values.
The weekly API outputs the latest published data for weekly surplus forecast for W+2 to W+156

        Args:
            year: 
            week: 
            range: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            ForecastSurplusWeekly_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["year"] = year
        params["week"] = week
        if range is not None:
            params["range"] = range
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/surplus/weekly/evolution", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return ForecastSurplusWeekly_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as ForecastSurplusWeekly_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_system_frequency(
        self,
        from_: Optional[str] = None,
        to_: Optional[str] = None,
        format: Optional[str] = None
    ) -> SystemFrequency_ResponseWithMetadata:
        """
        System frequency (FREQ)

        This endpoint allows for retrieving a collection of recent system frequency data from National Grid ESO. Results
can be filtered by a range of DateTime parameters. This endpoint is useful for ad-hoc querying frequency data.

        Args:
            from_: , optional
            to_: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            SystemFrequency_ResponseWithMetadata: Typed response object
        """
        params = {}
        if from_ is not None:
            params["from"] = from_
        if to_ is not None:
            params["to"] = to_
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/system/frequency", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return SystemFrequency_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as SystemFrequency_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_system_frequency_stream(
        self,
        from_: Optional[str] = None,
        to_: Optional[str] = None
    ) -> List[SystemFrequency]:
        """
        System frequency (FREQ) stream

        This endpoint allows for retrieving a stream of recent system frequency data from National Grid ESO. Results can
be filtered by a range of DateTime parameters. This endpoint has an optimised JSON payload and aimed at frequent
request for the frequency data.

        Args:
            from_: , optional
            to_: , optional

        Returns:
            List[SystemFrequency]: List of SystemFrequency objects
        """
        params = {}
        if from_ is not None:
            params["from"] = from_
        if to_ is not None:
            params["to"] = to_

        response = self._make_request("GET", f"/system/frequency/stream", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, list):
            try:
                return [SystemFrequency(**item) for item in response]
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse list response as List[SystemFrequency]: {e}. Returning raw data.")
                return response
        return response

    def get_system_warnings(
        self,
        warningType: Optional[str] = None,
        publishDateTimeFrom: Optional[str] = None,
        publishDateTimeTo: Optional[str] = None,
        format: Optional[str] = None
    ) -> SystemWarningsData_ResponseWithMetadata:
        """
        System warnings (SYSWARN)

        This endpoint provides system warnings data. Results can be filtered by warning type and a range of DateTime parameters.
- If no parameters are specified then the latest message is returned
- If just a warning type is specified then the latest message of that type is returned
- If just publish times are specified then all messages within that range are returned

        Args:
            warningType: , optional
            publishDateTimeFrom: , optional
            publishDateTimeTo: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            SystemWarningsData_ResponseWithMetadata: Typed response object
        """
        params = {}
        if warningType is not None:
            params["warningType"] = warningType
        if publishDateTimeFrom is not None:
            params["publishDateTimeFrom"] = publishDateTimeFrom
        if publishDateTimeTo is not None:
            params["publishDateTimeTo"] = publishDateTimeTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/system/warnings", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return SystemWarningsData_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as SystemWarningsData_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_system_demand_control_instructions(
        self,
        from_: Optional[str] = None,
        to_: Optional[str] = None,
        format: Optional[str] = None
    ) -> DemandControlInstructionData_ResponseWithMetadata:
        """
        Demand control instructions (DCI)

        This endpoint provides demand control instruction data, filtered by the time range of the instruction.
There is no date range limit on parameters.
If no query parameters are supplied all data is returned.

        Args:
            from_: , optional
            to_: , optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            DemandControlInstructionData_ResponseWithMetadata: Typed response object
        """
        params = {}
        if from_ is not None:
            params["from"] = from_
        if to_ is not None:
            params["to"] = to_
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/system/demand-control-instructions", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return DemandControlInstructionData_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as DemandControlInstructionData_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_forecast_system_loss_of_load(
        self,
        from_: str,
        to_: str,
        settlementPeriodFrom: Optional[int] = None,
        settlementPeriodTo: Optional[int] = None,
        format: Optional[str] = None
    ) -> LossOfLoadProbabilityDeratedMarginResponse_ResponseWithMetadata:
        """
        Loss of load probability and de-rated margin forecast (LOLPDRM)

        This endpoint provides the 1h, 2h, 4h, 8h and 12h+ Loss of Load Probability and De-rated Margin forecasts
for each settlement period over a requested time range.
            
For each forecast horizon at 1, 2, 4 or 8 hours, the returned value is the forecast received that number of hours
before the start of the settlement period.
            
For the forecast horizon of 12h, the returned value is the most recent forecast received 12 or more hours
before the start of the settlement period. That is, if the most recent forecast was published today at 00:00,
- for 11:30 today, the 12h forecast is the one published yesterday at 23:30 (12h before)
- for 12:00 today, the 12h forecast is the one published today at 00:00 (12h before)
- for 12:30 today, the 12h forecast is the one published today at 00:00 (the latest published)

        Args:
            from_: 
            to_: 
            settlementPeriodFrom: The "from" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            settlementPeriodTo: The "to" settlement period for the filter. This should be an integer from 1-50 inclusive., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            LossOfLoadProbabilityDeratedMarginResponse_ResponseWithMetadata: Typed response object
        """
        params = {}
        params["from"] = from_
        params["to"] = to_
        if settlementPeriodFrom is not None:
            params["settlementPeriodFrom"] = settlementPeriodFrom
        if settlementPeriodTo is not None:
            params["settlementPeriodTo"] = settlementPeriodTo
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/forecast/system/loss-of-load", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return LossOfLoadProbabilityDeratedMarginResponse_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as LossOfLoadProbabilityDeratedMarginResponse_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response

    def get_temperature(
        self,
        from_: Optional[str] = None,
        to_: Optional[str] = None,
        format: Optional[str] = None
    ) -> TemperatureData_ResponseWithMetadata:
        """
        Temperature data (TEMP)

        This endpoint provides daily average GB temperature data (in Celsius) as well as reference temperatures (low, normal and high).
This average data is calculated by National Grid ESO from the data retrieved from 6 weather stations around Britain.
NGESO use this data as part of the electricity demand forecasting process.
            
Date parameters must be provided in the exact format yyyy-MM-dd.

        Args:
            from_: The from date for the filter. This must be in the format yyyy-MM-dd., optional
            to_: The to date for the filter. This must be in the format yyyy-MM-dd., optional
            format: Response data format. Use json/xml to include metadata., optional

        Returns:
            TemperatureData_ResponseWithMetadata: Typed response object
        """
        params = {}
        if from_ is not None:
            params["from"] = from_
        if to_ is not None:
            params["to"] = to_
        if format is not None:
            params["format"] = format

        response = self._make_request("GET", f"/temperature", params=params)
        
        # Parse response into Pydantic model(s)
        if isinstance(response, dict):
            try:
                return TemperatureData_ResponseWithMetadata(**response)
            except Exception as e:
                import logging
                logging.warning(f"Failed to parse response as TemperatureData_ResponseWithMetadata: {e}. Returning raw data.")
                return response
        return response
