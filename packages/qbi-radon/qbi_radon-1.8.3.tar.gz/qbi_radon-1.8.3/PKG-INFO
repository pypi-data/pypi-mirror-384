Metadata-Version: 2.1
Name: qbi-radon
Version: 1.8.3
Summary: Radon Transformation for Pytorch 2
Author: Minh Nhat Trinh
Classifier: Intended Audience :: Science/Research
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: GNU General Public License v3 (GPLv3)
Classifier: Operating System :: OS Independent
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: torch>=2.0

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1GqOcOWj128oQ2ojBy8VX5bzg0zAY_MDz?usp=sharing)
# üì¶ QBI_radon

**QBI_radon** is a Python library that provides an efficient, GPU-accelerated, and differentiable implementation of the **Radon transform** using **PyTorch ‚â• 2.0**.

QBI_radon provides **GPU-accelerated forward and backward projection operations** for tomography, making it ideal for computed tomography (CT) research and development.

The Radon transform maps an image to its Radon space representation ‚Äî a key operation in solving **CT reconstruction problems**. This GPU-accelerated library is designed to help researchers and developers obtain **fast and accurate tomographic reconstructions**, and seamlessly combine **deep learning** and **model-based approaches** in a unified PyTorch framework.

---

## üöÄ Key Features

- ‚úÖ **Differentiable Forward & Back Projections**  
  All transformations are fully compatible with PyTorch‚Äôs autograd system, allowing gradient computation via `.backward()`.

- ‚ö° **Batch Processing & GPU Acceleration**  
  Designed for speed ‚Äî supports batched operations and runs efficiently on GPUs. Faster than `skimage`'s Radon transform.

- üîÅ **Transparent PyTorch API**  
  Seamless integration with PyTorch pipelines. Compatible with **Nvidia AMP** for mixed-precision training and inference.

- üß© **Cross-Platform Support**  
  Built entirely on PyTorch ‚â• 2.0, ensuring compatibility across major operating systems ‚Äî Windows, Ubuntu, macOS, and more.

---

## üß† Applications

- Deep learning for CT image reconstruction  
- Model-based & hybrid inverse problems  
- Differentiable physics-based layers in neural networks  
- GPU-accelerated Filtered Backprojection


## üîß Implemented Operations

- ‚úÖ **Parallel Beam Projections**

Additional projection geometries and advanced features are under development. Stay tuned!

---

## üì¶ Installation

```bash
pip install QBI-radon
```

## üìä Benchmarking

We benchmarked **QBI_radon** against the widely used `skimage` implementation of the Radon transform on a **NVIDIA GeForce RTX 4070 SUPER** with the following settings:

![Benchmarking Results](benchmarking.png)

üëâ **QBI_radon is > 25√ó faster** than the CPU-based `skimage` implementation in both forward and backward projections.

## üöÄ Google Colab

You can try the library from your browser using Google Colab, you can find an example notebook [here](https://colab.research.google.com/drive/1GqOcOWj128oQ2ojBy8VX5bzg0zAY_MDz?usp=sharing).

## üìö Citation
If you are using QBI_radon in your research, please cite the following:

[![DOI](https://zenodo.org/badge/811419352.svg)](https://doi.org/10.5281/zenodo.16416058)

```bibtex
@software{Trinh_QBioImaging_QBI_radon_2025,
author = {Trinh, Minh-Nhat and Teresa, M Correia},
doi = {https://doi.org/10.5281/zenodo.16416059},
month = jul,
title = {{QBioImaging/QBI\_radon}},
url = {https://github.com/QBioImaging/QBI_radon},
version = {v1.7},
year = {2025}
}
```

## üìù Acknowledgements
This study received Portuguese national funds from FCT‚ÄîFoundation for Science and Technology through projects UIDB/04326/2020 (DOI:https://doi.org/10.54499/UIDB/04326/2020), UIDP/04326/2020 (DOI:https://doi.org/10.54499/UIDP/04326/2020) and LA/P/0101/2020 (DOI:https://doi.org/10.54499/LA/P/0101/2020). This Project received funding from ‚Äòla Caixa‚Äô Foundation and FCT, I P under the Project code LCF/PR/HR22/00533, European Union‚Äôs Horizon 2020 research and innovation program under the Marie Sk≈Çodowska-Curie OPTIMAR grant with agreement no 867450 (DOI:https://doi.org/10.3030/867450), European Union‚Äôs Horizon Europe Programme IMAGINE under grant agreement no. 101094250
(DOI:https://doi.org/10.3030/101094250), and NVIDIA GPU hardware grant.
