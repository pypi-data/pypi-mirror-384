{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b67c8ba-ccad-4c8c-9f42-f32ea510ed3a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " # Lecture Downloader - Usage Guide\n",
    "\n",
    " This notebook demonstrates the lecture_downloader package with:\n",
    " - Complete pipeline workflow (recommended)\n",
    " - Individual functional API operations\n",
    " - Environment setup and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387ab34f-661b-48de-957f-7a938f895d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lecture_downloader as ld\n",
    "from lecture_downloader import LectureProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste links from video downloadhelper extension or video download urls here\n",
    "links_content = \"\"\"\n",
    "https://cfvod.kaltura.com/scf/...\n",
    "https://cfvod.kaltura.com/scf/...\n",
    "\"\"\"\n",
    "with open(\"example_links.txt\", \"w\") as f:\n",
    "    f.write(links_content)\n",
    "\n",
    "# Create example titles JSON (optional if you want to use custom titles)\n",
    "titles_content = \"\"\"\n",
    "{\n",
    "  \"Module 1: Introduction to ML\": [\n",
    "    \"Database Overview_Introduction\",\n",
    "    \"Database Overview_Fundamentals\"\n",
    "  ],\n",
    "  \"Module 2: SQL\": [\n",
    "    \"Database Overview_Advanced Queries\"\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "with open(\"example_titles.json\", \"w\") as f:\n",
    "    f.write(titles_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c082b05e-a34a-4a61-b350-29678cf1754a",
   "metadata": {},
   "source": [
    "## Complete Pipeline\n",
    "\n",
    " Run the entire workflow in a single command - download, merge, and transcribe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eead609e-879d-4363-8eac-3d2cfb623480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Downloading lectures...\n",
      "Download Plan:\n",
      "  Output: lecture_processing/01_downloads\n",
      "  Modules: 2\n",
      "  Total Lectures: 3\n",
      "\n",
      "├── Module 1: Introduction to ML (2 lectures)\n",
      "│   ├── CS8803-001_Database Overview_Introduction\n",
      "│   └── CS8803-001_Database Overview_Fundamentals\n",
      "└── Module 2: SQL (1 lectures)\n",
      "    └── CS8803-001_Database Overview_Advanced Queries\n",
      "\n",
      "Downloading Module 1: Introduction to ML/CS8803-001_Database Overview_Introduction to lecture_processing/01_downloads/Module 1: Introduction to ML/CS8803-001_Database Overview_Introduction.mp4...\n",
      "Downloading Module 1: Introduction to ML/CS8803-001_Database Overview_Fundamentals to lecture_processing/01_downloads/Module 1: Introduction to ML/CS8803-001_Database Overview_Fundamentals.mp4...\n",
      "Downloading Module 2: SQL/CS8803-001_Database Overview_Advanced Queries to lecture_processing/01_downloads/Module 2: SQL/CS8803-001_Database Overview_Advanced Queries.mp4...\n",
      "Successfully downloaded: Module 2: SQL/CS8803-001_Database Overview_Advanced Queries\n",
      "Successfully downloaded: Module 1: Introduction to ML/CS8803-001_Database Overview_Introduction\n",
      "Successfully downloaded: Module 1: Introduction to ML/CS8803-001_Database Overview_Fundamentals\n",
      "Download Summary: Successful: 3, Failed: 0\n",
      "\n",
      "Step 2: Merging videos by module...\n",
      "Merge Plan:\n",
      "  Input: lecture_processing/01_downloads\n",
      "  Output: lecture_processing/02_merged\n",
      "  Modules: 2\n",
      "\n",
      "\n",
      "  Successfully created: lecture_processing/02_merged/Module 02 SQL.mp4\n",
      "  Successfully created: lecture_processing/02_merged/Module 01 Introduction to ML.mp4\n",
      "Merge Summary: Successful: 2, Failed: 0\n",
      "\n",
      "Step 3: Transcribing videos...\n",
      "Transcription Plan:\n",
      "  Input: lecture_processing/02_merged\n",
      "  Output: lecture_processing/03_transcripts\n",
      "  Method: whisper\n",
      "  Videos: 2\n",
      "\n",
      "├── Module 01 Introduction to ML\n",
      "│   ├── Module 01 Introduction to ML.txt\n",
      "│   └── srt/Module 01 Introduction to ML.srt\n",
      "└── Module 02 SQL\n",
      "    ├── Module 02 SQL.txt\n",
      "    └── srt/Module 02 SQL.srt\n",
      "\n",
      "Processing: Module 01 Introduction to ML\n",
      "Loading Whisper model: base\n",
      "Whisper transcription completed: 1311 words\n",
      "Transcript saved: lecture_processing/03_transcripts/transcripts/Module 01 Introduction to ML.txt\n",
      "Subtitles successfully injected into video\n",
      "Completed: Module 01 Introduction to ML\n",
      "Processing: Module 02 SQL\n",
      "Loading Whisper model: base\n",
      "Whisper transcription completed: 380 words\n",
      "Transcript saved: lecture_processing/03_transcripts/transcripts/Module 02 SQL.txt\n",
      "Subtitles successfully injected into video\n",
      "Completed: Module 02 SQL\n",
      "\n",
      "Transcription Summary:\n",
      "   Successful: 2\n",
      "   Failed: 0\n",
      "Pipeline Results:\n",
      "  download: 3 successful, 0 failed\n",
      "  merge: 2 successful, 0 failed\n",
      "  transcribe: 2 successful, 0 failed\n"
     ]
    }
   ],
   "source": [
    "processor = LectureProcessor(\n",
    "    verbose=True,  # False for quiet operation\n",
    "    interactive=False  # True for interactive confirmations\n",
    ")\n",
    "\n",
    "# Complete pipeline - handles everything automatically\n",
    "pipeline_results = ld.process_pipeline(\n",
    "    links=\"example_links.txt\",      # or [\"url1\", \"url2\"], Can also be: single URL string, list of URLs\n",
    "    titles=\"example_titles.json\",   # or [\"Title 1\", \"Title 2\"], Can also be: single title string, list of titles, dict\n",
    "    output_dir=\"lecture_processing\",# Creates organized subdirectories\n",
    "    max_download_workers=8,         # 1-10, adjust based on system\n",
    "    max_transcribe_workers=4,       # 1-5, adjust based on system\n",
    "    transcription_method=\"whisper\", # \"auto\", \"gcloud\", \"whisper\"\n",
    "    language=\"en\",                  # \"en\" for Whisper, \"en-US\" for Google Cloud\n",
    "    inject_subtitles=True,          # False to skip subtitle injection\n",
    ")\n",
    "\n",
    "print(\"Pipeline Results:\")\n",
    "for step, results in pipeline_results.items():\n",
    "    print(f\"  {step}: {len(results['successful'])} successful, {len(results['failed'])} failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a4b4dd-0dc7-4165-a147-cafb61761e24",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## Individual Operations - Functional API\n",
    "\n",
    " Use individual functions for more control over each step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02693850-b221-4ae8-b734-f3ece086ba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single base directory where all downloads will be stored\n",
    "base_dir = \"Lecture-Downloads-Output\"\n",
    "\n",
    "# Step 1: Download lectures\n",
    "results = ld.download_lectures(\n",
    "    links=\"example_links.txt\",     # Can also be: single URL string, list of URLs\n",
    "    titles=\"example_titles.json\",  # Can also be: single title string, list of titles, dict\n",
    "    base_dir=base_dir,\n",
    "    max_workers=6,  # 1-10, concurrent downloads\n",
    "    verbose=False  # True for detailed logging output\n",
    ")\n",
    "print(f\"Download: {len(results['successful'])} successful, {len(results['failed'])} failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35542025-81dd-4288-ae8e-8e59853e3754",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ### Step 2: Merge Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c5fd7a-163f-482d-a48e-b56b4488352e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge Plan:\n",
      "  Input: Lecture-Downloads-Output/lecture-downloads\n",
      "  Output: Lecture-Downloads-Output/merged-lectures\n",
      "  Modules: 2\n",
      "\n",
      "├── Module 2: SQL and Queries (1 videos)\n",
      "│   └── CS8803-001_Database Overview_Advanced Queries\n",
      "└── Module 1: Introduction to Databases (2 videos)\n",
      "    ├── CS8803-001_Database Overview_Fundamentals\n",
      "    └── CS8803-001_Database Overview_Introduction\n",
      "\n",
      "  Successfully created: Lecture-Downloads-Output/merged-lectures/Module 02 SQL and Queries.mp4\n",
      "  Successfully created: Lecture-Downloads-Output/merged-lectures/Module 01 Introduction to Databases.mp4\n",
      "Merge Summary: Successful: 2, Failed: 0\n",
      "Merge: 2 successful, 0 failed\n"
     ]
    }
   ],
   "source": [
    "# Merge videos by module with chapter markers\n",
    "merged = ld.merge_videos(\n",
    "    base_dir=base_dir  # Auto-detects input/output directories\n",
    ")\n",
    "print(f\"Merge: {len(merged['successful'])} successful, {len(merged['failed'])} failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a908c6dd-44d9-4788-8b4c-7812df29d909",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ### Step 3: Transcribe Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc1fb9f-2e15-45d2-b6a0-ed384e5f50dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription Plan:\n",
      "  Input: Lecture-Downloads-Output/merged-lectures\n",
      "  Output: Lecture-Downloads-Output/transcripts\n",
      "  Method: whisper\n",
      "  Videos: 2\n",
      "\n",
      "├── Module 01 Introduction to Databases\n",
      "│   ├── Module 01 Introduction to Databases.txt\n",
      "│   └── srt/Module 01 Introduction to Databases.srt\n",
      "└── Module 02 SQL and Queries\n",
      "    ├── Module 02 SQL and Queries.txt\n",
      "    └── srt/Module 02 SQL and Queries.srt\n",
      "\n",
      "Processing: Module 01 Introduction to Databases\n",
      "Loading Whisper model: base\n",
      "Whisper transcription completed: 1311 words\n",
      "Transcript saved: Lecture-Downloads-Output/transcripts/transcripts/Module 01 Introduction to Databases.txt\n",
      "Subtitles successfully injected into video\n",
      "Completed: Module 01 Introduction to Databases\n",
      "Processing: Module 02 SQL and Queries\n",
      "Loading Whisper model: base\n",
      "Whisper transcription completed: 380 words\n",
      "Transcript saved: Lecture-Downloads-Output/transcripts/transcripts/Module 02 SQL and Queries.txt\n",
      "Subtitles successfully injected into video\n",
      "Completed: Module 02 SQL and Queries\n",
      "\n",
      "Transcription Summary:\n",
      "   Successful: 2\n",
      "   Failed: 0\n",
      "Transcribe: 2 successful, 0 failed\n"
     ]
    }
   ],
   "source": [
    "# Transcribe videos with automatic method detection\n",
    "transcripts = ld.transcribe_videos(\n",
    "    base_dir=base_dir,\n",
    "    method=\"whisper\",  # \"auto\", \"gcloud\", \"whisper\" - \"auto\" by default\n",
    "    max_workers=2,  # 1-5, concurrent transcriptions\n",
    "    language=\"en-US\",  # \"en\" for Whisper, \"en-US\" for Google Cloud\n",
    "    inject_subtitles=True  # False to skip subtitle injection into videos\n",
    ")\n",
    "print(f\"Transcribe: {len(transcripts['successful'])} successful, {len(transcripts['failed'])} failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19810937-f1b7-4744-9571-805f15f00437",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## CLI Usage Examples\n",
    "\n",
    " ### Complete Pipeline\n",
    " ```bash\n",
    " # Single command for everything\n",
    " lecture-downloader pipeline -l links.txt -t titles.json -o output\n",
    " ```\n",
    "\n",
    " ### Individual Operations\n",
    " ```bash\n",
    " # Step by step\n",
    " BASE_DIR=\"AI-Course\"\n",
    " lecture-downloader download -l links.txt -t titles.json -b $BASE_DIR\n",
    " lecture-downloader merge -b $BASE_DIR\n",
    " lecture-downloader transcribe -b $BASE_DIR -m whisper\n",
    " ```\n",
    "\n",
    " ### Pipeline Options\n",
    " ```bash\n",
    " # Download only\n",
    " lecture-downloader pipeline -l links.txt --download-only\n",
    "\n",
    " # Custom settings\n",
    " lecture-downloader pipeline \\\n",
    "   -l links.txt -t titles.json -o output \\\n",
    "   --max-download-workers 8 \\\n",
    "   --max-transcribe-workers 4 \\\n",
    "   --method whisper --language en\n",
    " ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
