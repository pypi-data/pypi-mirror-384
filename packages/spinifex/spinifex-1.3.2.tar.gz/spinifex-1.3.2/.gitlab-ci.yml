default:
  image: $CI_REGISTRY_IMAGE/ci-build-runner:$CI_COMMIT_REF_SLUG
  before_script:
    - python --version # For debugging
  cache:
    paths:
      - .cache/pip
      # Do not cache .tox, to recreate virtualenvs for every step

stages:
  - prepare
  - lint
  # check if this needs to be a separate step
  # - build_extensions
  - test
  - package
  - images
  - integration
  - publish # publish instead of deploy

# Caching of dependencies to speed up builds
variables:
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"

include:
  - template: Security/SAST.gitlab-ci.yml
  - template: Security/Dependency-Scanning.gitlab-ci.yml
  - template: Security/Secret-Detection.gitlab-ci.yml

# Prepare image to run ci on
trigger_prepare:
  stage: prepare
  trigger:
    strategy: depend
    include: .prepare.gitlab-ci.yml

pre_commit:
  stage: lint
  script:
    - tox -e pre-commit
  allow_failure: false

# build_extensions:
#   stage: build_extensions
#   script:
#     - echo "build fortran/c/cpp extension source code"

sast:
  variables:
    SAST_EXCLUDED_ANALYZERS:
      brakeman, flawfinder, kubesec, nodejs-scan, phpcs-security-audit, pmd-apex, security-code-scan, sobelow, spotbugs
  stage: test

dependency_scanning:
  # override default before_script, job won't have Python available
  before_script:
    - uname

secret_detection:
  # override default before_script, job won't have Python available
  before_script:
    - uname

# Basic setup for all Python versions for which we don't have a base image
.run_unit_test_version_base:
  before_script:
    - python --version # For debugging
    - python -m pip install --upgrade pip
    - python -m pip install --upgrade tox twine

# Run all unit tests for Python versions except the base image
run_unit_tests:
  extends: .run_unit_test_version_base
  stage: test
  image: python:3.${PY_VERSION}
  script:
    - tox -e py3${PY_VERSION}
  parallel:
    matrix: # use the matrix for testing
      - PY_VERSION: [9, 10, 11, 12, 13]

# Run code coverage on the base image thus also performing unit tests
run_unit_tests_coverage:
  stage: test
  script:
    - tox -e coverage
  coverage: '/(?i)total.*? (100(?:\.0+)?\%|[1-9]?\d(?:\.\d+)?\%)$/'
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml
    paths:
      - htmlcov/*

package_files:
  stage: package
  artifacts:
    expire_in: 1w
    paths:
      - dist/*
  script:
    - tox -e build

package_docs:
  stage: package
  before_script:
    - apt-get update -y
    - apt-get install -y pandoc
  artifacts:
    expire_in: 1w
    paths:
      - docs/build/*
  script:
    - tox -e docs

docker_build:
  stage: images
  image: docker:latest
  needs:
    - package_files
  tags:
    - dind
  before_script: []
  script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
    - docker build -f docker/spinifex/Dockerfile . --build-arg BUILD_ENV=copy --tag
      $CI_REGISTRY_IMAGE/spinifex:$CI_COMMIT_REF_SLUG
    # enable this push line once you have configured docker registry cleanup policy
    # - docker push $CI_REGISTRY_IMAGE/spinifex:$CI_COMMIT_REF_SLUG

run_integration_tests:
  stage: integration
  allow_failure: true
  needs:
    - package_files
  script:
    - echo "make sure to move out of source dir"
    - echo "install package from filesystem (or use the artefact)"
    - echo "run against foreign systems (e.g. databases, cwl etc.)"
    - exit 0

publish_on_pypi:
  stage: publish
  environment: pypi
  needs:
    - package_files
  rules:
    - if: $CI_COMMIT_TAG
  script:
    - |
      TWINE_USERNAME=__token__ \
      TWINE_PASSWORD=${PYPI_TOKEN} \
      python -m twine upload --verbose dist/*
