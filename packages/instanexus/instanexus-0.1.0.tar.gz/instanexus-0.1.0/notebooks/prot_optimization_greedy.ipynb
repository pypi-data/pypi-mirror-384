{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb66d408",
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"\"\"Protease optimization\n",
    " _____  _______  _    _\n",
    "|  __ \\|__   __|| |  | |\n",
    "| |  | |  | |   | |  | |\n",
    "| |  | |  | |   | |  | |\n",
    "| |__| |  | |   | |__| |\n",
    "|_____/   |_|   |______|\n",
    "\n",
    "__authors__ = Marco Reverenna & Konstantinos Kalogeropoulus\n",
    "__copyright__ = Copyright 2025-2026\n",
    "__research-group__ = DTU Biosustain (Multi-omics Network Analytics) and DTU Bioengineering\n",
    "__date__ = 14 Aug 2025\n",
    "__maintainer__ = Marco Reverenna\n",
    "__email__ = marcor@dtu.dk\n",
    "__status__ = Dev\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5e17a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "script_dir = os.getcwd()  # get the current working directory\n",
    "sys.path.append(os.path.join(script_dir, \"../src\"))\n",
    "\n",
    "# my modules\n",
    "import dbg\n",
    "import greedy_method as greedy\n",
    "import mapping as map\n",
    "import preprocessing as prep\n",
    "import compute_statistics as comp_stat\n",
    "\n",
    "# import libraries\n",
    "from itertools import combinations\n",
    "from scipy.stats import gaussian_kde\n",
    "from pathlib import Path\n",
    "from upsetplot import UpSet\n",
    "\n",
    "\n",
    "import json\n",
    "import math\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e535bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"default\")\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "plt.rcParams[\"font.size\"] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab33aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # works if you are in a script: __file__ exists\n",
    "    BASE_DIR = Path(__file__).resolve().parents[2]\n",
    "except NameError:\n",
    "    # works if you are in a notebook: __file__ does not exist\n",
    "    BASE_DIR = Path().resolve()\n",
    "    # go up until the project folder\n",
    "    while BASE_DIR.name != \"InstaNexus\" and BASE_DIR != BASE_DIR.parent:\n",
    "        BASE_DIR = BASE_DIR.parent\n",
    "\n",
    "JSON_DIR = BASE_DIR / \"json\"\n",
    "INPUT_DIR = BASE_DIR / \"inputs\"\n",
    "FASTA_DIR = BASE_DIR / \"fasta\"\n",
    "OUTPUTS_DIR = BASE_DIR / \"outputs\"\n",
    "FIGURES_DIR = BASE_DIR / \"figures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d354be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"BASE_DIR: {BASE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3e6cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_metadata(run, chain=\"\", json_path=JSON_DIR / \"sample_metadata.json\"):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        all_meta = json.load(f)\n",
    "\n",
    "    if run not in all_meta:\n",
    "        raise ValueError(f\"Run '{run}' not found in metadata.\")\n",
    "\n",
    "    entries = all_meta[run]\n",
    "\n",
    "    for entry in entries:\n",
    "        if entry[\"chain\"] == chain:\n",
    "            return entry\n",
    "\n",
    "    raise ValueError(f\"No metadata found for run '{run}' with chain '{chain}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c888a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colors_from_run(cat, is_scaffold=False, json_path=JSON_DIR / \"colors.json\"):\n",
    "    if not os.path.exists(json_path):\n",
    "        raise FileNotFoundError(f\"Missing color file: {json_path}\")\n",
    "\n",
    "    with open(json_path, \"r\") as f:\n",
    "        colors = json.load(f)\n",
    "\n",
    "    category = cat.split(\"_\")[0].lower()\n",
    "    key = \"scaffold\" if is_scaffold else \"contig\"\n",
    "\n",
    "    try:\n",
    "        return colors[category][key]\n",
    "    except KeyError:\n",
    "        raise ValueError(f\"Color not defined for category '{category}' and key '{key}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edb5e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combination_name(\n",
    "    ass_method,\n",
    "    conf,\n",
    "    kmer_size,\n",
    "    size_threshold,\n",
    "    min_overlap,\n",
    "    min_identity,\n",
    "    max_mismatches,\n",
    "):\n",
    "    if ass_method == \"dbg\":\n",
    "        return f\"comb_{ass_method}_c{conf}_ks{kmer_size}_ts{size_threshold}_mo{min_overlap}_mi{min_identity}_mm{max_mismatches}\"\n",
    "    else:\n",
    "        return f\"comb_{ass_method}_c{conf}_ts{size_threshold}_mo{min_overlap}_mi{min_identity}_mm{max_mismatches}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff1086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ridgeline_log_kde(\n",
    "    df,\n",
    "    protease_column=\"protease\",\n",
    "    conf_column=\"conf\",\n",
    "    protease_list=None,\n",
    "    vertical_gap=5,\n",
    "    figsize=(12, 12),\n",
    "    cmap=\"viridis\",\n",
    "    custom_colors=None,\n",
    "    title=\"Confidence score distributions of PSMs per protease in BSA\",\n",
    "    save_svg_path=None,\n",
    "):\n",
    "\n",
    "    if protease_list is None:\n",
    "        protease_list = sorted(df[protease_column].dropna().unique())\n",
    "\n",
    "    x_vals = np.linspace(0, 1, 500)\n",
    "\n",
    "    # Choose colors\n",
    "    if custom_colors is not None:\n",
    "        colors = [custom_colors.get(p, \"gray\") for p in protease_list]\n",
    "    else:\n",
    "        colors = plt.cm.get_cmap(cmap)(np.linspace(0, 1, len(protease_list)))\n",
    "\n",
    "    # Compute global minimum for consistent scaling\n",
    "    all_log_densities = []\n",
    "    for p in protease_list:\n",
    "        subset = df[df[protease_column] == p][conf_column].dropna()\n",
    "        if len(subset) < 2:\n",
    "            all_log_densities.append(None)\n",
    "            continue\n",
    "        kde = gaussian_kde(subset)\n",
    "        density = kde(x_vals)\n",
    "        log_density = np.log10(density + 1e-6)\n",
    "        all_log_densities.append(log_density)\n",
    "\n",
    "    global_min = np.min([d.min() for d in all_log_densities if d is not None])\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i, protease in enumerate(protease_list):\n",
    "        log_density = all_log_densities[i]\n",
    "        if log_density is None:\n",
    "            continue\n",
    "        log_density_shifted = log_density - global_min\n",
    "        offset = i * vertical_gap\n",
    "\n",
    "        plt.plot(x_vals, log_density_shifted + offset, color=colors[i], lw=1.5)\n",
    "        plt.fill_between(\n",
    "            x_vals, offset, log_density_shifted + offset, alpha=0.4, color=colors[i]\n",
    "        )\n",
    "        plt.text(1.01, offset + 0.5, protease, va=\"center\", fontsize=10)\n",
    "\n",
    "    plt.xlabel(\"Confidence\", fontsize=12)\n",
    "    plt.ylabel(\"\")\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.spines[\"bottom\"].set_color(\"black\")\n",
    "    ax.spines[\"left\"].set_color(\"black\")\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_svg_path:\n",
    "        plt.savefig(save_svg_path, format=\"svg\")\n",
    "        print(f\"Plot saved to: {save_svg_path}\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd4cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = \"bsa\"\n",
    "\n",
    "meta = get_sample_metadata(run)\n",
    "\n",
    "protein = meta[\"protein\"]\n",
    "chain = meta[\"chain\"]\n",
    "proteases = meta[\"proteases\"]\n",
    "\n",
    "print(f\"Protein: {protein}\")\n",
    "print(f\"Chain: {chain}\")\n",
    "print(f\"Proteases: {proteases}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256b4bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ass_method = \"greedy\"\n",
    "# kmer_size = 7\n",
    "conf = 0.8\n",
    "size_threshold = 20\n",
    "min_overlap = 3\n",
    "min_identity = 0.8\n",
    "max_mismatches = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac7ad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"ass_method\": ass_method,\n",
    "    \"conf\": conf,\n",
    "    # \"kmer_size\": kmer_size,\n",
    "    \"min_overlap\": min_overlap,\n",
    "    \"min_identity\": min_identity,\n",
    "    \"max_mismatches\": max_mismatches,\n",
    "    \"size_threshold\": size_threshold,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca8a5a9",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f0d5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_norm = prep.normalize_sequence(protein)\n",
    "\n",
    "df = pd.read_csv(INPUT_DIR / f\"{run}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34f7508",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"protease\"] = df[\"experiment_name\"].apply(\n",
    "    lambda name: prep.extract_protease(name, proteases)\n",
    ")\n",
    "\n",
    "df = prep.clean_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770c7892",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cleaned_preds\"] = df[\"preds\"].apply(prep.remove_modifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257f9bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_psms = df[\"cleaned_preds\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7adfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_psms = prep.filter_contaminants(\n",
    "    cleaned_psms, run, FASTA_DIR / \"contaminants.fasta\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43b90eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"cleaned_preds\"].isin(filtered_psms)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d6b9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"mapped\"] = df[\"cleaned_preds\"].apply(\n",
    "    lambda x: \"True\" if x in protein_norm else \"False\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c3e391",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(JSON_DIR / \"protease_colors.json\", \"r\") as f:\n",
    "    colors = json.load(f)\n",
    "\n",
    "plot_ridgeline_log_kde(\n",
    "    df,\n",
    "    protease_column=\"protease\",\n",
    "    conf_column=\"conf\",\n",
    "    protease_list=proteases,\n",
    "    custom_colors=colors,\n",
    "    save_svg_path=FIGURES_DIR / \"confidence_ridgeline.svg\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60d7c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"conf\"] > conf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7f34c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_psms = df[\"cleaned_preds\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27357c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc35a1e",
   "metadata": {},
   "source": [
    "## Protease optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcec9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order proteases by frequency (most frequent first)\n",
    "ordered_proteases = final_df[\"protease\"].value_counts().index.tolist()\n",
    "\n",
    "# Build results by gradually adding proteases one by one\n",
    "build_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0150a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(ordered_proteases) + 1):\n",
    "    # Select the first i proteases from the ordered list\n",
    "    selected_proteases = ordered_proteases[:i]\n",
    "    filtered_df = final_df[final_df[\"protease\"].isin(selected_proteases)]\n",
    "\n",
    "    # Extract sequences from the filtered DataFrame (using column \"preds\")\n",
    "    seqs = filtered_df[\"preds\"].tolist()\n",
    "\n",
    "    # Assembly pipeline for contigs\n",
    "    assembled_contigs = greedy.assemble_contigs(seqs, min_overlap)\n",
    "    assembled_contigs = list(set(assembled_contigs))\n",
    "    assembled_contigs = [\n",
    "        contig for contig in assembled_contigs if len(contig) > size_threshold\n",
    "    ]\n",
    "    assembled_contigs = sorted(assembled_contigs, key=len, reverse=True)\n",
    "\n",
    "    mapped_contigs = map.process_protein_contigs_scaffold(\n",
    "        assembled_contigs=assembled_contigs,\n",
    "        target_protein=protein_norm,\n",
    "        max_mismatches=max_mismatches,\n",
    "        min_identity=min_identity,\n",
    "    )\n",
    "    df_contigs_mapped = map.create_dataframe_from_mapped_sequences(data=mapped_contigs)\n",
    "\n",
    "    # in this case we do not need to save the statistics in a specific folder\n",
    "    # coverage results should be the same of the run with all proteases\n",
    "    stat_contigs = comp_stat.compute_assembly_statistics(\n",
    "        df=df_contigs_mapped,\n",
    "        sequence_type=\"contigs\",\n",
    "        output_folder=\".\",\n",
    "        reference=protein_norm,\n",
    "        **params\n",
    "    )\n",
    "\n",
    "    coverage_contigs = stat_contigs.get(\"coverage\")\n",
    "\n",
    "    # Assembly pipeline for scaffolds\n",
    "    assembled_scaffolds = greedy.combine_seqs_into_scaffolds(\n",
    "        assembled_contigs, min_overlap\n",
    "    )\n",
    "    assembled_scaffolds = list(set(assembled_scaffolds))\n",
    "    assembled_scaffolds = sorted(assembled_scaffolds, key=len, reverse=True)\n",
    "    assembled_scaffolds = [\n",
    "        scaffold for scaffold in assembled_scaffolds if len(scaffold) > size_threshold\n",
    "    ]\n",
    "\n",
    "    assembled_scaffolds = greedy.combine_seqs_into_scaffolds(\n",
    "        assembled_scaffolds, min_overlap\n",
    "    )\n",
    "\n",
    "    assembled_scaffolds = list(set(assembled_scaffolds))\n",
    "    assembled_scaffolds = sorted(assembled_scaffolds, key=len, reverse=True)\n",
    "    assembled_scaffolds = [\n",
    "        scaffold for scaffold in assembled_scaffolds if len(scaffold) > size_threshold\n",
    "    ]\n",
    "\n",
    "    assembled_scaffolds = greedy.merge_contigs(assembled_scaffolds)\n",
    "\n",
    "    assembled_scaffolds = list(set(assembled_scaffolds))\n",
    "    assembled_scaffolds = sorted(assembled_scaffolds, key=len, reverse=True)\n",
    "    assembled_scaffolds = [\n",
    "        scaffold for scaffold in assembled_scaffolds if len(scaffold) > size_threshold\n",
    "    ]\n",
    "\n",
    "    mapped_scaffolds = map.process_protein_contigs_scaffold(\n",
    "        assembled_contigs=assembled_scaffolds,\n",
    "        target_protein=protein_norm,\n",
    "        max_mismatches=max_mismatches,\n",
    "        min_identity=min_identity,\n",
    "    )\n",
    "    df_scaffolds_mapped = map.create_dataframe_from_mapped_sequences(\n",
    "        data=mapped_scaffolds\n",
    "    )\n",
    "\n",
    "    stat_scaffolds = comp_stat.compute_assembly_statistics(\n",
    "        df=df_scaffolds_mapped,\n",
    "        sequence_type=\"scaffolds\",\n",
    "        output_folder=\".\",\n",
    "        reference=protein_norm,\n",
    "        **params\n",
    "    )\n",
    "    coverage_scaffolds = stat_scaffolds.get(\"coverage\")\n",
    "\n",
    "    build_results.append(\n",
    "        {\n",
    "            \"n_proteases_used\": i,\n",
    "            \"coverage_contigs\": coverage_contigs,\n",
    "            \"coverage_scaffolds\": coverage_scaffolds,\n",
    "        }\n",
    "    )\n",
    "\n",
    "df_build = pd.DataFrame(build_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5944bc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4223e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute angles (in degrees) between consecutive coverage points.\n",
    "# maybe we do not need the degrees or we can make some cumulative thing to undetstand better, maybe a different plot\n",
    "# Since the x difference is 1 (each step adds one protease), angle = arctan(delta_coverage)\n",
    "\n",
    "angles_contigs = []\n",
    "angles_scaffolds = []\n",
    "for i in range(len(df_build) - 1):\n",
    "    delta_contigs = (\n",
    "        df_build[\"coverage_contigs\"].iloc[i + 1] - df_build[\"coverage_contigs\"].iloc[i]\n",
    "    )\n",
    "    angle_contigs = np.degrees(np.arctan(delta_contigs))\n",
    "    angles_contigs.append(angle_contigs)\n",
    "\n",
    "    delta_scaffolds = (\n",
    "        df_build[\"coverage_scaffolds\"].iloc[i + 1]\n",
    "        - df_build[\"coverage_scaffolds\"].iloc[i]\n",
    "    )\n",
    "    angle_scaffolds = np.degrees(np.arctan(delta_scaffolds))\n",
    "    angles_scaffolds.append(angle_scaffolds)\n",
    "\n",
    "annotations = []\n",
    "for i in range(len(angles_contigs)):\n",
    "    x_mid = (\n",
    "        df_build[\"n_proteases_used\"].iloc[i] + df_build[\"n_proteases_used\"].iloc[i + 1]\n",
    "    ) / 2\n",
    "\n",
    "    y_mid_contigs = (\n",
    "        df_build[\"coverage_contigs\"].iloc[i] + df_build[\"coverage_contigs\"].iloc[i + 1]\n",
    "    ) / 2\n",
    "    annotations.append(\n",
    "        dict(\n",
    "            x=x_mid,\n",
    "            y=y_mid_contigs,\n",
    "            text=f\"{angles_contigs[i]:.2f}°\",\n",
    "            showarrow=True,\n",
    "            arrowhead=2,\n",
    "            ax=0,\n",
    "            ay=-20,\n",
    "            font=dict(color=get_colors_from_run(run, is_scaffold=False)),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    y_mid_scaffolds = (\n",
    "        df_build[\"coverage_scaffolds\"].iloc[i]\n",
    "        + df_build[\"coverage_scaffolds\"].iloc[i + 1]\n",
    "    ) / 2\n",
    "    annotations.append(\n",
    "        dict(\n",
    "            x=x_mid,\n",
    "            y=y_mid_scaffolds,\n",
    "            text=f\"{angles_scaffolds[i]:.2f}°\",\n",
    "            showarrow=True,\n",
    "            arrowhead=2,\n",
    "            ax=0,\n",
    "            ay=20,\n",
    "            font=dict(color=get_colors_from_run(run, is_scaffold=True)),\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_build[\"n_proteases_used\"],\n",
    "        y=df_build[\"coverage_contigs\"],\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"Contigs\",\n",
    "        line=dict(color=get_colors_from_run(run, is_scaffold=False)),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_build[\"n_proteases_used\"],\n",
    "        y=df_build[\"coverage_scaffolds\"],\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"Scaffolds\",\n",
    "        line=dict(color=get_colors_from_run(run, is_scaffold=True)),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"\",\n",
    "    xaxis_title=\"Number of proteases used\",\n",
    "    yaxis_title=\"Coverage\",\n",
    "    annotations=annotations,\n",
    "    template=\"plotly_white\",\n",
    "    font=dict(size=14, family=\"Arial, sans-serif\", color=\"black\"),\n",
    "    legend=dict(title=\"Legend\"),\n",
    ")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    showline=True,\n",
    "    linewidth=1,\n",
    "    linecolor=\"black\",\n",
    "    showgrid=False,\n",
    "    tickmode=\"linear\",\n",
    "    dtick=1,\n",
    ")\n",
    "\n",
    "fig.update_yaxes(\n",
    "    showline=True,\n",
    "    linewidth=1,\n",
    "    linecolor=\"black\",\n",
    "    showgrid=False,\n",
    "    type=\"linear\",\n",
    "    range=[0, 1],\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(FIGURES_DIR / \"coverage_increment.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d233fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "proteases = final_df[\"protease\"].unique()\n",
    "\n",
    "build_results = []\n",
    "for protease in proteases:\n",
    "    # Exclude the current protease\n",
    "    filtered_df = final_df[final_df[\"protease\"] != protease]\n",
    "\n",
    "    # Extract sequences from the filtered DataFrame (assuming the column \"preds\")\n",
    "    seqs = filtered_df[\"preds\"].tolist()\n",
    "\n",
    "    # Assembly pipeline for contigs\n",
    "    assembled_contigs = greedy.assemble_contigs(seqs, min_overlap)\n",
    "    assembled_contigs = list(set(assembled_contigs))\n",
    "    assembled_contigs = [\n",
    "        contig for contig in assembled_contigs if len(contig) > size_threshold\n",
    "    ]\n",
    "    assembled_contigs = sorted(assembled_contigs, key=len, reverse=True)\n",
    "\n",
    "    mapped_contigs = map.process_protein_contigs_scaffold(\n",
    "        assembled_contigs=assembled_contigs,\n",
    "        target_protein=protein_norm,\n",
    "        max_mismatches=max_mismatches,\n",
    "        min_identity=min_identity,\n",
    "    )\n",
    "    df_contigs_mapped = map.create_dataframe_from_mapped_sequences(data=mapped_contigs)\n",
    "\n",
    "    # same as before, we do not need to save the statistics in a specific folder\n",
    "    stat_contigs = comp_stat.compute_assembly_statistics(\n",
    "        df=df_contigs_mapped,\n",
    "        sequence_type=\"contigs\",\n",
    "        output_folder=\".\",\n",
    "        reference=protein_norm,\n",
    "        **params\n",
    "    )\n",
    "    coverage_contigs = stat_contigs.get(\"coverage\")\n",
    "\n",
    "    assembled_scaffolds = greedy.combine_seqs_into_scaffolds(\n",
    "        assembled_contigs, min_overlap\n",
    "    )\n",
    "    assembled_scaffolds = list(set(assembled_scaffolds))\n",
    "    assembled_scaffolds = sorted(assembled_scaffolds, key=len, reverse=True)\n",
    "    assembled_scaffolds = [\n",
    "        scaffold for scaffold in assembled_scaffolds if len(scaffold) > size_threshold\n",
    "    ]\n",
    "\n",
    "    assembled_scaffolds = greedy.combine_seqs_into_scaffolds(\n",
    "        assembled_scaffolds, min_overlap\n",
    "    )\n",
    "    assembled_scaffolds = list(set(assembled_scaffolds))\n",
    "    assembled_scaffolds = sorted(assembled_scaffolds, key=len, reverse=True)\n",
    "    assembled_scaffolds = [\n",
    "        scaffold for scaffold in assembled_scaffolds if len(scaffold) > size_threshold\n",
    "    ]\n",
    "\n",
    "    assembled_scaffolds = greedy.merge_contigs(assembled_scaffolds)\n",
    "    assembled_scaffolds = list(set(assembled_scaffolds))\n",
    "    assembled_scaffolds = sorted(assembled_scaffolds, key=len, reverse=True)\n",
    "    assembled_scaffolds = [\n",
    "        scaffold for scaffold in assembled_scaffolds if len(scaffold) > size_threshold\n",
    "    ]\n",
    "\n",
    "    mapped_scaffolds = map.process_protein_contigs_scaffold(\n",
    "        assembled_contigs=assembled_scaffolds,\n",
    "        target_protein=protein_norm,\n",
    "        max_mismatches=max_mismatches,\n",
    "        min_identity=min_identity,\n",
    "    )\n",
    "    df_scaffolds_mapped = map.create_dataframe_from_mapped_sequences(\n",
    "        data=mapped_scaffolds\n",
    "    )\n",
    "\n",
    "    stat_scaffolds = comp_stat.compute_assembly_statistics(\n",
    "        df=df_scaffolds_mapped,\n",
    "        sequence_type=\"scaffolds\",\n",
    "        output_folder=\".\",\n",
    "        reference=protein_norm,\n",
    "        **params\n",
    "    )\n",
    "    coverage_scaffolds = stat_scaffolds.get(\"coverage\")\n",
    "\n",
    "    # Save the results for the current excluded protease\n",
    "    build_results.append(\n",
    "        {\n",
    "            \"excluded_protease\": protease,\n",
    "            \"coverage_contigs\": coverage_contigs,\n",
    "            \"coverage_scaffolds\": coverage_scaffolds,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Convert the results into a DataFrame\n",
    "df_build = pd.DataFrame(build_results)\n",
    "display(df_build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fcc634",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    df_build,\n",
    "    x=\"excluded_protease\",\n",
    "    y=[\"coverage_contigs\", \"coverage_scaffolds\"],\n",
    "    barmode=\"group\",\n",
    "    title=\"\",\n",
    "    labels={\n",
    "        \"excluded_protease\": \"Excluded protease\",\n",
    "        \"coverage_contigs\": \"contigs\",\n",
    "        \"coverage_scaffolds\": \"scaffolds\",\n",
    "        \"value\": \"Coverage\",\n",
    "    },\n",
    "    color_discrete_map={\n",
    "        \"coverage_contigs\": get_colors_from_run(run, is_scaffold=False),\n",
    "        \"coverage_scaffolds\": get_colors_from_run(run, is_scaffold=True),\n",
    "    },\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    legend_title_text=\"Legend\",\n",
    "    yaxis_range=[0, 1],\n",
    "    template=\"plotly_white\",\n",
    "    font=dict(size=14, family=\"Arial, sans-serif\", color=\"black\"),\n",
    "    showlegend=True,\n",
    ")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    showline=True,\n",
    "    linewidth=1,\n",
    "    linecolor=\"black\",\n",
    "    showgrid=False,\n",
    "    tickmode=\"linear\",\n",
    "    dtick=1,\n",
    "    title_text=\"Excluded protease\",\n",
    ")\n",
    "\n",
    "fig.update_yaxes(\n",
    "    showline=True,\n",
    "    linewidth=1,\n",
    "    linecolor=\"black\",\n",
    "    showgrid=False,\n",
    "    type=\"linear\",\n",
    "    title_text=\"Coverage\",\n",
    ")\n",
    "\n",
    "for trace in fig.data:\n",
    "    if trace.name == \"coverage_contigs\":\n",
    "        trace.name = \"contigs\"\n",
    "    elif trace.name == \"coverage_scaffolds\":\n",
    "        trace.name = \"scaffolds\"\n",
    "\n",
    "fig.update_traces(width=0.3)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50dae86",
   "metadata": {},
   "source": [
    "# Upset plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb55cf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "upset_proteases = [\"ProtK\", \"Chymotrypsin\", \"Trypsin\", \"Elastase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c2c6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_combinations = []\n",
    "for r in range(1, len(upset_proteases) + 1):\n",
    "    all_combinations.extend(combinations(upset_proteases, r))\n",
    "\n",
    "all_combinations = [list(comb) for comb in all_combinations]\n",
    "\n",
    "print(f\"All combinations of proteases: {all_combinations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574ee530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _json_default(o):\n",
    "\n",
    "    if isinstance(o, (np.integer,)):\n",
    "        return int(o)\n",
    "\n",
    "    if isinstance(o, (np.floating,)):\n",
    "        if math.isnan(o) or math.isinf(o):\n",
    "            return None\n",
    "        return float(o)\n",
    "\n",
    "    if isinstance(o, (np.bool_,)):\n",
    "        return bool(o)\n",
    "\n",
    "    return str(o)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f381c925",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "coverage_results = []\n",
    "\n",
    "for combo in all_combinations:\n",
    "\n",
    "    specific_df = df[df['protease'].isin(combo)]  \n",
    "    filtered_seqs = specific_df['preds'].tolist()\n",
    "    \n",
    "    kmers = dbg.get_kmers(filtered_seqs, kmer_size=kmer_size)\n",
    "    \n",
    "    edges = dbg.get_debruijn_edges_from_kmers(kmers)\n",
    "    \n",
    "    contigs = dbg.assemble_contigs(edges)\n",
    "    contigs = sorted(contigs, key=len, reverse=True)\n",
    "    contigs = list(set(contigs))\n",
    "    contigs = [seq for seq in contigs if len(seq) > size_threshold]\n",
    "    contigs = sorted(contigs, key=len, reverse=True)\n",
    "    mapped_contigs = map.process_protein_contigs_scaffold(contigs, protein_norm, max_mismatches, min_identity)\n",
    "    df_contigs_mapped = map.create_dataframe_from_mapped_sequences(data = mapped_contigs)\n",
    "\n",
    "    reference = protein_norm\n",
    "    sequence_type = 'contigs'\n",
    "    statistics = {}\n",
    "    statistics.update(params) # add the hyperparameters to the statistics\n",
    "    df_contigs_mapped['sequence_length'] = df_contigs_mapped['end'] - df_contigs_mapped['start'] + 1\n",
    "\n",
    "    statistics['reference_start'] = 0\n",
    "    statistics['reference_end'] = len(reference) + 1\n",
    "   \n",
    "    statistics['total_sequences'] = len(df_contigs_mapped)\n",
    "    statistics['average_length'] = df_contigs_mapped['sequence_length'].mean()\n",
    "    statistics['min_length'] = df_contigs_mapped['sequence_length'].min()\n",
    "    statistics['max_length'] = df_contigs_mapped['sequence_length'].max()\n",
    "\n",
    "    covered_positions = set()\n",
    "    for start, end in zip(df_contigs_mapped[\"start\"], df_contigs_mapped[\"end\"]):\n",
    "        covered_positions.update(range(start - 1, end))  # Convert 1-based to 0-based indexing\n",
    "\n",
    "    statistics['coverage'] = len(covered_positions) / statistics['reference_end']\n",
    "    \n",
    "    protease_str = '_'.join([p.lower() for p in combo])\n",
    "    file_name = f\"{sequence_type}_{protease_str}_stats.json\"\n",
    "    output_path = os.path.join(\"../json\", file_name)\n",
    "    with open(output_path, \"w\") as file:\n",
    "        json.dump(statistics, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82884ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_float_or_none(x):\n",
    "    try:\n",
    "        xf = float(x)\n",
    "        if math.isnan(xf) or math.isinf(xf):\n",
    "            return None\n",
    "        return xf\n",
    "    except (TypeError, ValueError):\n",
    "        return None\n",
    "\n",
    "\n",
    "def to_int_or_none(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except (TypeError, ValueError):\n",
    "        try:\n",
    "            xf = float(x)\n",
    "            if math.isnan(xf) or math.isinf(xf):\n",
    "                return None\n",
    "            return int(xf)\n",
    "        except (TypeError, ValueError):\n",
    "            return None\n",
    "\n",
    "\n",
    "reference_length = len(protein_norm)\n",
    "\n",
    "df_contigs_mapped[\"sequence_length\"] = (\n",
    "    df_contigs_mapped[\"end\"] - df_contigs_mapped[\"start\"] + 1\n",
    ")\n",
    "\n",
    "covered_positions = set()\n",
    "for s, e in zip(df_contigs_mapped[\"start\"], df_contigs_mapped[\"end\"]):\n",
    "    covered_positions.update(range(int(s) - 1, int(e)))\n",
    "\n",
    "coverage = (len(covered_positions) / reference_length) if reference_length else 0.0\n",
    "\n",
    "statistics = {}\n",
    "statistics.update(params)\n",
    "statistics.update(\n",
    "    {\n",
    "        \"reference_length\": reference_length,\n",
    "        \"total_sequences\": to_int_or_none(len(df_contigs_mapped)),\n",
    "        \"average_length\": to_float_or_none(df_contigs_mapped[\"sequence_length\"].mean()),\n",
    "        \"min_length\": to_int_or_none(df_contigs_mapped[\"sequence_length\"].min()),\n",
    "        \"max_length\": to_int_or_none(df_contigs_mapped[\"sequence_length\"].max()),\n",
    "        \"coverage\": to_float_or_none(coverage),\n",
    "    }\n",
    ")\n",
    "\n",
    "protease_str = \"_\".join(p.lower() for p in combo)\n",
    "file_name = f\"contigs_{protease_str}_stats.json\"\n",
    "output_path = os.path.join(\"../json\", file_name)\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "with open(output_path, \"w\") as file:\n",
    "    json.dump(statistics, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add6e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "proteases_order = [\"protk\", \"chymotrypsin\", \"elastase\", \"trypsin\"]\n",
    "\n",
    "matrix_rows = []\n",
    "\n",
    "for file in os.listdir(JSON_DIR):\n",
    "    if file.endswith(\"_stats.json\"):\n",
    "        if file.startswith(\"contigs_\"):\n",
    "            protease_part = file[len(\"contigs_\") : -len(\"_stats.json\")]\n",
    "            proteases_in_file = protease_part.split(\"_\")\n",
    "\n",
    "            file_path = os.path.join(JSON_DIR, file)\n",
    "            with open(file_path, \"r\") as f:\n",
    "                stats = json.load(f)\n",
    "            coverage = stats.get(\"coverage\", None)\n",
    "\n",
    "            row = {\n",
    "                prot: 1 if prot in proteases_in_file else 0 for prot in proteases_order\n",
    "            }\n",
    "            row[\"coverage\"] = coverage\n",
    "            matrix_rows.append(row)\n",
    "\n",
    "presence_absence_df = pd.DataFrame(matrix_rows)\n",
    "print(presence_absence_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f935d804",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(JSON_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "def to_float_or_none(x):\n",
    "    try:\n",
    "        xf = float(x)\n",
    "        if math.isnan(xf) or math.isinf(xf):\n",
    "            return None\n",
    "        return xf\n",
    "    except (TypeError, ValueError):\n",
    "        return None\n",
    "\n",
    "\n",
    "def to_int_or_none(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except (TypeError, ValueError):\n",
    "        try:\n",
    "            xf = float(x)\n",
    "            if math.isnan(xf) or math.isinf(xf):\n",
    "                return None\n",
    "            return int(xf)\n",
    "        except (TypeError, ValueError):\n",
    "            return None\n",
    "\n",
    "\n",
    "coverage_results = []\n",
    "matrix_rows = []\n",
    "\n",
    "for combo in all_combinations:\n",
    "    specific_df = df[df[\"protease\"].isin(combo)]\n",
    "    filtered_seqs = specific_df[\"preds\"].tolist()\n",
    "\n",
    "    kmers = dbg.get_kmers(filtered_seqs, kmer_size=kmer_size)\n",
    "    edges = dbg.get_debruijn_edges_from_kmers(kmers)\n",
    "    contigs = dbg.assemble_contigs(edges)\n",
    "    contigs = sorted(set(contigs), key=len, reverse=True)\n",
    "    contigs = [seq for seq in contigs if len(seq) > size_threshold]\n",
    "\n",
    "    mapped_contigs = map.process_protein_contigs_scaffold(\n",
    "        contigs, protein_norm, max_mismatches, min_identity\n",
    "    )\n",
    "    df_contigs_mapped = map.create_dataframe_from_mapped_sequences(data=mapped_contigs)\n",
    "\n",
    "    reference_length = len(protein_norm)\n",
    "    if len(df_contigs_mapped):\n",
    "        df_contigs_mapped[\"sequence_length\"] = (\n",
    "            df_contigs_mapped[\"end\"] - df_contigs_mapped[\"start\"] + 1\n",
    "        )\n",
    "        covered_positions = set()\n",
    "        for s, e in zip(df_contigs_mapped[\"start\"], df_contigs_mapped[\"end\"]):\n",
    "            covered_positions.update(range(int(s) - 1, int(e)))\n",
    "        coverage = (\n",
    "            (len(covered_positions) / reference_length) if reference_length else 0.0\n",
    "        )\n",
    "\n",
    "        avg_len = to_float_or_none(df_contigs_mapped[\"sequence_length\"].mean())\n",
    "        min_len = to_int_or_none(df_contigs_mapped[\"sequence_length\"].min())\n",
    "        max_len = to_int_or_none(df_contigs_mapped[\"sequence_length\"].max())\n",
    "        total_seq = to_int_or_none(len(df_contigs_mapped))\n",
    "    else:\n",
    "        coverage, avg_len, min_len, max_len, total_seq = 0.0, None, None, None, 0\n",
    "\n",
    "    statistics = {}\n",
    "    statistics.update(params)\n",
    "    statistics.update(\n",
    "        {\n",
    "            \"reference_length\": reference_length,\n",
    "            \"total_sequences\": total_seq,\n",
    "            \"average_length\": avg_len,\n",
    "            \"min_length\": min_len,\n",
    "            \"max_length\": max_len,\n",
    "            \"coverage\": to_float_or_none(coverage),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    protease_str = \"_\".join(p.lower() for p in combo)\n",
    "    file_name = f\"contigs_{protease_str}_stats.json\"\n",
    "    output_path = os.path.join(JSON_DIR, file_name)\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(statistics, f, indent=4)\n",
    "\n",
    "    row = {\n",
    "        prot: 1 if prot in combo else 0\n",
    "        for prot in [\"protk\", \"chymotrypsin\", \"elastase\", \"trypsin\"]\n",
    "    }\n",
    "    row[\"coverage\"] = statistics[\"coverage\"]\n",
    "    matrix_rows.append(row)\n",
    "\n",
    "presence_absence_df = pd.DataFrame(matrix_rows)\n",
    "print(presence_absence_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7344d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_cols = [\"protk\", \"chymotrypsin\", \"elastase\", \"trypsin\"]\n",
    "\n",
    "data_boolean = presence_absence_df.copy()\n",
    "for col in ind_cols:\n",
    "    data_boolean[col] = data_boolean[col].astype(bool)\n",
    "\n",
    "indexed = data_boolean.set_index(ind_cols)\n",
    "\n",
    "plt.figure(figsize=(14, 25))\n",
    "upset = UpSet(\n",
    "    indexed,\n",
    "    intersection_plot_elements=0,\n",
    "    totals_plot_elements=0,\n",
    "    subset_size=\"count\",\n",
    "    show_counts=False,\n",
    "    show_percentages=False,\n",
    "    element_size=50,\n",
    "    orientation=\"horizontal\",\n",
    ")\n",
    "\n",
    "upset.add_catplot(value=\"coverage\", kind=\"bar\", color=\"green\", width=0.4)\n",
    "\n",
    "axes = upset.plot()\n",
    "\n",
    "all_axes = plt.gcf().get_axes()\n",
    "print(\"Assi disponibili nella figura:\", all_axes)\n",
    "print(axes.keys())\n",
    "\n",
    "cat_ax = all_axes[-1]\n",
    "\n",
    "cat_ax.grid(False)\n",
    "cat_ax.spines[\"top\"].set_visible(False)\n",
    "cat_ax.spines[\"right\"].set_visible(False)\n",
    "cat_ax.spines[\"left\"].set_visible(True)\n",
    "cat_ax.spines[\"bottom\"].set_visible(False)\n",
    "cat_ax.set_ylim(0, 1.0)\n",
    "\n",
    "pos = cat_ax.get_position()\n",
    "cat_ax.set_position([pos.x0, pos.y0, pos.width, pos.height * 2.5])\n",
    "\n",
    "plt.suptitle(\"\", fontsize=12, fontweight=\"normal\")\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.savefig(FIGURES_DIR / \"upset_plot.png\", format=\"png\", dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "instanexus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
