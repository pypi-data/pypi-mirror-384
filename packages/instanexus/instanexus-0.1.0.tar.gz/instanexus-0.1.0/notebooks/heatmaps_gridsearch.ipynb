{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a9fe1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Full assembly workflow with a dbg approach.\\n _____  _______  _    _ \\n|  __ \\\\|__   __|| |  | |\\n| |  | |  | |   | |  | |\\n| |  | |  | |   | |  | |\\n| |__| |  | |   | |__| |\\n|_____/   |_|   |______|\\n\\n__authors__ = Marco Reverenna & Konstantinos Kalogeropoulus\\n__copyright__ = Copyright 2025-2026\\n__research-group__ = DTU Biosustain (Multi-omics Network Analytics) and DTU Bioengineering\\n__date__ = 25 Jun 2025\\n__maintainer__ = Marco Reverenna\\n__email__ = marcor@dtu.dk\\n__status__ = Dev\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r\"\"\"Heatmaps notebook.\n",
    " _____  _______  _    _\n",
    "|  __ \\|__   __|| |  | |\n",
    "| |  | |  | |   | |  | |\n",
    "| |  | |  | |   | |  | |\n",
    "| |__| |  | |   | |__| |\n",
    "|_____/   |_|   |______|\n",
    "\n",
    "__authors__ = Marco Reverenna & Konstantinos Kalogeropoulus\n",
    "__copyright__ = Copyright 2025-2026\n",
    "__research-group__ = DTU Biosustain (Multi-omics Network Analytics) and DTU Bioengineering\n",
    "__date__ = 25 Jun 2025\n",
    "__maintainer__ = Marco Reverenna\n",
    "__email__ = marcor@dtu.dk\n",
    "__status__ = Dev\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92184fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1978b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "abbrev = {\n",
    "    \"max_mismatches\": \"mm\",\n",
    "    \"min_identity\": \"id\",\n",
    "    \"size_threshold\": \"st\",\n",
    "    \"conf\": \"c\",\n",
    "    \"kmer_size\": \"k\",\n",
    "    \"min_overlap\": \"mo\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a07f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_theme(theme_json):\n",
    "\n",
    "    return json.loads(theme_json)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b0eee4e",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "def plot_grid_search_clustermap(df, index_cols, column_cols, theme, value_col, title='', aggfunc='max', output_file=None):\n",
    "    pivot = df.pivot_table(values=value_col, index=index_cols, columns=column_cols, aggfunc=aggfunc)\n",
    "    pivot = pivot.sort_index(level=index_cols).sort_index(axis=1, level=column_cols)\n",
    "\n",
    "    row_labels = [', '.join(f\"{abbrev.get(col, col)}={val}\" for col, val in zip(index_cols, idx)) for idx in pivot.index]\n",
    "    col_labels = [', '.join(f\"{abbrev.get(col, col)}={val}\" for col, val in zip(column_cols, col)) for col in pivot.columns]\n",
    "\n",
    "    global_mean = pivot.stack(future_stack=True).mean()\n",
    "    pivot = pivot.fillna(global_mean)\n",
    "\n",
    "    heatmap = go.Heatmap(\n",
    "        z=pivot.values, x=col_labels, y=row_labels,\n",
    "        colorscale=theme, zmin=0, zmax=1,\n",
    "        showscale=True, colorbar=dict(title=value_col, len=0.75, thickness=20)\n",
    "    )\n",
    "    fig = go.Figure(data=[heatmap])\n",
    "    fig.update_layout(\n",
    "        width=950, height=850, title=title,\n",
    "        xaxis=dict(tickangle=-45, showgrid=False, zeroline=False),\n",
    "        yaxis=dict(showgrid=False, zeroline=False),\n",
    "        plot_bgcolor='white', paper_bgcolor='white'\n",
    "    )\n",
    "\n",
    "    if output_file:\n",
    "        os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "        fig.write_image(output_file, format='svg', scale=2)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70064eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid_search_clustermap(\n",
    "    df,\n",
    "    index_cols,\n",
    "    column_cols,\n",
    "    theme,\n",
    "    value_col,\n",
    "    title=\"\",\n",
    "    aggfunc=\"max\",\n",
    "    output_file=None,\n",
    "):\n",
    "    pivot = df.pivot_table(\n",
    "        values=value_col, index=index_cols, columns=column_cols, aggfunc=aggfunc\n",
    "    )\n",
    "    pivot = pivot.sort_index(level=index_cols).sort_index(axis=1, level=column_cols)\n",
    "\n",
    "    row_labels = [\n",
    "        \", \".join(f\"{abbrev.get(col, col)}={val}\" for col, val in zip(index_cols, idx))\n",
    "        for idx in pivot.index\n",
    "    ]\n",
    "    col_labels = [\n",
    "        \", \".join(f\"{abbrev.get(col, col)}={val}\" for col, val in zip(column_cols, col))\n",
    "        for col in pivot.columns\n",
    "    ]\n",
    "\n",
    "    global_mean = pivot.stack(future_stack=True).mean()\n",
    "    pivot = pivot.fillna(global_mean)\n",
    "\n",
    "    heatmap = go.Heatmap(\n",
    "        z=pivot.values,\n",
    "        x=col_labels,\n",
    "        y=row_labels,\n",
    "        colorscale=theme,\n",
    "        zmin=0,\n",
    "        zmax=1,\n",
    "        showscale=True,\n",
    "        colorbar=dict(title=value_col, len=0.75, thickness=20),\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=[heatmap])\n",
    "\n",
    "    # Aggiunta dei bordi bianchi: linee orizzontali e verticali tra le celle\n",
    "    n_rows, n_cols = pivot.shape\n",
    "    shapes = []\n",
    "    for i in range(n_rows + 1):\n",
    "        shapes.append(\n",
    "            dict(\n",
    "                type=\"line\",\n",
    "                x0=-0.5,\n",
    "                x1=n_cols - 0.5,\n",
    "                y0=i - 0.5,\n",
    "                y1=i - 0.5,\n",
    "                line=dict(color=\"white\", width=2),\n",
    "            )\n",
    "        )\n",
    "    for j in range(n_cols + 1):\n",
    "        shapes.append(\n",
    "            dict(\n",
    "                type=\"line\",\n",
    "                x0=j - 0.5,\n",
    "                x1=j - 0.5,\n",
    "                y0=-0.5,\n",
    "                y1=n_rows - 0.5,\n",
    "                line=dict(color=\"white\", width=2),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        width=950,\n",
    "        height=850,\n",
    "        title=title,\n",
    "        xaxis=dict(tickangle=-45, showgrid=False, zeroline=False),\n",
    "        yaxis=dict(showgrid=False, zeroline=False, autorange=\"reversed\"),\n",
    "        plot_bgcolor=\"white\",\n",
    "        paper_bgcolor=\"white\",\n",
    "        shapes=shapes,\n",
    "    )\n",
    "\n",
    "    if output_file:\n",
    "        os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "        fig.write_image(output_file, format=\"svg\", scale=2)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff1199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_json_to_csv(run, type_sequence):\n",
    "    \"\"\"\n",
    "    Walks through directories, reads JSON files, and combines them into separate CSV files per method.\n",
    "    type_sequence: can be contigs or scaffolds, for example.\n",
    "    \"\"\"\n",
    "    base_path = \"../outputs/\" + run\n",
    "    dataframes_by_method = {}\n",
    "    files_added = {}\n",
    "\n",
    "    for root, dirs, _ in os.walk(base_path):\n",
    "        for dir_name in dirs:\n",
    "            if dir_name.startswith(\"comb_dbg\"):\n",
    "                method = \"dbg\"\n",
    "            elif dir_name.startswith(\"comb_greedy\"):\n",
    "                method = \"greedy\"\n",
    "            else:\n",
    "                method = \"other\"\n",
    "\n",
    "            json_path = os.path.join(\n",
    "                root, dir_name, \"statistics\", f\"{type_sequence}_stats.json\"\n",
    "            )\n",
    "\n",
    "            if os.path.exists(json_path):\n",
    "                try:\n",
    "                    with open(json_path, \"r\") as f:\n",
    "                        data = json.load(f)\n",
    "\n",
    "                    df = pd.json_normalize(data)\n",
    "                    df[\"source\"] = dir_name\n",
    "\n",
    "                    if method not in dataframes_by_method:\n",
    "                        dataframes_by_method[method] = []\n",
    "                        files_added[method] = 0\n",
    "\n",
    "                    dataframes_by_method[method].append(df)\n",
    "                    files_added[method] += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {json_path}: {e}\")\n",
    "\n",
    "    for method, dfs in dataframes_by_method.items():\n",
    "        if dfs:\n",
    "            combined_df = pd.concat(dfs, ignore_index=True)\n",
    "            combined_df[\"sequence_type\"] = type_sequence\n",
    "            combined_df[\"run\"] = run\n",
    "            combined_df[\"ass_method\"] = method\n",
    "\n",
    "            output_file = os.path.join(\n",
    "                base_path, f\"{type_sequence}_combined_stats_{method}.csv\"\n",
    "            )\n",
    "            combined_df.to_csv(output_file, index=False, sep=\",\", header=True)\n",
    "            print(f\"[{method}] Combined JSON saved to CSV: {output_file}\")\n",
    "            print(f\"[{method}] Files successfully added: {files_added[method]}\")\n",
    "        else:\n",
    "            print(f\"[{method}] No dataframes to concatenate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12136b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(run_name):\n",
    "    if run_name == \"bsa\":\n",
    "        return \"bsa\"\n",
    "    if run_name.startswith(\"NB\"):\n",
    "        return \"nanobodies\"\n",
    "    if run_name.startswith(\"BIND\"):\n",
    "        return \"binders\"\n",
    "    return \"antibodies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65a13bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_base = \"../outputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90d680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = [\n",
    "    d for d in os.listdir(output_base) if os.path.isdir(os.path.join(output_base, d))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90104abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_sequences = [\"contigs\", \"scaffolds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24585db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in runs:\n",
    "    for seq in type_sequences:\n",
    "        combine_json_to_csv(run=r, type_sequence=seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911ff4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = []\n",
    "\n",
    "for r in runs:\n",
    "    category = get_category(r)\n",
    "    for seq in type_sequences:\n",
    "        for method in [\"dbg\", \"greedy\"]:\n",
    "            csv_path = os.path.join(\n",
    "                \"../outputs\", r, f\"{seq}_combined_stats_{method}.csv\"\n",
    "            )\n",
    "            if os.path.exists(csv_path):\n",
    "                df = pd.read_csv(csv_path)\n",
    "                df[\"run\"] = r\n",
    "                df[\"sequence_type\"] = seq\n",
    "                df[\"ass_method\"] = method\n",
    "                df[\"category\"] = category\n",
    "                all_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bc7ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat(all_dfs, ignore_index=True) if all_dfs else pd.DataFrame()\n",
    "\n",
    "theme_map = {\n",
    "    \"bsa\": [\n",
    "        [0.0, \"#fee8c8\"],\n",
    "        [0.8, \"#fdbb84\"],\n",
    "        [0.9, \"#ef6548\"],\n",
    "        [0.95, \"#b30000\"],\n",
    "        [1.0, \"#7f0000\"],\n",
    "    ],\n",
    "    \"antibodies\": [\n",
    "        [0.0, \"#c7e9c0\"],\n",
    "        [0.7, \"#a1d99b\"],\n",
    "        [0.8, \"#74c476\"],\n",
    "        [0.9, \"#41ab5d\"],\n",
    "        [1.0, \"#238b45\"],\n",
    "    ],\n",
    "    \"nanobodies\": [\n",
    "        [0.0, \"#deebf7\"],\n",
    "        [0.7, \"#9ecae1\"],\n",
    "        [0.8, \"#6baed6\"],\n",
    "        [0.9, \"#3182bd\"],\n",
    "        [1.0, \"#08519c\"],\n",
    "    ],\n",
    "    \"binders\": [\n",
    "        [0.0, \"#f2f0f7\"],\n",
    "        [0.7, \"#cbc9e2\"],\n",
    "        [0.8, \"#9e9ac8\"],\n",
    "        [0.9, \"#756bb1\"],\n",
    "        [1.0, \"#54278f\"],\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4405205",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cols = [\"max_mismatches\", \"min_identity\"]\n",
    "column_cols = [\"conf\", \"size_threshold\"]\n",
    "value_col = \"coverage\"\n",
    "aggfunc = \"max\"\n",
    "base_out = \"heatmaps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4034f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in df_all[\"category\"].unique():\n",
    "    cat_df = df_all[df_all[\"category\"] == category]\n",
    "    for r in cat_df[\"run\"].unique():\n",
    "        for seq in type_sequences:\n",
    "            for method in [\"dbg\", \"greedy\"]:\n",
    "                subset = cat_df[\n",
    "                    (cat_df[\"run\"] == r)\n",
    "                    & (cat_df[\"sequence_type\"] == seq)\n",
    "                    & (cat_df[\"ass_method\"] == method)\n",
    "                ]\n",
    "\n",
    "                if subset.empty:\n",
    "                    continue\n",
    "\n",
    "                theme = theme_map[category]\n",
    "\n",
    "                title = f\"{r} - {seq} - {method} coverage\"\n",
    "                out_dir = os.path.join(base_out, category)\n",
    "                os.makedirs(out_dir, exist_ok=True)\n",
    "                output_file = os.path.join(\n",
    "                    out_dir, f\"{r}_{seq}_{method}_coverage_clustermap.svg\"\n",
    "                )\n",
    "\n",
    "                plot_grid_search_clustermap(\n",
    "                    subset,\n",
    "                    index_cols,\n",
    "                    column_cols,\n",
    "                    theme,\n",
    "                    value_col,\n",
    "                    title=title,\n",
    "                    aggfunc=aggfunc,\n",
    "                    output_file=output_file,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e815c7e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assembly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
