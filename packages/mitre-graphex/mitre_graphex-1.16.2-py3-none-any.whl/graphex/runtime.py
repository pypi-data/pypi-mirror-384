import base64
import re
import threading
import time
import traceback
import typing
import uuid

from graphex.datatype import DataType
from graphex.exceptions import (
    GraphexException,
    GraphValidationError,
    LoopBreakException,
    LoopContinueException,
    SocketError,
    SubGraphRuntimeError,
    ThreadedRunTimeError,
)
from graphex.graphfile import NodeMetadata, GraphInputValueMetadata
from graphex.log import GraphexLogger
from graphex.node import Node

if typing.TYPE_CHECKING:
    from graphex.graph import Graph


def base64encode(node_name: str, node_id: str, graph_name: str, graph_path: typing.Optional[str] = None):
    """
    Encodes the provided node name and ID into a base64 encoded string for transfer to the frontend.

    :param node_name: the name of the node
    :param node_id: the ID of the node
    :param graph_name: the name of the graph containing the node
    :returns: a base64 encoded string
    """
    graph_location = graph_path if graph_path else graph_name
    node_info: str = node_name + "+" + node_id + "+" + graph_location
    node_info_bytes = node_info.encode("ascii")
    node_info_base64_bytes = base64.b64encode(node_info_bytes)
    return "errorLink://" + node_info_base64_bytes.decode("ascii")


class NodeThread(threading.Thread):
    """
    Custom thread class for running nodes in a separate thread.

    :param thread_id: The Thread ID to use for this thread.
    :param runtime: The runtime to run in.
    :param instance_metadata: The instance metadata of the node to run.
    :param forked: Whether this should be a forked thread.
    :param daemon: Whether this is a daemon thread.
    :param pool: The pool (if any) that this thread belongs to.
    :param pool_semaphore: Semaphore used for this pool, used to ensure this thread does not run until available "workers" are in the pool.
    :param buffer_logs: Whether to buffer logs generated by this thread until the thread is joined. This only applies to forked threads.
    """

    def __init__(
        self,
        thread_id: int,
        runtime: "Runtime",
        instance_metadata: NodeMetadata,
        forked: bool,
        daemon: bool,
        pool: typing.Optional[str],
        pool_semaphore: typing.Optional[threading.Semaphore] = None,
        buffer_logs: bool = False,
    ):
        super().__init__(daemon=daemon)

        self.original_runtime = runtime
        """The original runtime as passed to this class."""

        self.runtime = runtime
        """The runtime to use for execution (may be changed from the original runtime)."""

        self.instance_metadata = instance_metadata
        """The initial node to execute."""

        self.forked = forked
        """Whether this is a forked thread."""

        self.daemon = daemon
        """Whether this is a daemon thread."""

        self.pool = pool
        """The pool to which this thread belongs."""

        self.pool_semaphore = pool_semaphore
        """The pool semaphore."""

        self.thread_id = thread_id
        """Unique ID for this thread."""

        self.exception: typing.Optional[BaseException] = None
        """Any exception encountered while this thread is executing."""

        self.buffer_logs = buffer_logs
        """Whether to buffer logs."""

        self.log_buffer: typing.List[typing.Tuple[str, str, str]] = []
        """List of buffered logs."""

    def start(self):
        if self.forked:
            # Fork the runtime
            logger = self.original_runtime.logger
            if self.buffer_logs:
                logger = self.runtime.logger.clone()
                logger.callback = lambda x1, x2, x3: self.log_buffer.append(
                    (x1, x2, x3)
                )
            if isinstance(self.runtime, GraphRuntime):
                self.runtime = ForkedThreadRuntime(
                    self.runtime,
                    self.runtime,
                    logger=logger,
                    azure_integration=self.original_runtime.azure_integration,
                )
            elif isinstance(self.runtime, ForkedThreadRuntime):
                self.runtime = ForkedThreadRuntime(
                    self.runtime.graph_runtime,
                    self.runtime,
                    logger=logger,
                    azure_integration=self.original_runtime.azure_integration,
                )

        super().start()

    def run(self):
        if self.pool_semaphore:
            # Note: We use a semaphore for managing the "max workers" rather than a ThreadPoolExecutor
            # because the ThreadPoolExecutor does not provide the 'daemon' distinction that a standard
            # thread does
            self.pool_semaphore.acquire()

        try:
            self.runtime.execute_node(self.instance_metadata)
        except NodeRuntimeError as e:
            e.thread = self
            self.exception = e
        except BaseException as e:
            self.exception = e

        if self.pool_semaphore:
            self.pool_semaphore.release()

    def join(self, merge_forked_state: bool):
        if self.buffer_logs and self.original_runtime.logger.callback:
            self.runtime.logger.lock.acquire()
            self.original_runtime.logger.lock.acquire()
            if len(self.log_buffer):
                self.original_runtime.logger.write(
                    f"Buffered logs for Thread {self.thread_id}:",
                    level="INFO",
                    acquire_lock=False,
                )
            try:
                for x1, x2, x3 in self.log_buffer:
                    x1 = re.sub(r"^", "  │  ", x1, flags=re.MULTILINE)
                    x2 = re.sub(r"^", "  │  ", x2, flags=re.MULTILINE)
                    self.original_runtime.logger.callback(x1, x2, x3)
            finally:
                self.runtime.logger.callback = (
                    self.original_runtime.logger.callback
                )  # After buffered logs are done, let the thread print normally
                self.runtime.logger.lock.release()
                self.original_runtime.logger.lock.release()

        super().join()

        if merge_forked_state and isinstance(self.runtime, ForkedThreadRuntime):
            self.runtime.merge_to_graph_state()


class NodeRuntimeError(GraphexException):
    """
    Runtime error for a node instance in a running graph. Raised when a node raises an exception during execution. For internal use by a Runtime only.

    :param runtime: The runtime that the node raising this exception belongs to.
    :param node: The node raising this exception.
    :param exception: The base exception that this exception wraps.
    :param is_deferred: Whether this is a deferred exception.
    :param thread: The thread that this node was running in when it errored (if any).
    """

    def __init__(
        self,
        runtime: "Runtime",
        node: Node,
        exception: BaseException,
        is_deferred: bool = False,
        thread: typing.Optional[NodeThread] = None,
        verbose_info: bool = False,
    ):
        self.runtime = runtime
        self.node = node
        self.exception = exception
        self.stack_summary = traceback.extract_tb(exception.__traceback__)
        self.is_deferred = is_deferred
        self.thread = thread
        self.graph_name = self.runtime.graph.name if self.runtime.graph.name else "?"
        self.error_link = base64encode(self.node.name, self.node.id, self.graph_name, runtime.graph.filepath)
        self.verbose_info = verbose_info

        super().__init__(f"Node {str(node)} failed with exception: {str(exception)}")

    def __str__(self) -> str:
        return self.formatted()

    def formatted(self) -> str:
        # Get backward nodes from this failed node
        previous_nodes: typing.List[Node] = []
        current_backwards_target: Node = self.node
        for i in range(5):
            backwards = self.runtime.graph.get_backward(
                current_backwards_target._instance_metadata
            )
            if len(backwards) == 0:
                break
            previous_node = self.runtime.nodes[backwards[0]["id"]]
            previous_nodes.append(previous_node)
            current_backwards_target = previous_node
        previous_nodes_string = (
            " -> ".join([str(node) for node in reversed(previous_nodes)])
            + " --> "
            + str(self.node)
        )

        thread_info = ""
        if self.thread:
            thread_info += f" (Thread {self.thread.thread_id}"
            if self.thread.pool:
                thread_info += f", Pool '{self.thread.pool}')"
            else:
                thread_info += ")"

        traceback_info = ""
        if len(self.stack_summary):
            for tb in self.stack_summary:
                traceback_info += f'    File "{tb.filename}", line {tb.lineno}, in {tb.name}\n        {tb.line}\n'

        # Format the exception
        exception_str = str(self.exception)
        exception_str = (
            ("\n" + re.sub(r"^", "  │  ", exception_str, flags=re.MULTILINE))
            if "\n" in exception_str
            else exception_str
        )

        error_info = ""
        if (
            self.node.logger.azure_integration
            and self.exception.__class__
            not in [SubGraphRuntimeError, ThreadedRunTimeError]
            and exception_str
        ):
            single_line_error_msg = exception_str.replace("\n", " ")
            error_info += f"##vso[task.logissue type=error]{self.exception.__class__.__name__}: {single_line_error_msg}\n"
        error_info += f"""
Node: {self.node.name}{thread_info}
Message: {exception_str}
Error Type: {self.exception.__class__.__name__}{' (Deferred)' if self.is_deferred else ''}
Error Link: {self.error_link}
""".strip()

        if self.verbose_info:
            error_info += "\n" + f"""
ID: {self.node.id}
Previous Nodes: {previous_nodes_string}
Traceback (most recent call last):
{traceback_info}
""".strip()

        error_info = re.sub(r"^", "│ ", error_info, flags=re.MULTILINE)
        error_info = f"Node {str(self.node)} failed.\n" + error_info
        return error_info


class Runtime:
    """
    Runtime for executing nodes.
    """

    def __init__(
        self,
        graph: "Graph",
        logger: GraphexLogger,
        input_values: typing.Dict[str, typing.Any],
        azure_integration: bool = False,
        verbose_errors: bool = False,
        print_graph_inputs: bool = False,
        hide_secret_names: typing.List[str] = [],
        composite_inputs: typing.List[str] = [],
    ):
        self.graph = graph
        """The graph."""

        self.registry = graph.registry
        """The registry."""

        self.nodes: typing.Dict[str, Node] = {}
        """The store of node instances in the graph. Maps Node ID -> Node object."""

        self.logger = logger
        """Logger instance for all nodes in this graph"""

        self.azure_integration = azure_integration
        """Whether to use Azure integration with this runtime."""

        self.variables: typing.Dict[str, typing.Tuple[typing.Any, DataType, bool]] = {}
        """Variables saved in this runtime. This maps Variable Name -> (Variable Value, DataType, Is List)."""

        self.inventory_constants: typing.Dict[str, typing.Tuple[typing.Any, DataType, bool]] = {}
        """Inventory specific variables saved in this runtime. This maps Constant Name -> (Constant Value, DataType, Is List)."""

        self.inputs: typing.Dict[
            str, typing.Tuple[typing.Any, DataType, bool, bool]
        ] = {}
        """Graph inputs saved in this runtime. This maps Input Name -> (Input Value, DataType, Is List, Is Password)."""

        self.outputs: typing.Dict[str, typing.Tuple[typing.Any, DataType, bool]] = {}
        """Graph outputs saved in this runtime. This maps Output Name -> (Output Value, DataType, Is List)."""

        self.threads: typing.List[NodeThread] = []
        """All background threads in this runtime."""

        self._thread_pools: typing.Dict[
            str,
            typing.Tuple[typing.Optional[int], typing.Optional[threading.Semaphore]],
        ] = {}
        """Semaphore objects for each thread pool, used to limit the number of concurrent threads within that pool. Maps 'Pool Name' -> (Workers Count, Semaphore)"""

        self._deferred_functions: typing.List[
            typing.Tuple[typing.Callable, typing.Optional[Node]]
        ] = []
        """List of functions 'deferred' to run after the module ends. List of tuples: (function, origin node)"""

        self._deferred_exceptions: typing.List[BaseException] = []
        """List of exceptions that don't get raised until the end of the program"""

        self._thread_lock = threading.Lock()
        """Lock to use for creating threads."""

        self.verbose_errors = verbose_errors
        """Whether to log more error information (such as stack trace) or not"""

        self.print_graph_inputs = print_graph_inputs
        """Whether to print the graph inputs before execution of the graph or not"""

        self.hide_secret_names = hide_secret_names
        """Secret names not to reveal when printing graph inputs"""

        # Set input values
        for input_metadata in self.graph.inputs:
            is_list = input_metadata.get("isList", False)
            datatype = self.registry.get_datatype(input_metadata["datatype"])
            name = input_metadata["name"]
            is_password = input_metadata.get("isPassword", False)

            value = None
            if name in input_values:

                if name in composite_inputs:
                    value = self.process_input(name, input_values[name])
                else:
                    value = input_values[name]

            elif "defaultValue" in input_metadata:
                value = input_metadata["defaultValue"]

            if value is not None:
                if self.azure_integration and input_metadata.get("isPassword", False):
                    # Hide secret values
                    values_to_hide = (
                        value if isinstance(value, list) and is_list else [value]
                    )

                    for value_to_hide in values_to_hide:
                        random_name = str(uuid.uuid4()).replace("-", "_")
                        print(
                            f"##vso[task.setvariable variable={random_name};issecret=true]{value_to_hide}"
                        )

                # Set the specified value
                try:
                    datatype.assert_type(value, is_list=is_list)
                except Exception as e:
                    raise RuntimeError(f'Failed to set Graph Input "{name}": {str(e)}')
                self.inputs[name] = (value, datatype, is_list, is_password)

        # Init nodes
        for instance_metadata in self.graph.nodes:
            try:
                self.reset_node(instance_metadata)
            except Exception as e:
                if "does not exist" in str(e).lower():
                    n = instance_metadata["name"]
                    if 'requiresInventory' in instance_metadata:
                        f = n[:n.index('$')]
                        p = n[n.index('$')+1:]
                        raise Exception(f"Could not find a node created by a GraphEx Inventory. The graph you are trying to run requires values from the inventory in which it was created with. Make sure you have included the path to the inventory directory using either the '-inv' argument or the 'inventory_path' key is set in your configuration file. The missing inventory file is: '{f}' and the following path is unable to be loaded: '{p}'.")
                    raise Exception(f"Could not find a node required to run this graph. Please make sure your plugins are installed and properly linked to this graph using either the '-l' argument or the 'plugins' key in your configuration file. The node that can't be found is called: '{n}'. The original error message is: {str(e)}")
                raise e

    def process_input(self, name: str, input: GraphInputValueMetadata) -> typing.Any:

        if len(input["childValues"]) > 0:
            self.logger.info(
                f"Processing composite input '{name}' of datatype '{input['datatype']}'..."
            )

        if "fromSecret" in input:
            raise RuntimeError(
                f"Error: Secret value '{input['fromSecret']}' for input '{input[name]}' must be decrypted before runtime"
            )
        elif "value" in input:
            return input["value"]
        else:
            ci = self.registry.composite_inputs[input["datatype"]]
            ci._runtime = self
            return ci(
                {
                    child_name: self.process_input(child_name, child_input)
                    for (child_name, child_input) in input["childValues"].items()
                }
            ).constructInput()

    def get_node(self, node_id: str) -> Node:
        """
        Get a Node in this runtime.

        :param node_id: The ID of the node.

        :returns: The node.
        :throws: If the node is not found.
        """
        return self.nodes[node_id]

    def reset_node(self, instance_metadata: NodeMetadata):
        """Reset the given node."""
        node = self.registry.get_node(instance_metadata["name"])(
            self, instance_metadata
        )
        self.nodes[instance_metadata["id"]] = node

    def defer(
        self,
        func: typing.Callable,
        insert_back: bool = False,
        origin_node: typing.Optional[Node] = None,
    ):
        """
        Defer a function call until this runtime ends. This function runs when the runtime exits, either successfully or with an exception.
        This is typically used for any clean-up steps that need to always be performed regardless of the runtime exit status.
        All deferred functions will be run in the order of most recently added (even if one previously failed).

        :param func: The function to call.
        :param insert_back: Add the function to be executed to the back of the list (i.e. executed last) instead of the front.
        :param origin_node: The node from which this deferred function originated (used for logging).
        """
        if insert_back:
            self._deferred_functions.append((func, origin_node))
        else:
            self._deferred_functions.insert(0, (func, origin_node))

    def defer_exception(self, exc: BaseException):
        """
        Defer an exception until this runtime ends.

        :param exc: The exception to raise.
        """
        if isinstance(exc, NodeRuntimeError) and self.verbose_errors:
            exc.verbose_info = self.verbose_errors
        setattr(exc, "is_deferred", True)
        self._deferred_exceptions.append(exc)

    def set_variable(
        self,
        variable_name: str,
        datatype: DataType,
        is_list: bool,
        variable_value: typing.Any,
    ):
        """
        Save a variable in this runtime.

        :param variable_name: The name of the variable.
        :param datatype: The DataType for this variable.
        :param is_list: Whether this is a list variable (list of data types).
        :param variable_value: The value of the variable.

        :throws: If type checking fails.
        """
        if variable_name in self.variables:
            _, existing_var_datatype, existing_var_is_list = self.variables[
                variable_name
            ]
            if datatype != existing_var_datatype:
                raise RuntimeError(
                    f'Failed to set Variable "{variable_name}": Variable already exists as a different DataType ({existing_var_datatype.name})'
                )
            if existing_var_is_list != is_list:
                raise RuntimeError(
                    f'Failed to set Variable "{variable_name}": Variable already exists with a different List-value ({existing_var_is_list})'
                )

        try:
            datatype.assert_type(variable_value, is_list=is_list)
        except Exception as e:
            raise RuntimeError(f'Failed to set Variable "{variable_name}": {str(e)}')
        self.variables[variable_name] = (variable_value, datatype, is_list)

    def get_variable(self, variable_name: str) -> typing.Any:
        """
        Get the value of a variable in this runtime.

        :param variable_name: The name of the variable.

        :returns: The value of the variable.
        :throws: If the variable does not exist or fails type checking.
        """
        if variable_name not in self.variables:
            raise RuntimeError(f"No variable exist with name '{variable_name}'")
        value, datatype, is_list = self.variables[variable_name]
        datatype.assert_type(value, is_list=is_list)
        return value

    def set_inv_constant(
        self,
        variable_name: str,
        datatype: DataType,
        is_list: bool,
        variable_value: typing.Any,
    ):
        """
        Save an inventory constant in this runtime.

        :param variable_name: The name of the variable.
        :param datatype: The DataType for this variable.
        :param is_list: Whether this is a list variable (list of data types).
        :param variable_value: The value of the variable.

        :throws: If type checking fails.
        """
        if variable_name in self.variables:
            raise RuntimeError(
                    f'Failed to set Inventory Constant: "{variable_name}": Inventory Constant name already exists! Inventory hierarchies must be unique.'
                )

        try:
            datatype.assert_type(variable_value, is_list=is_list)
        except Exception as e:
            raise RuntimeError(f'Failed to set Inventory Constant: "{variable_name}": {str(e)}')
        self.inventory_constants[variable_name] = (variable_value, datatype, is_list)

    def get_inv_constant(self, variable_name: str) -> typing.Any:
        """
        Get the value of a inventory constant in this runtime.

        :param variable_name: The name of the variable.

        :returns: The value of the inventory constant.
        :throws: If the inventory constant does not exist or fails type checking.
        """
        if variable_name not in self.inventory_constants:
            raise RuntimeError(f"No inventory constant exist with name '{variable_name}'")
        value, datatype, is_list = self.inventory_constants[variable_name]
        datatype.assert_type(value, is_list=is_list)
        return value

    def get_input(self, input_name: str) -> typing.Any:
        """
        Get the value of an input in this runtime.

        :param input_name: The name of the input.

        :returns: The value of the input.
        :throws: If the input does not exist or type checking fails.
        """
        if input_name not in self.inputs:
            raise RuntimeError(f"No input exist with name '{input_name}'")
        value, datatype, is_list, is_password = self.inputs[input_name]
        datatype.assert_type(value, is_list=is_list)
        return value

    def set_output(
        self,
        output_name: str,
        datatype: DataType,
        is_list: bool,
        output_value: typing.Any,
    ):
        """
        Save an output to this runtime.

        :param output_name: The name of the output.
        :param datatype: The DataType for this output.
        :param is_list: Whether this is a list variable (list of data types).
        :param output_value: The value of the output.

        :throws: If type checking fails.
        """
        datatype.assert_type(output_value, is_list=is_list)
        self.outputs[output_name] = (output_value, datatype, is_list)

    def get_output(self, output_name: str) -> typing.Any:
        """
        Get the value of an output in this runtime.

        :param output_name: The name of the output.

        :returns: The value of the output.
        :throws: If the output does not exist or type checking fails.
        """
        if output_name not in self.outputs:
            raise RuntimeError(f"No output exist with name '{output_name}'")
        value, datatype, is_list = self.outputs[output_name]
        datatype.assert_type(value, is_list=is_list)
        return value

    def get_thread(self, thread: int) -> NodeThread:
        """
        Get a thread by index (same as ID).

        :param thread: The index / ID of this thread.

        :returns: The thread object.
        :throws RuntimeError: If the thread does not exist.
        """
        if thread < 0 or thread >= len(self.threads):
            raise RuntimeError(f"No thread exists with ID {thread}")
        return self.threads[thread]

    def execute_node(self, instance_metadata: NodeMetadata):
        """
        Execute this node.

        This function will return when the chain of execution (i.e. this node and any nodes triggered by it) completes.

        :param node: The node metadata.
        """
        self.reset_node(instance_metadata)
        node = self.nodes[instance_metadata["id"]]

        try:
            # (Re-)Evaluate all non-linked inputs
            for socket_metadata in instance_metadata.get("inputs", []):
                socket = node.get_input(
                    socket_metadata["name"], self.graph, instance_metadata
                )
                if socket.is_link:
                    continue

                target_node_ids = {
                    connection.split("::")[0]
                    for connection in socket_metadata.get("connections", [])
                }
                target_nodes = [self.nodes[id] for id in target_node_ids]

                for target_node in target_nodes:
                    if target_node.has_link_sockets(
                        self.graph, target_node._instance_metadata
                    ):
                        continue

                    # Execute this target
                    self.execute_node(target_node._instance_metadata)

            # Run
            node.run()

            # Ensure all output sockets were handled/populated
            invalid_output_sockets: typing.List[str] = []
            for output_socket in node.data_outputs(self.graph, instance_metadata):
                name = output_socket.name
                if node.output_socket_is_disabled(name):
                    continue
                if node.output_socket_has_value(name):
                    continue
                invalid_output_sockets.append(name)

            if len(invalid_output_sockets):
                raise RuntimeError(
                    f"{str(node)}: Node failed to handle all output sockets. The following output sockets are invalid: {', '.join(invalid_output_sockets)} ...  This is likely an error in the Python code for the node. Please ensure that the node itself is properly initializing its dynamic sockets."
                )

            # Run the next nodes
            node.run_next()
        except (
            KeyboardInterrupt,
            LoopBreakException,
            LoopContinueException,
            NodeRuntimeError,
        ) as e:
            raise e
        except BaseException as e:
            raise NodeRuntimeError(self, node, e, verbose_info=self.verbose_errors)

    def execute_node_in_thread(
        self,
        instance_metadata: NodeMetadata,
        forked: bool,
        daemon: bool,
        pool: typing.Optional[str] = None,
        max_workers: typing.Optional[int] = None,
        buffer_logs: bool = False,
        start_immediately: bool = True,
    ) -> NodeThread:
        """
        Execute this node in a separate thread. Any nodes in this chain of execution (i.e. this node and any nodes triggered by it) will be run in a separate thread.

        :param instance_metadata: The node metadata.
        :param forked: Whether this should be a forked thread.
        :param daemon: Whether this is a daemon thread.
        :param pool: The pool to add this thread to.
        :param max_workers: The maximum number of workers that are allowed in the given pool (i.e. number of concurrent threads). This only applies to the first time the pool is created.
        :param buffer_logs: Whether to buffer logs generated by this thread until the thread is joined. This only applies to forked threads.
        :param start_immediately: Whether to start this thread immediately. If False, it is up to the caller to start the thread.

        :returns: The new index (same as ID) for this thread within this runtime.
        """
        self._thread_lock.acquire()

        if max_workers and max_workers < 1:
            max_workers = None

        if pool and pool in self._thread_pools:
            # max_workers value is different from the previously set value
            current_max_workers = self._thread_pools[pool][0]
            if current_max_workers is not None and current_max_workers < 1:
                current_max_workers = None

            if max_workers != current_max_workers:
                raise RuntimeError(
                    f"Max workers requested for pool '{pool}' ({max_workers}) is different from the previously set value ({self._thread_pools[pool][0]})."
                )

        if pool and pool not in self._thread_pools:
            # Set the initial thread pool workers value
            self._thread_pools[pool] = (
                (max_workers, threading.Semaphore(value=max_workers))
                if max_workers
                else (None, None)
            )

        try:
            thread = NodeThread(
                thread_id=len(self.threads),
                runtime=self,
                instance_metadata=instance_metadata,
                forked=forked,
                daemon=daemon,
                pool=pool,
                pool_semaphore=self._thread_pools[pool][1] if pool else None,
                buffer_logs=buffer_logs,
            )
            self.threads.append(thread)

            if start_immediately:
                thread.start()

            return thread
        finally:
            self._thread_lock.release()


class GraphRuntime(Runtime):
    """
    The graph runtime. This object contains all relevant logic for executing a graph file.

    :param graph: The graph that this runtime will execute.
    :param logger: The GraphexLogger to use for printing messages.
    :param input_values: Values to provide as inputs to the graph in this runtime. Maps: Input Name -> Input Value
    :param is_subgraph: Set to True if executing this runtime as a subgraph from the 'Execute Graph' node
    :param azure_integration: Whether to enable Azure integration (e.g. hide secret values in pipelines).
    """

    def __init__(
        self,
        graph: "Graph",
        logger: GraphexLogger,
        input_values: typing.Dict[str, typing.Any],
        is_subgraph: typing.Optional[bool] = False,
        azure_integration: bool = False,
        verbose_errors: bool = False,
        print_graph_inputs: bool = False,
        hide_secret_names: typing.List[str] = [],
        composite_inputs: typing.List[str] = [],
    ):

        super().__init__(
            graph,
            logger,
            input_values,
            azure_integration,
            verbose_errors=verbose_errors,
            print_graph_inputs=print_graph_inputs,
            hide_secret_names=hide_secret_names,
            composite_inputs=composite_inputs,
        )

        self._started: bool = False
        """Whether this runtime has been started. A runtime may only be used once."""

        self.is_subgraph = is_subgraph
        """When set to True: this graph is being run as a subgraph via an Execute Graph node"""

    def validate(self):
        """
        Validate this runtime.

        :throws: When the validation fails.
        """
        if self._started:
            raise RuntimeError(f"Graph runtime has already been executed.")

        # if self.graph.name:
        #     self.logger.debug(f"Validating runtime for graph {self.graph.name}...")
        # else:
        #     self.logger.debug(f"Validating graph runtime...")

        # Ensure all input values are populated
        missing_input_names = [
            input_metadata["name"]
            for input_metadata in self.graph.inputs
            if input_metadata["name"] not in self.inputs
        ]
        if len(missing_input_names):
            raise RuntimeError(
                f"Graph is missing a value for the following inputs: {', '.join(missing_input_names)}"
            )

        # Validate the graph
        error = None
        try:
            self.graph.validate()
        except SocketError as se:
            error = se
            relevant_part = str(se).split("node")[1]
            name_id_parts = relevant_part.split("(")
            node_name = name_id_parts[0].strip()
            node_id = name_id_parts[1].split(")")[0]
            graph_name = self.graph.name if self.graph.name else "?"
            self.logger.error(base64encode(node_name, node_id, graph_name, self.graph.filepath))
        except Exception as e:
            error = e

        if error:
            raise GraphValidationError(
                self.graph.name, f"({type(error).__name__}) {str(error)}"
            )

        # if self.graph.name:
        #     self.logger.debug(f"Runtime valid for graph {self.graph.name}")
        # else:
        #     self.logger.debug("Graph runtime valid.")

    def log_graph_inputs(self):
        # the string that will be logged at the top of the terminal
        output_str: str = ""
        for k, v in self.inputs.items():
            # store indexes in human readable variable names for maintainability
            actual_input_value = v[0]
            if self.hide_secret_names != None and k in self.hide_secret_names:
                actual_input_value = "ENCRYPTED_SECRET"
            v_datatype = v[1]
            v_is_list = v[2]
            v_is_password = v[3]
            # get the value of the graph input as a string
            vl = str(actual_input_value)
            # if the input is a list, format it the way that you would on the CLI (strip the brackets)
            if v_is_list:
                if v_is_password:
                    vl = ""
                    # build a string where all the password items are replaced with asterisks
                    for list_item in actual_input_value:
                        vl += f"'{len(str(list_item)) * '*'}', "
                    if len(vl) > 2:
                        # strip off the last comma space
                        vl = vl[:-2]
                else:
                    vl = vl[1:-1]
            # not a list
            else:
                # if the input is a password, replace its characters with asterisks
                if v_is_password:
                    vl = len(vl) * "*"
                # if the value is a string datatype and not a string list, add quotation marks around it
                if v_datatype.name == "String":
                    vl = f"'{vl}'"
            # append to the string that will be logged
            output_str += f"{str(k)}={vl} "
        # remove the last characters from the output
        if len(output_str) > 1:
            output_str = output_str[:-1]
        self.logger.notice(f"Graph executing with the following inputs: {output_str}")

    def run(self) -> typing.List[BaseException]:
        """
        Run this runtime.

        :returns: List of errors from the run.
        """
        errors: typing.List[BaseException] = []
        start_time = time.perf_counter()
        try:
            self.validate()
            if self.print_graph_inputs:
                if self.inputs:
                    self.log_graph_inputs()
                else:
                    self.logger.notice("No graph inputs are defined for this graph.")
            self._started = True

            # Start the first node
            start_node = self.graph.get_start_node()
            self.execute_node(start_node)
        except KeyboardInterrupt as e:
            self.logger.critical("Graph execution terminated by user.")
            errors.append(RuntimeError("Keyboard Interrupt."))
        except (SubGraphRuntimeError, NodeRuntimeError) as e:
            errors.append(e)
        except BaseException as e:
            self.logger.error(f"Error: {traceback.format_exc()}")
            errors.append(e)

        # Join any non-daemon threads
        non_daemon_threads = [
            thread for thread in self.threads if not thread.daemon and thread.is_alive()
        ]
        if len(non_daemon_threads):
            self.logger.debug(
                f"{len(non_daemon_threads)} non-daemon threads are still running. Waiting for threads to complete..."
            )
            for thread in non_daemon_threads:
                thread.join(merge_forked_state=False)
                if thread.exception:
                    errors.append(thread.exception)

        errors.extend(self._deferred_exceptions)

        # Run deferred functions
        for func, origin_node in self._deferred_functions:
            try:
                func()
            except NodeRuntimeError as e:
                errors.append(e)
            except BaseException as e:
                origin_node_string = (
                    f" (from Node {str(origin_node)})" if origin_node else ""
                )
                if origin_node:
                    self.logger.error(
                        base64encode(
                            origin_node.name,
                            origin_node.id,
                            origin_node._graph.name if origin_node._graph.name else "?",
                            origin_node._graph.filepath
                        )
                    )
                self.logger.error(
                    f"Error in deferred function{origin_node_string}: {str(e)}"
                )
                errors.append(e)

        end_time = time.perf_counter()
        delta_time_seconds = end_time - start_time
        minutes = int(delta_time_seconds / 60)
        graph_name_string = f" {self.graph.name}" if self.graph.name else ""
        if minutes > 0:
            seconds = int(delta_time_seconds % 60)
            self.logger.debug(
                f"Graph{graph_name_string} completed in {minutes} minutes {seconds} seconds."
            )
        else:
            self.logger.debug(
                f"Graph{graph_name_string} completed in {round(delta_time_seconds, ndigits=1)} seconds."
            )
        return errors


class ForkedThreadRuntime(Runtime):
    """
    Runtime for executing nodes in a forked thread.

    A forked thread is a special, GraphEX-only type of thread that attempts to replicate the "forking" ability for multiprocessing.
    A forked thread will copy the state of the graph at the time of its creation, and then reference that saved state rather than
    the current state of the graph (which may change while the thread runs). This allows for the values of variables and output sockets
    to be "remembered" by the thread as they were at the time of creation, making it easier to use those values when multithreading.

    A good example of where a forked thread may be useful: when looping through a list of items and generating a thread for each,
    we want each thread to "remember" the item of the iteration that generated the thread. Without forked threads, each thread may
    end up referencing an incorrect element if the loop iterates again (and thus overwrites the previous value) before a node in the
    thread can get that value.
    """

    def __init__(
        self,
        graph_runtime: GraphRuntime,
        parent_runtime: Runtime,
        logger: typing.Optional[GraphexLogger] = None,
        azure_integration: bool = False,
    ):
        self.graph_runtime = graph_runtime
        self.parent_runtime = parent_runtime

        super().__init__(
            self.graph_runtime.graph,
            logger or self.parent_runtime.logger,
            dict(),
            azure_integration,
        )

        self.saved_state_nodes = {**self.parent_runtime.nodes}
        """Saved state of the nodes in the parent runtime"""

        self.original_variables: typing.Dict[
            str, typing.Tuple[typing.Any, DataType, bool]
        ] = (
            {**self.parent_runtime.original_variables, **self.parent_runtime.variables}
            if isinstance(self.parent_runtime, ForkedThreadRuntime)
            else {**self.parent_runtime.variables}
        )
        """Copy of the original variables from the parent runtime. This maps Variable Name -> (Variable Value, DataType, Is List)."""

        self.original_outputs: typing.Dict[
            str, typing.Tuple[typing.Any, DataType, bool]
        ] = (
            {**self.parent_runtime.original_outputs, **self.parent_runtime.outputs}
            if isinstance(self.parent_runtime, ForkedThreadRuntime)
            else {**self.parent_runtime.outputs}
        )
        """Copy of the original outputs from the parent runtime. This maps Output Name -> (Output Value, DataType, Is List)."""

        # Init based on the parent state
        self.nodes = {
            node_id: node.clone() for node_id, node in self.parent_runtime.nodes.items()
        }

    def defer(
        self,
        func: typing.Callable,
        insert_back: bool = False,
        origin_node: typing.Optional[Node] = None,
    ):
        self.graph_runtime.defer(func, insert_back, origin_node)

    def defer_exception(self, exc: BaseException):
        self.graph_runtime.defer_exception(exc)

    def get_variable(self, variable_name: str) -> typing.Any:
        if variable_name in self.variables:
            value, datatype, is_list = self.variables[variable_name]
            datatype.assert_type(value, is_list=is_list)
            return value

        if variable_name in self.original_variables:
            value, datatype, is_list = self.original_variables[variable_name]
            datatype.assert_type(value, is_list=is_list)
            return value

        raise RuntimeError(f"No variable exist with name '{variable_name}'")

    def get_input(self, input_name: str) -> typing.Any:
        return self.graph_runtime.get_input(input_name)

    def get_output(self, output_name: str) -> typing.Any:
        """
        Get the value of an output in this runtime.

        :param output_name: The name of the output.

        :returns: The value of the output.
        :throws: If the output does not exist or type checking fails.
        """
        if output_name in self.outputs:
            value, datatype, is_list = self.outputs[output_name]
            datatype.assert_type(value, is_list=is_list)
            return value

        if output_name in self.original_outputs:
            value, datatype, is_list = self.original_outputs[output_name]
            datatype.assert_type(value, is_list=is_list)
            return value

        raise RuntimeError(f"No output exist with name '{output_name}'")

    def get_thread(self, thread: int) -> NodeThread:
        return self.graph_runtime.get_thread(thread)

    def merge_to_graph_state(self):
        """
        Merge the local state changes made by within this forked runtime into the parent graph.
        """
        for name, val in self.variables.items():
            self.graph_runtime.variables[name] = val

        for name, val in self.outputs.items():
            self.graph_runtime.outputs[name] = val
