{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54922093",
   "metadata": {},
   "source": [
    "# Self-Consistency Algorithm Demo\n",
    "This notebook demonstrates the Self-Consistency algorithm for mathematical reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674a3131",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4852b5b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from its_hub.utils import SAL_STEP_BY_STEP_SYSTEM_PROMPT\n",
    "from its_hub.lms import OpenAICompatibleLanguageModel\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Main example: OpenAI API endpoint with gpt-4o-mini\n",
    "lm = OpenAICompatibleLanguageModel(\n",
    "    endpoint=\"https://api.openai.com/v1\", \n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),  # Load API key from environment\n",
    "    model_name=\"gpt-4o-mini\", \n",
    "    system_prompt=SAL_STEP_BY_STEP_SYSTEM_PROMPT, \n",
    "    is_async=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28420e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: vLLM local endpoint (commented out)\n",
    "# lm = OpenAICompatibleLanguageModel(\n",
    "#     endpoint=\"http://localhost:8000/v1\", \n",
    "#     api_key=\"NO_API_KEY\", \n",
    "#     model_name=\"qwen2-math-1.5b-instruct\", \n",
    "#     system_prompt=SAL_STEP_BY_STEP_SYSTEM_PROMPT, \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3c7f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mathematical problem to solve\n",
    "prompt = r\"Let $a$ be a positive real number such that all the roots of \\[x^3 + ax^2 + ax + 1 = 0\\]are real. Find the smallest possible value of $a.$\"\n",
    "\n",
    "# Generate response using the proper format\n",
    "from its_hub.types import ChatMessages\n",
    "chat_messages = ChatMessages.from_prompt_or_messages(prompt)\n",
    "response = lm.generate(chat_messages.to_batch(1))[0]\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431b232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_boxed(s: str) -> str:\n",
    "    import re\n",
    "    # find all occurrences of \\boxed{...}\n",
    "    boxed_matches = re.findall(r'\\\\boxed\\{([^{}]+(?:\\{[^{}]*\\}[^{}]*)*)\\}', s)\n",
    "    # return the last match if any were found\n",
    "    return boxed_matches[-1] if boxed_matches else \"\"\n",
    "    \n",
    "extract_boxed(response['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1776fa0",
   "metadata": {},
   "source": [
    "## Self-Consistency Algorithm\n",
    "Now we'll use the Self-Consistency algorithm to improve the answer quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7017fe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from its_hub.algorithms import SelfConsistency\n",
    "\n",
    "# Set computational budget for scaling\n",
    "budget = 4\n",
    "\n",
    "scaling_alg = SelfConsistency(extract_boxed)\n",
    "\n",
    "scaling_result = scaling_alg.infer(\n",
    "    lm, prompt, budget, return_response_only=False\n",
    ")\n",
    "\n",
    "print(\"######## Self-Consistency Result ########\")\n",
    "print(scaling_result.the_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57faf111",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"######## Extracted Response Counts ########\")\n",
    "print(scaling_result.response_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2488b8d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "all"
  },
  "kernelspec": {
   "display_name": "inference_time_scaling-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
