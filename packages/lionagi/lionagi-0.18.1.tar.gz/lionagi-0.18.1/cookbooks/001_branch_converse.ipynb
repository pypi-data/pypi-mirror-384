{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start a chat with LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Branch` object is the foundational building block of lionagi, serving as your primary interface for AI model interactions.\n",
    "\n",
    "Think of a Branch as a conversation thread that:\n",
    "- **Manages messages**: Automatically handles system prompts, user inputs, and AI responses in a structured conversation flow\n",
    "- **Enables multi-turn conversations**: Maintains context across multiple exchanges, allowing for natural back-and-forth dialogue\n",
    "- **Handles advanced features**: Supports structured outputs, tool usage, and sophisticated context management out of the box\n",
    "\n",
    "**Architecture Overview:**\n",
    "- A `Session` can contain multiple branches, but every session starts with a default `'main'` branch\n",
    "- Each branch maintains its own conversation history in `branch.messages`\n",
    "\n",
    "This design allows you to organize complex AI workflows into logical conversation threads, each with their own context and purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configuration and Model Selection:**\n",
    "\n",
    "lionagi comes with sensible defaults for popular AI providers. You can explore these configurations in `lionagi.integrations.config` to understand available models and their settings.\n",
    "\n",
    "The framework supports multiple AI providers through a unified interface, making it easy to switch between different models without changing your core application logic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Using `chat()` - Stateless Interactions\n",
    "\n",
    "The `chat()` method provides **stateless** communication with AI models. Each call is independent, making it perfect for one-off queries or when you want to control conversation history manually.\n",
    "\n",
    "**When to use `chat()`:**\n",
    "- Single-shot questions that don't require conversation context\n",
    "- When you want to manually manage conversation state\n",
    "- For parallel processing of independent queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lionagi import iModel, Branch\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM = \"As a comedian, you are sarcastically funny\"\n",
    "prompt1 = \"short joke: a blue whale and a big shark meet at the bar and start dancing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**comedian1**: So a blue whale and a big shark walk into a bar, see each other, and suddenly break out into dance. Guess they're just trying to out-swim each other in the dance floor—because nothing says \"peak aquatic rivalry\" like a synchronized swim… in flip-flops."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a branch with gpt-4.1-nano model, need an OpenAI API key\n",
    "comedian1 = Branch(\n",
    "    chat_model=iModel(model=\"openai/gpt-4.1-nano\"), system=SYSTEM\n",
    ")\n",
    "joke1 = await comedian1.chat(prompt1)\n",
    "\n",
    "Markdown(f\"**comedian1**: {joke1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Provider Flexibility:**\n",
    "\n",
    "lionagi's unified interface allows you to seamlessly switch between different AI providers. Whether you're using OpenAI's latest models, local Ollama instances, or other providers, the API remains consistent.\n",
    "\n",
    "This provider-agnostic approach gives you the flexibility to:\n",
    "- Choose the best model for your specific use case\n",
    "- Switch providers based on cost, performance, or availability\n",
    "- Test the same logic across different AI models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using `communicate()` - Stateful Conversations\n",
    "\n",
    "The `communicate()` method provides **stateful** interactions where each message builds upon the previous conversation history. This is ideal for multi-turn dialogues and complex reasoning tasks.\n",
    "\n",
    "**Key Difference from `chat()`:**\n",
    "- `chat()` is **stateless**: Each call is independent, no memory between calls\n",
    "- `communicate()` is **stateful**: Automatically maintains conversation history, enabling context-aware responses\n",
    "\n",
    "**When to use `communicate()`:**\n",
    "- Multi-turn conversations where context matters\n",
    "- Building up complex reasoning over multiple exchanges\n",
    "- When you want automatic conversation memory management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**comedian2**: <think>\n",
       "Okay, so I need to create a joke for this scenario. The premise is that a blue whale and a big shark meet at the bar and start dancing as if they're both just having fun. However, it's important these two represent a pair of opposites.\n",
       "\n",
       "First, I should think about the qualities each animal brings. Blue whales are big and have that iconic black fur; they're often associated with luxury and status. Big sharks are also large but might bring the feel of danger or raw anger to the party, especially during the heat.\n",
       "\n",
       "The issue here is how to combine these two so they don't end up arguing over their similarities. I need a neutral way for them to dance together instead.\n",
       "\n",
       "I should come up with a situation where both animals find solace in each other's company. Maybe something that highlights their mutual love or support without making them argue.\n",
       "\n",
       "What emotions could work here? Fear might come to mind when big sharks are around, especially in the heat of dinner or socializing at a bar. But that could create some tension at the end.\n",
       "\n",
       "Another angle is their emotional journey—exploiting and then surrendering by dancing together. It shows mutual support but also highlights their contrasting traits over time. That seems relatable.\n",
       "\n",
       "Let me structure this as an exchange where each animal acknowledges the other's role in providing comfort or stability.\n",
       "</think>\n",
       "\n",
       "Oh, I've had a lot easier since you came to the bar. Maybe next time I'll keep it simple and just come with both my teeth and my legs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to install \"lionagi[ollama]\" to use Ollama models\n",
    "\n",
    "comedian2 = Branch(\n",
    "    chat_model=iModel(model=\"ollama/deepseek-r1:1.5b\"), system=SYSTEM\n",
    ")\n",
    "joke2 = await comedian2.communicate(prompt1)\n",
    "\n",
    "Markdown(f\"**comedian2**: {joke2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>role</th>\n",
       "      <th>content</th>\n",
       "      <th>id</th>\n",
       "      <th>sender</th>\n",
       "      <th>recipient</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.753196e+09</td>\n",
       "      <td>system</td>\n",
       "      <td>{'system_message': 'As a comedian, you are sar...</td>\n",
       "      <td>51f0b9b6-c278-4c8a-996a-3da8c3ad3bdd</td>\n",
       "      <td>system</td>\n",
       "      <td>b7ced6ad-8b83-4ddb-84a4-21b2cc6f0b35</td>\n",
       "      <td>{'lion_class': 'lionagi.protocols.messages.sys...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     created_at    role                                            content  \\\n",
       "0  1.753196e+09  system  {'system_message': 'As a comedian, you are sar...   \n",
       "\n",
       "                                     id  sender  \\\n",
       "0  51f0b9b6-c278-4c8a-996a-3da8c3ad3bdd  system   \n",
       "\n",
       "                              recipient  \\\n",
       "0  b7ced6ad-8b83-4ddb-84a4-21b2cc6f0b35   \n",
       "\n",
       "                                            metadata  \n",
       "0  {'lion_class': 'lionagi.protocols.messages.sys...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One message, only the system\n",
    "\n",
    "comedian1.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>role</th>\n",
       "      <th>content</th>\n",
       "      <th>id</th>\n",
       "      <th>sender</th>\n",
       "      <th>recipient</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.753196e+09</td>\n",
       "      <td>system</td>\n",
       "      <td>{'system_message': 'As a comedian, you are sar...</td>\n",
       "      <td>670fbe44-1efa-49fe-bbc8-ff08a356c634</td>\n",
       "      <td>system</td>\n",
       "      <td>6eeb5846-5bb0-446f-bec3-f9b8ab10ef65</td>\n",
       "      <td>{'lion_class': 'lionagi.protocols.messages.sys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.753196e+09</td>\n",
       "      <td>user</td>\n",
       "      <td>{'context': [], 'instruction': 'short joke: a ...</td>\n",
       "      <td>94f80a80-fcac-41d8-912b-8c06c3874df6</td>\n",
       "      <td>user</td>\n",
       "      <td>6eeb5846-5bb0-446f-bec3-f9b8ab10ef65</td>\n",
       "      <td>{'lion_class': 'lionagi.protocols.messages.ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.753196e+09</td>\n",
       "      <td>assistant</td>\n",
       "      <td>{'assistant_response': '&lt;think&gt;\n",
       "Okay, so I nee...</td>\n",
       "      <td>44a82dd2-02e5-47a0-96fc-3636af5ada0a</td>\n",
       "      <td>6eeb5846-5bb0-446f-bec3-f9b8ab10ef65</td>\n",
       "      <td>user</td>\n",
       "      <td>{'model_response': {'id': 'chatcmpl-532', 'obj...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     created_at       role                                            content  \\\n",
       "0  1.753196e+09     system  {'system_message': 'As a comedian, you are sar...   \n",
       "1  1.753196e+09       user  {'context': [], 'instruction': 'short joke: a ...   \n",
       "2  1.753196e+09  assistant  {'assistant_response': '<think>\n",
       "Okay, so I nee...   \n",
       "\n",
       "                                     id                                sender  \\\n",
       "0  670fbe44-1efa-49fe-bbc8-ff08a356c634                                system   \n",
       "1  94f80a80-fcac-41d8-912b-8c06c3874df6                                  user   \n",
       "2  44a82dd2-02e5-47a0-96fc-3636af5ada0a  6eeb5846-5bb0-446f-bec3-f9b8ab10ef65   \n",
       "\n",
       "                              recipient  \\\n",
       "0  6eeb5846-5bb0-446f-bec3-f9b8ab10ef65   \n",
       "1  6eeb5846-5bb0-446f-bec3-f9b8ab10ef65   \n",
       "2                                  user   \n",
       "\n",
       "                                            metadata  \n",
       "0  {'lion_class': 'lionagi.protocols.messages.sys...  \n",
       "1  {'lion_class': 'lionagi.protocols.messages.ins...  \n",
       "2  {'model_response': {'id': 'chatcmpl-532', 'obj...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Three messages, system + user + assistant\n",
    "\n",
    "comedian2.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_response': {'id': 'chatcmpl-532',\n",
       "  'object': 'chat.completion',\n",
       "  'created': 1753196352,\n",
       "  'model': 'deepseek-r1:1.5b',\n",
       "  'system_fingerprint': 'fp_ollama',\n",
       "  'choices': [{'index': 0,\n",
       "    'message': {'role': 'assistant',\n",
       "     'content': \"<think>\\nOkay, so I need to create a joke for this scenario. The premise is that a blue whale and a big shark meet at the bar and start dancing as if they're both just having fun. However, it's important these two represent a pair of opposites.\\n\\nFirst, I should think about the qualities each animal brings. Blue whales are big and have that iconic black fur; they're often associated with luxury and status. Big sharks are also large but might bring the feel of danger or raw anger to the party, especially during the heat.\\n\\nThe issue here is how to combine these two so they don't end up arguing over their similarities. I need a neutral way for them to dance together instead.\\n\\nI should come up with a situation where both animals find solace in each other's company. Maybe something that highlights their mutual love or support without making them argue.\\n\\nWhat emotions could work here? Fear might come to mind when big sharks are around, especially in the heat of dinner or socializing at a bar. But that could create some tension at the end.\\n\\nAnother angle is their emotional journey—exploiting and then surrendering by dancing together. It shows mutual support but also highlights their contrasting traits over time. That seems relatable.\\n\\nLet me structure this as an exchange where each animal acknowledges the other's role in providing comfort or stability.\\n</think>\\n\\nOh, I've had a lot easier since you came to the bar. Maybe next time I'll keep it simple and just come with both my teeth and my legs.\"},\n",
       "    'finish_reason': 'stop'}],\n",
       "  'usage': {'prompt_tokens': 40,\n",
       "   'completion_tokens': 311,\n",
       "   'total_tokens': 351}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the entire model response from LLMs\n",
    "\n",
    "comedian2.messages[-1].metadata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lionagi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
