Metadata-Version: 2.4
Name: mcp-rag
Version: 0.1.0
Summary: Add your description here
Requires-Python: >=3.13
Description-Content-Type: text/markdown
Requires-Dist: python-dotenv>=1.0.1
Requires-Dist: openai>=1.40.0
Requires-Dist: mcp>=1.12.4
Requires-Dist: requests>=2.32.3
Requires-Dist: rich>=14.1.0
Requires-Dist: tqdm>=4.67.1

# ä¸ªäºº RAG æœåŠ¡å™¨ï¼ˆåŸºäº MCPï¼‰

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªå…¼å®¹æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼ŒModel Context Protocolï¼‰çš„æœåŠ¡å™¨ï¼Œèµ‹èƒ½ AI å®¢æˆ·ç«¯ï¼ˆå¦‚ Cursorã€Claude for Desktop ç­‰ï¼‰å…·å¤‡å¢å¼ºæ£€ç´¢ç”Ÿæˆï¼ˆRAGï¼ŒRetrieval-Augmented Generationï¼‰èƒ½åŠ›ã€‚å…è®¸è¯­è¨€æ¨¡å‹è®¿é—®åŸºäºä½ è‡ªå·±æ–‡æœ¬å’Œæ–‡æ¡£çš„æœ¬åœ°ç§æœ‰çŸ¥è¯†åº“ã€‚

## âœ¨ ä¸»è¦ç‰¹æ€§

- **ä¸ºä½ çš„ AI æä¾›æŒä¹…è®°å¿†**ï¼šè®© AI å­¦ä¹ æ–°ä¿¡æ¯ï¼Œå¹¶èƒ½è·¨ä¼šè¯è®°å¿†ã€‚
- **ğŸ†• å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰**ï¼šç›´è§‚çš„æ¡Œé¢åº”ç”¨ï¼Œå¸¦æœ‰ç»“æ„åŒ–è„šæœ¬ï¼Œæ–¹ä¾¿å®‰è£…ä¸è¿è¡Œã€‚
- **ğŸš€ é«˜çº§æ–‡æ¡£å¤„ç†**ï¼šæ”¯æŒè¶…è¿‡ 25 ç§æ ¼å¼æ–‡ä»¶ï¼ŒåŒ…æ‹¬ PDFã€DOCXã€PPTXã€XLSXã€å›¾ç‰‡ï¼ˆå« OCRï¼‰ã€é‚®ä»¶ç­‰ã€‚
- **ğŸ§  æ™ºèƒ½å¤„ç†å¼•æ“ Unstructured**ï¼šä¼ä¸šçº§æ–‡æ¡£å¤„ç†ï¼Œä¿æŒè¯­ä¹‰ç»“æ„ï¼Œè‡ªåŠ¨å»å™ªï¼Œæ”¯æŒå¤æ‚æ ¼å¼ã€‚
- **ğŸ”„ å¯é å›é€€æœºåˆ¶**ï¼šå¤šé‡å¤„ç†ç­–ç•¥ç¡®ä¿æ‰€æœ‰æ–‡æ¡£å‡èƒ½æˆåŠŸå¤„ç†ã€‚
- **ğŸ“Š ç»“æ„åŒ–å…ƒæ•°æ®**ï¼šè¯¦ç»†æ–‡æ¡£ç»“æ„ä¿¡æ¯ï¼ˆæ ‡é¢˜ã€è¡¨æ ¼ã€åˆ—è¡¨ï¼‰ï¼Œæ–¹ä¾¿è¿½è¸ªã€‚
- **ğŸ” é«˜çº§æœç´¢è¿‡æ»¤**ï¼šåŸºäºå…ƒæ•°æ®çš„ç²¾å‡†è¿‡æ»¤ï¼Œæé«˜æœç´¢ç›¸å…³æ€§ã€‚
- **ğŸ“ˆ çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯**ï¼šè¯¦å°½å†…å®¹ä¸ç»“æ„åˆ†æã€‚
- **æœ¬åœ°ç§æœ‰å¤§è¯­è¨€æ¨¡å‹**ï¼šé€šè¿‡ [Ollama](https://ollama.com/) ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼ˆå¦‚ Llama 3ã€Mistralï¼‰ï¼Œä¿è¯æ•°æ®å’Œæé—®ä¸å‡ºæœ¬æœºã€‚
- **100% æœ¬åœ°ç¦»çº¿è¿è¡Œ**ï¼šè¯­è¨€æ¨¡å‹å’Œå‘é‡åµŒå…¥å‡æœ¬åœ°æ‰§è¡Œï¼Œæ•°æ®ä¸è”ç½‘ï¼Œæ¨¡å‹ä¸‹è½½å®Œæˆåæ— éœ€ç½‘ç»œã€‚
- **æ‰¹é‡å¯¼å…¥æ”¯æŒ**ï¼šä¸“ç”¨è„šæœ¬æ‰¹é‡å¤„ç†æ–‡æ¡£ç›®å½•ï¼Œé«˜æ•ˆæ„å»ºçŸ¥è¯†åº“ã€‚
- **æ¨¡å—åŒ–æ¶æ„**ï¼šRAG é€»è¾‘ä¸æœåŠ¡å™¨ã€å¯¼å…¥è„šæœ¬åˆ†ç¦»ï¼Œä¾¿äºç»´æŠ¤å’Œæ‰©å±•ã€‚
- **Markdown å¤‡ä»½**ï¼šè‡ªåŠ¨ä¿å­˜å¤„ç†åçš„æ¯ä¸ªæ–‡æ¡£ä¸º Markdown æ ¼å¼ï¼Œä¾¿äºéªŒè¯å’Œå¤ç”¨ã€‚
- **ğŸ†• æ¥æºå…ƒæ•°æ®**ï¼šå®Œæ•´çš„ä¿¡æ¯æº¯æºï¼Œå›ç­”é™„å¸¦æ¥æºå½’å±ã€‚
- **ğŸ†• AI ä»£ç†ä¼˜åŒ–**ï¼šè¯¦å°½æè¿°å’Œæ™ºèƒ½é”™è¯¯å¤„ç†ï¼Œæå‡ä»£ç†ä½¿ç”¨æ•ˆç‡ã€‚
- **ğŸ†• ç»“æ„åŒ–è„šæœ¬ä½“ç³»**ï¼šæ¨¡å—åŒ–è„šæœ¬åˆ’åˆ†å®‰è£…ã€è¿è¡Œå’Œè¯Šæ–­æµç¨‹ã€‚


---

#### OpenAI é…ç½®ï¼ˆäº‘ç«¯ GPT-3.5/4ï¼‰

å¦‚éœ€ä½¿ç”¨ OpenAI æˆ–å…¼å®¹ APIï¼ˆå¦‚ä»£ç†/Azureï¼‰ï¼Œåœ¨ `.env` è®¾ç½®ï¼š
```env
MODEL_TYPE=OPENAI
OPENAI_API_KEY=sk-xxxxxx
OPENAI_API_BASE=https://api.openai.com/v1
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_TEMPERATURE=0.7
```
å‚æ•°è¯´æ˜ï¼š
- `MODEL_TYPE`ï¼š`OPENAI` æˆ– `OLLAMA`
- `OPENAI_API_KEY`ï¼šOpenAI API å¯†é’¥
- `OPENAI_API_BASE`ï¼šAPI åœ°å€ï¼ˆå®˜æ–¹/ä»£ç†/Azureï¼‰
- `OPENAI_MODEL`ï¼šå¦‚ `gpt-3.5-turbo`ã€`gpt-4`
- `OPENAI_TEMPERATURE`ï¼šç”Ÿæˆæ¸©åº¦ï¼ˆ0~1ï¼‰

**åˆ‡æ¢æ¨¡å‹**ï¼šä»…éœ€ä¿®æ”¹ `.env` çš„ `MODEL_TYPE` å­—æ®µã€‚

**å¸¸è§é—®é¢˜ï¼š**
- API Key æ— æ•ˆ/é¢åº¦ä¸è¶³ï¼šæ£€æŸ¥å¯†é’¥ä¸è°ƒç”¨é¢åº¦
- API åœ°å€é”™è¯¯ï¼šç¡®è®¤ `OPENAI_API_BASE` æ­£ç¡®ï¼ˆä»£ç†/Azureï¼‰
- æ¨¡å‹åç§°ä¸æ”¯æŒï¼šç¡®è®¤æ‰€å¡«æ¨¡å‹å·²å¼€æ”¾
- ç½‘ç»œé—®é¢˜ï¼šå¦‚è¿æ¥è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–ä»£ç†

**æµ‹è¯• OpenAIï¼š**
```bash
curl --request POST \
    --url https://api.openai.com/v1/chat/completions \
    --header 'Authorization: Bearer sk-xxxxxx' \
    --header 'Content-Type: application/json' \
    --data '{
        "model": "gpt-3.5-turbo",
        "messages": [{"role": "user", "content": "ä½ å¥½"}]
    }'
```

### æ–¹å¼ 3ï¼šé…ç½® MCP å®¢æˆ·ç«¯ï¼ˆä¾‹å¦‚ Cursorï¼‰

ä¸ºäº†è®©ä½ çš„ AI ç¼–è¾‘å™¨ä½¿ç”¨æœåŠ¡å™¨ï¼Œä½ å¿…é¡»å¯¹å…¶è¿›è¡Œé…ç½®ã€‚

1. **æ‰¾åˆ°ä½ ç¼–è¾‘å™¨çš„ MCP æœåŠ¡å™¨é…ç½®æ–‡ä»¶ã€‚** å¯¹äº Cursorï¼Œè¯·åœ¨å…¶é…ç½®ç›®å½•ï¼ˆWindows ä¸Šä¸ºâ€œ%APPDATA%\cursorâ€ï¼‰ä¸­æŸ¥æ‰¾ç±»ä¼¼â€œmcp_servers.jsonâ€çš„æ–‡ä»¶ã€‚å¦‚æœè¯¥æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½ å¯ä»¥åˆ›å»ºå®ƒã€‚
2. **å°†ä»¥ä¸‹é…ç½®æ·»åŠ åˆ° JSON æ–‡ä»¶ã€‚**

æ­¤æ–¹æ³•ä½¿ç”¨ MCP æœåŠ¡å™¨è„šæœ¬ (`run_server_organized.bat`) æ¥è¿è¡Œ RAG æœåŠ¡å™¨ã€‚

**é‡è¦æç¤ºï¼** æ‚¨å¿…é¡»å°†â€œD:\full\path\to\your\MCP_RAG\projectâ€æ›¿æ¢ä¸ºæ‚¨è®¡ç®—æœºä¸Šè¯¥é¡¹ç›®æ–‡ä»¶å¤¹çš„å®é™…ç»å¯¹è·¯å¾„ã€‚

```json
{
    "mcpServers": {
        "rag": {
            "command": "uv",
            "args": [
                "run",
                "--directory",
                "/app/mcp_server_organized_cloud",
                "server.py"
            ],
            "env": {
                "PYTHONUNBUFFERED": "1",
                "MODEL_TYPE": "OPENAI",

                "OLLAMA_MODEL": "phi3",
                "OLLAMA_TEMPERATURE": "0",

                "OPENAI_API_KEY": "key",
                "OPENAI_API_BASE": "https://api.openai.com/v1",
                "OPENAI_MODEL": "gpt-4o-mini",
                "OPENAI_TEMPERATURE": "0",

                "EMBEDDING_PROVIDER": "OPENAI",
                "OPENAI_EMBEDDING_MODEL": "text-embedding-3-large",

                "COLLECTION_NAME": "default_collection"
            }
        }
    }
}
```

3. **é‡å¯ç¼–è¾‘å™¨ã€‚** å¯åŠ¨åï¼Œç¼–è¾‘å™¨ä¼šæ£€æµ‹å¹¶å¯åŠ¨ MCP æœåŠ¡å™¨ï¼Œè¿™å°†æ˜¾ç¤º RAG å·¥å…·ä»¥ä¾›èŠå¤©ä½¿ç”¨ã€‚

### æ–¹å¼å››ï¼šåœ¨èŠå¤©ä¸­ç›´æ¥è°ƒç”¨å·¥å…·

é…ç½®å®Œæˆåï¼Œæ‚¨å¯ä»¥ç›´æ¥åœ¨ç¼–è¾‘å™¨èŠå¤©ä¸­ä½¿ç”¨è¿™äº›å·¥å…·ã€‚

### å¯ç”¨å·¥å…·ï¼š



**1. `learn_text(text, source_name)` - æ·»åŠ æ–‡æœ¬ä¿¡æ¯**
```
@rag learn_text("é’›çš„ç†”ç‚¹ä¸º 1.668 Â°Cã€‚", "material_properties")
```
- **ä½¿ç”¨åœºæ™¯**ï¼šæ·»åŠ äº‹å®ã€å®šä¹‰ã€è®¨è®ºæ³¨é‡Šç­‰ã€‚
- **å‚æ•°**ï¼š
- `text`ï¼šè¦å­˜å‚¨çš„å†…å®¹
- `source_name`ï¼šæºçš„æè¿°æ€§åç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºâ€œmanual_inputâ€ï¼‰
**2. `learn_document(file_path)` - å¤„ç†æ–‡æ¡£**
```
@rag learn_document("C:\\Reports\\q3.pdf")
```

- **é€‚ç”¨åœºæ™¯**ï¼šå¤„ç† PDFã€DOCXã€PPTXã€XLSXã€TXTã€HTMLã€CSVã€JSONã€XMLã€å›¾ç‰‡ã€ç”µå­é‚®ä»¶ä»¥åŠè¶…è¿‡ 25 ç§å…¶ä»–æ ¼å¼
- **å¢å¼ºåŠŸèƒ½**ï¼š
- **æ™ºèƒ½å¤„ç†**ï¼šä½¿ç”¨éç»“æ„åŒ–æ•°æ®å»é™¤å™ªéŸ³å¹¶ä¿ç•™ç»“æ„
- **åå¤‡ç³»ç»Ÿ**ï¼šå¤šç§ç­–ç•¥ç¡®ä¿å¤„ç†æˆåŠŸ
- **ç»“æ„åŒ–å…ƒæ•°æ®**ï¼šæ ‡é¢˜ã€è¡¨æ ¼å’Œåˆ—è¡¨çš„è¯¦ç»†ä¿¡æ¯
- **è‡ªåŠ¨è½¬æ¢**ï¼šæ ¹æ®æ–‡ä»¶ç±»å‹ä¼˜åŒ–å¤„ç†
- **å·²ä¿å­˜å‰¯æœ¬**ï¼šå¤„ç†åçš„æ–‡æ¡£ä¿å­˜åœ¨ `./converted_docs/` ä¸­

**3. `ask_rag(query)` - æŸ¥è¯¢ä¿¡æ¯**
```
@rag ask_rag("é’›çš„ç†”ç‚¹æ˜¯å¤šå°‘ï¼Ÿ")
```
- **ä½¿ç”¨åœºæ™¯**ï¼šæœç´¢å…ˆå‰å­˜å‚¨çš„ä¿¡æ¯
- **ç­”æ¡ˆåŒ…å«**ï¼š
- AI ç”Ÿæˆçš„ç­”æ¡ˆï¼Œå¹¶å¢å¼ºäº†ä¸Šä¸‹æ–‡
- ğŸ“š åŒ…å«ç»“æ„åŒ–å…ƒæ•°æ®çš„æ¥æºåˆ—è¡¨
- æ¯ä¸ªæ¥æºçš„ç›¸å…³æ€§ä¿¡æ¯

**4. `ask_rag_filtered(query, file_type, min_tables, min_titles, processing_method)` - ä½¿ç”¨è¿‡æ»¤å™¨æœç´¢**
```
@rag ask_rag_filtered("æˆ‘ä»¬æœ‰å“ªäº›æ•°æ®è¡¨ï¼Ÿ", file_type=".pdf", min_tables=1)
```
- **ä½•æ—¶ä½¿ç”¨**ï¼šä½¿ç”¨å…ƒæ•°æ®è¿‡æ»¤å™¨è¿›è¡Œæ›´ç²¾ç¡®çš„æœç´¢
- **å¯ç”¨çš„è¿‡æ»¤å™¨**ï¼š
- `file_type`ï¼šæ–‡ä»¶ç±»å‹ï¼ˆä¾‹å¦‚ï¼Œ".pdf"ã€".docx"ã€".xlsx"ï¼‰
- `min_tables`ï¼šæ–‡æ¡£ä¸­è¡¨æ ¼çš„æœ€å°æ•°é‡
- `min_titles`ï¼šæ–‡æ¡£ä¸­æ ‡é¢˜çš„æœ€å°æ•°é‡
- `processing_method`ï¼šä½¿ç”¨çš„å¤„ç†æ–¹æ³•
- **ä¼˜ç‚¹**ï¼šæœç´¢æ›´ç›¸å…³ã€æ›´å…·ä½“

**5. `get_knowledge_base_stats()` - çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯**
```
@rag get_knowledge_base_stats()
```
- **ä½¿ç”¨åœºæ™¯**ï¼šè·å–å­˜å‚¨å†…å®¹ä¿¡æ¯
- **æä¾›çš„ä¿¡æ¯**ï¼š
- æ–‡æ¡£æ€»æ•°
- æŒ‰æ–‡ä»¶ç±»å‹åˆ†å¸ƒ
- ç»“æ„ç»Ÿè®¡ä¿¡æ¯ï¼ˆè¡¨æ ¼ã€æ ‡é¢˜ã€åˆ—è¡¨ï¼‰
- ä½¿ç”¨çš„å¤„ç†æ–¹æ³•

#### å®Œæ•´æµç¨‹ç¤ºä¾‹ï¼š
```bash
@rag learn_text("é’›çš„ç†”ç‚¹æ˜¯ 1,668Â°Cã€‚", "material_properties")
@rag learn_document("C:\\Documents\\manual_titanium.pdf")
@rag ask_rag("é’›çš„ç†”ç‚¹æ˜¯å¤šå°‘ï¼Ÿ")
@rag ask_rag_filtered("æˆ‘ä»¬æœ‰å“ªäº›è¡¨æ ¼æ•°æ®ï¼Ÿ", min_tables=1)
@rag get_knowledge_base_stats()
```

**é¢„æœŸå›ç­”ï¼š**

```
é’›çš„ç†”ç‚¹æ˜¯ 1668Â°Cã€‚

ğŸ“š ä¿¡æ¯æ¥æºï¼š  
   1. material_propertiesï¼ˆæ‰‹åŠ¨è¾“å…¥ï¼‰  
   2. manual_titanio.pdfï¼ˆç¬¬3é¡µï¼Œâ€œç‰©ç†æ€§èƒ½â€ç« èŠ‚ï¼‰

ğŸ“Š è¿‡æ»¤åæœç´¢ç»Ÿè®¡ï¼š  
   â€¢ å‘ç°åŒ…å«è¡¨æ ¼çš„æ–‡æ¡£æ•°é‡ï¼š3  
   â€¢ æ–‡ä»¶ç±»å‹ï¼šPDFï¼ˆ2ä»½ï¼‰ã€DOCXï¼ˆ1ä»½ï¼‰  
   â€¢ è¡¨æ ¼æ€»æ•°ï¼š7  
```

---

## ğŸ§ª æµ‹è¯•ä¸éªŒè¯

### æµ‹è¯•ç³»ç»Ÿ

éªŒè¯ä¸€åˆ‡æ˜¯å¦æ­£å¸¸è¿è¡Œï¼š

```bash
# è¯•ç”¨å¢å¼ºå‹ RAG ç³»ç»Ÿçš„æ‰€æœ‰åŠŸèƒ½
python test_enhanced_rag.py
```

#### **æ”¹è¿›çš„æµ‹è¯•è„šæœ¬ (`test_enhanced_rag.py`)**

è¯¥æµ‹è¯•è„šæœ¬éªŒè¯äº†æ‰€æœ‰å·²å®æ–½çš„æ”¹è¿›ï¼š

**ğŸ§ª åŒ…å«çš„æµ‹è¯•ï¼š**
- **æ”¹è¿›çš„æ–‡æ¡£å¤„ç†**ï¼šä½¿ç”¨ç»“æ„åŒ–å…ƒæ•°æ®éªŒè¯éç»“æ„åŒ–ç³»ç»Ÿ
- **æ”¹è¿›çš„çŸ¥è¯†åº“**ï¼šæµ‹è¯•æ”¹è¿›çš„åˆ†å—å’Œä¸°å¯Œçš„å…ƒæ•°æ®
- **MCP æœåŠ¡å™¨é›†æˆ**ï¼šéªŒè¯æ”¹è¿›çš„æœåŠ¡å™¨å·¥å…·
- **æ ¼å¼æ”¯æŒ**ï¼šç¡®è®¤è¶…è¿‡ 25 ç§æ ¼å¼çš„é…ç½®

**ğŸ“Š è¾“å‡ºä¿¡æ¯ï¼š**
- æ¯ä¸ªæµ‹è¯•çš„çŠ¶æ€ï¼ˆâœ… é€šè¿‡ / âŒ å¤±è´¥ï¼‰
- æå–çš„ç»“æ„åŒ–å…ƒæ•°æ®
- ä½¿ç”¨çš„å¤„ç†æ–¹æ³•
- æºå’Œåˆ†å—ä¿¡æ¯
- å®Œæ•´çš„ç³»ç»Ÿæ‘˜è¦

### éªŒè¯æ•°æ®åº“
å­˜å‚¨ä½ç½®ï¼š
- å‘é‡æ•°æ®åº“ï¼š`./rag_mcp_db/`
- è½¬æ¢å‰¯æœ¬ï¼š`./converted_docs/`ï¼ˆè®°å½•å¤„ç†æ–¹æ³•ï¼‰

---

## ğŸ¤– AI ä»£ç†ä½¿ç”¨

è¯¥ç³»ç»Ÿé’ˆå¯¹ AI ä»£ç†è¿›è¡Œäº†ä¼˜åŒ–ã€‚è¯·å‚é˜… [`AGENT_INSTRUCTIONS.md`](./AGENT_INSTRUCTIONS.md) äº†è§£ä»¥ä¸‹å†…å®¹ï¼š

- è¯¦ç»†ä½¿ç”¨æŒ‡å—
- ç”¨ä¾‹ç¤ºä¾‹
- æœ€ä½³å®è·µ
- é”™è¯¯å¤„ç†
- é‡è¦æ³¨æ„äº‹é¡¹

### ä»£ç†åŠŸèƒ½ï¼š

- **æ¯ä¸ªå·¥å…·çš„è¯¦ç»†æè¿°**
- **æ¸…æ™°å…·ä½“çš„ä½¿ç”¨ç¤ºä¾‹**
- **æ™ºèƒ½é”™è¯¯å¤„ç†**å¹¶æä¾›å®ç”¨å»ºè®®
- **æºå…ƒæ•°æ®**ï¼Œå®ç°å…¨é¢å¯è¿½æº¯æ€§
- **ç»“æ„åŒ–å“åº”**ï¼ŒåŒ…å«æºä¿¡æ¯

--

## ğŸ”§ å·²å®æ–½çš„æŠ€æœ¯å¢å¼º

æœ¬èŠ‚ä»‹ç»äº†å°†ç³»ç»Ÿè½¬å˜ä¸ºä¼ä¸šçº§è§£å†³æ–¹æ¡ˆçš„é«˜çº§æŠ€æœ¯å¢å¼ºåŠŸèƒ½ã€‚

### **A. ä½¿ç”¨éç»“æ„åŒ–æ•°æ®è¿›è¡Œæ™ºèƒ½å¤„ç†**

Unstructured æ˜¯ä¸€ä¸ªæ–‡æ¡£å¤„ç†åº“ï¼Œå®ƒçš„åŠŸèƒ½è¿œä¸æ­¢ç®€å•çš„æ–‡æœ¬æå–ã€‚å®ƒèƒ½å¤Ÿåˆ†ææ–‡æ¡£çš„è¯­ä¹‰ç»“æ„ï¼Œä»è€Œï¼š

- è¯†åˆ«å…ƒç´ ï¼šæ ‡é¢˜ã€æ®µè½ã€åˆ—è¡¨ã€è¡¨æ ¼
- å»é™¤å™ªéŸ³ï¼šç§»é™¤é¡µçœ‰ã€é¡µè„šå’Œä¸ç›¸å…³çš„å…ƒç´ 
- ä¿ç•™ä¸Šä¸‹æ–‡ï¼šç»´æŠ¤æ–‡æ¡£çš„å±‚æ¬¡ç»“æ„å’Œç»“æ„
- å¤„ç†å¤æ‚æ ¼å¼ï¼šæ‰«æçš„ PDFã€åŒ…å«è¡¨æ ¼çš„æ–‡æ¡£ç­‰ã€‚

#### **æŒ‰æ–‡ä»¶ç±»å‹ä¼˜åŒ–é…ç½®ï¼š**

```python
UNSTRUCTURED_CONFIGS = {
    '.pdf': {
        'strategy': 'hi_res',        # Alta resoluciÃ³n para PDFs complejos
        'include_metadata': True,    # Incluir metadatos estructurales
        'include_page_breaks': True, # Preservar saltos de pÃ¡gina
        'max_partition': 2000,       # TamaÃ±o mÃ¡ximo de particiÃ³n
        'new_after_n_chars': 1500    # Nuevo elemento despuÃ©s de N caracteres
    },
    '.docx': {
        'strategy': 'fast',          # Office æ–‡æ¡£çš„å¿«é€Ÿå¤„ç†
        'include_metadata': True,
        'max_partition': 2000,
        'new_after_n_chars': 1500
    },
    # ... è¶…è¿‡ 25 ç§æ ¼å¼çš„é…ç½®
}
```

#### **æ™ºèƒ½å…ƒç´ å¤„ç†ï¼š**

```python
def process_unstructured_elements(elements: List[Any]) -> str:
    """å¤„ç† Unstructured å…ƒç´ ï¼Œä¿æŒè¯­ä¹‰ç»“æ„ã€‚"""
    for element in elements:
        element_type = type(element).__name__
        
        if element_type == 'Title':
            # Los tÃ­tulos van con formato especial
            processed_parts.append(f"\n## {element.text.strip()}\n")
        elif element_type == 'ListItem':
            # Las listas mantienen su estructura
            processed_parts.append(f"â€¢ {element.text.strip()}")
        elif element_type == 'Table':
            # Las tablas se convierten a texto legible
            table_text = convert_table_to_text(element)
            processed_parts.append(f"\n{table_text}\n")
        elif element_type == 'NarrativeText':
            # El texto narrativo va tal como estÃ¡
            processed_parts.append(element.text.strip())
```

### **B. å¼ºå¤§çš„å›é€€ç³»ç»Ÿ**

#### **çº§è”å›é€€ç­–ç•¥ï¼š**

ç³»ç»Ÿä¼šæŒ‰ä¼˜å…ˆé¡ºåºå°è¯•å¤šç§ç­–ç•¥ï¼š

1. **éç»“æ„åŒ–ï¼Œé‡‡ç”¨æœ€ä½³é…ç½®**
- ä½¿ç”¨ç‰¹å®šæ–‡ä»¶ç±»å‹çš„è®¾ç½®
- æœ€é«˜å¤„ç†è´¨é‡

2. **éç»“æ„åŒ–ï¼Œé‡‡ç”¨åŸºæœ¬é…ç½®**
- â€œå¿«é€Ÿâ€ç­–ç•¥ï¼Œç¡®ä¿å…¼å®¹æ€§
- æ›´ç®€å•ä½†åŠŸèƒ½å¼ºå¤§çš„å¤„ç†

3. **è¯­è¨€é“¾ä¸“ç”¨åŠ è½½å™¨**
- æ¯ç§æ–‡ä»¶ç±»å‹ä½¿ç”¨ä¸“ç”¨åŠ è½½å™¨
- é’ˆå¯¹æœ‰é—®é¢˜æ ¼å¼çš„æœ€åè§£å†³æ–¹æ¡ˆ

#### **å›é€€ç¤ºä¾‹ï¼š**

```python
def load_document_with_fallbacks(file_path: str) -> tuple[str, dict]:
    file_extension = os.path.splitext(file_path)[1].lower()
    
    # Estrategia 1: Unstructured Ã³ptimo
    try:
        config = UNSTRUCTURED_CONFIGS.get(file_extension, DEFAULT_CONFIG)
        elements = partition(filename=file_path, **config)
        processed_text = process_unstructured_elements(elements)
        metadata = extract_structural_metadata(elements, file_path)
        return processed_text, metadata
    except Exception as e:
        log(f"Core Warning: Unstructured Ã³ptimo fallÃ³: {e}")
    
    # Estrategia 2: Unstructured bÃ¡sico
    try:
        elements = partition(filename=file_path, strategy="fast")
        # ... procesamiento
    except Exception as e:
        log(f"Core Warning: Unstructured bÃ¡sico fallÃ³: {e}")
    
    # Estrategia 3: LangChain fallbacks
    try:
        fallback_text = load_with_langchain_fallbacks(file_path)
        # ... procesamiento
    except Exception as e:
        log(f"Core Warning: LangChain fallbacks fallaron: {e}")
    
    return "", {}  # Solo si todas las estrategias fallan
```

### **C. ä¸°å¯Œçš„ç»“æ„å…ƒæ•°æ®**

#### **æ•è·çš„ç»“æ„ä¿¡æ¯ï¼š**

```python
def extract_structural_metadata(elements: List[Any], file_path: str) -> Dict[str, Any]:
    structural_info = {
        "total_elements": len(elements),
        "titles_count": sum(1 for e in elements if type(e).__name__ == 'Title'),
        "tables_count": sum(1 for e in elements if type(e).__name__ == 'Table'),
        "lists_count": sum(1 for e in elements if type(e).__name__ == 'ListItem'),
        "narrative_blocks": sum(1 for e in elements if type(e).__name__ == 'NarrativeText'),
        "total_text_length": total_text_length,
        "avg_element_length": total_text_length / len(elements) if elements else 0
    }
    
metadata = {
        "source": os.path.basename(file_path),
        "file_path": file_path,
        "file_type": os.path.splitext(file_path)[1].lower(),
        "processed_date": datetime.now().isoformat(),
        "processing_method": "unstructured_enhanced",
        "structural_info": structural_info
    }
```

#### **ç»“æ„åŒ–å…ƒæ•°æ®çš„ä¼˜åŠ¿ï¼š**

- **å¯è¿½æº¯æ€§**ï¼šæ‚¨å¯ä»¥å‡†ç¡®äº†è§£æ–‡æ¡£çš„å“ªä¸ªéƒ¨åˆ†è¢«ä½¿ç”¨
- **è´¨é‡**ï¼šå†…å®¹ç»“æ„ä¿¡æ¯
- **ä¼˜åŒ–**ï¼šç”¨äºæ”¹è¿›åç»­å¤„ç†çš„æ•°æ®
- **è°ƒè¯•**ï¼šç”¨äºè§£å†³é—®é¢˜çš„è¯¦ç»†ä¿¡æ¯

### **D. æ”¹è¿›çš„æ™ºèƒ½æ–‡æœ¬æ–­å­—åŠŸèƒ½**

#### **ä¼˜åŒ–é…ç½®ï¼š**

```python
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,        # TamaÃ±o mÃ¡ximo de cada fragmento
    chunk_overlap=200,      # Caracteres que se comparten entre fragmentos
    length_function=len,    # FunciÃ³n para medir longitud
    separators=["\n\n", "\n", ". ", "! ", "? ", " ", ""]  # Separadores inteligentes
)
```

#### **æ™ºèƒ½åˆ†éš”ç¬¦ï¼š**

ç³»ç»Ÿä¼šæŒ‰ä»¥ä¸‹é¡ºåºæŸ¥æ‰¾æœ€ä½³æ–­ç‚¹ï¼š
1. **`\n\n`** - æ®µè½ï¼ˆæœ€ä½³é€‰æ‹©ï¼‰
2. **`\n`** - æ¢è¡Œç¬¦
3. **`. `** - å¥å°¾
4. **`! `** - æ„Ÿå¹å·ç»“å°¾
5. **`? `** - ç–‘é—®å¥ç»“å°¾
6. **` `** - ç©ºæ ¼ï¼ˆæœ€åé€‰æ‹©ï¼‰

### **E. æœç´¢å¼•æ“ä¼˜åŒ–**

#### **å½“å‰é…ç½®ï¼š**

```python
retriever = vector_store.as_retriever(
    search_type="similarity_score_threshold",  # BÃºsqueda con umbral de similitud
search_kwargs={
        "k": 5,                # Recupera 5 fragmentos mÃ¡s relevantes
        "score_threshold": 0.3, # Umbral de distancia (similitud > 0.7)
    }
)
```

#### **ä¼˜åŒ–å‚æ•°ï¼š**

- **`k=5`**ï¼šä» 5 ä¸ªä¸åŒæ¥æºè·å–ä¿¡æ¯ï¼Œä»¥è·å¾—æ›´å®Œæ•´çš„ç­”æ¡ˆ
- **`score_threshold=0.3`**ï¼šç¡®ä¿ä»…ä½¿ç”¨é«˜åº¦ç›¸å…³çš„ä¿¡æ¯ï¼ˆç›¸ä¼¼åº¦ > 70%ï¼‰
- **ç›¸ä¼¼åº¦æœç´¢**ï¼šæŸ¥æ‰¾è¯­ä¹‰ä¸Šæœ€ç›¸ä¼¼çš„å†…å®¹

### **F. è‡ªåŠ¨æ–‡æœ¬æ¸…ç†**

#### **æ¸…ç†è¿‡ç¨‹ï¼š**

```python
def clean_text_for_rag(text: str) -> str:
    """Limpia y prepara el texto para mejorar la calidad de las bÃºsquedas RAG."""
    if not text:
        return ""
    
    # Eliminar espacios mÃºltiples y saltos de lÃ­nea excesivos
    text = re.sub(r'\s+', ' ', text)
    
    # Eliminar caracteres especiales problemÃ¡ticos pero mantener puntuaciÃ³n importante
    text = re.sub(r'[^\w\s\.\,\!\?\;\:\-\(\)\[\]\{\}\"\']', '', text)
    
    # Normalizar espacios alrededor de puntuaciÃ³n
    text = re.sub(r'\s+([\.\,\!\?\;\:])', r'\1', text)
    
    # Eliminar lÃ­neas vacÃ­as mÃºltiples
    text = re.sub(r'\n\s*\n', '\n\n', text)
    
    # Limpiar espacios al inicio y final
    text = text.strip()
    
    return text
```

### **G. é«˜çº§å…ƒæ•°æ®è¿‡æ»¤ç³»ç»Ÿ**

#### **è¿‡æ»¤åŠŸèƒ½ï¼š**

ç³»ç»Ÿç°å·²åŒ…å«é«˜çº§è¿‡æ»¤åŠŸèƒ½ï¼Œå¯å®ç°æ›´ç²¾ç¡®ã€æ›´ç›¸å…³çš„æœç´¢ï¼š

```python
def create_metadata_filter(file_type: str = None, processing_method: str = None,
                          min_tables: int = None, min_titles: int = None,
                          source_contains: str = None) -> dict:
    """Crea filtros de metadatos para bÃºsquedas mÃ¡s precisas."""
    filters = []
    
    if file_type:
        filters.append({"file_type": file_type})
    if processing_method:
        filters.append({"processing_method": processing_method})
    if min_tables:
        filters.append({"structural_info_tables_count": {"$gte": min_tables}})
    if min_titles:
        filters.append({"structural_info_titles_count": {"$gte": min_titles}})
    if source_contains:
        filters.append({"source": {"$contains": source_contains}})
    
    return {"$and": filters} if len(filters) > 1 else filters[0] if filters else None
```

#### **ä½¿ç”¨è¿‡æ»¤å™¨æœç´¢ï¼š**

```python
def search_with_metadata_filters(vector_store: Chroma, query: str, 
                                metadata_filter: dict = None, k: int = 5) -> List[Any]:
    """Realiza bÃºsquedas con filtros de metadatos para mayor precisiÃ³n."""
    if metadata_filter:
        # BÃºsqueda con filtros especÃ­ficos
        results = vector_store.similarity_search_with_relevance_scores(
            query, k=k, filter=metadata_filter
        )
    else:
        # BÃºsqueda normal sin filtros
        results = vector_store.similarity_search_with_relevance_scores(query, k=k)
    
    return results
```

#### **çŸ¥è¯†åº“ç»Ÿè®¡ï¼š**

```python
def get_document_statistics(vector_store: Chroma) -> dict:
    """Obtiene estadÃ­sticas detalladas sobre la base de conocimientos."""
    all_docs = vector_store.get()
    
    if not all_docs or not all_docs.get('metadatas'):
        return {"total_documents": 0}
    
    metadatas = all_docs['metadatas']
    
    # AnÃ¡lisis por tipo de archivo
    file_types = {}
    processing_methods = {}
    total_tables = 0
    total_titles = 0
    
    for metadata in metadatas:
        file_type = metadata.get("file_type", "unknown")
        processing_method = metadata.get("processing_method", "unknown")
        tables_count = metadata.get("structural_info_tables_count", 0)
        titles_count = metadata.get("structural_info_titles_count", 0)
        
        file_types[file_type] = file_types.get(file_type, 0) + 1
        processing_methods[processing_method] = processing_methods.get(processing_method, 0) + 1
        total_tables += tables_count
        total_titles += titles_count
    
    return {
        "total_documents": len(metadatas),
        "file_types": file_types,
        "processing_methods": processing_methods,
        "total_tables": total_tables,
        "total_titles": total_titles,
        "avg_tables_per_doc": total_tables / len(metadatas) if metadatas else 0,
        "avg_titles_per_doc": total_titles / len(metadatas) if metadatas else 0
    }
```

#### **è¿‡æ»¤ç”¨ä¾‹ï¼š**

1) æŒ‰æ–‡ä»¶ç±»å‹è¿‡æ»¤ PDFï¼š
```python
pdf_filter = create_metadata_filter(file_type=".pdf")
results = search_with_metadata_filters(vector_store, "datos", pdf_filter)
```

2) ä»…å«è¡¨æ ¼çš„æ–‡æ¡£ï¼š
```python
tables_filter = create_metadata_filter(min_tables=1)
results = search_with_metadata_filters(vector_store, "datos tabulares", tables_filter)
```

3) æŒ‰å¤„ç†æ–¹æ³•è¿‡æ»¤ï¼ˆä»… Unstructured å¢å¼ºï¼‰ï¼š
```python
unstructured_filter = create_metadata_filter(processing_method="unstructured_enhanced")
results = search_with_metadata_filters(vector_store, "contenido", unstructured_filter)
```

4) ç»„åˆè¿‡æ»¤ï¼š
```python
complex_filter = create_metadata_filter(file_type=".pdf", min_tables=1, processing_method="unstructured_enhanced")
results = search_with_metadata_filters(vector_store, "datos", complex_filter)
```

### **H. å¢å¼ºå‹ MCP å·¥å…·**

#### **æ–°å¢å·¥å…·ï¼š**

1. **`ask_rag_filtered`**ï¼šä½¿ç”¨å…ƒæ•°æ®è¿‡æ»¤å™¨è¿›è¡Œæœç´¢
2. **`get_knowledge_base_stats`**ï¼šè¯¦ç»†çš„çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯

#### **ä¸ AI ä»£ç†é›†æˆï¼š**

æ–°å·¥å…·é’ˆå¯¹ AI ä»£ç†è¿›è¡Œäº†ä¼˜åŒ–ï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š
- **å‚æ•°å’Œç”¨ä¾‹çš„è¯¦ç»†æè¿°**
- **æ¯ä¸ªå·¥å…·çš„å…·ä½“ç¤ºä¾‹**
- **æ™ºèƒ½é”™è¯¯å¤„ç†**å¹¶æä¾›å®ç”¨å»ºè®®
- **ç»“æ„åŒ–å“åº”**å¹¶æä¾›å…ƒæ•°æ®ä¿¡æ¯

---

## ğŸ§² å‘é‡åµŒå…¥æä¾›å•†åˆ‡æ¢ï¼ˆHF æœ¬åœ° vs OpenAI äº‘ç«¯ï¼‰

ç³»ç»ŸåŒæ—¶æ”¯æŒä¸¤ç§åµŒå…¥æ–¹æ¡ˆï¼š

- æœ¬åœ° HuggingFaceï¼ˆé»˜è®¤ all-MiniLM-L6-v2ï¼Œ768 ç»´ï¼‰ï¼šå…è´¹ã€ä½å»¶è¿Ÿï¼Œå¯ç”¨ CPU/GPU è®¡ç®—
- OpenAI Embeddingsï¼ˆé»˜è®¤ text-embedding-3-largeï¼Œâ‰ˆ3072 ç»´ï¼‰ï¼šç²¾åº¦é«˜ã€éœ€ç½‘ç»œä¸è´¹ç”¨

åœ¨æ ¹ç›®å½• `.env` ä¸­é…ç½®ï¼š

```ini
# åµŒå…¥æä¾›å•†ï¼šHF æˆ– OPENAIï¼ˆé»˜è®¤ HFï¼‰
EMBEDDING_PROVIDER=OPENAI

# OpenAI åµŒå…¥æ¨¡å‹ï¼ˆå¯é€‰ï¼Œé»˜è®¤ text-embedding-3-largeï¼‰
OPENAI_EMBEDDING_MODEL=text-embedding-3-large

# å¯é€‰ï¼šè¦†ç›–é›†åˆåå‰ç¼€ï¼ˆç³»ç»Ÿä¼šè‡ªåŠ¨æ´¾ç”Ÿæä¾›å•†/æ¨¡å‹åç¼€ï¼‰
# COLLECTION_NAME=default_collection
```

æ³¨æ„äº‹é¡¹ï¼š
- åˆ‡æ¢æä¾›å•†/æ¨¡å‹ä¼šæ”¹å˜åµŒå…¥å‘é‡ç»´åº¦ã€‚ä¸ºé¿å…ç»´åº¦å†²çªï¼Œç³»ç»Ÿè‡ªåŠ¨ä¸º Chroma é›†åˆåè¿½åŠ åç¼€ï¼ˆä¾‹å¦‚ `default_collection-openai_text-embedding-3-large` æˆ– `default_collection-hf_all-MiniLM-L6-v2`ï¼‰ã€‚
- å¦‚éœ€ç»§ç»­ä½¿ç”¨æ—¢æœ‰æ—§é›†åˆï¼Œå¯æŠŠ EMBEDDING_PROVIDER åˆ‡å›åŸå€¼ï¼›å¦‚æœæƒ³è¿ç§»ï¼Œè¯·é‡æ–°å…¥åº“ï¼ˆre-ingestï¼‰ã€‚
- æ—¥å¿—ä¼šæ ‡æ˜å½“å‰åµŒå…¥åˆ†æ”¯ï¼š
    - HF æœ¬åœ°ï¼šæ˜¾ç¤ºâ€œä½¿ç”¨ GPU/CPU è¿›è¡Œ embeddings è®¡ç®—â€
    - OpenAIï¼šæ˜¾ç¤ºâ€œä½¿ç”¨ OpenAI Embeddings: text-embedding-3-large â€¦â€

å¸¸è§é—®é¢˜ï¼š
- OpenAI è°ƒç”¨å¤±è´¥ï¼šæ£€æŸ¥ OPENAI_API_KEYã€OPENAI_API_BASEï¼ˆä»£ç†/Azureï¼‰ã€ç½‘ç»œè¿é€šæ€§ä¸é…é¢
- ç»´åº¦ä¸åŒ¹é…é”™è¯¯ï¼šç¡®ä¿æ£€ç´¢ä½¿ç”¨ä¸å…¥åº“ä¸€è‡´çš„æä¾›å•†/æ¨¡å‹ï¼Œæˆ–ä½¿ç”¨ç³»ç»Ÿè‡ªåŠ¨åŒºåˆ†çš„é›†åˆå
- æ€§èƒ½ä¸æˆæœ¬ï¼šHF å…è´¹ä½†ç²¾åº¦ç¨ä½ï¼›OpenAI ç²¾åº¦æ›´é«˜ä½†æœ‰è°ƒç”¨æˆæœ¬

