"""
Server implementation embedded in package.

This file contains the real server implementation migrated from the repository
top-level `server.py`. It attempts to add the repository `src/` to sys.path
when running in a development checkout (detected by presence of pyproject.toml),
so imports like `tools`, `utils`, and `rag_core_openai` continue to work during
development. When installed as a package, repository files won't be found and
the normal installed packages are used.

Keep this file minimal and prefer relative imports within the package when
refactoring further.
"""

import os
import sys
from datetime import datetime
from urllib.parse import urlparse

# optional runtime dependencies: prefer to import but fall back to safe no-op
try:
    from dotenv import load_dotenv
except Exception:
    def load_dotenv():
        return None

try:
    from mcp.server.fastmcp import FastMCP
except Exception:
    # Minimal dummy FastMCP to allow import-time stability in environments
    # without the real `mcp` package. The dummy supports `tool` decorator and
    # `run` so code that attaches functions to mcp or calls run won't crash at import.
    class FastMCP:
        def __init__(self, *args, **kwargs):
            self._tools = {}

        def tool(self, *dargs, **dkwargs):
            def decorator(func):
                # store but do not change behavior
                self._tools[func.__name__] = func
                return func
            return decorator

        def run(self, *args, **kwargs):
            # no-op runtime fallback
            return None



def _maybe_add_repo_src():
    """If this code is running from a repository checkout, add repo/src to sys.path.

    This looks for a parent directory containing pyproject.toml and, if found,
    inserts its `src` subdirectory onto sys.path. This preserves developer
    convenience while remaining safe when installed from a wheel.
    """
    cur = os.path.abspath(os.path.dirname(__file__))
    prev = None
    while cur and cur != prev:
        if os.path.isfile(os.path.join(cur, 'pyproject.toml')):
            src_dir = os.path.join(cur, 'src')
            if os.path.isdir(src_dir):
                sys.path.insert(0, os.path.abspath(src_dir))
            break
        prev = cur
        cur = os.path.dirname(cur)


_maybe_add_repo_src()

# å¯¼å…¥å·¥å…·ï¼ˆåœ¨ repo å¼€å‘æ¨¡å¼ä¸‹ï¼Œä¸Šé¢çš„ä»£ç ä½¿è¿™äº›å¯¼å…¥å¯ç”¨ï¼‰
try:
    from utils.logger import log, log_mcp_server
except Exception:
    # minimal fallback logger for import-time stability
    def log(*args, **kwargs):
        print(*args, **kwargs)

    def log_mcp_server(*args, **kwargs):
        print(*args, **kwargs)

try:
    from utils.config import Config
except Exception:
    # minimal Config fallback used only during import/smoke checks
    class Config:
        SERVER_NAME = 'mcp-rag'
        CONVERTED_DOCS_DIR = os.path.join(os.path.abspath('.'), 'converted_docs')

        @staticmethod
        def ensure_directories():
            os.makedirs(Config.CONVERTED_DOCS_DIR, exist_ok=True)

# RAG core functions are imported lazily inside functions to avoid
# forcing heavy external deps (like openai) at import time.
_rag_core = None

def _ensure_rag_core_loaded():
    global _rag_core
    if _rag_core is None:
        try:
            import rag_core_openai as _rc
            _rag_core = _rc
        except Exception:
            _rag_core = None
    return _rag_core

# å¯¼å…¥ç»“æ„åŒ–æ¨¡å‹
try:
    from models import DocumentModel, MetadataModel
    MODELS_AVAILABLE = True
    log_mcp_server("âœ… ç»“æ„åŒ–æ¨¡å‹ (DocumentModel, MetadataModel) å¯ç”¨")
except Exception as e:
    MODELS_AVAILABLE = False
    # At this point logger may not be available; fallback to print if necessary
    try:
        log_mcp_server(f"âš ï¸ ç»“æ„åŒ–æ¨¡å‹ä¸å¯ç”¨: {e}")
    except Exception:
        print(f"âš ï¸ ç»“æ„åŒ–æ¨¡å‹ä¸å¯ç”¨: {e}")

# --- åˆå§‹åŒ–æœåŠ¡å™¨å’Œé…ç½® ---
load_dotenv()
mcp = FastMCP(Config.SERVER_NAME)

# çŠ¶æ€ç°åœ¨åŒ…æ‹¬æœ‰å…³ç»“æ„åŒ–æ¨¡å‹çš„ä¿¡æ¯
rag_state = {
    "models_available": MODELS_AVAILABLE,
    "structured_processing": MODELS_AVAILABLE,
    "document_models": [],  # å·²å¤„ç†çš„ DocumentModel åˆ—è¡¨
    "metadata_cache": {}    # æ¯ä¸ªæ–‡æ¡£çš„ MetadataModel ç¼“å­˜
}

md_converter = None


def warm_up_rag_system():
    """
    é¢„åŠ è½½ RAG ç³»ç»Ÿçš„é‡å‹ç»„ä»¶ï¼Œä»¥é¿å…é¦–æ¬¡è°ƒç”¨å·¥å…·æ—¶çš„å»¶è¿Ÿå’Œå†²çªã€‚
    """
    if "warmed_up" in rag_state:
        return
    
    try:
        log_mcp_server("æ­£åœ¨é¢„çƒ­ RAG ç³»ç»Ÿ...")
        log_mcp_server("åˆå§‹åŒ–äº‘ç«¯å‘é‡å­˜å‚¨ï¼ˆOpenAI-onlyï¼‰...")
    except Exception:
        pass
    
    rag_state["warmed_up"] = True
    try:
        log_mcp_server("RAG ç³»ç»Ÿå·²é¢„çƒ­å¹¶å‡†å¤‡å°±ç»ªã€‚")
    except Exception:
        pass


def ensure_converted_docs_directory():
    """ç¡®ä¿å­˜åœ¨ç”¨äºå­˜å‚¨è½¬æ¢æ–‡æ¡£çš„æ–‡ä»¶å¤¹ã€‚"""
    Config.ensure_directories()
    if not os.path.exists(Config.CONVERTED_DOCS_DIR):
        os.makedirs(Config.CONVERTED_DOCS_DIR)
        try:
            log_mcp_server(f"å·²åˆ›å»ºè½¬æ¢æ–‡æ¡£æ–‡ä»¶å¤¹: {Config.CONVERTED_DOCS_DIR}")
        except Exception:
            pass


def save_processed_copy(file_path: str, processed_content: str, processing_method: str = "unstructured") -> str:
    """
    ä¿å­˜å¤„ç†åçš„æ–‡æ¡£å‰¯æœ¬ä¸º Markdown æ ¼å¼ã€‚

    å‚æ•°ï¼š
        file_path: åŸå§‹æ–‡ä»¶è·¯å¾„
        processed_content: å¤„ç†åçš„å†…å®¹
        processing_method: ä½¿ç”¨çš„å¤„ç†æ–¹æ³•

    è¿”å›ï¼š
        ä¿å­˜çš„ Markdown æ–‡ä»¶è·¯å¾„
    """
    ensure_converted_docs_directory()
    
    # è·å–åŸå§‹æ–‡ä»¶åï¼ˆæ— æ‰©å±•åï¼‰
    original_filename = os.path.basename(file_path)
    name_without_ext = os.path.splitext(original_filename)[0]
    
    # åˆ›å»ºåŒ…å«æ–¹æ³•ä¿¡æ¯çš„ Markdown æ–‡ä»¶å
    md_filename = f"{name_without_ext}_{processing_method}.md"
    md_filepath = os.path.join(Config.CONVERTED_DOCS_DIR, md_filename)
    
    # ä¿å­˜å†…å®¹åˆ° Markdown æ–‡ä»¶
    try:
        with open(md_filepath, 'w', encoding='utf-8') as f:
            f.write(processed_content)
        try:
            log_mcp_server(f"å·²ä¿å­˜å¤„ç†åçš„å‰¯æœ¬: {md_filepath}")
        except Exception:
            pass
        return md_filepath
    except Exception as e:
        try:
            log_mcp_server(f"è­¦å‘Š: æ— æ³•ä¿å­˜å¤„ç†åçš„å‰¯æœ¬: {e}")
        except Exception:
            pass
        return ""


def initialize_rag():
    """
    ä½¿ç”¨æ ¸å¿ƒåˆå§‹åŒ– RAG ç³»ç»Ÿçš„æ‰€æœ‰ç»„ä»¶ã€‚
    """
    if "initialized" in rag_state:
        return

    try:
        log_mcp_server("é€šè¿‡æ ¸å¿ƒåˆå§‹åŒ– RAG ç³»ç»Ÿ...")
    except Exception:
        pass
    
    # ä»äº‘ç«¯æ ¸å¿ƒè·å–å‘é‡å­˜å‚¨å’Œ QA é“¾ï¼ˆå»¶åå¯¼å…¥ä»¥é¿å… import-time é”™è¯¯ï¼‰
    rc = _ensure_rag_core_loaded()
    if rc is None:
        raise RuntimeError("rag_core_openai is unavailable; install optional extras to enable cloud features")
    vector_store = rc.get_vector_store()
    qa_chain = rc.get_qa_chain(vector_store)
    
    rag_state["vector_store"] = vector_store
    rag_state["qa_chain"] = qa_chain
    rag_state["initialized"] = True
    
    # å…³äºæ¨¡å‹çŠ¶æ€çš„ä¿¡æ¯
    if MODELS_AVAILABLE:
        try:
            log_mcp_server("âœ… RAG ç³»ç»Ÿå·²åˆå§‹åŒ–ï¼Œæ”¯æŒç»“æ„åŒ–æ¨¡å‹")
            log_mcp_server("ğŸ§  DocumentModel å’Œ MetadataModel å¯ç”¨äºé«˜çº§å¤„ç†")
        except Exception:
            pass
    else:
        try:
            log_mcp_server("âš ï¸ RAG ç³»ç»Ÿå·²åˆå§‹åŒ–ï¼Œä½†æœªå¯ç”¨ç»“æ„åŒ–æ¨¡å‹ (ä½¿ç”¨å­—å…¸)")
        except Exception:
            pass
    
    try:
        log_mcp_server("RAG ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸã€‚")
    except Exception:
        pass


# --- æ³¨æ„: ä¸è¦åœ¨æ¨¡å—å¯¼å…¥æ—¶è‡ªåŠ¨åˆå§‹åŒ– RAG ç³»ç»Ÿ ---
# åˆå§‹åŒ–ï¼ˆinitialize_rag / warm_up_rag_systemï¼‰åº”å½“æŒ‰éœ€è°ƒç”¨ï¼Œä¾‹å¦‚åœ¨ CLI
# çš„ `serve` å­å‘½ä»¤æˆ–åœ¨ `if __name__ == '__main__'` ä¸‹è°ƒç”¨ã€‚è‡ªåŠ¨åˆå§‹åŒ–
# åœ¨ç¼ºå°‘å¯é€‰è¿è¡Œæ—¶ä¾èµ–ï¼ˆopenai ç­‰ï¼‰æ—¶ä¼šå¯¼è‡´å¯¼å…¥å¤±è´¥ï¼Œå½±å“å®‰è£…å’Œ
# ç®€å•çš„å¯¼å…¥æ£€æŸ¥ã€‚

# --- å·¥å…·æ¨¡å—çš„æ‡’é…ç½® ---
def configure_tools():
    """Configure tools' RAG state lazily.

    Call this once during startup (for example from the CLI `serve`
    subcommand) when the runtime dependencies are available.
    """
    try:
        from tools import configure_rag_state, ALL_TOOLS
    except Exception:
        # If tools cannot be imported (missing optional deps), skip configuration.
        return

    try:
        configure_rag_state(
            rag_state=rag_state,
            initialize_rag_func=initialize_rag,
            save_processed_copy_func=save_processed_copy
        )
    except Exception:
        # Best-effort: do not raise during lazy configuration
        pass

# --- Definir las herramientas MCP directamente en el servidor ---
@mcp.tool()
def learn_text(text: str, source_name: str = "manual_input") -> str:
    from tools.document_tools import learn_text as learn_text_logic
    return learn_text_logic(text, source_name)


@mcp.tool()
def learn_document(file_path: str) -> str:
    from tools.document_tools import learn_document as learn_document_logic
    return learn_document_logic(file_path)


@mcp.tool()
def ask_rag(query: str) -> str:
    from tools.search_tools import ask_rag as ask_rag_logic
    return ask_rag_logic(query)


@mcp.tool()
def ask_rag_filtered(query: str, file_type: str = None, min_tables: int = None, min_titles: int = None, processing_method: str = None) -> str:
    from tools.search_tools import ask_rag_filtered as ask_rag_filtered_logic
    return ask_rag_filtered_logic(query, file_type, min_tables, min_titles, processing_method)


@mcp.tool()
def get_knowledge_base_stats() -> str:
    from tools.utility_tools import get_knowledge_base_stats as get_knowledge_base_stats_logic
    return get_knowledge_base_stats_logic()


@mcp.tool()
def get_embedding_cache_stats() -> str:
    from tools.utility_tools import get_embedding_cache_stats as get_embedding_cache_stats_logic
    return get_embedding_cache_stats_logic()


@mcp.tool()
def clear_embedding_cache_tool() -> str:
    from tools.utility_tools import clear_embedding_cache_tool as clear_embedding_cache_tool_logic
    return clear_embedding_cache_tool_logic()


@mcp.tool()
def optimize_vector_database() -> str:
    from tools.utility_tools import optimize_vector_database as optimize_vector_database_logic
    return optimize_vector_database_logic()


@mcp.tool()
def get_vector_database_stats() -> str:
    from tools.utility_tools import get_vector_database_stats as get_vector_database_stats_logic
    return get_vector_database_stats_logic()


@mcp.tool()
def reindex_vector_database(profile: str = 'auto') -> str:
    from tools.utility_tools import reindex_vector_database as reindex_vector_database_logic
    return reindex_vector_database_logic(profile)

# --- å°†æ‰€æœ‰å·¥å…·å‡½æ•°æš´éœ²ä¸º mcp çš„æ–¹æ³•ï¼Œæ–¹ä¾¿ç›´æ¥è°ƒç”¨ï¼ˆå…¨å±€ä½œç”¨åŸŸï¼Œæ‰€æœ‰å‡½æ•°å®šä¹‰ä¹‹åï¼‰ ---
mcp.learn_text = learn_text
mcp.learn_document = learn_document
mcp.ask_rag = ask_rag
mcp.ask_rag_filtered = ask_rag_filtered
mcp.get_knowledge_base_stats = get_knowledge_base_stats
mcp.get_embedding_cache_stats = get_embedding_cache_stats
mcp.clear_embedding_cache_tool = clear_embedding_cache_tool
mcp.optimize_vector_database = optimize_vector_database
mcp.get_vector_database_stats = get_vector_database_stats
mcp.reindex_vector_database = reindex_vector_database

# --- å¯åŠ¨ MCP RAG æœåŠ¡å™¨ ---
if __name__ == "__main__":
    try:
        log_mcp_server("å¯åŠ¨ MCP RAG æœåŠ¡å™¨...")
    except Exception:
        pass
    warm_up_rag_system()  # å¯åŠ¨æ—¶é¢„çƒ­ç³»ç»Ÿ
    try:
        log_mcp_server("ğŸš€ æœåŠ¡å™¨å·²å¯åŠ¨ï¼Œè¿è¡Œæ¨¡å¼: stdio (å¦‚éœ€ Web æœåŠ¡è¯·è®¾ç½® host/port)")
    except Exception:
        pass
    # å°†æ‰€æœ‰å·¥å…·å‡½æ•°æš´éœ²ä¸º mcp çš„æ–¹æ³•ï¼Œæ–¹ä¾¿ç›´æ¥è°ƒç”¨
    mcp.learn_text = learn_text
    mcp.learn_document = learn_document
    mcp.ask_rag = ask_rag
    mcp.ask_rag_filtered = ask_rag_filtered
    mcp.get_knowledge_base_stats = get_knowledge_base_stats
    mcp.get_embedding_cache_stats = get_embedding_cache_stats
    mcp.clear_embedding_cache_tool = clear_embedding_cache_tool
    mcp.optimize_vector_database = optimize_vector_database
    mcp.get_vector_database_stats = get_vector_database_stats
    mcp.reindex_vector_database = reindex_vector_database
    # å¦‚éœ€ Web æœåŠ¡å¯æ”¹ä¸º: mcp.run(host="127.0.0.1", port=8000)
    mcp.run(transport='stdio')
