[agent.task_decomposition.model]
platform = "watsonx"
model_name = "meta-llama/llama-4-maverick-17b-128e-instruct-fp8"
temperature = 0.1
max_tokens = 1000

[agent.shortlister.model]
platform = "watsonx"
model_name = "meta-llama/llama-4-maverick-17b-128e-instruct-fp8"
temperature = 0.1
max_tokens = 7000

[agent.planner.model]
platform = "watsonx"
model_name = "meta-llama/llama-4-maverick-17b-128e-instruct-fp8"
temperature = 0.1
max_tokens = 5000

[agent.chat.model]
platform = "watsonx"
model_name = "meta-llama/llama-4-maverick-17b-128e-instruct-fp8"
temperature = 0.1
max_tokens = 5000

[agent.plan_controller.model]
platform = "watsonx"
model_name = "meta-llama/llama-4-maverick-17b-128e-instruct-fp8"
temperature = 0.1
max_tokens = 5000

[agent.final_answer.model]
platform = "watsonx"
model_name = "meta-llama/llama-4-maverick-17b-128e-instruct-fp8"
api_version ="2024-08-06"
temperature = 0.1
max_tokens = 15000

[agent.code.model]
platform = "watsonx"
model_name = "meta-llama/llama-4-maverick-17b-128e-instruct-fp8"
temperature = 0.1
max_tokens = 3000

[agent.code_planner.model]
platform = "watsonx"
model_name = "meta-llama/llama-4-maverick-17b-128e-instruct-fp8"
temperature = 0.1
max_tokens = 3000

[agent.qa.model]
platform = "watsonx"
model_name = "meta-llama/llama-4-maverick-17b-128e-instruct-fp8"
temperature = 0.1
max_tokens = 4000

[agent.action.model]
platform = "watsonx"
model_name = "meta-llama/llama-4-maverick-17b-128e-instruct-fp8"
temperature = 0.1
max_tokens = 400