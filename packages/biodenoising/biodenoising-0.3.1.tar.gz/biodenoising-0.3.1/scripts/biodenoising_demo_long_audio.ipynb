{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4FYJAV3ElZ5h"
   },
   "source": [
    "#Biodenoising - Animal vocalization denoising\n",
    "This is a demo for animal vocalization denoising without access to clean data.\n",
    "For the more info check the [associated page](https://mariusmiron.com/research/biodenoising/) and the code repository on [github](https://github.com/earthspecies/biodenoising).\n",
    "\n",
    "First, let's install the package from pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pl7pGTRidM1Q",
    "outputId": "119e964a-0fa7-4251-9ffc-1e4ed23f45fe"
   },
   "outputs": [],
   "source": [
    "!pip install biodenoising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzZIcD2PmJxB"
   },
   "source": [
    "We import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cypBqtncgE9Q"
   },
   "outputs": [],
   "source": [
    "from IPython import display as disp\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from biodenoising import pretrained\n",
    "from biodenoising.denoiser.dsp import convert_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMfAk2Z2mRp3"
   },
   "source": [
    "We download some noisy animal vocalizations from the biodenoising_validation dataset. Note that these files, species, noise conditions were not seen during training, to test for generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayCjnCxFmeJH"
   },
   "source": [
    "We set the device, gpu or cpu. You can use a computing instance with a GPU for faster processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "snrSxC8Uh4lt"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czIUjWoRmjh-"
   },
   "source": [
    "Let's load the 16kHz model. If it's the first time you run this, it will download the model locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kpuap38kgnxY",
    "outputId": "0a5fd42c-192e-493c-a986-48e523cf315e"
   },
   "outputs": [],
   "source": [
    "model = pretrained.biodenoising16k_dns48().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8tHqnWtm2v9"
   },
   "source": [
    "We use the model above to denoise the first demo sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "id": "XexsuKUEg2W4",
    "outputId": "d863247a-a9d3-4f7f-acba-5b8f3ee10aaa"
   },
   "outputs": [],
   "source": [
    "wav, sr = torchaudio.load(os.path.join('whale.wav'))\n",
    "wav = convert_audio(wav, sr, model.sample_rate, model.chin).to(device)\n",
    "\n",
    "if wav.shape[-1] > 640000:\n",
    "    import asteroid\n",
    "    ola_model = asteroid.dsp.overlap_add.LambdaOverlapAdd(\n",
    "        nnet=model,  # function to apply to each segment.\n",
    "        n_src=1,  # number of sources in the output of nnet\n",
    "        window_size=640000,  # Size of segmenting window\n",
    "        hop_size=640000//4,  # segmentation hop size\n",
    "        window=\"hann\",  # Type of the window (see scipy.signal.get_window\n",
    "        reorder_chunks=False,  # Whether to reorder each consecutive segment.\n",
    "        enable_grad=False,  # Set gradient calculation on of off (see torch.set_grad_enabled)\n",
    "    )\n",
    "    ola_model.window = ola_model.window.to(device)\n",
    "    with torch.no_grad():\n",
    "      denoised = ola_model(wav[None])[0]\n",
    "else:\n",
    "  with torch.no_grad():\n",
    "      denoised = model(wav[None])[0]\n",
    "disp.display(disp.Audio(wav.data.cpu().numpy(), rate=model.sample_rate))\n",
    "disp.display(disp.Audio(denoised.data.cpu().numpy(), rate=model.sample_rate))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
