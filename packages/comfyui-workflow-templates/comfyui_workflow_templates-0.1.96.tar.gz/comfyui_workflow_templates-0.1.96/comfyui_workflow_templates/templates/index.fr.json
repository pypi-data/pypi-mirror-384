[
  {
    "moduleName": "default",
    "type": "image",
    "isEssential": true,
    "title": "Bases",
    "templates": [
      {
        "name": "default",
        "title": "Génération d'images",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images à partir de prompts textuels.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/basic/text-to-image",
        "tags": ["Texte vers Image", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "size": 1.99,
        "vram": 2.88
      },
      {
        "name": "image2image",
        "title": "Image vers Image",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Transformer des images existantes en utilisant des prompts textuels.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/basic/image-to-image",
        "tags": ["Image vers Image", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "size": 1.99,
        "vram": 2.88,
        "thumbnailVariant": "hoverDissolve"
      },
      {
        "name": "lora",
        "title": "LoRA",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images avec des modèles LoRA pour des styles ou sujets spécialisés.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/basic/lora",
        "tags": ["Texte vers Image", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "size": 2.27,
        "vram": 2.88
      },
      {
        "name": "lora_multiple",
        "title": "LoRA Multiple",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images en combinant plusieurs modèles LoRA.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/basic/lora",
        "tags": ["Texte vers Image", "Image", "LoRA"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "size": 2.27,
        "vram": 3.12
      },
      {
        "name": "inpaint_example",
        "title": "Inpainting",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Éditer des parties spécifiques d'images de manière transparente.",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/basic/inpaint",
        "tags": ["Inpainting", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "size": 4.86,
        "vram": 3.82
      },
      {
        "name": "inpaint_model_outpainting",
        "title": "Outpainting",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Étendre les images au-delà de leurs limites d'origine.",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/basic/inpaint",
        "tags": ["Outpainting", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "size": 4.86,
        "vram": 3.82
      },
      {
        "name": "embedding_example",
        "title": "Embedding",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images en utilisant l'inversion textuelle pour des styles cohérents.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/textual_inversion_embeddings/",
        "tags": ["Embedding", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "size": 4.86,
        "vram": 3.84
      },
      {
        "name": "gligen_textbox_example",
        "title": "Gligen Textbox",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images avec un placement précis d'objets en utilisant des boîtes de texte.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/gligen/",
        "tags": ["Gligen", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "size": 2.77,
        "vram": 3.8
      },
      {
        "name": "area_composition",
        "title": "Composition de Zone",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images en contrôlant la composition avec des zones définies.",
        "tags": ["Composition de Zone", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/area_composition/",
        "size": 2.3,
        "vram": 5.76
      },
      {
        "name": "area_composition_square_area_for_subject",
        "title": "Area Composition Square Area for Subject",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images avec un placement cohérent du sujet en utilisant la composition de zone.",
        "tags": ["Composition de Zone", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/area_composition/#increasing-consistency-of-images-with-area-composition",
        "size": 2.3,
        "vram": 5.52
      },
      {
        "name": "hiresfix_latent_workflow",
        "title": "Agrandissement",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Agrandir les images en améliorant la qualité dans l'espace latent.",
        "thumbnailVariant": "compareSlider",
        "tags": ["Agrandissement", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/",
        "size": 1.99,
        "vram": 3.66
      },
      {
        "name": "esrgan_example",
        "title": "ESRGAN",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Agrandir les images en utilisant les modèles ESRGAN pour améliorer la qualité.",
        "thumbnailVariant": "compareSlider",
        "tags": ["Agrandissement", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/upscale_models/",
        "size": 2.05,
        "vram": 6.0
      },
      {
        "name": "hiresfix_esrgan_workflow",
        "title": "HiresFix ESRGAN Workflow",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Agrandir les images en utilisant les modèles ESRGAN pendant les étapes de génération intermédiaires.",
        "thumbnailVariant": "compareSlider",
        "tags": ["Agrandissement", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/#non-latent-upscaling",
        "size": 2.05,
        "vram": 6.0
      },
      {
        "name": "latent_upscale_different_prompt_model",
        "title": "Latent Upscale Different Prompt Model",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Agrandir les images tout en changeant les prompts à travers les passes de génération.",
        "thumbnailVariant": "zoomHover",
        "tags": ["Agrandissement", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/#more-examples",
        "size": 3.97,
        "vram": 4.8
      },
      {
        "name": "controlnet_example",
        "title": "Scribble ControlNet",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images guidées par des images de référence griffonnées en utilisant ControlNet.",
        "thumbnailVariant": "hoverDissolve",
        "tags": ["ControlNet", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/controlnet/",
        "size": 2.97,
        "vram": 6.0
      },
      {
        "name": "2_pass_pose_worship",
        "title": "Pose ControlNet 2 Pass",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images guidées par des références de pose en utilisant ControlNet.",
        "thumbnailVariant": "hoverDissolve",
        "tags": ["ControlNet", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/controlnet/#pose-controlnet",
        "size": 4.34,
        "vram": 6.0
      },
      {
        "name": "depth_controlnet",
        "title": "Depth ControlNet",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images guidées par les informations de profondeur en utilisant ControlNet.",
        "thumbnailVariant": "hoverDissolve",
        "tags": ["ControlNet", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/controlnet/#t2i-adapter-vs-controlnets",
        "size": 2.69,
        "vram": 6.0
      },
      {
        "name": "depth_t2i_adapter",
        "title": "Depth T2I Adapter",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images guidées par les informations de profondeur en utilisant l'adaptateur T2I.",
        "thumbnailVariant": "hoverDissolve",
        "tags": ["Adaptateur T2I", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/controlnet/#t2i-adapter-vs-controlnets",
        "size": 2.35,
        "vram": 6.0
      },
      {
        "name": "mixing_controlnets",
        "title": "Mixing ControlNets",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images en combinant plusieurs modèles ControlNet.",
        "thumbnailVariant": "hoverDissolve",
        "tags": ["ControlNet", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/controlnet/#mixing-controlnets",
        "size": 3.1,
        "vram": 6.0
      }
    ]
  },
  {
    "moduleName": "default",
    "type": "image",
    "category": "GENERATION TYPE",
    "icon": "icon-[lucide--image]",
    "title": "Image",
    "templates": [
      {
        "name": "image_qwen_image",
        "title": "Qwen-Image Texte vers Image",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images avec des capacités exceptionnelles de rendu et d'édition de texte multilingue en utilisant le modèle MMDiT 20B de Qwen-Image.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/qwen/qwen-image",
        "tags": ["Texte vers Image", "Image"],
        "models": ["Qwen-Image"],
        "date": "2025-08-05",
        "size": 29.59
      },
      {
        "name": "image_qwen_image_instantx_controlnet",
        "title": "Qwen-Image InstantX ControlNet",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images avec Qwen-Image InstantX ControlNet, prenant en charge canny, contours doux, profondeur, pose",
        "tags": ["Image vers Image", "Image", "ControlNet"],
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/qwen/qwen-image",
        "models": ["Qwen-Image"],
        "date": "2025-08-23",
        "size": 32.88
      },
      {
        "name": "image_qwen_image_instantx_inpainting_controlnet",
        "title": "Qwen-Image InstantX Inpainting ControlNet",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "description": "Professional inpainting and image editing with Qwen-Image InstantX ControlNet. Supports object replacement, text modification, background changes, and outpainting.",
        "tags": ["Image to Image", "Image", "ControlNet", "Inpainting"],
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/qwen/qwen-image",
        "models": ["Qwen-Image"],
        "date": "2025-09-12",
        "size": 33.54
      },
      {
        "name": "image_qwen_image_union_control_lora",
        "title": "Qwen-Image Union Control",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images avec un contrôle structurel précis en utilisant le LoRA ControlNet unifié de Qwen-Image. Prend en charge plusieurs types de contrôle incluant canny, depth, lineart, softedge, normal et openpose pour diverses applications créatives.",
        "tags": ["Texte vers Image", "Image", "ControlNet"],
        "models": ["Qwen-Image"],
        "date": "2025-08-23",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/qwen/qwen-image",
        "size": 30.47
      },
      {
        "name": "image_qwen_image_controlnet_patch",
        "title": "Qwen-Image ControlNet Basique",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Contrôler la génération d'images en utilisant les modèles ControlNet de Qwen-Image. Prend en charge les contrôles canny, depth et inpainting via le patching de modèles.",
        "tags": ["Texte vers Image", "Image", "ControlNet"],
        "models": ["Qwen-Image"],
        "date": "2025-08-24",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/qwen/qwen-image",
        "size": 31.7,
        "thumbnailVariant": "compareSlider"
      },
      {
        "name": "image_qwen_image_edit_2509",
        "title": "Qwen Image Edit 2509",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "description": "Advanced image editing with multi-image support, improved consistency, and ControlNet integration.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/qwen/qwen-image-edit",
        "tags": ["Image to Image", "Image Edit", "Multi-Image", "ControlNet"],
        "models": ["Qwen-Image"],
        "date": "2025-09-25",
        "size": 29.59
      },
      {
        "name": "image_qwen_image_edit",
        "title": "Édition d'Image Qwen",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "description": "Éditer des images avec une édition de texte bilingue précise et des capacités d'édition sémantique/apparence duales en utilisant le modèle MMDiT 20B de Qwen-Image-Edit.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/qwen/qwen-image-edit",
        "tags": ["Image vers Image", "Édition d'Image"],
        "models": ["Qwen-Image"],
        "date": "2025-08-18",
        "size": 29.59
      },
      {
        "name": "flux_kontext_dev_basic",
        "title": "Flux Kontext Dev (Basique)",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "hoverDissolve",
        "description": "Éditer une image en utilisant Flux Kontext avec une visibilité complète des nœuds, parfait pour apprendre le flux de travail.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-kontext-dev",
        "tags": ["Édition d'Image", "Image vers Image"],
        "models": ["Flux"],
        "date": "2025-06-26",
        "size": 16.43,
        "vram": 18.0
      },
      {
        "name": "image_chroma1_radiance_text_to_image",
        "title": "Chroma1 Radiance text to image",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Chroma1-Radiance works directly with image pixels instead of compressed latents, delivering higher quality images with reduced artifacts and distortion.",
        "tags": ["Text to Image", "Image"],
        "models": ["Chroma"],
        "date": "2025-09-18",
        "size": 22.0,
        "vram": 22.0
      },
      {
        "name": "image_netayume_lumina_t2i",
        "title": "NetaYume Lumina Text to Image",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "High-quality anime-style image generation with enhanced character understanding and detailed textures. Fine-tuned from Neta Lumina on Danbooru dataset.",
        "tags": ["Text to Image", "Image", "Anime"],
        "models": ["NetaYume Lumina"],
        "date": "2025-10-10",
        "size": 9.89
      },
      {
        "name": "image_chroma_text_to_image",
        "title": "Chroma texte vers image",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Chroma est modifié à partir de Flux et présente quelques changements dans l'architecture.",
        "tags": ["Texte vers Image", "Image"],
        "models": ["Chroma", "Flux"],
        "date": "2025-06-04",
        "size": 21.69,
        "vram": 14.5
      },
      {
        "name": "image_flux.1_fill_dev_OneReward",
        "title": "Flux.1 Dev OneReward",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "description": "Supports various tasks such as image inpainting, outpainting, and object removal",
        "tags": ["Inpainting", "Outpainting"],
        "models": ["Flux"],
        "date": "2025-09-21",
        "size": 27.01,
        "vram": 20.0
      },
      {
        "name": "flux_dev_checkpoint_example",
        "title": "Flux Dev fp8",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images en utilisant la version quantifiée Flux Dev fp8. Convient aux appareils avec une VRAM limitée, ne nécessite qu'un seul fichier de modèle, mais la qualité de l'image est légèrement inférieure à la version complète.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-text-to-image",
        "tags": ["Texte vers Image", "Image"],
        "models": ["Flux"],
        "date": "2025-03-01",
        "size": 16.06,
        "vram": 17.0
      },
      {
        "name": "flux1_dev_uso_reference_image_gen",
        "title": "Génération d'images de référence Flux.1 Dev USO",
        "description": "Utilisez des images de référence pour contrôler à la fois le style et le sujet : conservez le visage de votre personnage tout en changeant de style artistique, ou appliquez des styles artistiques à de nouvelles scènes",
        "thumbnailVariant": "hoverDissolve",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image to Image", "Image"],
        "models": ["Flux"],
        "date": "2025-09-02",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-uso",
        "size": 17.32,
        "vram": 18.5
      },
      {
        "name": "flux_schnell",
        "title": "Flux Schnell fp8",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer rapidement des images avec la version quantifiée Flux Schnell fp8. Idéal pour le matériel d'entrée de gamme, ne nécessite que 4 étapes pour générer des images.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-text-to-image",
        "tags": ["Texte vers Image", "Image"],
        "models": ["Flux"],
        "date": "2025-03-01",
        "size": 16.05,
        "vram": 17.0
      },
      {
        "name": "flux1_krea_dev",
        "title": "Flux.1 Krea Dev",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Un modèle FLUX affiné poussant le photoréalisme à son maximum",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux1-krea-dev",
        "tags": ["Texte vers Image", "Image", "Photoréalisme"],
        "models": ["Flux"],
        "date": "2025-07-31",
        "size": 20.74,
        "vram": 21.5
      },
      {
        "name": "flux_dev_full_text_to_image",
        "title": "Flux Dev texte vers image complet",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images de haute qualité avec la version complète de Flux Dev. Nécessite plus de VRAM et plusieurs fichiers de modèles, mais offre la meilleure capacité de suivi des prompts et la qualité d'image.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-text-to-image",
        "tags": ["Texte vers Image", "Image"],
        "models": ["Flux"],
        "date": "2025-03-01",
        "size": 31.83,
        "vram": 22.0
      },
      {
        "name": "flux_schnell_full_text_to_image",
        "title": "Flux Schnell texte vers image complet",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images rapidement avec la version complète de Flux Schnell. Utilise la licence Apache2.0, ne nécessite que 4 étapes pour générer des images tout en maintenant une bonne qualité d'image.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-text-to-image",
        "tags": ["Texte vers Image", "Image"],
        "models": ["Flux"],
        "date": "2025-03-01",
        "size": 31.81
      },
      {
        "name": "flux_fill_inpaint_example",
        "title": "Flux Inpainting",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Combler les parties manquantes des images en utilisant l'inpainting Flux.",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-fill-dev",
        "tags": ["Image vers Image", "Inpainting", "Image"],
        "models": ["Flux"],
        "date": "2025-03-01",
        "size": 9.66
      },
      {
        "name": "flux_fill_outpaint_example",
        "title": "Flux Outpainting",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Étendre les images au-delà des limites en utilisant l'outpainting Flux.",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-fill-dev",
        "tags": ["Outpainting", "Image", "Image vers Image"],
        "models": ["Flux"],
        "date": "2025-03-01",
        "size": 9.66
      },
      {
        "name": "flux_canny_model_example",
        "title": "Modèle Flux Canny",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images guidées par la détection de contours en utilisant Flux Canny.",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-controlnet",
        "tags": ["Image vers Image", "ControlNet", "Image"],
        "models": ["Flux"],
        "date": "2025-03-01",
        "size": 31.83
      },
      {
        "name": "flux_depth_lora_example",
        "title": "Flux Depth LoRA",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images guidées par les informations de profondeur en utilisant Flux LoRA.",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "ttps://docs.comfy.org/tutorials/flux/flux-1-controlnet",
        "tags": ["Image vers Image", "ControlNet", "Image", "LoRA"],
        "models": ["Flux"],
        "date": "2025-03-01",
        "size": 32.98
      },
      {
        "name": "flux_redux_model_example",
        "title": "Modèle Flux Redux",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images en transférant le style à partir d'images de référence en utilisant Flux Redux.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-controlnet",
        "tags": ["Image vers Image", "ControlNet", "Image", "LoRA"],
        "models": ["Flux"],
        "date": "2025-03-01",
        "size": 32.74
      },
      {
        "name": "image_omnigen2_t2i",
        "title": "OmniGen2 Texte vers Image",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images de haute qualité à partir de prompts textuels en utilisant le modèle multimodal unifié 7B d'OmniGen2 avec une architecture à double chemin.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/omnigen/omnigen2",
        "tags": ["Texte vers Image", "Image"],
        "models": ["OmniGen"],
        "date": "2025-06-30",
        "size": 14.7
      },
      {
        "name": "image_omnigen2_image_edit",
        "title": "Édition d'Image OmniGen2",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "hoverDissolve",
        "description": "Éditer des images avec des instructions en langage naturel en utilisant les capacités avancées d'édition d'images d'OmniGen2 et le support de rendu de texte.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/omnigen/omnigen2",
        "tags": ["Édition d'Image", "Image"],
        "models": ["OmniGen"],
        "date": "2025-06-30",
        "size": 14.7
      },
      {
        "name": "hidream_i1_dev",
        "title": "HiDream I1 Dev",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images avec HiDream I1 Dev - Version équilibrée avec 28 étapes d'inférence, adaptée au matériel de gamme moyenne.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/hidream/hidream-i1",
        "tags": ["Texte vers Image", "Image"],
        "models": ["HiDream"],
        "date": "2025-04-17",
        "size": 31.03
      },
      {
        "name": "hidream_i1_fast",
        "title": "HiDream I1 Fast",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images rapidement avec HiDream I1 Fast - Version légère avec 16 étapes d'inférence, idéale pour des aperçus rapides sur du matériel d'entrée de gamme.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/hidream/hidream-i1",
        "tags": ["Texte vers Image", "Image"],
        "models": ["HiDream"],
        "date": "2025-04-17",
        "size": 22.57
      },
      {
        "name": "hidream_i1_full",
        "title": "HiDream I1 Full",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images avec HiDream I1 Full - Version complète avec 50 étapes d'inférence pour une sortie de la plus haute qualité.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/hidream/hidream-i1",
        "tags": ["Texte vers Image", "Image"],
        "models": ["HiDream"],
        "date": "2025-04-17",
        "size": 22.57
      },
      {
        "name": "hidream_e1_1",
        "title": "Édition d'Image HiDream E1.1",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "description": "Éditer des images avec HiDream E1.1 – il est meilleur en qualité d'image et en précision d'édition que HiDream-E1-Full.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/hidream/hidream-e1",
        "tags": ["Édition d'Image", "Image"],
        "models": ["HiDream"],
        "date": "2025-07-21",
        "size": 46.96
      },
      {
        "name": "hidream_e1_full",
        "title": "Édition d'Image HiDream E1",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "description": "Éditer des images avec HiDream E1 - Modèle professionnel d'édition d'images en langage naturel.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/hidream/hidream-e1",
        "tags": ["Édition d'Image", "Image"],
        "models": ["HiDream"],
        "date": "2025-05-01",
        "size": 31.86
      },
      {
        "name": "sd3.5_simple_example",
        "title": "SD3.5 Simple",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images en utilisant SD 3.5.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sd3/#sd35",
        "tags": ["Texte vers Image", "Image"],
        "models": ["SD3.5"],
        "date": "2025-03-01",
        "size": 13.91
      },
      {
        "name": "sd3.5_large_canny_controlnet_example",
        "title": "SD3.5 Large Canny ControlNet",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images guidées par la détection de contours en utilisant SD 3.5 Canny ControlNet.",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sd3/#sd35-controlnets",
        "tags": ["Image vers Image", "Image", "ControlNet"],
        "models": ["SD3.5"],
        "date": "2025-03-01",
        "size": 21.97
      },
      {
        "name": "sd3.5_large_depth",
        "title": "SD3.5 Large Depth",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images guidées par les informations de profondeur en utilisant SD 3.5.",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sd3/#sd35-controlnets",
        "tags": ["Image vers Image", "Image", "ControlNet"],
        "models": ["SD3.5"],
        "date": "2025-03-01",
        "size": 21.97
      },
      {
        "name": "sd3.5_large_blur",
        "title": "SD3.5 Large Blur",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images guidées par des images de référence floues en utilisant SD 3.5.",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sd3/#sd35-controlnets",
        "tags": ["Image vers Image", "Image"],
        "models": ["SD3.5"],
        "date": "2025-03-01",
        "size": 21.97
      },
      {
        "name": "sdxl_simple_example",
        "title": "SDXL Simple",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images de haute qualité en utilisant SDXL.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sdxl/",
        "tags": ["Texte vers Image", "Image"],
        "models": ["SDXL", "Stability"],
        "date": "2025-03-01",
        "size": 12.12
      },
      {
        "name": "sdxl_refiner_prompt_example",
        "title": "SDXL Refiner Prompt",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Améliorer les images SDXL en utilisant des modèles de raffinement.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sdxl/",
        "tags": ["Texte vers Image", "Image"],
        "models": ["SDXL", "Stability"],
        "date": "2025-03-01",
        "size": 12.12
      },
      {
        "name": "sdxl_revision_text_prompts",
        "title": "SDXL Revision Text Prompts",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images en transférant des concepts à partir d'images de référence en utilisant SDXL Revision.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sdxl/#revision",
        "tags": ["Texte vers Image", "Image"],
        "models": ["SDXL", "Stability"],
        "date": "2025-03-01",
        "size": 9.9
      },
      {
        "name": "sdxlturbo_example",
        "title": "SDXL Turbo",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images en une seule étape en utilisant SDXL Turbo.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sdturbo/",
        "tags": ["Texte vers Image", "Image"],
        "models": ["SDXL", "Stability"],
        "date": "2025-03-01",
        "size": 6.46
      },
      {
        "name": "image_lotus_depth_v1_1",
        "title": "Lotus Depth",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "description": "Exécuter Lotus Depth dans ComfyUI pour une estimation de profondeur monoculaire efficace zero-shot avec une haute rétention de détails.",
        "tags": ["Profondeur", "Image"],
        "models": ["SD1.5"],
        "date": "2025-05-21",
        "size": 1.93
      }
    ]
  },
  {
    "moduleName": "default",
    "type": "video",
    "category": "GENERATION TYPE",
    "icon": "icon-[lucide--film]",
    "title": "Vidéo",
    "templates": [
      {
        "name": "video_wan2_2_14B_t2v",
        "title": "Wan 2.2 14B Text to Video",
        "description": "Générer des vidéos de haute qualité à partir de prompts textuels avec un contrôle esthétique cinématographique et une génération de mouvement dynamique en utilisant Wan 2.2.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan2_2",
        "tags": ["Texte vers Vidéo", "Vidéo"],
        "models": ["Wan2.2", "Wan"],
        "date": "2025-07-29",
        "size": 35.42
      },
      {
        "name": "video_wan2_2_14B_i2v",
        "title": "Wan 2.2 14B Image to Video",
        "description": "Transformer des images statiques en vidéos dynamiques avec un contrôle précis du mouvement et une préservation du style en utilisant Wan 2.2.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan2_2",
        "tags": ["Image vers Vidéo", "Vidéo"],
        "models": ["Wan2.2", "Wan"],
        "date": "2025-07-29",
        "size": 35.42
      },
      {
        "name": "video_wan2_2_14B_flf2v",
        "title": "Wan 2.2 14B First-Last Frame to Video",
        "description": "Générer des transitions vidéo fluides en définissant les images de début et de fin.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan2_2",
        "tags": ["FLF2V", "Vidéo"],
        "models": ["Wan2.2", "Wan"],
        "date": "2025-08-02",
        "size": 35.42
      },
      {
        "name": "video_wan2_2_14B_animate",
        "title": "Wan2.2 Animate, character animation and replacement",
        "description": "Unified character animation and replacement framework with precise motion and expression replication.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan2-2-animate",
        "tags": ["Video", "Image to Video"],
        "models": ["Wan2.2", "Wan"],
        "date": "2025-09-22",
        "size": 25.535
      },
      {
        "name": "video_wan2_2_14B_s2v",
        "title": "Wan2.2-S2V Génération de Vidéo Pilotée par l'Audio",
        "description": "Transformer des images statiques et de l'audio en vidéos dynamiques avec une synchronisation parfaite et une génération au niveau de la minute.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan2-2-s2v",
        "tags": ["Vidéo"],
        "models": ["Wan2.2", "Wan"],
        "date": "2025-08-02",
        "size": 23.52
      },
      {
        "name": "video_humo",
        "title": "HuMo Video Generation",
        "description": "Generate videos basic on audio, image, and text, keep the character's lip sync.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Video"],
        "models": ["HuMo"],
        "date": "2025-09-21",
        "size": 25.98
      },
      {
        "name": "video_wan2_2_14B_fun_inpaint",
        "title": "Wan 2.2 14B Fun Inp",
        "description": "Generate videos from start and end frames using Wan 2.2 Fun Inp.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan2-2-fun-inp",
        "tags": ["FLF2V", "Video"],
        "models": ["Wan2.2", "Wan"],
        "date": "2025-08-12",
        "size": 35.42
      },
      {
        "name": "video_wan2_2_14B_fun_control",
        "title": "Wan 2.2 14B Fun Control",
        "description": "Générer des vidéos guidées par des contrôles de pose, de profondeur et de contours en utilisant Wan 2.2 Fun Control.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan2-2-fun-control",
        "tags": ["Vidéo vers Vidéo", "Vidéo"],
        "models": ["Wan2.2", "Wan"],
        "date": "2025-08-12",
        "size": 35.42
      },
      {
        "name": "video_wan2_2_14B_fun_camera",
        "title": "Wan 2.2 14B Fun Camera Control",
        "description": "Générer des vidéos avec des contrôles de mouvement de caméra incluant le panoramique, le zoom et la rotation en utilisant Wan 2.2 Fun Camera Control.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan2-2-fun-camera",
        "tags": ["Vidéo vers Vidéo", "Vidéo"],
        "models": ["Wan2.2", "Wan"],
        "date": "2025-08-17",
        "size": 37.3
      },
      {
        "name": "video_wan2_2_5B_ti2v",
        "title": "Wan 2.2 5B Video Generation",
        "description": "Générer des vidéos à partir de texte ou d'images en utilisant le modèle hybride Wan 2.2 5B",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan2_2",
        "tags": ["Texte vers Vidéo", "Vidéo"],
        "models": ["Wan2.2", "Wan"],
        "date": "2025-07-29",
        "size": 16.9
      },
      {
        "name": "video_wan2_2_5B_fun_inpaint",
        "title": "Wan 2.2 5B Fun Inpaint",
        "description": "Inpainting vidéo efficace à partir des images de début et de fin. Le modèle 5B offre des itérations rapides pour tester les flux de travail.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Vidéo", "Vidéo"],
        "models": ["Wan2.2", "Wan"],
        "date": "2025-07-29",
        "size": 16.9
      },
      {
        "name": "video_wan2_2_5B_fun_control",
        "title": "Wan 2.2 5B Fun Control",
        "description": "Contrôle vidéo multi-conditions avec guidance par pose, profondeur et contours. Taille compacte 5B pour un développement expérimental.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Vidéo", "Vidéo"],
        "models": ["Wan2.2", "Wan"],
        "date": "2025-07-29",
        "size": 16.9
      },
      {
        "name": "video_wan_vace_14B_t2v",
        "title": "Wan VACE Text to Video",
        "description": "Transformer des descriptions textuelles en vidéos de haute qualité. Prend en charge à la fois 480p et 720p avec le modèle VACE-14B.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/vace",
        "tags": ["Texte vers Vidéo", "Vidéo"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-05-21",
        "size": 53.79
      },
      {
        "name": "video_wan_vace_14B_ref2v",
        "title": "Wan VACE Reference to Video",
        "description": "Créer des vidéos qui correspondent au style et au contenu d'une image de référence. Parfait pour la génération de vidéos cohérentes en style.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/vace",
        "tags": ["Référence vers Vidéo", "Vidéo"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-05-21",
        "size": 53.79
      },
      {
        "name": "video_wan_vace_14B_v2v",
        "title": "Wan VACE Control Video",
        "description": "Générer des vidéos en contrôlant les vidéos d'entrée et les images de référence en utilisant Wan VACE.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/vace",
        "tags": ["Vidéo vers Vidéo", "Vidéo"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-05-21",
        "size": 53.79
      },
      {
        "name": "video_wan_vace_outpainting",
        "title": "Wan VACE Outpainting",
        "description": "Générer des vidéos étendues en agrandissant la taille de la vidéo en utilisant l'outpainting Wan VACE.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/vace",
        "tags": ["Outpainting", "Vidéo"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-05-21",
        "size": 53.79
      },
      {
        "name": "video_wan_vace_flf2v",
        "title": "Wan VACE First-Last Frame",
        "description": "Générer des transitions vidéo fluides en définissant les images de début et de fin. Prend en charge les séquences d'images clés personnalisées.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/vace",
        "tags": ["FLF2V", "Vidéo"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-05-21",
        "size": 53.79
      },
      {
        "name": "video_wan_vace_inpainting",
        "title": "Wan VACE Inpainting",
        "description": "Éditer des régions spécifiques dans les vidéos tout en préservant le contenu environnant. Idéal pour la suppression ou le remplacement d'objets.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/vace",
        "tags": ["Inpainting", "Vidéo"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-05-21",
        "size": 53.79
      },
      {
        "name": "video_wan2.1_alpha_t2v_14B",
        "title": "Wan2.1 Alpha T2V",
        "description": "Generate text-to-video with alpha channel support for transparent backgrounds and semi-transparent objects.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Text to Video", "Video"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-10-06",
        "size": 20.95
      },
      {
        "name": "video_wan_ati",
        "title": "Wan ATI",
        "description": "Génération de vidéo contrôlée par trajectoire.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan-ati",
        "tags": ["Vidéo"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-05-21",
        "size": 23.65
      },
      {
        "name": "video_wan2.1_fun_camera_v1.1_1.3B",
        "title": "Wan 2.1 Fun Camera 1.3B",
        "description": "Générer des vidéos dynamiques avec des mouvements de caméra cinématographiques en utilisant le modèle Wan 2.1 Fun Camera 1.3B.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/fun-control",
        "tags": ["Vidéo"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-04-15",
        "size": 10.7
      },
      {
        "name": "video_wan2.1_fun_camera_v1.1_14B",
        "title": "Wan 2.1 Fun Camera 14B",
        "description": "Générer des vidéos de haute qualité avec un contrôle avancé de la caméra en utilisant le modèle 14B complet",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/fun-control",
        "tags": ["Vidéo"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-04-15",
        "size": 39.16
      },
      {
        "name": "text_to_video_wan",
        "title": "Wan 2.1 Text to Video",
        "description": "Générer des vidéos à partir de prompts textuels en utilisant Wan 2.1.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan-video",
        "tags": ["Texte vers Vidéo", "Vidéo"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-03-01",
        "size": 9.15
      },
      {
        "name": "image_to_video_wan",
        "title": "Wan 2.1 Image to Video",
        "description": "Générer des vidéos à partir d'images en utilisant Wan 2.1.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan-video",
        "tags": ["Texte vers Vidéo", "Vidéo"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-03-01",
        "size": 38.23
      },
      {
        "name": "wan2.1_fun_inp",
        "title": "Wan 2.1 Inpainting",
        "description": "Générer des vidéos à partir des images de début et de fin en utilisant l'inpainting Wan 2.1.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/fun-inp",
        "tags": ["Inpainting", "Vidéo"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-04-15",
        "size": 10.6
      },
      {
        "name": "wan2.1_fun_control",
        "title": "Wan 2.1 ControlNet",
        "description": "Générer des vidéos guidées par des contrôles de pose, de profondeur et de contours en utilisant Wan 2.1 ControlNet.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/fun-control",
        "tags": ["Vidéo vers Vidéo", "Vidéo"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-04-15",
        "size": 10.6
      },
      {
        "name": "wan2.1_flf2v_720_f16",
        "title": "Wan 2.1 FLF2V 720p F16",
        "description": "Générer des vidéos en contrôlant les première et dernière images en utilisant Wan 2.1 FLF2V.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan-flf",
        "tags": ["FLF2V", "Vidéo"],
        "models": ["Wan2.1", "Wan"],
        "date": "2025-04-15",
        "size": 38.23
      },
      {
        "name": "ltxv_text_to_video",
        "title": "LTXV Text to Video",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des vidéos à partir de prompts textuels.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/ltxv",
        "tags": ["Texte vers Vidéo", "Vidéo"],
        "models": ["LTXV"],
        "date": "2025-03-01",
        "size": 17.84
      },
      {
        "name": "ltxv_image_to_video",
        "title": "LTXV Image to Video",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des vidéos à partir d'images fixes.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/ltxv",
        "tags": ["Image vers Vidéo", "Vidéo"],
        "models": ["LTXV"],
        "date": "2025-03-01",
        "size": 17.84
      },
      {
        "name": "mochi_text_to_video_example",
        "title": "Mochi Text to Video",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des vidéos à partir de prompts textuels en utilisant le modèle Mochi.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/mochi/",
        "tags": ["Texte vers Vidéo", "Vidéo"],
        "models": ["Mochi"],
        "date": "2025-03-01",
        "size": 28.65
      },
      {
        "name": "hunyuan_video_text_to_video",
        "title": "Hunyuan Video Text to Video",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des vidéos à partir de prompts textuels en utilisant le modèle Hunyuan.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/hunyuan_video/",
        "tags": ["Texte vers Vidéo", "Vidéo"],
        "models": ["Hunyuan Video"],
        "date": "2025-03-01",
        "size": 33.04
      },
      {
        "name": "image_to_video",
        "title": "SVD Image to Video",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des vidéos à partir d'images fixes.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/video/#image-to-video",
        "tags": ["Image vers Vidéo", "Vidéo"],
        "models": ["SVD"],
        "date": "2025-03-01",
        "size": 8.9
      },
      {
        "name": "txt_to_image_to_video",
        "title": "SVD Text to Image to Video",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des vidéos en créant d'abord des images à partir de prompts textuels.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/video/#image-to-video",
        "tags": ["Texte vers Vidéo", "Vidéo"],
        "models": ["SVD"],
        "date": "2025-03-01",
        "size": 15.36
      }
    ]
  },
  {
    "moduleName": "default",
    "type": "audio",
    "category": "GENERATION TYPE",
    "icon": "icon-[lucide--volume-2]",
    "title": "Audio",
    "templates": [
      {
        "name": "audio_stable_audio_example",
        "title": "Stable Audio",
        "mediaType": "audio",
        "mediaSubtype": "mp3",
        "description": "Générer de l'audio à partir de prompts textuels en utilisant Stable Audio.",
        "tags": ["Texte vers Audio", "Audio"],
        "models": ["Stable Audio"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/audio/",
        "size": 5.35
      },
      {
        "name": "audio_ace_step_1_t2a_instrumentals",
        "title": "ACE-Step v1 Text to Instrumentals Music",
        "mediaType": "audio",
        "mediaSubtype": "mp3",
        "description": "Générer de la musique instrumentale à partir de prompts textuels en utilisant ACE-Step v1.",
        "tags": ["Texte vers Audio", "Audio", "Instrumentals"],
        "models": ["ACE-Step"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/audio/ace-step/ace-step-v1",
        "size": 7.17
      },
      {
        "name": "audio_ace_step_1_t2a_song",
        "title": "ACE Step v1 Text to Song",
        "mediaType": "audio",
        "mediaSubtype": "mp3",
        "description": "Générer des chansons avec des voix à partir de prompts textuels en utilisant ACE-Step v1, prenant en charge la multilingue et la personnalisation du style.",
        "tags": ["Texte vers Audio", "Audio", "Song"],
        "models": ["ACE-Step"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/audio/ace-step/ace-step-v1",
        "size": 7.17
      },
      {
        "name": "audio_ace_step_1_m2m_editing",
        "title": "ACE Step v1 M2M Editing",
        "mediaType": "audio",
        "mediaSubtype": "mp3",
        "description": "Éditer des chansons existantes pour changer le style et les paroles en utilisant ACE-Step v1 M2M.",
        "tags": ["Édition Audio", "Audio"],
        "models": ["ACE-Step"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/audio/ace-step/ace-step-v1",
        "size": 7.17
      }
    ]
  },
  {
    "moduleName": "default",
    "type": "3d",
    "category": "GENERATION TYPE",
    "icon": "icon-[lucide--box]",
    "title": "3D",
    "templates": [
      {
        "name": "3d_hunyuan3d-v2.1",
        "title": "Hunyuan3D 2.1",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate 3D models from single images using Hunyuan3D 2.0.",
        "tags": ["Image to Model", "3D"],
        "models": ["Hunyuan3D"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "size": 4.59
      },
      {
        "name": "3d_hunyuan3d_image_to_model",
        "title": "Hunyuan3D 2.0",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des modèles 3D à partir d'images simples en utilisant Hunyuan3D 2.0.",
        "tags": ["Image vers Modèle", "3D"],
        "models": ["Hunyuan3D"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 4.59
      },
      {
        "name": "3d_hunyuan3d_multiview_to_model",
        "title": "Hunyuan3D 2.0 MV",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des modèles 3D à partir de vues multiples en utilisant Hunyuan3D 2.0 MV.",
        "tags": ["Multivue vers Modèle", "3D"],
        "models": ["Hunyuan3D"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "thumbnailVariant": "hoverDissolve",
        "size": 4.59
      },
      {
        "name": "3d_hunyuan3d_multiview_to_model_turbo",
        "title": "Hunyuan3D 2.0 MV Turbo",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des modèles 3D à partir de vues multiples en utilisant Hunyuan3D 2.0 MV Turbo.",
        "tags": ["Multivue vers Modèle", "3D"],
        "models": ["Hunyuan3D"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "thumbnailVariant": "hoverDissolve",
        "size": 4.59
      }
    ]
  },
  {
    "moduleName": "default",
    "type": "image",
    "category": "CLOSED SOURCE MODELS",
    "icon": "icon-[lucide--hand-coins]",
    "title": "API Image",
    "templates": [
      {
        "name": "api_bytedance_seedream4",
        "title": "ByteDance Seedream 4.0",
        "description": "Multi-modal AI model for text-to-image and image editing. Generate 2K images in under 2 seconds with natural language control.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image Edit", "Image", "API", "Text-to-Image"],
        "models": ["Seedream 4.0", "ByteDance"],
        "date": "2025-09-11",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_google_gemini_image",
        "title": "Google Gemini Image",
        "description": "Nano-banana (Gemini-2.5-Flash Image) - édition d'images avec cohérence.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Édition d'Image", "Image", "API", "Texte-vers-Image"],
        "models": ["Gemini-2.5-Flash", "nano-banana", "Google"],
        "date": "2025-08-27",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_bfl_flux_1_kontext_multiple_images_input",
        "title": "BFL Flux.1 Kontext Multiple Image Input",
        "description": "Importer plusieurs images et les éditer avec Flux.1 Kontext.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/black-forest-labs/flux-1-kontext",
        "tags": ["Édition d'Image", "Image"],
        "models": ["Flux", "Kontext"],
        "date": "2025-05-29",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_bfl_flux_1_kontext_pro_image",
        "title": "BFL Flux.1 Kontext Pro",
        "description": "Éditer des images avec Flux.1 Kontext pro image.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/black-forest-labs/flux-1-kontext",
        "tags": ["Édition d'Image", "Image"],
        "models": ["Flux", "Kontext", "BFL"],
        "date": "2025-05-29",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_bfl_flux_1_kontext_max_image",
        "title": "BFL Flux.1 Kontext Max",
        "description": "Éditer des images avec Flux.1 Kontext max image.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/black-forest-labs/flux-1-kontext",
        "tags": ["Édition d'Image", "Image"],
        "models": ["Flux", "Kontext", "BFL"],
        "date": "2025-05-29",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_wan_text_to_image",
        "title": "Wan2.5: Text to Image",
        "description": "Generate images with excellent prompt following and visual quality using FLUX.1 Pro.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Text to Image", "Image", "API"],
        "models": ["Wan2.5"],
        "date": "2025-09-25",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_bfl_flux_pro_t2i",
        "title": "BFL Flux[Pro]: Text to Image",
        "description": "Générer des images avec un excellent suivi des prompts et une qualité visuelle en utilisant FLUX.1 Pro.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/black-forest-labs/flux-1-1-pro-ultra-image",
        "tags": ["Édition d'Image", "Image"],
        "models": ["Flux", "BFL"],
        "date": "2025-05-01",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_luma_photon_i2i",
        "title": "Luma Photon: Image to Image",
        "description": "Guider la génération d'images en utilisant une combinaison d'images et de prompt.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tags": ["Image vers Image", "Image", "API"],
        "models": ["Luma"],
        "date": "2025-03-01",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_luma_photon_style_ref",
        "title": "Luma Photon: Style Reference",
        "description": "Générer des images en mélangeant des références de style avec un contrôle précis en utilisant Luma Photon.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tags": ["Texte vers Image", "Image", "API", "Transfert de Style"],
        "models": ["Luma"],
        "date": "2025-03-01",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_recraft_image_gen_with_color_control",
        "title": "Recraft: Color Control Image Generation",
        "description": "Générer des images avec des palettes de couleurs personnalisées et des visuels spécifiques à la marque en utilisant Recraft.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Image", "Image", "API", "Contrôle de Couleur"],
        "models": ["Recraft"],
        "date": "2025-03-01",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_recraft_image_gen_with_style_control",
        "title": "Recraft: Style Control Image Generation",
        "description": "Contrôler le style avec des exemples visuels, aligner le positionnement et affiner les objets. Stocker et partager des styles pour une cohérence de marque parfaite.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Image", "Image", "API", "Contrôle de Style"],
        "models": ["Recraft"],
        "date": "2025-03-01",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_recraft_vector_gen",
        "title": "Recraft: Vector Generation",
        "description": "Générer des images vectorielles de haute qualité à partir de prompts textuels en utilisant le générateur AI vectoriel de Recraft.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Image", "Image", "API", "Vector"],
        "models": ["Recraft"],
        "date": "2025-03-01",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_runway_text_to_image",
        "title": "Runway: Text to Image",
        "description": "Générer des images de haute qualité à partir de prompts textuels en utilisant le modèle AI de Runway.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Image", "Image", "API"],
        "models": ["Runway"],
        "date": "2025-03-01",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_runway_reference_to_image",
        "title": "Runway: Reference to Image",
        "description": "Générer de nouvelles images basées sur des styles et compositions de référence avec l'AI de Runway.",
        "mediaType": "image",
        "thumbnailVariant": "compareSlider",
        "mediaSubtype": "webp",
        "tags": ["Image vers Image", "Image", "API", "Transfert de Style"],
        "models": ["Runway"],
        "date": "2025-03-01",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_stability_ai_stable_image_ultra_t2i",
        "title": "Stability AI: Stable Image Ultra Text to Image",
        "description": "Générer des images de haute qualité avec un excellent respect des prompts. Parfait pour des cas d'utilisation professionnels à une résolution de 1 mégapixel.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Image", "Image", "API"],
        "models": ["Stability"],
        "date": "2025-03-01",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_stability_ai_i2i",
        "title": "Stability AI: Image to Image",
        "description": "Transformer des images avec une génération de haute qualité en utilisant Stability AI, parfait pour l'édition professionnelle et le transfert de style.",
        "mediaType": "image",
        "thumbnailVariant": "compareSlider",
        "mediaSubtype": "webp",
        "tags": ["Image vers Image", "Image", "API"],
        "models": ["Stability"],
        "date": "2025-03-01",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_stability_ai_sd3.5_t2i",
        "title": "Stability AI: SD3.5 Text to Image",
        "description": "Générer des images de haute qualité avec un excellent respect des prompts. Parfait pour des cas d'utilisation professionnels à une résolution de 1 mégapixel.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Image", "Image", "API"],
        "models": ["Stability"],
        "date": "2025-03-01",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_stability_ai_sd3.5_i2i",
        "title": "Stability AI: SD3.5 Image to Image",
        "description": "Générer des images de haute qualité avec un excellent respect des prompts. Parfait pour des cas d'utilisation professionnels à une résolution de 1 mégapixel.",
        "mediaType": "image",
        "thumbnailVariant": "compareSlider",
        "mediaSubtype": "webp",
        "tags": ["Image vers Image", "Image", "API"],
        "models": ["Stability"],
        "date": "2025-03-01",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_ideogram_v3_t2i",
        "title": "Ideogram V3: Text to Image",
        "description": "Générer des images de qualité professionnelle avec un excellent alignement des prompts, du photoréalisme et un rendu de texte en utilisant Ideogram V3.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Image", "Image", "API", "Text Rendering"],
        "models": ["Ideogram"],
        "date": "2025-03-01",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_openai_image_1_t2i",
        "title": "OpenAI: GPT-Image-1 Text to Image",
        "description": "Générer des images à partir de prompts textuels en utilisant l'API OpenAI GPT Image 1.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Image", "Image", "API"],
        "models": ["GPT-Image-1", "OpenAI"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/openai/gpt-image-1",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_openai_image_1_i2i",
        "title": "OpenAI: GPT-Image-1 Image to Image",
        "description": "Générer des images à partir d'images d'entrée en utilisant l'API OpenAI GPT Image 1.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tags": ["Image vers Image", "Image", "API"],
        "models": ["GPT-Image-1"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/openai/gpt-image-1",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_openai_image_1_inpaint",
        "title": "OpenAI: GPT-Image-1 Inpaint",
        "description": "Éditer des images en utilisant l'inpainting avec l'API OpenAI GPT Image 1.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tags": ["Inpainting", "Image", "API"],
        "models": ["GPT-Image-1"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/openai/gpt-image-1",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_openai_image_1_multi_inputs",
        "title": "OpenAI: GPT-Image-1 Multi Inputs",
        "description": "Générer des images à partir de plusieurs entrées en utilisant l'API OpenAI GPT Image 1.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tags": ["Texte vers Image", "Image", "API", "Multi Input"],
        "models": ["GPT-Image-1"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/openai/gpt-image-1",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_openai_dall_e_2_t2i",
        "title": "OpenAI: Dall-E 2 Text to Image",
        "description": "Générer des images à partir de prompts textuels en utilisant l'API OpenAI Dall-E 2.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Image", "Image", "API"],
        "models": ["Dall-E", "OpenAI"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/openai/dall-e-2",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_openai_dall_e_2_inpaint",
        "title": "OpenAI: Dall-E 2 Inpaint",
        "description": "Éditer des images en utilisant l'inpainting avec l'API OpenAI Dall-E 2.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tags": ["Inpainting", "Image", "API"],
        "models": ["Dall-E", "OpenAI"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/openai/dall-e-2",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_openai_dall_e_3_t2i",
        "title": "OpenAI: Dall-E 3 Text to Image",
        "description": "Générer des images à partir de prompts textuels en utilisant l'API OpenAI Dall-E 3.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Image", "Image", "API"],
        "models": ["Dall-E", "OpenAI"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/openai/dall-e-3",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      }
    ]
  },
  {
    "moduleName": "default",
    "type": "video",
    "category": "CLOSED SOURCE MODELS",
    "icon": "icon-[lucide--film]",
    "title": "API Vidéo",
    "templates": [
      {
        "name": "api_openai_sora_video",
        "title": "Sora 2: Text & Image to Video",
        "description": "OpenAI's Sora-2 and Sora-2 Pro video generation with synchronized audio.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image to Video", "Text to Video", "API"],
        "models": ["OpenAI"],
        "date": "2025-10-08",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_wan_text_to_video",
        "title": "Wan2.5: Text to Video",
        "description": "Generate videos with synchronized audio, enhanced motion, and superior quality.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image to Video", "Video", "API"],
        "models": ["Wan2.5"],
        "date": "2025-09-27",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_wan_image_to_video",
        "title": "Wan2.5: Image to Video",
        "description": "Transform images into videos with synchronized audio, enhanced motion, and superior quality.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image to Video", "Video", "API"],
        "models": ["Wan2.5"],
        "date": "2025-09-27",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_kling_i2v",
        "title": "Kling: Image to Video",
        "description": "Générer des vidéos avec une excellente adhérence aux prompts pour les actions, expressions et mouvements de caméra en utilisant Kling.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image vers Vidéo", "Vidéo", "API"],
        "models": ["Kling"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_kling_effects",
        "title": "Kling: Video Effects",
        "description": "Générer des vidéos dynamiques en appliquant des effets visuels aux images en utilisant Kling.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Effets Vidéo", "Vidéo", "API"],
        "models": ["Kling"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_kling_flf",
        "title": "Kling: FLF2V",
        "description": "Générer des vidéos en contrôlant les première et dernière images.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Génération de Vidéo", "Vidéo", "API", "Contrôle de Cadre"],
        "models": ["Kling"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_vidu_text_to_video",
        "title": "Vidu: Text to Video",
        "description": "Générer des vidéos 1080p de haute qualité à partir de prompts textuels avec un contrôle ajustable de l'amplitude des mouvements et de la durée en utilisant le modèle AI avancé de Vidu.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Vidéo", "Vidéo", "API"],
        "models": ["Vidu"],
        "date": "2025-08-23",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_vidu_image_to_video",
        "title": "Vidu: Image to Video",
        "description": "Transformer des images statiques en vidéos 1080p dynamiques avec un contrôle précis du mouvement et une amplitude de mouvement personnalisable en utilisant Vidu.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image vers Vidéo", "Vidéo", "API"],
        "models": ["Vidu"],
        "date": "2025-08-23",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_vidu_reference_to_video",
        "title": "Vidu: Reference to Video",
        "description": "Generate videos with consistent subjects using multiple reference images (up to 7) for character and style continuity across the video sequence.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Référence vers Vidéo", "Vidéo", "API"],
        "models": ["Vidu"],
        "date": "2025-08-23",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_vidu_start_end_to_video",
        "title": "Vidu: Start End to Video",
        "description": "Create smooth video transitions between defined start and end frames with natural motion interpolation and consistent visual quality.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["FLF2V", "Vidéo", "API"],
        "models": ["Vidu"],
        "date": "2025-08-23",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_bytedance_text_to_video",
        "title": "ByteDance: Text to Video",
        "description": "Generate high-quality videos directly from text prompts using ByteDance's Seedance model. Supports multiple resolutions and aspect ratios with natural motion and cinematic quality.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Video", "API", "Text to Video"],
        "models": ["ByteDance"],
        "date": "2025-10-6",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_bytedance_image_to_video",
        "title": "ByteDance: Image to Video",
        "description": "Transform static images into dynamic videos using ByteDance's Seedance model. Analyzes image structure and generates natural motion with consistent visual style and coherent video sequences.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Video", "API", "Image to Video"],
        "models": ["ByteDance"],
        "date": "2025-10-6",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_bytedance_flf2v",
        "title": "ByteDance: Start End to Video",
        "description": "Generate cinematic video transitions between start and end frames with fluid motion, scene consistency, and professional polish using ByteDance's Seedance model.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Video", "API", "FLF2V"],
        "models": ["ByteDance"],
        "date": "2025-10-6",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_luma_i2v",
        "title": "Luma: Image to Video",
        "description": "Take static images and instantly create magical high quality animations.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image vers Vidéo", "Vidéo", "API"],
        "models": ["Luma"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_luma_t2v",
        "title": "Luma: Text to Video",
        "description": "High-quality videos can be generated using simple prompts.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Vidéo", "Vidéo", "API"],
        "models": ["Luma"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_moonvalley_text_to_video",
        "title": "Moonvalley: Text to Video",
        "description": "Generate cinematic, 1080p videos from text prompts through a model trained exclusively on licensed data.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Vidéo", "Vidéo", "API"],
        "models": ["Moonvalley"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_moonvalley_image_to_video",
        "title": "Moonvalley: Image to Video",
        "description": "Generate cinematic, 1080p videos with an image through a model trained exclusively on licensed data.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image vers Vidéo", "Vidéo", "API"],
        "models": ["Moonvalley"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_moonvalley_video_to_video_motion_transfer",
        "title": "Moonvalley: Motion Transfer",
        "description": "Apply motion from one video to another.",
        "mediaType": "image",
        "thumbnailVariant": "hoverDissolve",
        "mediaSubtype": "webp",
        "tags": ["Vidéo vers Vidéo", "Vidéo", "API", "Transfert de Mouvement"],
        "models": ["Moonvalley"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_moonvalley_video_to_video_pose_control",
        "title": "Moonvalley: Pose Control",
        "description": "Apply human pose and movement from one video to another.",
        "mediaType": "image",
        "thumbnailVariant": "hoverDissolve",
        "mediaSubtype": "webp",
        "tags": ["Vidéo vers Vidéo", "Vidéo", "API", "Contrôle de Pose"],
        "models": ["Moonvalley"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_hailuo_minimax_video",
        "title": "MiniMax: Video",
        "description": "Generate high-quality videos from text prompts with optional first-frame control using MiniMax Hailuo-02 model. Supports multiple resolutions (768P/1080P) and durations (6/10s) with intelligent prompt optimization.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Vidéo", "Vidéo", "API"],
        "models": ["MiniMax"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_hailuo_minimax_t2v",
        "title": "MiniMax: Text to Video",
        "description": "Generate high-quality videos directly from text prompts. Explore MiniMax's advanced AI capabilities to create diverse visual narratives with professional CGI effects and stylistic elements to bring your descriptions to life.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Vidéo", "Vidéo", "API"],
        "models": ["MiniMax"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_hailuo_minimax_i2v",
        "title": "MiniMax: Image to Video",
        "description": "Generate refined videos from images and text with CGI integration using MiniMax.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image vers Vidéo", "Vidéo", "API"],
        "models": ["MiniMax"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_pixverse_i2v",
        "title": "PixVerse: Image to Video",
        "description": "Generate dynamic videos from static images with motion and effects using PixVerse.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image vers Vidéo", "Vidéo", "API"],
        "models": ["PixVerse"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_pixverse_template_i2v",
        "title": "PixVerse Templates: Image to Video",
        "description": "Generate dynamic videos from static images with motion and effects using PixVerse.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image vers Vidéo", "Vidéo", "API", "Modèles"],
        "models": ["PixVerse"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_pixverse_t2v",
        "title": "PixVerse: Text to Video",
        "description": "Generate videos with accurate prompt interpretation and stunning video dynamics.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Vidéo", "Vidéo", "API"],
        "models": ["PixVerse"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_runway_gen3a_turbo_image_to_video",
        "title": "Runway: Gen3a Turbo Image to Video",
        "description": "Generate cinematic videos from static images using Runway Gen3a Turbo.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image vers Vidéo", "Vidéo", "API"],
        "models": ["Runway"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_runway_gen4_turo_image_to_video",
        "title": "Runway: Gen4 Turbo Image to Video",
        "description": "Generate dynamic videos from images using Runway Gen4 Turbo.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image vers Vidéo", "Vidéo", "API"],
        "models": ["Runway"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_runway_first_last_frame",
        "title": "Runway: First Last Frame to Video",
        "description": "Generate smooth video transitions between two keyframes with Runway's precision.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Génération de Vidéo", "Vidéo", "API", "Contrôle de Cadre"],
        "models": ["Runway"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_pika_i2v",
        "title": "Pika: Image to Video",
        "description": "Generate smooth animated videos from single static images using Pika AI.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image vers Vidéo", "Vidéo", "API"],
        "models": ["Pika"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_pika_scene",
        "title": "Pika Scenes: Images to Video",
        "description": "Generate videos that incorporate multiple input images using Pika Scenes.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image vers Vidéo", "Vidéo", "API", "Multi-Image"],
        "models": ["Pika"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_veo2_i2v",
        "title": "Veo2: Image to Video",
        "description": "Generate videos from images using Google Veo2 API.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image vers Vidéo", "Vidéo", "API"],
        "models": ["Veo", "Google"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_veo3",
        "title": "Veo3: Image to Video",
        "description": "Generate high-quality 8-second videos from text prompts or images using Google's advanced Veo 3 API. Features audio generation, prompt enhancement, and dual model options for speed or quality.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image vers Vidéo", "Texte vers Vidéo", "API"],
        "models": ["Veo", "Google"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      }
    ]
  },
  {
    "moduleName": "default",
    "type": "image",
    "category": "CLOSED SOURCE MODELS",
    "icon": "icon-[lucide--box]",
    "title": "API 3D",
    "templates": [
      {
        "name": "api_rodin_gen2",
        "title": "Rodin: Gen-2 Image to Model",
        "description": "Generate detailed 4X mesh quality 3D models from photos using Rodin Gen2",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image to Model", "3D", "API"],
        "models": ["Rodin"],
        "date": "2025-09-27",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_rodin_image_to_model",
        "title": "Rodin: Image to Model",
        "description": "Generate detailed 3D models from single photos using Rodin AI.",
        "mediaType": "image",
        "thumbnailVariant": "compareSlider",
        "mediaSubtype": "webp",
        "tags": ["Image vers Modèle", "3D", "API"],
        "models": ["Rodin"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_rodin_multiview_to_model",
        "title": "Rodin: Multiview to Model",
        "description": "Sculpt comprehensive 3D models using Rodin's multi-angle reconstruction.",
        "mediaType": "image",
        "thumbnailVariant": "compareSlider",
        "mediaSubtype": "webp",
        "tags": ["Multivue vers Modèle", "3D", "API"],
        "models": ["Rodin"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_tripo_text_to_model",
        "title": "Tripo: Text to Model",
        "description": "Craft 3D objects from descriptions with Tripo's text-driven modeling.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Modèle", "3D", "API"],
        "models": ["Tripo"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_tripo_image_to_model",
        "title": "Tripo: Image to Model",
        "description": "Generate professional 3D assets from 2D images using Tripo engine.",
        "mediaType": "image",
        "thumbnailVariant": "compareSlider",
        "mediaSubtype": "webp",
        "tags": ["Image vers Modèle", "3D", "API"],
        "models": ["Tripo"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_tripo_multiview_to_model",
        "title": "Tripo: Multiview to Model",
        "description": "Build 3D models from multiple angles with Tripo's advanced scanner.",
        "mediaType": "image",
        "thumbnailVariant": "compareSlider",
        "mediaSubtype": "webp",
        "tags": ["Multivue vers Modèle", "3D", "API"],
        "models": ["Tripo"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      }
    ]
  },
  {
    "moduleName": "default",
    "type": "audio",
    "category": "CLOSED SOURCE MODELS",
    "icon": "icon-[lucide--volume-2]",
    "title": "API Audio",
    "templates": [
      {
        "name": "api_stability_ai_text_to_audio",
        "title": "Stability AI : Texte vers Audio",
        "description": "Générez de la musique à partir de texte avec Stable Audio 2.5. Créez des pistes de plusieurs minutes en quelques secondes.",
        "mediaType": "audio",
        "mediaSubtype": "mp3",
        "tags": ["Texte vers Audio", "Audio", "API"],
        "date": "2025-09-09",
        "models": ["Stability", "Stable Audio"],
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_stability_ai_audio_to_audio",
        "title": "Stability AI : Audio vers Audio",
        "description": "Transformez de l'audio en de nouvelles compositions avec Stable Audio 2.5. Téléversez un audio et l'IA crée des pistes complètes.",
        "mediaType": "audio",
        "mediaSubtype": "mp3",
        "tags": ["Audio vers Audio", "Audio", "API"],
        "date": "2025-09-09",
        "models": ["Stability", "Stable Audio"],
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_stability_ai_audio_inpaint",
        "title": "Stability AI : Inpainting Audio",
        "description": "Complétez ou prolongez des pistes audio avec Stable Audio 2.5. Téléversez un audio et l'IA génère le reste.",
        "mediaType": "audio",
        "mediaSubtype": "mp3",
        "tags": ["Audio vers Audio", "Audio", "API"],
        "date": "2025-09-09",
        "models": ["Stability", "Stable Audio"],
        "OpenSource": false,
        "size": 0,
        "vram": 0
      }
    ]
  },
  {
    "moduleName": "default",
    "type": "image",
    "category": "CLOSED SOURCE MODELS",
    "icon": "icon-[lucide--message-square-text]",
    "title": "API LLM",
    "templates": [
      {
        "name": "api_openai_chat",
        "title": "OpenAI: Chat",
        "description": "Engage with OpenAI's advanced language models for intelligent conversations.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Chat", "LLM", "API"],
        "models": ["OpenAI"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_google_gemini",
        "title": "Google Gemini: Chat",
        "description": "Experience Google's multimodal AI with Gemini's reasoning capabilities.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Chat", "LLM", "API"],
        "models": ["Google Gemini", "Google"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "OpenSource": false,
        "size": 0,
        "vram": 0
      }
    ]
  }
]