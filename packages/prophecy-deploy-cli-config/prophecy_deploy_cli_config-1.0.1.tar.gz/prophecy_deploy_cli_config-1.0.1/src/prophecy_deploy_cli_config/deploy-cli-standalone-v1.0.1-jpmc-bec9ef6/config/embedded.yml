# Rest Service Port
rest_service:
  port: 9089
  pipeline_file_store_location: "/tmp/app/"
orchestration_db:
  dsn: "file::memory:"
  engine: "sqlite"
  max_open_conns: 10
  max_idle_conns: 3
  conn_max_lifetime_in_sec: 1800
  sqlite:
    busy_timeout_ms: 5000      # Wait up to 5s when database is locked
    cache_size: 2000           # Use 2000 pages (~8MB) of memory for caching - https://sqlite.org/pragma.html#pragma_cache_size
    mmap_size: 268435456      # Use memory mapping for up to 256MB (256 * 1024 * 1024)
    max_open_conns: 1         # SQLite only supports one writer at a time
    max_idle_conns: 1
  postgres:
    url: "localhost"
    port: 5432
    username: ""
    password: ""
    db_name: "orchestration"
    ssl_mode: "disable"
domain:
  value: ""
scheduler:
  worker: 4
  job_watcher_interval_ms: 100
secret:
  key: "NxP>@j=%0_9HyB=4V^|x|t@qtkRl9=m#"
  token:
    control_plane_master_key: "4k/5dyqFYn13l+xhN2V+hKh/7XUzFEptBXKFr0MnKzM=" # Generated using hmac_test.go. This should be removed and stored in secrets DB against each control plane's cluster.
    token_expiration_in_minute: 600
data_client:
  buffer_size: 2
  send_timeout_ms: 14400000 # 4 * 60 * 60 * 1000 - 4 hrs
  receive_timeout_ms: 14400000 # 4 * 60 * 60 * 1000 - 4 hrs
  progress_interval_ms: 5000 # 50 * 1000 - 5 seconds
resource_manager:
  kubeconfig: ""
  k8timeoutsec: 20
  pod_health_poll_interval_sec: 15
  pod_health_poll_max_attempt: 5
  type: "embedded"
  go_local_url: "localhost"
  python_local_url: "localhost"
  max_unhealthy_retries: 3
mode: orchestrator
grpc:
  max_recv_msg_size: 10485760000 # 1024 * 1024 * 10000
  max_send_msg_size: 10485760000 # 1024 * 1024 * 10000
  host: orchestrator
  port: 50055
websocket:
  response_timeout_ms: 1800000 # 30 * 60 * 1000 = 30mins
  read_buffer_size: 104857600 # 100 * 1024 * 1024 = 100MB
  write_buffer_size: 104857600 # 100 * 1024 * 1024 = 100MB
sandbox:
  image_pull_secret: "prophecyregcred"
  unused_cleanup_duration_mins: 0
  watch_ms: 10000
  timeout_secs: 100
  namespace: "prophecy"
  port: 50051
  http_port: 50052
  min_idle_pods: 1
  max_pods: 45
  cleanup_after_sec: 3600 # 60 * 60 = 1 hour
  close_after_sec: 5
  config_map: ""
  python_sandbox:
    max_tenant: 5
    cpu: "1"
    mem: "512Mi"
    image: "k8s.gcr.io/pause"
  go_sandbox:
    max_tenant: 5
    cpu: "1"
    mem: "512Mi"
    image: "133450206866.dkr.ecr.us-west-1.amazonaws.com/prophecy-orchestrate-sandbox:latest"
  custom_cert: false
dbt:
  server:
    enabled: false
    host: "localhost"
    port: 50053
    http_port: 50054
job:
  num_parallel_jobs: 3
  num_parallel_tasks_per_job: 5
  phase_execution_timeout_ms: 18000000 # 5 * 60 * 60 * 1000 - 5 hrs. Keeping it higher than the job_timeout_ms to avoid phase timeout.
  close_timeout_ms: 60000 # 60 seconds
  job_timeout_ms: 10800000 # 3 * 60 * 60 * 1000 - 3 hrs
  interim_data_max_rows: 10000 # 10k
  infer_schema_max_rows: 1000
  waiting_timeout_ms: 5000 # 5 seconds
  interim_data_max_mb: 10 # 10MB
  pipeline_trigger_max_depth: 10
sensor:
  max_backoff_multiplier: 5
  retention_days: 30
  max_records_per_sensor: 1000
  default_poke_interval_seconds: 60
dump_trace_on_exit: true
mail:
  from: "noreply@prophecy.io"
  password: "1prophecyIo?"
  smtp_host: "smtp.gmail.com"
  smtp_port: 587
oauth:
  databricks_client_id: "b5d989d5-c028-49df-9395-a04043df09be"
  databricks_client_secret: "dose82de0e8a7a94bf46d73638c5364d24c5"
  snowflake_client_id: "IpBSPmZGcS8HDYEQrJprzpP1dog="
  snowflake_client_secret: "Nk+0e32VxHSwY4mjkj7irNAkoKVcqi6I9cIG93DfXac="
  bigquery_client_id: "d9046370-6b47-465a-ab14-bb6609e07c99"
  bigquery_client_secret: "dose95bd0e467bc3c7b0d28272fa9275d336"
upload:
  path: "/tmp/file_uploads" # TODO (Arpit): fetch from kubernetes config
  expiry_time_seconds: 3600 # 1 hour
  chunk_size_bytes: 10485760 # 10 MegaBytes = 10 * 1024 * 1024 Bytes, uploaded file will be split into chunks of this size
  supported_formats:
    - "csv"
    - "json"
    - "xlsx"
    - "xml"
    - "parquet"
monitoring:
  pyroscope_url: ""
retry:
  max_retries: 5
  backoff_factor: 2
  backoff_initial_interval_seconds: 1
  backoff_max_interval_seconds: 60 # 1 minute
knowledge_graph:
  enabled: false
  endpoint: knowledge-graph-service
  port: 50055
  retry_attempts: 3              # Number of retry attempts for KG requests
  request_timeout: 30            # Base timeout in seconds for KG requests
  browsing_timeout: 5            # Timeout for browsing operations (list tables/schemas/databases) in seconds
  browsing_retry_attempts: 1     # Retry attempts for browsing operations
  staleness_limit:
    database: 86400 # 24 hours
    schema: 86400 # 24 hours
    table: 86400 # 24 hours
    table_description : 86400 # 24 hours
    general: 86400 # 24 hours
  throttle:
    enabled: true                      # Enable throttling mechanism for KG cache calls
    max_cache_calls_threshold: 500     # Threshold for cache calls before health check
    backoff_initial_ms: 1000           # Initial backoff in milliseconds (1 second)
    backoff_max_ms: 120000             # Maximum backoff in milliseconds (2 minutes)
    backoff_multiplier: 2              # Exponential backoff multiplier
    max_retries: 10    # Maximum retry attempts for health check
  ignore_prefix:
    - alteryx_generic_pipelines
    - prophecy-libs
    - prophecy-installer
    - prophecy-python-libs
    - prophecy-byos
    - streaming
  ignore_subfolder:
    - prophecy/artifacts
metric:
  port: 2678
  task_coordinator_port: 2680
ledger:
  enabled: false
  frequency: daily
  cloud:
    gcp:
      use_sa_key: true
      sa_key_path: "/orchestrator/gcp-sa-key.json"
      billing_project_id: "prophecy-on-gcp-public"
      billing_dataset_id: "prophecyongcppublicdataset"
      billing_table_id: "gcp_billing_export_v1_013F6A_B1B1FE_D9C335"
      vpc_project_id: ""
      vpc_flow_logs_dataset_id: "vpcflowlogs"
      vpc_flow_logs_table_id: "networkmanagement_googleapis_com_vpc_flows_*"
      vpc_flow_logs_project_id: "prophecy-on-gcp-public"
timeout:
  test_connection_timeout_sec: 20
databricks:
  max_idle_conns: 5
  max_open_conns: 10
  conn_max_lifetime_in_sec: 3600
  conn_max_idle_time_in_sec: 1800
  print_stats_interval_sec: 60 # 1 minute
formats:
  xlsx:
    unzip_size_limit: 1048576000 # 1000 * 1024 * 1024 = 1GB
    unzip_xml_size_limit: 1048576 # 0.1% of unzip_size_limit
copilot:
  host: "copilot"
  port: 9016
  enable_kg_sync: true
crawler:
  delay_ms: 0 # Delay between each request sent using a connection
  concurrency: 50 # Maximum no of parallel goroutines
  max_requests_per_connection: 1000000 # Maximum number of requests to be sent for each connection, increasing it to 1 Million
  interval_sec: 72000 # 20 hours (keeping a bit lower than the KG cache expiry of 24 hours)
  incremental_crawl: true # Enable incremental crawling to only cache updated tables and handle deleted tables
  heartbeat_interval_sec: 5 # Heartbeat interval in seconds to keep KG informed about crawler session status
  schema_worker_pool_size: 5 # Number of parallel workers for processing schemas (except last batch)
  sandbox:
    max_tenant: 5
    cpu: "1"
    mem: "512Mi"
    image: ""
  file:
    enabled: true # Disable file crawler for now to increase performance
    max_depth: 0 # Maximum depth of directory tree to be crawled. 0 to disable
  background:
    enabled: false # Disable background crawler for now
    blacklist_urls: ""
    blacklist_urls_limit: 1000 # Maximum number of entries, beyond which we honor blacklist_urls. If not set, then we honor blacklist_urls for all connections.
  kg_mode: "sync" # Call knowledge graph service in sync mode or async mode
cache:
  default_ttl: 300 # 5*60 seconds - 5 minutes
  cleanup_interval: 600 # 10*60 seconds - 10 minutes
stored_proc:
  batch_size : 1
duckdb:
  enabled: false
  s3_region: "us-west-1"
  s3_key_id: ""
  s3_secret: ""
  s3_bucket: ""
  disable_parquet_copy: false
  s3_proxy:
    enabled: false
    cache_folder: "/app/s3_cache/"
    port: 8899
    cache_max_stale_hours: 120
    cache_bucket_count: 10
    url: "orchestrator"
gem_config:
  min_total_rows_to_buffer: 10000 # 10k rows
  script:
    timeout_secs: 600 # 10 * 60 seconds - 10 minute
    tmp_dir_location: "/tmp"
  databricks:
    parquet_ingestion_enabled: true
    enable_file_read_sql_fallback: false
  hana:
    rows_per_query_in_merge_mode: 5
egress:
  enabled: false
  allowed_targets:
    - "HANATarget"
    - "SFTPTarget"
    - "BigQueryTarget"
    - "Model"
  private_sources:
    - "HANASource"
  unsafe_gems:
    - "Script"
ide:
  session_ttl_mins: 1440 # 1440 minutes - 24 hours
  config_cache_enabled: true
tracing:
  send_trace_to_ui: false
  send_trace_to_orchestrator: false
  orchestrator_batch_export_duration_ms: 100
  zipkin:
    enabled: false
    url: "http://zipkin:9411/api/v2/spans"
