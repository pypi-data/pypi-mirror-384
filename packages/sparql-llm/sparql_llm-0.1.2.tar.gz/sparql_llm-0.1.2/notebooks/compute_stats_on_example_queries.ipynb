{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate stats on examples queries. Require to have the `sparql-examples` repository cloned alongside this repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of queries overall: 1016\n",
      "Total number of triples overall: 6632\n",
      "Errors while parsing queries: 3\n",
      "\n",
      "endpoint,queries_count,average_triples_patterns,median_triples_patterns,max_triples_patterns\n",
      "https://biosoda.unil.ch/graphdb/repositories/emi-dbgi,9,21.44,22.0,35\n",
      "https://sparql.rhea-db.org/sparql/,20,7.05,5.5,22\n",
      "https://glyconnect.expasy.org/sparql,5,5.0,3.0,9\n",
      "https://sparql.omabrowser.org/sparql/,15,10.93,9.0,19\n",
      "https://sparql.nextprot.org/sparql,773,5.95,5.0,26\n",
      "https://sparql.uniprot.org/sparql/,110,6.71,5.0,32\n",
      "https://sparql.swisslipids.org/sparql/,22,6.73,5.0,16\n",
      "https://sparql.orthodb.org/sparql/,20,11.2,8.0,34\n",
      "https://hamap.expasy.org/sparql/,4,2.0,1.0,6\n",
      "https://rdf.metanetx.org/sparql/,13,7.31,7.0,12\n",
      "https://www.bgee.org/sparql/,25,11.88,9.0,25\n",
      "total,1016,6.53,5.0,35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from statistics import mean, median\n",
    "\n",
    "import pandas as pd\n",
    "from rdflib import Graph\n",
    "\n",
    "from sparql_llm.validate_sparql import sparql_query_to_dict\n",
    "\n",
    "GET_EXAMPLE_QUERY = \"\"\"PREFIX sh: <http://www.w3.org/ns/shacl#>\n",
    "PREFIX schema: <https://schema.org/>\n",
    "SELECT DISTINCT ?sq ?query ?endpoint\n",
    "WHERE {\n",
    "    ?sq a sh:SPARQLExecutable ;\n",
    "        schema:target ?endpoint ;\n",
    "        sh:select|sh:construct|sh:describe|sh:ask ?query .\n",
    "}\"\"\"\n",
    "\n",
    "\n",
    "def compute_queries_stats(directory: str) -> pd.DataFrame:\n",
    "    ttl_files = []\n",
    "    # Walk through the directories to a depth of 2\n",
    "    for root, _dirs, files in os.walk(directory):\n",
    "        depth = root[len(directory) :].count(os.sep)\n",
    "        if depth < 3:\n",
    "            for file in files:\n",
    "                if file.endswith(\".ttl\") and not file.endswith(\"prefixes.ttl\"):\n",
    "                    ttl_files.append(os.path.join(root, file))\n",
    "\n",
    "    triples_per_query = []\n",
    "    triples_per_endpoint = defaultdict(\n",
    "        list\n",
    "    )  # Store triples per query for each endpoint\n",
    "    parsing_errors = 0\n",
    "\n",
    "    # ttl_files = [\"../../sparql-examples/examples/neXtProt/NXQ_00266.ttl\"]\n",
    "\n",
    "    for ttl_file in ttl_files:\n",
    "        # print(ttl_file)\n",
    "        g = Graph()\n",
    "        g.parse(ttl_file, format=\"turtle\")\n",
    "        for row in g.query(GET_EXAMPLE_QUERY):\n",
    "            query = row[\"query\"]\n",
    "            main_target_endpoint = str(row[\"endpoint\"])\n",
    "            # print(query)\n",
    "            try:\n",
    "                query_dict = sparql_query_to_dict(query, main_target_endpoint)\n",
    "                # print(json.dumps(query_dict, indent=2))\n",
    "\n",
    "                # Count triples for this query\n",
    "                num_triples = 0\n",
    "                for _endpoint, subjects in query_dict.items():\n",
    "                    for _subject, predicates in subjects.items():\n",
    "                        for _predicate, objects in predicates.items():\n",
    "                            num_triples += len(objects)\n",
    "\n",
    "                # if num_triples == 0:\n",
    "                # print(f\"{num_triples} triples for query:\\n{query}\\n\\n\")\n",
    "\n",
    "                triples_per_query.append(num_triples)\n",
    "                triples_per_endpoint[main_target_endpoint].append(num_triples)\n",
    "            except RecursionError:\n",
    "                # Known issue with nested SERVICE clauses https://github.com/RDFLib/rdflib/issues/2136\n",
    "                parsing_errors += 1\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing query for {ttl_file} {main_target_endpoint}: {e}\")\n",
    "                print(query)\n",
    "                parsing_errors += 1\n",
    "\n",
    "    # Prepare data for the DataFrame\n",
    "    data = []\n",
    "    for endpoint, triples_list in triples_per_endpoint.items():\n",
    "        data.append(\n",
    "            {\n",
    "                \"endpoint\": endpoint,\n",
    "                \"queries_count\": len(triples_list),\n",
    "                \"average_triples_patterns\": round(mean(triples_list), 2),\n",
    "                \"median_triples_patterns\": median(triples_list),\n",
    "                \"max_triples_patterns\": max(triples_list),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    data.append(\n",
    "        {\n",
    "            \"endpoint\": \"total\",\n",
    "            \"queries_count\": len(triples_per_query),\n",
    "            \"average_triples_patterns\": round(mean(triples_per_query), 2)\n",
    "            if triples_per_query\n",
    "            else 0,\n",
    "            \"median_triples_patterns\": median(triples_per_query)\n",
    "            if triples_per_query\n",
    "            else 0,\n",
    "            \"max_triples_patterns\": max(triples_per_query) if triples_per_query else 0,\n",
    "        }\n",
    "    )\n",
    "    print(f\"Total number of queries overall: {len(triples_per_query)}\")\n",
    "    print(f\"Total number of triples overall: {sum(triples_per_query)}\")\n",
    "    print(f\"Errors while parsing queries: {parsing_errors}\\n\")\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "df = compute_queries_stats(\"../../sparql-examples/examples\")\n",
    "print(df.to_csv(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
