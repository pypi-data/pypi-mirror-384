# Generated by the protocol buffer compiler.  DO NOT EDIT!
# sources: gateway/account.proto, gateway/api_key.proto, gateway/audit_log.proto, gateway/aws_iam_role_binding.proto, gateway/batch_inference_job.proto, gateway/batch_job.proto, gateway/billing.proto, gateway/cluster.proto, gateway/dataset.proto, gateway/dataset_validation_job.proto, gateway/deployed_model.proto, gateway/deployment.proto, gateway/deployment_template.proto, gateway/eagle_training_job.proto, gateway/environment.proto, gateway/evaluation.proto, gateway/evaluation_job.proto, gateway/evaluator.proto, gateway/feature_flag.proto, gateway/fine_tuning_job.proto, gateway/gateway.proto, gateway/identity_provider.proto, gateway/inference_log.proto, gateway/job_progress.proto, gateway/mcp_server.proto, gateway/model.proto, gateway/node_pool.proto, gateway/node_pool_binding.proto, gateway/options.proto, gateway/peft_merge_job.proto, gateway/quota.proto, gateway/reinforcement_fine_tuning_epoch.proto, gateway/reinforcement_fine_tuning_job.proto, gateway/reservation.proto, gateway/rlor_trainer_job.proto, gateway/secret.proto, gateway/sign_in.proto, gateway/snapshot.proto, gateway/status.proto, gateway/supervised_fine_tuning_job.proto, gateway/training.proto, gateway/user.proto, gateway/wandb.proto, gateway/workload.proto, gateway/workload_shape.proto
# plugin: python-betterproto
# This file has been @generated

__all__ = (
    "Code",
    "JobState",
    "UserState",
    "AccountAccountType",
    "AccountState",
    "AccountSuspendState",
    "Region",
    "MultiRegion",
    "AcceleratorType",
    "DirectRouteType",
    "Metrics",
    "DeploymentState",
    "DeploymentPrecision",
    "DeploymentEngine",
    "BatchJobState",
    "PythonExecutorTargetType",
    "StripeCheckoutSessionMode",
    "InvoiceState",
    "ClusterState",
    "DatasetState",
    "DatasetAccessPolicy",
    "DatasetFormat",
    "DatasetValidationFormat",
    "DatasetValidationJobResult",
    "DeployedModelState",
    "WeightPrecision",
    "EnvironmentState",
    "AssertionAssertionType",
    "EvaluatorState",
    "CriterionType",
    "FineTuningJobState",
    "McpServerAuthenticationType",
    "McpServerState",
    "ModelState",
    "ModelKind",
    "BaseModelDetailsCheckpointFormat",
    "NodePoolState",
    "SnapshotState",
    "SupervisedFineTuningJobWeightPrecision",
    "WorkloadState",
    "ApiResource",
    "Status",
    "User",
    "CreateUserRequest",
    "GetUserRequest",
    "ListUsersRequest",
    "ListUsersResponse",
    "UpdateUserRequest",
    "DeleteUserRequest",
    "WandbConfig",
    "Account",
    "CreateAccountRequest",
    "GetAccountRequest",
    "ListAccountsRequest",
    "ListAccountsResponse",
    "UpdateAccountRequest",
    "DeleteAccountRequest",
    "ApiKey",
    "CreateApiKeyRequest",
    "ListApiKeysRequest",
    "ListApiKeysResponse",
    "DeleteApiKeyRequest",
    "GetInternalApiKeyRequest",
    "UpdateApiKeyAccountRequest",
    "AuditLogEntry",
    "ListAuditLogsRequest",
    "ListAuditLogsResponse",
    "AwsIamRoleBinding",
    "CreateAwsIamRoleBindingRequest",
    "ListAwsIamRoleBindingsRequest",
    "ListAwsIamRoleBindingsResponse",
    "DeleteAwsIamRoleBindingRequest",
    "Deployment",
    "Placement",
    "AutoTune",
    "AutoscalingPolicy",
    "CreateDeploymentRequest",
    "GetDeploymentRequest",
    "ListDeploymentsRequest",
    "ListDeploymentsResponse",
    "UpdateDeploymentRequest",
    "DeleteDeploymentRequest",
    "UndeleteDeploymentRequest",
    "ScaleDeploymentRequest",
    "GetDeploymentMetricsRequest",
    "GetDeploymentMetricsResponse",
    "GetDeploymentPrerequisitesRequest",
    "DeploymentPrerequisites",
    "DeploymentAcceleratorConfig",
    "ListDeploymentMetricsRequest",
    "TimeSeriesPoint",
    "TimeSeries",
    "ListDeploymentMetricsResponse",
    "JobProgress",
    "BatchInferenceJob",
    "InferenceParameters",
    "AppendToMessages",
    "GetBatchInferenceJobRequest",
    "CreateBatchInferenceJobRequest",
    "ListBatchInferenceJobsRequest",
    "ListBatchInferenceJobsResponse",
    "UpdateBatchInferenceJobRequest",
    "DeleteBatchInferenceJobRequest",
    "GetBatchInferenceJobInputUploadEndpointRequest",
    "GetBatchInferenceJobInputUploadEndpointResponse",
    "ValidateBatchInferenceJobInputUploadRequest",
    "GetBatchInferenceJobOutputDownloadEndpointRequest",
    "GetBatchInferenceJobOutputDownloadEndpointResponse",
    "BatchJob",
    "CreateBatchJobRequest",
    "GetBatchJobRequest",
    "ListBatchJobsRequest",
    "ListBatchJobsResponse",
    "UpdateBatchJobRequest",
    "DeleteBatchJobRequest",
    "BatchDeleteBatchJobsRequest",
    "CancelBatchJobRequest",
    "GetBatchJobLogsRequest",
    "GetBatchJobLogsResponse",
    "PythonExecutor",
    "ShellExecutor",
    "NotebookExecutor",
    "LogEntry",
    "GetBalanceRequest",
    "Balance",
    "ListPaymentMethodsRequest",
    "StripeCheckoutSession",
    "ListPaymentMethodsResponse",
    "ListPaymentMethodsResponseCard",
    "ListPaymentMethodsResponseUsBankAccount",
    "ListPaymentMethodsResponseStripePaymentMethod",
    "ListCostsRequest",
    "ListCostsResponse",
    "ListCostsResponseCostDataItem",
    "ListInvoicesRequest",
    "Invoice",
    "ListInvoicesResponse",
    "SkuInfo",
    "ExportBillingMetricsRequest",
    "ExportBillingMetricsResponse",
    "GetTotalHistoricalSpendRequest",
    "GetTotalHistoricalSpendResponse",
    "ListHuggingFaceBillingCostsRecords",
    "BillingRequestCostRecord",
    "ListHuggingFaceBillingCostsResponse",
    "GetAccountUsageRequest",
    "AccountUsage",
    "AccountUsageServerlessUsage",
    "AccountUsageDedicatedDeploymentUsage",
    "Cluster",
    "EksCluster",
    "FakeCluster",
    "CreateClusterRequest",
    "GetClusterRequest",
    "ListClustersRequest",
    "ListClustersResponse",
    "UpdateClusterRequest",
    "DeleteClusterRequest",
    "GetClusterConnectionInfoRequest",
    "ClusterConnectionInfo",
    "Dataset",
    "PreviewDatasetRequest",
    "PreviewDatasetResponse",
    "Example",
    "UserUploaded",
    "Transformed",
    "Splitted",
    "FireworksTraced",
    "DraftModelStates",
    "EvaluationResult",
    "GetDatasetRequest",
    "CreateDatasetRequest",
    "UpdateDatasetRequest",
    "UploadDatasetRequest",
    "UploadDatasetResponse",
    "GetDatasetUploadEndpointRequest",
    "GetDatasetUploadEndpointResponse",
    "ValidateDatasetUploadRequest",
    "GetDatasetDownloadEndpointRequest",
    "GetDatasetDownloadEndpointResponse",
    "ListDatasetsRequest",
    "ListDatasetsResponse",
    "DeleteDatasetRequest",
    "SplitDatasetRequest",
    "SplitDatasetResponse",
    "DatasetValidationJob",
    "GetDatasetValidationJobRequest",
    "CreateDatasetValidationJobRequest",
    "ListDatasetValidationJobsRequest",
    "ListDatasetValidationJobsResponse",
    "DeleteDatasetValidationJobRequest",
    "DeployedModel",
    "DeployedModelRef",
    "CreateDeployedModelRequest",
    "DeleteDeployedModelRequest",
    "GetDeployedModelRequest",
    "ListDeployedModelsRequest",
    "ListDeployedModelsResponse",
    "UpdateDeployedModelRequest",
    "DeploymentTemplate",
    "CreateDeploymentTemplateRequest",
    "GetDeploymentTemplateRequest",
    "ListDeploymentTemplatesRequest",
    "ListDeploymentTemplatesResponse",
    "UpdateDeploymentTemplateRequest",
    "DeleteDeploymentTemplateRequest",
    "EarlyStopConfig",
    "BaseTrainingConfig",
    "EagleTrainingJob",
    "GetEagleTrainingJobRequest",
    "CreateEagleTrainingJobRequest",
    "ListEagleTrainingJobsRequest",
    "ListEagleTrainingJobsResponse",
    "UpdateEagleTrainingJobRequest",
    "DeleteEagleTrainingJobRequest",
    "Environment",
    "EnvironmentConnection",
    "CreateEnvironmentRequest",
    "GetEnvironmentRequest",
    "ListEnvironmentsRequest",
    "ListEnvironmentsResponse",
    "UpdateEnvironmentRequest",
    "DeleteEnvironmentRequest",
    "BatchDeleteEnvironmentsRequest",
    "ConnectEnvironmentRequest",
    "DisconnectEnvironmentRequest",
    "Evaluation",
    "Assertion",
    "LlmAssertion",
    "CodeAssertion",
    "CodeAssertionExecutionOptions",
    "Provider",
    "EvaluateOptions",
    "GetEvaluationRequest",
    "CreateEvaluationRequest",
    "ListEvaluationsRequest",
    "ListEvaluationsResponse",
    "UpdateEvaluationRequest",
    "DeleteEvaluationRequest",
    "TestEvaluationRequest",
    "ValidateAssertionsRequest",
    "ValidateAssertionsResponse",
    "ValidateAssertionsResponseValidateAssertionError",
    "PreviewEvaluationRequest",
    "PreviewEvaluationResult",
    "PreviewEvaluationResponse",
    "EvaluationJob",
    "GetEvaluationJobRequest",
    "CreateEvaluationJobRequest",
    "ListEvaluationJobsRequest",
    "ListEvaluationJobsResponse",
    "DeleteEvaluationJobRequest",
    "Evaluator",
    "Criterion",
    "CodeSnippets",
    "RollupSettings",
    "GetEvaluatorRequest",
    "ListEvaluatorsRequest",
    "ListEvaluatorsResponse",
    "CreateEvaluatorRequest",
    "DeleteEvaluatorRequest",
    "PreviewEvaluatorRequest",
    "PreviewEvaluatorSampleResult",
    "PreviewEvaluatorResponse",
    "FeatureFlag",
    "CreateFeatureFlagRequest",
    "GetFeatureFlagRequest",
    "ListFeatureFlagsRequest",
    "ListFeatureFlagsResponse",
    "UpdateFeatureFlagRequest",
    "DeleteFeatureFlagRequest",
    "FineTuningJob",
    "FineTuningJobDataset",
    "FineTuningJobLegacyJob",
    "FineTuningJobTextCompletion",
    "FineTuningJobTextClassification",
    "FineTuningJobDraftModelData",
    "FineTuningJobDraftModel",
    "FineTuningJobConversation",
    "FineTuningJobGenie",
    "GetFineTuningJobRequest",
    "CreateFineTuningJobRequest",
    "ListFineTuningJobsRequest",
    "ListFineTuningJobsResponse",
    "UpdateFineTuningJobRequest",
    "DeleteFineTuningJobRequest",
    "IdentityProvider",
    "SamlConfig",
    "OidcConfig",
    "CreateIdentityProviderRequest",
    "GetIdentityProviderRequest",
    "ListIdentityProvidersRequest",
    "ListIdentityProvidersResponse",
    "UpdateIdentityProviderRequest",
    "DeleteIdentityProviderRequest",
    "InferenceLog",
    "GetInferenceLogRequest",
    "DeleteInferenceLogRequest",
    "ListInferenceLogsRequest",
    "ListInferenceLogsResponse",
    "McpServer",
    "CreateMcpServerRequest",
    "GetMcpServerRequest",
    "ListMcpServersRequest",
    "ListMcpServersResponse",
    "UpdateMcpServerRequest",
    "DeleteMcpServerRequest",
    "Model",
    "BaseModelDetails",
    "PeftDetails",
    "TeftDetails",
    "ConversationConfig",
    "CreateModelRequest",
    "GetModelRequest",
    "PrepareModelRequest",
    "GetModelUploadEndpointRequest",
    "GetModelUploadEndpointResponse",
    "GetModelDownloadEndpointRequest",
    "GetModelDownloadEndpointResponse",
    "ValidateModelUploadRequest",
    "ListModelsRequest",
    "ListModelsResponse",
    "ListServerlessLoraModelsRequest",
    "ListServerlessLoraModelsResponse",
    "ValidateModelConfigRequest",
    "UpdateModelRequest",
    "DeleteModelRequest",
    "AwsS3ModelSource",
    "ImportModelRequest",
    "NodePool",
    "EksNodePool",
    "FakeNodePool",
    "NodePoolStats",
    "CreateNodePoolRequest",
    "GetNodePoolRequest",
    "ListNodePoolsRequest",
    "ListNodePoolsResponse",
    "UpdateNodePoolRequest",
    "DeleteNodePoolRequest",
    "BatchDeleteNodePoolsRequest",
    "GetNodePoolStatsRequest",
    "NodePoolBinding",
    "CreateNodePoolBindingRequest",
    "ListNodePoolBindingsRequest",
    "ListNodePoolBindingsResponse",
    "DeleteNodePoolBindingRequest",
    "PeftMergeJob",
    "GetPeftMergeJobRequest",
    "CreatePeftMergeJobRequest",
    "ListPeftMergeJobsRequest",
    "ListPeftMergeJobsResponse",
    "DeletePeftMergeJobRequest",
    "Quota",
    "GetQuotaRequest",
    "ListQuotasRequest",
    "UpdateQuotaRequest",
    "ListQuotasResponse",
    "ReinforcementFineTuningEpoch",
    "GetReinforcementFineTuningEpochRequest",
    "CreateReinforcementFineTuningEpochRequest",
    "ListReinforcementFineTuningEpochsRequest",
    "ListReinforcementFineTuningEpochsResponse",
    "DeleteReinforcementFineTuningEpochRequest",
    "ReinforcementFineTuningJob",
    "GetReinforcementFineTuningJobRequest",
    "CreateReinforcementFineTuningJobRequest",
    "ListReinforcementFineTuningJobsRequest",
    "ListReinforcementFineTuningJobsResponse",
    "DeleteReinforcementFineTuningJobRequest",
    "ResumeReinforcementFineTuningJobRequest",
    "DebugReinforcementFineTuningJobRequest",
    "DebugReinforcementFineTuningJobResponse",
    "Reservation",
    "GetReservationRequest",
    "ListReservationsRequest",
    "ListReservationsResponse",
    "RlorTrainerJob",
    "GetRlorTrainerJobRequest",
    "CreateRlorTrainerJobRequest",
    "ListRlorTrainerJobsRequest",
    "ListRlorTrainerJobsResponse",
    "DeleteRlorTrainerJobRequest",
    "Secret",
    "CreateSecretRequest",
    "GetSecretRequest",
    "ListSecretsRequest",
    "ListSecretsResponse",
    "UpdateSecretRequest",
    "DeleteSecretRequest",
    "GetOAuthArgumentsRequest",
    "GetOAuthArgumentsResponse",
    "Snapshot",
    "CreateSnapshotRequest",
    "GetSnapshotRequest",
    "ListSnapshotsRequest",
    "ListSnapshotsResponse",
    "DeleteSnapshotRequest",
    "SupervisedFineTuningJob",
    "GetSupervisedFineTuningJobRequest",
    "CreateSupervisedFineTuningJobRequest",
    "ListSupervisedFineTuningJobsRequest",
    "ListSupervisedFineTuningJobsResponse",
    "DeleteSupervisedFineTuningJobRequest",
    "Workload",
    "CreateWorkloadRequest",
    "GetWorkloadRequest",
    "ListWorkloadsRequest",
    "ListWorkloadsResponse",
    "UpdateWorkloadRequest",
    "DeleteWorkloadRequest",
    "WorkloadShape",
    "CreateWorkloadShapeRequest",
    "GetWorkloadShapeRequest",
    "ListWorkloadShapesRequest",
    "ListWorkloadShapesResponse",
    "UpdateWorkloadShapeRequest",
    "DeleteWorkloadShapeRequest",
    "GatewayStub",
    "GatewayBase",
)

import warnings
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import (
    TYPE_CHECKING,
    Dict,
    List,
    Optional,
)

import betterproto
import grpclib
from betterproto.grpc.grpclib_server import ServiceBase

if TYPE_CHECKING:
    import grpclib.server
    from betterproto.grpc.grpclib_client import MetadataLike
    from grpclib.metadata import Deadline


class Code(betterproto.Enum):
    """
    Mimics [https://github.com/googleapis/googleapis/blob/master/google/rpc/code.proto]
    """

    OK = 0
    """
    Not an error; returned on success.
    
    HTTP Mapping: 200 OK
    """

    CANCELLED = 1
    """
    The operation was cancelled, typically by the caller.
    
    HTTP Mapping: 499 Client Closed Request
    """

    UNKNOWN = 2
    """
    Unknown error.  For example, this error may be returned when
    a `Status` value received from another address space belongs to
    an error space that is not known in this address space.  Also
    errors raised by APIs that do not return enough error information
    may be converted to this error.
    
    HTTP Mapping: 500 Internal Server Error
    """

    INVALID_ARGUMENT = 3
    """
    The client specified an invalid argument.  Note that this differs
    from `FAILED_PRECONDITION`.  `INVALID_ARGUMENT` indicates arguments
    that are problematic regardless of the state of the system
    (e.g., a malformed file name).
    
    HTTP Mapping: 400 Bad Request
    """

    DEADLINE_EXCEEDED = 4
    """
    The deadline expired before the operation could complete. For operations
    that change the state of the system, this error may be returned
    even if the operation has completed successfully.  For example, a
    successful response from a server could have been delayed long
    enough for the deadline to expire.
    
    HTTP Mapping: 504 Gateway Timeout
    """

    NOT_FOUND = 5
    """
    Some requested entity (e.g., file or directory) was not found.
    
    Note to server developers: if a request is denied for an entire class
    of users, such as gradual feature rollout or undocumented allowlist,
    `NOT_FOUND` may be used. If a request is denied for some users within
    a class of users, such as user-based access control, `PERMISSION_DENIED`
    must be used.
    
    HTTP Mapping: 404 Not Found
    """

    ALREADY_EXISTS = 6
    """
    The entity that a client attempted to create (e.g., file or directory)
    already exists.
    
    HTTP Mapping: 409 Conflict
    """

    PERMISSION_DENIED = 7
    """
    The caller does not have permission to execute the specified
    operation. `PERMISSION_DENIED` must not be used for rejections
    caused by exhausting some resource (use `RESOURCE_EXHAUSTED`
    instead for those errors). `PERMISSION_DENIED` must not be
    used if the caller can not be identified (use `UNAUTHENTICATED`
    instead for those errors). This error code does not imply the
    request is valid or the requested entity exists or satisfies
    other pre-conditions.
    
    HTTP Mapping: 403 Forbidden
    """

    UNAUTHENTICATED = 16
    """
    The request does not have valid authentication credentials for the
    operation.
    
    HTTP Mapping: 401 Unauthorized
    """

    RESOURCE_EXHAUSTED = 8
    """
    Some resource has been exhausted, perhaps a per-user quota, or
    perhaps the entire file system is out of space.
    
    HTTP Mapping: 429 Too Many Requests
    """

    FAILED_PRECONDITION = 9
    """
    The operation was rejected because the system is not in a state
    required for the operation's execution.  For example, the directory
    to be deleted is non-empty, an rmdir operation is applied to
    a non-directory, etc.
    
    Service implementors can use the following guidelines to decide
    between `FAILED_PRECONDITION`, `ABORTED`, and `UNAVAILABLE`:
     (a) Use `UNAVAILABLE` if the client can retry just the failing call.
     (b) Use `ABORTED` if the client should retry at a higher level. For
         example, when a client-specified test-and-set fails, indicating the
         client should restart a read-modify-write sequence.
     (c) Use `FAILED_PRECONDITION` if the client should not retry until
         the system state has been explicitly fixed. For example, if an "rmdir"
         fails because the directory is non-empty, `FAILED_PRECONDITION`
         should be returned since the client should not retry unless
         the files are deleted from the directory.
    
    HTTP Mapping: 400 Bad Request
    """

    ABORTED = 10
    """
    The operation was aborted, typically due to a concurrency issue such as
    a sequencer check failure or transaction abort.
    
    See the guidelines above for deciding between `FAILED_PRECONDITION`,
    `ABORTED`, and `UNAVAILABLE`.
    
    HTTP Mapping: 409 Conflict
    """

    OUT_OF_RANGE = 11
    """
    The operation was attempted past the valid range.  E.g., seeking or
    reading past end-of-file.
    
    Unlike `INVALID_ARGUMENT`, this error indicates a problem that may
    be fixed if the system state changes. For example, a 32-bit file
    system will generate `INVALID_ARGUMENT` if asked to read at an
    offset that is not in the range [0,2^32-1], but it will generate
    `OUT_OF_RANGE` if asked to read from an offset past the current
    file size.
    
    There is a fair bit of overlap between `FAILED_PRECONDITION` and
    `OUT_OF_RANGE`.  We recommend using `OUT_OF_RANGE` (the more specific
    error) when it applies so that callers who are iterating through
    a space can easily look for an `OUT_OF_RANGE` error to detect when
    they are done.
    
    HTTP Mapping: 400 Bad Request
    """

    UNIMPLEMENTED = 12
    """
    The operation is not implemented or is not supported/enabled in this
    service.
    
    HTTP Mapping: 501 Not Implemented
    """

    INTERNAL = 13
    """
    Internal errors.  This means that some invariants expected by the
    underlying system have been broken.  This error code is reserved
    for serious errors.
    
    HTTP Mapping: 500 Internal Server Error
    """

    UNAVAILABLE = 14
    """
    The service is currently unavailable.  This is most likely a
    transient condition, which can be corrected by retrying with
    a backoff. Note that it is not always safe to retry
    non-idempotent operations.
    
    See the guidelines above for deciding between `FAILED_PRECONDITION`,
    `ABORTED`, and `UNAVAILABLE`.
    
    HTTP Mapping: 503 Service Unavailable
    """

    DATA_LOSS = 15
    """
    Unrecoverable data loss or corruption.
    
    HTTP Mapping: 500 Internal Server Error
    """


class JobState(betterproto.Enum):
    """JobState represents the state an asynchronous job can be in."""

    UNSPECIFIED = 0
    """
    
    """

    CREATING = 1
    """
    
    """

    RUNNING = 2
    """
    
    """

    COMPLETED = 3
    """
    
    """

    FAILED = 4
    """
    
    """

    CANCELLED = 5
    """
    
    """

    DELETING = 6
    """
    
    """

    WRITING_RESULTS = 7
    """
    
    """

    VALIDATING = 8
    """
    
    """

    ROLLOUT = 9
    """
    
    """

    EVALUATION = 10
    """
    
    """

    FAILED_CLEANING_UP = 11
    """
    
    """

    DELETING_CLEANING_UP = 12
    """
    
    """

    POLICY_UPDATE = 13
    """
    
    """

    PENDING = 14
    """
    
    """

    EXPIRED_CLEANING_UP = 15
    """
    
    """

    EXPIRED = 16
    """
    
    """

    CREATING_DEPENDENCIES = 17
    """
    
    """

    RE_QUEUEING = 18
    """
    
    """

    CREATING_INPUT_DATASET = 19
    """
    
    """


class UserState(betterproto.Enum):
    """ """

    STATE_UNSPECIFIED = 0
    """
    
    """

    CREATING = 1
    """
    
    """

    READY = 2
    """
    
    """

    UPDATING = 3
    """
    
    """

    DELETING = 4
    """
    
    """


class AccountAccountType(betterproto.Enum):
    """Next ID: 5"""

    ACCOUNT_TYPE_UNSPECIFIED = 0
    """
    
    """

    DEVELOPER = 1
    """
    
    """

    ENTERPRISE = 2
    """
    
    """

    BUSINESS = 4
    """
    
    """


class AccountState(betterproto.Enum):
    """ """

    STATE_UNSPECIFIED = 0
    """
    
    """

    CREATING = 1
    """
    
    """

    READY = 2
    """
    
    """

    UPDATING = 3
    """
    
    """

    DELETING = 4
    """
    
    """


class AccountSuspendState(betterproto.Enum):
    """ """

    UNSUSPENDED = 0
    """
    
    """

    FAILED_PAYMENTS = 1
    """
    
    """

    CREDIT_DEPLETED = 2
    """
    
    """

    MONTHLY_SPEND_LIMIT_EXCEEDED = 3
    """
    
    """


class Region(betterproto.Enum):
    """ """

    UNSPECIFIED = 0
    """
    
    """

    US_IOWA_1 = 1
    """GCP us-central1 (Iowa)"""

    US_VIRGINIA_1 = 2
    """AWS us-east-1 (N. Virginia)"""

    US_VIRGINIA_2 = 3
    """OCI us-ashburn-1"""

    US_ILLINOIS_1 = 4
    """OCI us-chicago-1"""

    AP_TOKYO_1 = 5
    """OCI ap-tokyo-1"""

    EU_LONDON_1 = 6
    """OCI uk-london-1"""

    US_ARIZONA_1 = 7
    """OCI us-phoenix-1"""

    US_TEXAS_1 = 8
    """Lambda us-south-3 (C. Texas)"""

    US_ILLINOIS_2 = 9
    """Lambda us-midwest-1 (Illinois)"""

    EU_FRANKFURT_1 = 10
    """OCI eu-frankfurt-1"""

    US_TEXAS_2 = 11
    """Lambda us-south-2 (N. Texas)"""

    EU_PARIS_1 = 12
    """Nebius eu-west1"""

    EU_HELSINKI_1 = 14
    """Nebius eu-north1"""

    US_NEVADA_1 = 15
    """GCP us-west4"""

    EU_ICELAND_1 = 16
    """Crusoe eu-iceland1"""

    EU_ICELAND_2 = 17
    """Crusoe eu-iceland1 (network1)"""

    US_WASHINGTON_1 = 18
    """Voltage Park us-pyl-1"""

    US_WASHINGTON_2 = 19
    """Voltage Park us-seattle-2"""

    EU_ICELAND_DEV_1 = 20
    """Crusoe eu-iceland1 (dev) [HIDE_FROM_DOCS]"""

    US_WASHINGTON_3 = 21
    """Vultr Seattle 1"""

    US_ARIZONA_2 = 22
    """Azure westus3 (Anysphere BYOC) [HIDE_FROM_DOCS]"""

    AP_TOKYO_2 = 23
    """AWS ap-northeast-1"""

    US_CALIFORNIA_1 = 24
    """AWS us-west-1 (N. California)"""

    US_MISSOURI_1 = 25
    """Nebius us-central1 (Anysphere BYOC) [HIDE_FROM_DOCS]"""

    US_UTAH_1 = 26
    """GCP us-west3 (Utah)"""


class MultiRegion(betterproto.Enum):
    """ """

    UNSPECIFIED = 0
    """
    
    """

    GLOBAL = 1
    """
    
    """

    US = 2
    """
    
    """


class AcceleratorType(betterproto.Enum):
    """ """

    UNSPECIFIED = 0
    """
    
    """

    NVIDIA_A100_80GB = 1
    """
    
    """

    NVIDIA_H100_80GB = 2
    """
    
    """

    AMD_MI300X_192GB = 3
    """
    
    """

    NVIDIA_A10G_24GB = 4
    """
    
    """

    NVIDIA_A100_40GB = 5
    """
    
    """

    NVIDIA_L4_24GB = 6
    """
    
    """

    NVIDIA_H200_141GB = 7
    """
    
    """

    NVIDIA_B200_180GB = 8
    """
    
    """


class DirectRouteType(betterproto.Enum):
    """ """

    UNSPECIFIED = 0
    """No direct routing"""

    INTERNET = 1
    """The direct route is exposed via the public internet"""

    GCP_PRIVATE_SERVICE_CONNECT = 2
    """The direct route is exposed via GCP Private Service Connect"""

    AWS_PRIVATELINK = 3
    """The direct route is exposed via AWS PrivateLink"""


class Metrics(betterproto.Enum):
    """ """

    UNSPECIFIED = 0
    """
    
    """

    REPLICA_COUNT = 1
    """
    
    """

    LOAD = 2
    """
    
    """

    CONCURRENT_REQUESTS = 3
    """
    
    """

    PROMPT_CACHE_HIT_RATE = 4
    """
    
    """

    REQUESTS_TOTAL = 5
    """
    
    """

    REQUESTS_ERROR_RATE = 6
    """
    
    """

    TOKENS_PROMPT_PER_REQUEST = 7
    """
    
    """

    TOKENS_GENERATED_PER_REQUEST = 8
    """
    
    """

    SPECULATIVE_HIT_TOTAL = 9
    """
    
    """

    SPECULATIVE_HIT_USER = 10
    """
    
    """

    REQUESTS_PER_SECOND = 11
    """
    
    """

    TOKENS_PER_SECOND = 12
    """
    
    """

    LATENCY = 13
    """Percentile metrics"""

    GENERATION_QUEUE_LATENCY = 14
    """
    
    """

    PREFILL_QUEUE_LATENCY = 15
    """
    
    """

    FIRST_TOKEN_LATENCY = 16
    """
    
    """

    GENERATION_PER_TOKEN_LATENCY = 17
    """
    
    """

    SERVERLESS_REQUESTS_TOTAL = 18
    """Serverless account-specific metrics"""

    SERVERLESS_REQUESTS_RATE_MIRROR_PER_ACCOUNT = 19
    """
    
    """

    SERVERLESS_REQUESTS_LIMIT_PER_ACCOUNT = 20
    """
    
    """

    SERVERLESS_TOKENS_PROMPT_LIMIT_PER_ACCOUNT = 21
    """
    
    """

    SERVERLESS_TOKENS_PROMPT_RATE_MIRROR_PER_ACCOUNT = 22
    """
    
    """

    SERVERLESS_TOKENS_GENERATED_LIMIT_PER_ACCOUNT = 23
    """
    
    """

    SERVERLESS_TOKENS_GENERATED_RATE_MIRROR_PER_ACCOUNT = 24
    """
    
    """


class DeploymentState(betterproto.Enum):
    """ """

    STATE_UNSPECIFIED = 0
    """
    
    """

    CREATING = 1
    """The deployment is still being created."""

    READY = 2
    """The deployment is ready to be used."""

    DELETING = 3
    """The deployment is being deleted."""

    FAILED = 4
    """
    The deployment failed to be created. See the `status` field for
    additional details on why it failed.
    """

    UPDATING = 5
    """There are in-progress updates happening with the deployment."""

    DELETED = 6
    """The deployment is soft-deleted."""


class DeploymentPrecision(betterproto.Enum):
    """ """

    PRECISION_UNSPECIFIED = 0
    """
    if left unspecified we will treat this as a legacy model created before
    self serve
    """

    FP16 = 1
    """
    
    """

    FP8 = 2
    """
    
    """

    FP8_MM = 3
    """
    
    """

    FP8_AR = 4
    """
    
    """

    FP8_MM_KV_ATTN = 5
    """
    
    """

    FP8_KV = 6
    """
    
    """

    FP8_MM_V2 = 7
    """
    
    """

    FP8_V2 = 8
    """
    
    """

    FP8_MM_KV_ATTN_V2 = 9
    """
    
    """

    NF4 = 10
    """
    
    """

    FP4 = 11
    """
    
    """

    BF16 = 12
    """
    
    """


class DeploymentEngine(betterproto.Enum):
    """ """

    ENGINE_UNSPECIFIED = 0
    """
    
    """

    FIREATTENTION = 1
    """
    
    """

    VLLM = 2
    """
    
    """

    NIM = 3
    """
    
    """


class BatchJobState(betterproto.Enum):
    """Next ID: 10"""

    STATE_UNSPECIFIED = 0
    """
    
    """

    CREATING = 7
    """The batch job is being created."""

    QUEUED = 1
    """
    The batch job is in the queue and waiting to be scheduled.
    Currently unused.
    """

    PENDING = 2
    """The batch job scheduled and is waiting for resource allocation."""

    RUNNING = 3
    """The batch job is running."""

    COMPLETED = 4
    """The batch job has finished successfully."""

    FAILED = 5
    """The batch job has failed."""

    CANCELLING = 8
    """The batch job is being cancelled."""

    CANCELLED = 6
    """The batch job was cancelled."""

    DELETING = 9
    """The batch job is being deleted."""


class PythonExecutorTargetType(betterproto.Enum):
    """ """

    TARGET_TYPE_UNSPECIFIED = 0
    """
    
    """

    MODULE = 1
    """Runs a python module, i.e. passed as -m argument."""

    FILENAME = 2
    """Runs a python file."""


class StripeCheckoutSessionMode(betterproto.Enum):
    """ """

    MODE_UNSPECIFIED = 0
    """
    
    """

    PAYMENT = 1
    """
    
    """

    SETUP = 2
    """
    
    """


class InvoiceState(betterproto.Enum):
    """ """

    STATE_UNSPECIFIED = 0
    """
    
    """

    DRAFT = 1
    """
    
    """

    ISSUED = 2
    """
    
    """

    PAID = 3
    """
    
    """

    VOID = 4
    """
    
    """

    FAILED = 5
    """
    
    """


class ClusterState(betterproto.Enum):
    """ """

    STATE_UNSPECIFIED = 0
    """
    
    """

    CREATING = 1
    """The cluster is still being created."""

    READY = 2
    """The cluster is ready to be used."""

    DELETING = 3
    """The cluster is being deleted."""

    FAILED = 4
    """
    Cluster is not operational.
    Consult 'status' for detailed messaging.
    Cluster needs to be deleted and re-created.
    """


class DatasetState(betterproto.Enum):
    """ """

    STATE_UNSPECIFIED = 0
    """
    
    """

    UPLOADING = 1
    """
    
    """

    READY = 2
    """
    
    """


class DatasetAccessPolicy(betterproto.Enum):
    """ """

    PRIVATE = 0
    """
    The dataset can only be accessed privately from the account.
    The default access policy for dataset.
    """

    PUBLIC = 1
    """
    The dataset is public, and can be merged with other datasets.
    Currently, can be only set for datasets in `fireworks` account.
    """


class DatasetFormat(betterproto.Enum):
    """ """

    FORMAT_UNSPECIFIED = 0
    """
    
    """

    CHAT = 1
    """
    
    """

    COMPLETION = 2
    """
    
    """

    RL = 3
    """
    
    """


class DatasetValidationFormat(betterproto.Enum):
    """ """

    UNSPECIFIED = 0
    """Unspecified format."""

    CHAT = 1
    """
    Chat dataset format. One or more .jsonl files, in which each line is a JSON object with a "messages" list,
    containing objects with a "role" field and a "content" field.
    {"messages": [{"role": "user", "content": "Hello, world!"}, {"role": "assistant", "content": "Hello, user!"}]}
    """

    CHAT_RELAXED = 2
    """
    Chat dataset relaxed format. Same as DATASET_VALIDATION_FORMAT_CHAT, but optionally allows the assistant message to be missing, and allows extra fields.
    """

    RLOR = 3
    """
    RLOR dataset format. One or more .jsonl files, in which each line is a JSON object with a "samples" array,
    containing objects with "messages" list and optional metrics keys with values ranging from 0.0 to 1.0.
    {"samples": [{"messages": [{"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}], "metric_key": 1.0}, ...]}
    """

    BATCH_INFERENCE_STRICT = 4
    """
    Batch inference strict format. Same as chat except no trailing assistant messages allowed.
    """

    BATCH_INFERENCE_ALLOW_TRAILING_ASSISTANT = 5
    """
    Batch inference format with trailing assistant messages allowed. Same as chat except trailing assistant messages are optional.
    """

    BATCH_INFERENCE = 6
    """
    Batch inference format (new). It will allow chat format and also OpenAI format.
    """


class DatasetValidationJobResult(betterproto.Enum):
    """ """

    UNSPECIFIED = 0
    """
    
    """

    SUCCESS = 1
    """
    
    """

    FAILURE = 2
    """
    
    """


class DeployedModelState(betterproto.Enum):
    """Next ID: 6"""

    STATE_UNSPECIFIED = 0
    """
    
    """

    UNDEPLOYING = 1
    """The model is being undeployed."""

    DEPLOYING = 2
    """The model is being deployed."""

    DEPLOYED = 3
    """The model is deployed and ready for inference."""

    UPDATING = 4
    """there are updates happening with the deployed model"""


class WeightPrecision(betterproto.Enum):
    """The weight precision for model training/inference."""

    UNSPECIFIED = 0
    """
    
    """

    BFLOAT16 = 1
    """no quantization applied"""

    INT8 = 2
    """enable 8-bit quantization with LLM.int8()"""

    NF4 = 3
    """enable 4-bit quantization with LLM.nf4()"""


class EnvironmentState(betterproto.Enum):
    """Next ID: 8"""

    STATE_UNSPECIFIED = 0
    """
    
    """

    CREATING = 1
    """The environment is being created."""

    DISCONNECTED = 2
    """The environment is not connected."""

    CONNECTING = 3
    """The environment is being connected to a node."""

    CONNECTED = 4
    """The environment is connected to a node."""

    DISCONNECTING = 5
    """The environment is being disconnected from a node."""

    RECONNECTING = 7
    """The environment is reconnecting with new connection parameters."""

    DELETING = 6
    """The environment is being deleted."""


class AssertionAssertionType(betterproto.Enum):
    """ """

    ASSERTION_TYPE_UNSPECIFIED = 0
    """
    
    """

    ASSERTION_TYPE_LLM = 1
    """
    
    """

    ASSERTION_TYPE_CODE = 2
    """
    
    """


class EvaluatorState(betterproto.Enum):
    """ """

    STATE_UNSPECIFIED = 0
    """
    
    """

    ACTIVE = 1
    """
    The evaluator is ready to use for evaluation
    
    The evaluator is not ready to use for evaluation, could be deploying, updating, or manually marked as inactive.
    INACTIVE = 2;
    """


class CriterionType(betterproto.Enum):
    """ """

    TYPE_UNSPECIFIED = 0
    """
    
    """

    CODE_SNIPPETS = 1
    """Code snippets for Sandbox based evaluation"""


class FineTuningJobState(betterproto.Enum):
    """Next ID: 8"""

    STATE_UNSPECIFIED = 0
    """
    
    """

    CREATING = 1
    """The fine-tuning job is being created."""

    PENDING = 2
    """
    The fine-tuning job scheduled and is waiting for resource allocation.
    """

    RUNNING = 3
    """The fine-tuning job is running."""

    COMPLETED = 4
    """The fine-tuning job has finished successfully."""

    FAILED = 5
    """The fine-tuning job has failed."""

    DELETING = 6
    """The fine-tuning job is being deleted"""


class McpServerAuthenticationType(betterproto.Enum):
    """Next ID: 5"""

    AUTHENTICATION_TYPE_UNSPECIFIED = 0
    """
    
    """

    OPEN = 1
    """No authentication required (open access)"""

    API_KEY = 2
    """API key authentication via secrets"""

    OAUTH2 = 3
    """OAuth 2.0 authentication"""

    BEARER_TOKEN = 4
    """Bearer token authentication"""


class McpServerState(betterproto.Enum):
    """Next ID: 5"""

    STATE_UNSPECIFIED = 0
    """
    
    """

    CREATING = 1
    """
    
    """

    ACTIVE = 2
    """
    
    """

    FAILED = 3
    """
    
    """

    DELETING = 4
    """
    
    """


class ModelState(betterproto.Enum):
    """Next ID: 7"""

    STATE_UNSPECIFIED = 0
    """
    
    """

    UPLOADING = 1
    """The model is still being uploaded (upload is asynchronous)."""

    READY = 6
    """The model is ready to be used."""


class ModelKind(betterproto.Enum):
    """ """

    KIND_UNSPECIFIED = 0
    """
    
    """

    HF_BASE_MODEL = 1
    """An LLM base model."""

    HF_PEFT_ADDON = 2
    """A parameter-efficent fine-tuned addon."""

    HF_TEFT_ADDON = 3
    """A token-eficient fine-tuned addon."""

    FLUMINA_BASE_MODEL = 4
    """A Flumina base model."""

    FLUMINA_ADDON = 5
    """A Flumina addon."""

    DRAFT_ADDON = 6
    """A draft model used for speculative decoding in a deployment."""

    FIRE_AGENT = 7
    """A FireAgent model."""

    LIVE_MERGE = 8
    """A live-merge model."""

    CUSTOM_MODEL = 9
    """A customized model"""


class BaseModelDetailsCheckpointFormat(betterproto.Enum):
    """ """

    CHECKPOINT_FORMAT_UNSPECIFIED = 0
    """
    
    """

    NATIVE = 1
    """
    
    """

    HUGGINGFACE = 2
    """
    
    """


class NodePoolState(betterproto.Enum):
    """ """

    STATE_UNSPECIFIED = 0
    """
    
    """

    CREATING = 1
    """The cluster is still being created."""

    READY = 2
    """The node pool is ready to be used."""

    DELETING = 3
    """The node pool is being deleted."""

    FAILED = 4
    """
    Node pool is not operational.
    Consult 'status' for detailed messaging.
    Node pool needs to be deleted and re-created.
    """


class SnapshotState(betterproto.Enum):
    """ """

    STATE_UNSPECIFIED = 0
    """
    
    """

    CREATING = 1
    """
    
    """

    READY = 2
    """
    
    """

    FAILED = 3
    """
    
    """

    DELETING = 4
    """
    
    """


class SupervisedFineTuningJobWeightPrecision(betterproto.Enum):
    """The weight precision of the base model."""

    WEIGHT_PRECISION_UNSPECIFIED = 0
    """
    
    """

    BFLOAT16 = 1
    """no quantization applied"""

    INT8 = 2
    """enable 8-bit quantization with LLM.int8()"""

    NF4 = 3
    """enable 4-bit quantization with LLM.nf4()"""

    FP8 = 4
    """
    
    """

    FP4_FP8 = 5
    """
    
    """


class WorkloadState(betterproto.Enum):
    """ """

    STATE_UNSPECIFIED = 0
    """
    
    """

    CREATING = 1
    """The workload is still being created."""

    READY = 2
    """The workload is ready to be used."""

    DELETING = 3
    """The workload is being deleted."""

    FAILED = 4
    """
    The workload failed to be created. See the `status` field for
    additional details on why it failed.
    """

    UPDATING = 5
    """There are in-progress updates happening with the workload."""

    DELETED = 6
    """The workload is soft-deleted."""


@dataclass(eq=False, repr=False)
class ApiResource(betterproto.Message):
    """ """

    parent_type: str = betterproto.string_field(1)
    """
    The name of the parent resource type. e.g. Account
    If empty, then there is no parent.
    """

    skip_gorm: bool = betterproto.bool_field(2)
    """If true, skip GORM generation for this resource."""

    has_db_only_fields: bool = betterproto.bool_field(3)
    """If true, embed extra database-only fields for the generated struct."""


@dataclass(eq=False, repr=False)
class Status(betterproto.Message):
    """
    Mimics [https://github.com/googleapis/googleapis/blob/master/google/rpc/status.proto]
    """

    code: "Code" = betterproto.enum_field(1)
    """The status code."""

    message: str = betterproto.string_field(2)
    """A developer-facing error message in English."""


@dataclass(eq=False, repr=False)
class User(betterproto.Message):
    """Next ID: 13"""

    name: str = betterproto.string_field(1)
    """
    The resource name of the user. e.g. accounts/my-account/users/my-user
    """

    display_name: str = betterproto.string_field(3)
    """
    Human-readable display name of the user. e.g. "Alice"
    Must be fewer than 64 characters long.
    """

    first_name: str = betterproto.string_field(9)
    """The user's first name"""

    last_name: str = betterproto.string_field(10)
    """The user's last name"""

    stated_role: str = betterproto.string_field(11)
    """The user's stated role (e.g., developer, student)"""

    service_account: bool = betterproto.bool_field(12)
    """Whether this user is a service account (can only be set by admins)"""

    create_time: datetime = betterproto.message_field(5)
    """The creation time of the user."""

    role: str = betterproto.string_field(2)
    """The user's role, e.g. admin or user."""

    email: str = betterproto.string_field(4)
    """The user's email address."""

    state: "UserState" = betterproto.enum_field(6)
    """The state of the user."""

    status: "Status" = betterproto.message_field(7)
    """Contains information about the user status."""

    update_time: datetime = betterproto.message_field(8)
    """The update time for the user."""


@dataclass(eq=False, repr=False)
class CreateUserRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The resource name of the parent account."""

    user: "User" = betterproto.message_field(2)
    """The properties of the user being created."""

    user_id: str = betterproto.string_field(3)
    """
    The user ID to use in the user name. e.g. my-user
    If not specified, a default ID is generated from user.email.
    """


@dataclass(eq=False, repr=False)
class GetUserRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the user."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListUsersRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """Resource name of the parent account."""

    page_size: int = betterproto.int32_field(2)
    """
    The maximum number of users to return. The maximum page_size is 200,
    values above 200 will be coerced to 200.
    If unspecified, the default is 50.
    """

    page_token: str = betterproto.string_field(3)
    """
    A page token, received from a previous ListUsers call. Provide this
    to retrieve the subsequent page. When paginating, all other parameters
    provided to ListUsers must match the call that provided the page
    token.
    """

    filter: str = betterproto.string_field(4)
    """
    Only users satisfying the provided filter (if specified) will be
    returned. See https://google.aip.dev/160 for the filter grammar.
    """

    order_by: str = betterproto.string_field(5)
    """
    A comma-separated list of fields to order by. e.g. "foo,bar"
    The default sort order is ascending. To specify a descending order for a
    field, append a " desc" suffix. e.g. "foo desc,bar"
    Subfields are specified with a "." character. e.g. "foo.bar"
    If not specified, the default order is by "name".
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListUsersResponse(betterproto.Message):
    """ """

    users: List["User"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of users."""


@dataclass(eq=False, repr=False)
class UpdateUserRequest(betterproto.Message):
    """ """

    user: "User" = betterproto.message_field(1)
    """
    The properties of the User being updated. `user.name` must
    be populated with the updated resource's name.
    """

    update_mask: "betterproto_lib_google_protobuf.FieldMask" = (
        betterproto.message_field(2)
    )
    """List of field paths to be updated. If empty we replace all fields."""


@dataclass(eq=False, repr=False)
class DeleteUserRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the user."""


@dataclass(eq=False, repr=False)
class WandbConfig(betterproto.Message):
    """
    WandbConfig is the configuration for the Weights & Biases (wandb) logging which
    will be used by a training job.
    """

    enabled: bool = betterproto.bool_field(1)
    """Whether to enable wandb logging."""

    api_key: str = betterproto.string_field(2)
    """The API key for the wandb service."""

    project: str = betterproto.string_field(3)
    """The project name for the wandb service."""

    entity: str = betterproto.string_field(4)
    """The entity name for the wandb service."""

    run_id: str = betterproto.string_field(5)
    """The run ID for the wandb service."""

    url: str = betterproto.string_field(6)
    """The URL for the wandb service."""

    def __post_init__(self) -> None:
        super().__post_init__()
        if self.is_set("run_id"):
            warnings.warn("WandbConfig.run_id is deprecated", DeprecationWarning)


@dataclass(eq=False, repr=False)
class Account(betterproto.Message):
    """Next ID: 21"""

    name: str = betterproto.string_field(1)
    """The resource name of the account. e.g. accounts/my-account"""

    display_name: str = betterproto.string_field(2)
    """
    Human-readable display name of the account. e.g. "My Account"
    Must be fewer than 64 characters long.
    """

    create_time: datetime = betterproto.message_field(3)
    """The creation time of the account."""

    intended_use: str = betterproto.string_field(19)
    """The intended use of the account (e.g., playing around, prototyping)"""

    prometheus_endpoint: str = betterproto.string_field(4)
    """
    The URL of the Prometheus endpoint where cluster metrics should be
    exported. e.g. https://aps-workspaces.us-east-1.amazonaws.com/workspaces/ws-1ffad64d-3d0e-4363-941b-0ef966b2b593/
    The remote write URL will be <prometheus_endpoint>/api/v1/remote_write
    and the query URL will be <prometheus_endpoint>/api/v1/query.
    """

    athena_cost_usage_report_bucket: str = betterproto.string_field(5)
    """
    The s3 bucket name where athena cost and usage report query data is stored.
    e.g. s3://aws-athena-query-results-fireworks-1234-kubecost
    """

    account_type: "AccountAccountType" = betterproto.enum_field(6)
    """
    The account type.
    The default is DEVELOPER.
    """

    email: str = betterproto.string_field(9)
    """
    For developer accounts, this is the email of the developer user and is
    immutable. For ENTERPRISE and BUSINESS accounts, this is mutable and
    it is the email that will recieve the invoice for the account if
    automated billing is used.
    """

    state: "AccountState" = betterproto.enum_field(7)
    """The state of the account."""

    status: "Status" = betterproto.message_field(8)
    """Contains information about the account status."""

    suspend_state: "AccountSuspendState" = betterproto.enum_field(12)
    """
    
    """

    stripe_customer_id: str = betterproto.string_field(13)
    """The Stripe customer ID for this account"""

    oidc_issuer_url: str = betterproto.string_field(14)
    """
    The AWS Cognito issuer URL.
    If not specified, the multi-tenant user pool will be used.
    If specified, both oidc_client_id and cognito_domain must be specified.
    """

    oidc_client_id: str = betterproto.string_field(15)
    """
    The AWS Cognito client ID.
    If not specified, the multi-tenant user pool will be used.
    If specified, both oidc_issuer_url and cognito_domain must be specified.
    """

    cognito_domain: str = betterproto.string_field(16)
    """
    The AWS Cognito domain.
    If not specified, the multi-tenant user pool will be used.
    If specified, both oidc_issuer_url and oidc_client_id must be specified.
    """

    wandb_config: "WandbConfig" = betterproto.message_field(17)
    """
    
    """

    update_time: datetime = betterproto.message_field(18)
    """The update time for the account."""

    def __post_init__(self) -> None:
        super().__post_init__()
        if self.is_set("account_type"):
            warnings.warn("Account.account_type is deprecated", DeprecationWarning)


@dataclass(eq=False, repr=False)
class CreateAccountRequest(betterproto.Message):
    """ """

    account: "Account" = betterproto.message_field(1)
    """The properties of the Environment being created."""

    account_id: str = betterproto.string_field(2)
    """
    The account ID to use in the account name. e.g. my-account
    If not specified, an account ID will be auto-generated.
    """

    wait: bool = betterproto.bool_field(3)
    """
    If specified, wait for the account to be READY before returning the RPC.
    The timeout is 60s.
    """

    user: "User" = betterproto.message_field(4)
    """
    These fields will optionally be used to create the initial developer user.
    """


@dataclass(eq=False, repr=False)
class GetAccountRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the account."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListAccountsRequest(betterproto.Message):
    """ """

    page_size: int = betterproto.int32_field(2)
    """
    The maximum number of accounts to return. The maximum page_size is 200,
    values above 200 will be coerced to 200.
    If unspecified, the default is 50.
    """

    page_token: str = betterproto.string_field(3)
    """
    A page token, received from a previous ListAccounts call. Provide this
    to retrieve the subsequent page. When paginating, all other parameters
    provided to ListAccounts must match the call that provided the page
    token.
    """

    filter: str = betterproto.string_field(4)
    """
    Only accounts satisfying the provided filter (if specified) will be
    returned. See https://google.aip.dev/160 for the filter grammar.
    """

    order_by: str = betterproto.string_field(5)
    """
    Not supported.
    Accounts will be returned ordered by `name`.
    """

    show_all: bool = betterproto.bool_field(6)
    """
    By default, only accounts where the principal has been explicitly added as
    a  user will be returned. Superusers additionally have access to all
    accounts. If true, all accounts will be returned. This must be combined
    with the filter option.
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        7
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListAccountsResponse(betterproto.Message):
    """ """

    accounts: List["Account"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of accounts."""


@dataclass(eq=False, repr=False)
class UpdateAccountRequest(betterproto.Message):
    """ """

    account: "Account" = betterproto.message_field(1)
    """
    The properties of the Account being updated. `account.name` must
    be populated with the updated resource's name.
    """

    update_mask: "betterproto_lib_google_protobuf.FieldMask" = (
        betterproto.message_field(2)
    )
    """List of field paths to be updated. If empty we replace all fields."""


@dataclass(eq=False, repr=False)
class DeleteAccountRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the account."""

    force: bool = betterproto.bool_field(2)
    """
    If specified, skip checking for outstanding invoices before deleting the account.
    """


@dataclass(eq=False, repr=False)
class ApiKey(betterproto.Message):
    """ """

    key_id: str = betterproto.string_field(1)
    """
    Unique identifier (Key ID) for the API key, used primarily for deletion.
    """

    display_name: str = betterproto.string_field(2)
    """
    Display name for the API key, defaults to "default" if not specified.
    """

    key: str = betterproto.string_field(3)
    """
    The actual API key value, only available upon creation and not stored thereafter.
    """

    create_time: datetime = betterproto.message_field(5)
    """Timestamp indicating when the API key was created."""

    secure: bool = betterproto.bool_field(6)
    """
    Indicates whether the plaintext value of the API key is unknown to Fireworks.
    If true, Fireworks does not know this API key's plaintext value. If false, Fireworks does
    know the plaintext value.
    """

    email: str = betterproto.string_field(7)
    """Email of the user who owns this API key."""

    prefix: str = betterproto.string_field(8)
    """The first few characters of the API key to visually identify it"""


@dataclass(eq=False, repr=False)
class CreateApiKeyRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The resource name of the parent user."""

    api_key: "ApiKey" = betterproto.message_field(2)
    """The API key to be created."""


@dataclass(eq=False, repr=False)
class ListApiKeysRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    Resource name of the parent user.
    To list keys across all users in an account, use the format "accounts/{account}/users/-"
    following the AIP-159 pattern for reading across collections.
    """

    page_size: int = betterproto.int32_field(2)
    """
    Number of API keys to return in the response. Pagination support to be added.
    TODO: Implement pagination
    """

    page_token: str = betterproto.string_field(3)
    """
    Token for fetching the next page of results. Pagination support to be added.
    TODO: Implement pagination
    """

    filter: str = betterproto.string_field(4)
    """
    Field for filtering results.
    TODO: Unused but required to use existing ListRequest functionality.
    """

    order_by: str = betterproto.string_field(5)
    """
    Field for ordering results.
    TODO: Unused but required to use existing ListRequest functionality.
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListApiKeysResponse(betterproto.Message):
    """ """

    api_keys: List["ApiKey"] = betterproto.message_field(1)
    """List of API keys retrieved."""

    next_page_token: str = betterproto.string_field(2)
    """
    Token for fetching the next page of results. Pagination support to be added.
    TODO: Implement pagination
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of API keys."""


@dataclass(eq=False, repr=False)
class DeleteApiKeyRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The resource name of the parent user."""

    key_id: str = betterproto.string_field(2)
    """The key ID for the API key."""


@dataclass(eq=False, repr=False)
class GetInternalApiKeyRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The resource name of the parent user."""


@dataclass(eq=False, repr=False)
class UpdateApiKeyAccountRequest(betterproto.Message):
    """ """

    old_account: str = betterproto.string_field(1)
    """The resource name of the old account."""

    new_account: str = betterproto.string_field(2)
    """The resource name of the new account."""


@dataclass(eq=False, repr=False)
class AuditLogEntry(betterproto.Message):
    """ """

    id: str = betterproto.string_field(1)
    """Audit log entry id."""

    method: str = betterproto.string_field(2)
    """The gRPC method name."""

    principal: str = betterproto.string_field(3)
    """The email of the principal user who performed this action."""

    payload: "betterproto_lib_google_protobuf.Struct" = betterproto.message_field(4)
    """The payload as JSON."""

    status: "Status" = betterproto.message_field(5)
    """The response status."""

    timestamp: datetime = betterproto.message_field(6)
    """The timestamp when the request was received."""

    message: str = betterproto.string_field(7)
    """Optional message describing the audit log entry"""

    resource: str = betterproto.string_field(8)
    """The resource being operated on (e.g. accounts/123)"""

    is_admin_action: bool = betterproto.bool_field(9)
    """
    Whether this action was taken by an admin and should not be shown to regular users
    """


@dataclass(eq=False, repr=False)
class ListAuditLogsRequest(betterproto.Message):
    """Next ID: 10"""

    parent: str = betterproto.string_field(1)
    """Resource name of the parent account."""

    start_time: datetime = betterproto.message_field(2)
    """
    Start time of the audit logs to retrieve.
    If unspecified, the default is 30 days before now.
    """

    end_time: datetime = betterproto.message_field(3)
    """
    End time of the audit logs to retrieve.
    If unspecified, the default is the current time.
    """

    email: str = betterproto.string_field(8)
    """
    Optional.
    Filter audit logs for user email associated with the account.
    """

    page_size: int = betterproto.int32_field(4)
    """
    The maximum number of audit logs to return. The maximum page_size is 200,
    values above 200 will be coerced to 200.
    If unspecified, the default is 10.
    """

    page_token: str = betterproto.string_field(5)
    """
    A page token, received from a previous ListAuditLogs call. Provide this
    to retrieve the subsequent page. When paginating, all other parameters
    provided to ListAuditLogs must match the call that provided the page
    token.
    """

    filter: str = betterproto.string_field(6)
    """Unused but required to use existing ListRequest functionality."""

    order_by: str = betterproto.string_field(7)
    """Unused but required to use existing ListRequest functionality."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        9
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListAuditLogsResponse(betterproto.Message):
    """ """

    audit_logs: List["AuditLogEntry"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of request logs matching the request."""


@dataclass(eq=False, repr=False)
class AwsIamRoleBinding(betterproto.Message):
    """ """

    account_id: str = betterproto.string_field(1)
    """The account ID that this binding is associated with."""

    create_time: datetime = betterproto.message_field(2)
    """The creation time of the AWS IAM role binding."""

    principal: str = betterproto.string_field(3)
    """
    The principal that is allowed to assume the AWS IAM role. This must be
    the email address of the user.
    """

    role: str = betterproto.string_field(4)
    """The AWS IAM role ARN that is allowed to be assumed by the principal."""


@dataclass(eq=False, repr=False)
class CreateAwsIamRoleBindingRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The resource name of the parent account."""

    aws_iam_role_binding: "AwsIamRoleBinding" = betterproto.message_field(2)
    """The properties of the AWS IAM role binding being created."""


@dataclass(eq=False, repr=False)
class ListAwsIamRoleBindingsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The resource name of the parent account."""

    page_size: int = betterproto.int32_field(2)
    """
    The maximum number of bindings to return. The maximum page_size is 200,
    values above 200 will be coerced to 200.
    If unspecified, the default is 50.
    """

    page_token: str = betterproto.string_field(3)
    """
    A page token, received from a previous ListAwsIamRoleBindings call.
    Provide this to retrieve the subsequent page. When paginating, all other
    parameters provided to ListAwsIamRoleBindings must match the call that
    provided the page token.
    """

    filter: str = betterproto.string_field(4)
    """
    Only bindings satisfying the provided filter (if specified) will be
    returned. See https://google.aip.dev/160 for the filter grammar.
    """

    order_by: str = betterproto.string_field(5)
    """
    A comma-separated list of fields to order by. e.g. "foo,bar"
    The default sort order is ascending. To specify a descending order for a
    field, append a " desc" suffix. e.g. "foo desc,bar"
    Subfields are specified with a "." character. e.g. "foo.bar"
    If not specified, the default order is by "name".
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListAwsIamRoleBindingsResponse(betterproto.Message):
    """ """

    aws_iam_role_bindings: List["AwsIamRoleBinding"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of AWS IAM role bindings."""


@dataclass(eq=False, repr=False)
class DeleteAwsIamRoleBindingRequest(betterproto.Message):
    """ """

    aws_iam_role_binding: "AwsIamRoleBinding" = betterproto.message_field(2)
    """
    The AWS IAM role binding being deleted.
    Must specify account_id, principal, and role.
    """


@dataclass(eq=False, repr=False)
class Deployment(betterproto.Message):
    """Next ID: 72"""

    name: str = betterproto.string_field(1)
    """
    The resource name of the deployment. e.g. accounts/my-account/deployments/my-deployment
    """

    display_name: str = betterproto.string_field(2)
    """
    Human-readable display name of the deployment. e.g. "My Deployment"
    Must be fewer than 64 characters long.
    """

    description: str = betterproto.string_field(8)
    """Description of the deployment."""

    create_time: datetime = betterproto.message_field(3)
    """The creation time of the deployment."""

    expire_time: datetime = betterproto.message_field(56)
    """The time at which this deployment will automatically be deleted."""

    purge_time: datetime = betterproto.message_field(54)
    """The time at which the resource will be hard deleted."""

    delete_time: datetime = betterproto.message_field(61)
    """The time at which the resource will be soft deleted."""

    created_by: str = betterproto.string_field(29)
    """The email address of the user who created this deployment."""

    state: "DeploymentState" = betterproto.enum_field(5)
    """The state of the deployment."""

    status: "Status" = betterproto.message_field(6)
    """Detailed status information regarding the most recent operation."""

    annotations: Dict[str, str] = betterproto.map_field(
        64, betterproto.TYPE_STRING, betterproto.TYPE_STRING
    )
    """
    Annotations to identify deployment properties.
    Key/value pairs may be used by external tools or other services.
    """

    min_replica_count: int = betterproto.int32_field(13)
    """
    The minimum number of replicas.
    If not specified, the default is 0.
    """

    max_replica_count: int = betterproto.int32_field(14)
    """
    The maximum number of replicas.
    If not specified, the default is max(min_replica_count, 1).
    May be set to 0 to downscale the deployment to 0.
    """

    replica_count: int = betterproto.int32_field(35)
    """
    
    """

    autoscaling_policy: "AutoscalingPolicy" = betterproto.message_field(38)
    """
    
    """

    base_model: str = betterproto.string_field(18)
    """The base model name. e.g. accounts/fireworks/models/falcon-7b"""

    accelerator_count: int = betterproto.int32_field(42)
    """
    The number of accelerators used per replica.
    If not specified, the default is the estimated minimum required by the
    base model.
    """

    accelerator_type: "AcceleratorType" = betterproto.enum_field(43)
    """
    The type of accelerator to use.
    If not specified, the default is NVIDIA_A100_80GB.
    """

    precision: "DeploymentPrecision" = betterproto.enum_field(46)
    """
    The precision with which the model should be served.
    TODO: Make the default value FP16 once legacy models are fixed.
    """

    world_size: int = betterproto.int32_field(24)
    """
    The number of accelerators the base model is served with. Must only be
    specified if accelerator_count is not specified.
    The default is the estimated minimum required to serve the base model if
    accelerator_count is 0. Otherwise, it is accelerator_count/2 if
    disaggregated prefill is enabled.
    """

    generator_count: int = betterproto.int32_field(26)
    """
    the number of generator groups, for multi-node deployments. then world_size is the number of GPUs per generator group.
    """

    disaggregated_prefill_count: int = betterproto.int32_field(19)
    """
    The number of copies of the model that should be used for disaggregated
    prefill. Must only be specified if accelerator_count is not specified.
    The default is 1 if auto_tune.long_prompt is true and the base model is
    small enough to support disaggregated prefill within the
    accelerator_count constraint, else 0.
    """

    disaggregated_prefill_world_size: int = betterproto.int32_field(25)
    """
    The number of accelerators used for disaggregated prefill. Must only be
    specified if accelerator_count is not specified.
    The default is world_size if disaggregated_prefill_count is non-zero.
    """

    max_batch_size: int = betterproto.int32_field(20)
    """
    The maximum batch size supported by the server.
    If not specified, the default is 16.
    """

    cluster: str = betterproto.string_field(52)
    """If set, this deployment is deployed to a cloud-premise cluster."""

    enable_addons: bool = betterproto.bool_field(49)
    """If true, PEFT addons are enabled for this deployment."""

    draft_token_count: int = betterproto.int32_field(27)
    """
    The number of candidate tokens to generate per step for speculative
    decoding.
    Default is the base model's draft_token_count. Set
    CreateDeploymentRequest.disable_speculative_decoding to false to disable
    this behavior.
    """

    draft_model: str = betterproto.string_field(34)
    """
    The draft model name for speculative decoding. e.g. accounts/fireworks/models/my-draft-model
    If empty, speculative decoding using a draft model is disabled.
    Default is the base model's default_draft_model. Set
    CreateDeploymentRequest.disable_speculative_decoding to false to disable
    this behavior.
    """

    ngram_speculation_length: int = betterproto.int32_field(50)
    """
    The length of previous input sequence to be considered for N-gram speculation.
    """

    max_peft_batch_size: int = betterproto.int32_field(30)
    """
    The maximum peft batch size supported by the server.
    If not specified, the default is 16. This cannot exceed max_batch_size.
    """

    kv_cache_memory_pct: int = betterproto.int32_field(31)
    """
    Percentage of remaiming memory to allocate for KV cache.
    If not specified, the default is 80.
    """

    enable_session_affinity: bool = betterproto.bool_field(32)
    """Whether to apply sticky routing based on `user` field."""

    direct_route_api_keys: List[str] = betterproto.string_field(44)
    """
    When we have the direct route setup, which set of api keys do we want to use for the dedicated deployments
    """

    image_tag: str = betterproto.string_field(33)
    """
    The container image tag to use. If not specified, the latest production
    version will be used.
    """

    num_peft_device_cached: int = betterproto.int32_field(48)
    """How many peft adapters to keep on gpu side for caching"""

    direct_route_type: "DirectRouteType" = betterproto.enum_field(53)
    """
    If set, this deployment will expose an endpoint that bypasses our middleware.
    Applies to Enterprise tier only.
    """

    direct_route_handle: str = betterproto.string_field(57)
    """
    The handle for calling a direct route. The meaning of the handle depends on the
    direct route type of the deployment:
       INTERNET                    -> The host name for accessing the deployment
       GCP_PRIVATE_SERVICE_CONNECT -> The service attachment name used to create the PSC endpoint.
       AWS_PRIVATELINK             -> The service name used to create the VPC endpoint.
    """

    deployment_template: str = betterproto.string_field(39, group="preconfig")
    """
    The name of the deployment template to use for this deployment. Only
    available to enterprise accounts.
    """

    auto_tune: "AutoTune" = betterproto.message_field(40, group="preconfig")
    """The performance profile to use for this deployment."""

    placement: "Placement" = betterproto.message_field(68)
    """
    The desired geographic region where the deployment must be placed.
    If unspecified, the default is the GLOBAL multi-region.
    """

    region: "Region" = betterproto.enum_field(51)
    """
    The geographic region where the deployment is presently located. This region may change
    over time, but within the `placement` constraint.
    """

    disable_accounting: bool = betterproto.bool_field(55)
    """
    If true, billing is disabled for this deployment and it will not count
    towards quotas. If specified, expire_time must also be set.
    This flag should only be used for internal test deployments, proof-of-
    concepts, etc.
    """

    extra_args: List[str] = betterproto.string_field(58)
    """A list of extra arguments that should be passed to the server."""

    max_context_length: int = betterproto.int32_field(67)
    """
    The maximum context length supported by the model (context window).
    If not specified, the model's default maximum context length will be used.
    """

    extra_values: Dict[str, str] = betterproto.map_field(
        60, betterproto.TYPE_STRING, betterproto.TYPE_STRING
    )
    """
    A JSON object of extra values that should be passed to the helm chart when installed.
    """

    engine: "DeploymentEngine" = betterproto.enum_field(66)
    """
    Whether this deployment should be created with FIREATTENTION, VLLM, or NIM engine.
    If unspecified, the default is FIREATTENTION.
    """

    update_time: datetime = betterproto.message_field(63)
    """The update time for the deployment."""

    for_training: bool = betterproto.bool_field(65)
    """Whether this deployment is for training."""

    disable_deployment_size_validation: bool = betterproto.bool_field(69)
    """Whether the deployment size validation is disabled."""

    workload: str = betterproto.string_field(70)
    """The name of the workload that owns this deployment."""

    spot: bool = betterproto.bool_field(71)
    """Whether to use spot instances for this deployment."""


@dataclass(eq=False, repr=False)
class Placement(betterproto.Message):
    """
    The desired geographic region where the deployment must be placed. Exactly one field will be
    specified.
    """

    region: "Region" = betterproto.enum_field(1)
    """The region where the deployment must be placed."""

    multi_region: "MultiRegion" = betterproto.enum_field(2)
    """The multi-region where the deployment must be placed."""

    regions: List["Region"] = betterproto.enum_field(3)
    """The list of regions where the deployment must be placed"""


@dataclass(eq=False, repr=False)
class AutoTune(betterproto.Message):
    """ """

    long_prompt: bool = betterproto.bool_field(1)
    """If true, this deployment is optimized for long prompt lengths."""


@dataclass(eq=False, repr=False)
class AutoscalingPolicy(betterproto.Message):
    """ """

    scale_up_window: timedelta = betterproto.message_field(3)
    """
    The duration the autoscaler will wait before scaling up a deployment after observing
    increased load. Default is 30s.
    """

    scale_down_window: timedelta = betterproto.message_field(2)
    """
    The duration the autoscaler will wait before scaling down a deployment after observing
    decreased load. Default is 10m.
    """

    scale_to_zero_window: timedelta = betterproto.message_field(1)
    """
    The duration after which there are no requests that the deployment will be scaled down
    to zero replicas, if min_replica_count==0. Default is 1h.
    This must be at least 5 minutes.
    """

    load_targets: Dict[str, float] = betterproto.map_field(
        4, betterproto.TYPE_STRING, betterproto.TYPE_FLOAT
    )
    """
    Map of load metric names to their target utilization factors.
    Currently only the "default" key is supported, which specifies the default target for all metrics.
    If not specified, the default target is 0.8
    """


@dataclass(eq=False, repr=False)
class CreateDeploymentRequest(betterproto.Message):
    """Next ID: 8"""

    parent: str = betterproto.string_field(1)
    """The resource name of the parent account."""

    deployment: "Deployment" = betterproto.message_field(2)
    """The properties of the deployment being created."""

    disable_auto_deploy: bool = betterproto.bool_field(5)
    """
    By default, a deployment created with a currently undeployed base model
    will be deployed to this deployment. If true, this auto-deploy function
    is disabled.
    """

    disable_speculative_decoding: bool = betterproto.bool_field(6)
    """
    By default, a deployment will use the speculative decoding settings from
    the base model. If true, this will disable speculative decoding.
    """

    deployment_id: str = betterproto.string_field(7)
    """
    The ID of the deployment. If not specified, a random ID will be generated.
    """

    dry_run: bool = betterproto.bool_field(8)
    """
    If true, this will not create the deployment, but will return the deployment
    that would be created.
    """


@dataclass(eq=False, repr=False)
class GetDeploymentRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the deployment."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListDeploymentsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """Resource name of the parent deployment."""

    page_size: int = betterproto.int32_field(2)
    """
    The maximum number of deployments to return. The maximum page_size is 200,
    values above 200 will be coerced to 200.
    If unspecified, the default is 50.
    """

    page_token: str = betterproto.string_field(3)
    """
    A page token, received from a previous ListDeployments call. Provide this
    to retrieve the subsequent page. When paginating, all other parameters
    provided to ListDeployments must match the call that provided the page
    token.
    """

    filter: str = betterproto.string_field(4)
    """
    Only deployment satisfying the provided filter (if specified) will be
    returned. See https://google.aip.dev/160 for the filter grammar.
    """

    order_by: str = betterproto.string_field(5)
    """
    A comma-separated list of fields to order by. e.g. "foo,bar"
    The default sort order is ascending. To specify a descending order for a
    field, append a " desc" suffix. e.g. "foo desc,bar"
    Subfields are specified with a "." character. e.g. "foo.bar"
    If not specified, the default order is by "create_time".
    """

    show_deleted: bool = betterproto.bool_field(6)
    """If set, DELETED deployments will be included."""

    show_internal: bool = betterproto.bool_field(7)
    """If set, internal resources will be included."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        8
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListDeploymentsResponse(betterproto.Message):
    """ """

    deployments: List["Deployment"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of deployments."""


@dataclass(eq=False, repr=False)
class UpdateDeploymentRequest(betterproto.Message):
    """ """

    deployment: "Deployment" = betterproto.message_field(1)
    """
    The properties of the deployment being updated. `deployment.name` must
    be populated with the updated resource's name.
    """

    update_mask: "betterproto_lib_google_protobuf.FieldMask" = (
        betterproto.message_field(2)
    )
    """List of field paths to be updated. If empty we replace all fields."""


@dataclass(eq=False, repr=False)
class DeleteDeploymentRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the deployment."""

    hard: bool = betterproto.bool_field(2)
    """If true, this will perform a hard deletion."""

    ignore_checks: bool = betterproto.bool_field(3)
    """
    If true, this will ignore checks and force the deletion of a deployment that is currently
    deployed and is in use.
    """


@dataclass(eq=False, repr=False)
class UndeleteDeploymentRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the deployment."""


@dataclass(eq=False, repr=False)
class ScaleDeploymentRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the deployment."""

    replica_count: int = betterproto.int32_field(2)
    """The desired number of replicas."""


@dataclass(eq=False, repr=False)
class GetDeploymentMetricsRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the deployment."""

    time_range: str = betterproto.string_field(2)
    """
    The time range to fetch metrics for (e.g. "1m", "10m", "2h"). Defaults to 10m.
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        3
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class GetDeploymentMetricsResponse(betterproto.Message):
    """ """

    metrics: Dict[str, float] = betterproto.map_field(
        1, betterproto.TYPE_STRING, betterproto.TYPE_DOUBLE
    )
    """Map of metric name to metric value for the specified time range"""


@dataclass(eq=False, repr=False)
class GetDeploymentPrerequisitesRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    The resource name of the account where the deployment will be created.
    """

    name: str = betterproto.string_field(2)
    """The resource name of the base model."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        3
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class DeploymentPrerequisites(betterproto.Message):
    """ """

    accelerator_configs: List["DeploymentAcceleratorConfig"] = (
        betterproto.message_field(1)
    )
    """
    
    """


@dataclass(eq=False, repr=False)
class DeploymentAcceleratorConfig(betterproto.Message):
    """ """

    accelerator_type: "AcceleratorType" = betterproto.enum_field(1)
    """Key: The accelerator type for this config"""

    precision: "DeploymentPrecision" = betterproto.enum_field(2)
    """Key: Supported precisions."""

    min_accelerator_count: int = betterproto.int32_field(3)
    """Value: Minimum number of accelerators required."""

    regions: List["Region"] = betterproto.enum_field(4)
    """
    Value: Regions where the account has quota for this accelerator type.
    """


@dataclass(eq=False, repr=False)
class ListDeploymentMetricsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The resource name of the deployment. Can contain wildcards."""

    account: str = betterproto.string_field(2)
    """
    The resource name of the account. Required if parent contains wildcards.
    """

    model: str = betterproto.string_field(3)
    """The resource name of the model. Can contain wildcards."""

    metric: "Metrics" = betterproto.enum_field(4)
    """The metric to fetch time series for."""

    start: datetime = betterproto.message_field(5)
    """The start time for the time series data."""

    end: datetime = betterproto.message_field(6)
    """The end time for the time series data."""

    interval: timedelta = betterproto.message_field(7)
    """
    The interval between data points. Defaults to 1m.
    This value is also used as the step size for data aggregation.
    """

    group_by: str = betterproto.string_field(8)
    """
    Optional field to override the default grouping logic.
    If specified, this will be used as the 'by' clause in the Prometheus query. e.g. "status_code"
    """

    percentiles: List[float] = betterproto.float_field(9)
    """
    The percentiles to calculate for percentile metrics (e.g. [0.5, 0.9, 0.99])
    Only used when metric is a percentile metric type
    """


@dataclass(eq=False, repr=False)
class TimeSeriesPoint(betterproto.Message):
    """ """

    timestamp: int = betterproto.int64_field(1)
    """Unix timestamp in seconds"""

    value: str = betterproto.string_field(2)
    """The value at this timestamp"""


@dataclass(eq=False, repr=False)
class TimeSeries(betterproto.Message):
    """ """

    labels: Dict[str, str] = betterproto.map_field(
        1, betterproto.TYPE_STRING, betterproto.TYPE_STRING
    )
    """
    Labels for this time series (e.g. {"deployment": "deploy1", "instance": "pod1"})
    """

    values: List["TimeSeriesPoint"] = betterproto.message_field(2)
    """Array of [timestamp, value] pairs for this series"""


@dataclass(eq=False, repr=False)
class ListDeploymentMetricsResponse(betterproto.Message):
    """ """

    series: List["TimeSeries"] = betterproto.message_field(1)
    """Array of time series, each with its own labels and values"""


@dataclass(eq=False, repr=False)
class JobProgress(betterproto.Message):
    """Progress of a job, e.g. RLOR, EVJ, BIJ etc."""

    percent: int = betterproto.int32_field(1)
    """Progress percent, within the range from 0 to 100."""

    epoch: int = betterproto.int32_field(2)
    """
    The epoch for which the progress percent is reported, usually starting from 0.
    This is optional for jobs that don't run in an epoch fasion, e.g. BIJ, EVJ.
    """

    chunk: int = betterproto.int32_field(3)
    """The chunk index, now only available for RFT epoch."""

    total_input_requests: int = betterproto.int32_field(4)
    """Total number of input requests/rows in the job."""

    total_processed_requests: int = betterproto.int32_field(5)
    """
    Total number of requests that have been processed (successfully or failed).
    """

    successfully_processed_requests: int = betterproto.int32_field(6)
    """Number of requests that were processed successfully."""

    failed_requests: int = betterproto.int32_field(7)
    """Number of requests that failed to process."""

    output_rows: int = betterproto.int32_field(8)
    """Number of output rows generated."""

    input_tokens: int = betterproto.int32_field(9)
    """Total number of input tokens processed."""

    output_tokens: int = betterproto.int32_field(10)
    """Total number of output tokens generated."""


@dataclass(eq=False, repr=False)
class BatchInferenceJob(betterproto.Message):
    """Next ID: 27"""

    name: str = betterproto.string_field(1)
    """
    The resource name of the batch inference job. e.g. accounts/my-account/batchInferenceJobs/my-batch-inference-job
    """

    display_name: str = betterproto.string_field(2)
    """
    Human-readable display name of the batch inference job. e.g. "My Batch Inference Job"
    """

    create_time: datetime = betterproto.message_field(3)
    """The creation time of the batch inference job."""

    expire_time: datetime = betterproto.message_field(4)
    """
    The time when the batch inference job will expire, and any completed requests will be written to the output dataset.
    """

    created_by: str = betterproto.string_field(5)
    """
    The email address of the user who initiated this batch inference job.
    """

    state: "JobState" = betterproto.enum_field(6)
    """JobState represents the state an asynchronous job can be in."""

    status: "Status" = betterproto.message_field(7)
    """
    
    """

    model: str = betterproto.string_field(8)
    """The name of the model to use for inference."""

    input_dataset_id: str = betterproto.string_field(9)
    """The name of the dataset used for inference."""

    output_dataset_id: str = betterproto.string_field(10)
    """
    The name of the dataset used for storing the results. This will also contain the error file.
    """

    append_to_messages: "AppendToMessages" = betterproto.message_field(
        11, group="format"
    )
    """
    
    """

    inference_parameters: "InferenceParameters" = betterproto.message_field(12)
    """Parameters controlling the inference process."""

    update_time: datetime = betterproto.message_field(13)
    """The update time for the batch inference job."""

    ending_assistant_messages: str = betterproto.string_field(14)
    """
    Specifies how to handle trailing assistant messages when generating a response.
    Valid values are "continue_from" or "drop".
    If "continue_from", the model will continue from any trailing assistant messages.
    If "drop", the model will ignore any trailing assistant messages.
    If unspecified (null or empty string), the dataset rows should not end with any assistant messages.
    """

    region: "Region" = betterproto.enum_field(15)
    """The region where the batch inference job will be run."""

    max_replica_count: Optional[int] = betterproto.int32_field(16, optional=True)
    """
    Maximum number of replicas to use for the deployment.
    Default is 1
    """

    accelerator_type: "AcceleratorType" = betterproto.enum_field(17)
    """
    The type of accelerator to use.
    If not specified, a default will be chosen based on the model.
    """

    accelerator_count: Optional[int] = betterproto.int32_field(18, optional=True)
    """
    The number of accelerators to use per replica.
    If not specified, a default will be chosen based on the model.
    """

    precision: "DeploymentPrecision" = betterproto.enum_field(19)
    """
    The precision with which the model should be served.
    If PRECISION_UNSPECIFIED, a default will be chosen based on the model.
    """

    reinforcement_fine_tuning_epoch_id: str = betterproto.string_field(20)
    """The ID of the RFT epoch that this batch inference job belongs to."""

    skip_dataset_validation: bool = betterproto.bool_field(21)
    """Whether to skip dataset validation."""

    job_progress: "JobProgress" = betterproto.message_field(22)
    """Job progress."""

    priority: int = betterproto.int32_field(23)
    """
    The priority of the batch inference job
    If not specified, will default to 0
    """

    toleration: str = betterproto.string_field(24)
    """The taint key to tolerate for the batch inference job."""

    deployment_extra_args: List[str] = betterproto.string_field(25)
    """The extra args for deployment"""

    mcp_server: str = betterproto.string_field(26)
    """MCP server for rollout-based batch inference (used with RFT)"""

    continued_from_job_name: str = betterproto.string_field(27)
    """
    The resource name of the batch inference job that this job continues from.
    Used for lineage tracking to understand job continuation chains.
    """


@dataclass(eq=False, repr=False)
class InferenceParameters(betterproto.Message):
    """Parameters for the inference requests."""

    max_tokens: Optional[int] = betterproto.int32_field(1, optional=True)
    """Maximum number of tokens to generate per response."""

    temperature: Optional[float] = betterproto.float_field(2, optional=True)
    """Sampling temperature, typically between 0 and 2."""

    top_p: Optional[float] = betterproto.float_field(3, optional=True)
    """Top-p sampling parameter, typically between 0 and 1."""

    n: Optional[int] = betterproto.int32_field(4, optional=True)
    """Number of response candidates to generate per input."""

    extra_body: str = betterproto.string_field(5)
    """
    Additional parameters for the inference request as a JSON string.
    For example: "{\"stop\": [\"\\n\"]}".
    """

    top_k: Optional[int] = betterproto.int32_field(6, optional=True)
    """
    Top-k sampling parameter, limits the token selection to the top k tokens.
    """


@dataclass(eq=False, repr=False)
class AppendToMessages(betterproto.Message):
    """
    AppendToMessages specifies the appending behavior in formatting the output of
    the batch inference job. If the last message is a user message, the output
    will be appended to the last message. If the last message is an assistant
    message, the model output will overwrite the content of that message.

    Let the following be the content of dataset.jsonl:
    {"messages": [{"role": "user", "content": "hi"}, {"role": "assistant", "content": "hello"}]}
    {"messages": [{"role": "user", "content": "hi"}}
    {"messages": [{"role": "system", "content": "you are a helpful assistant"}, {"role": "user", "content": "hi"}}

    Assuming the target model will always respond with `RESPONSE`, the output dataset will contain the following:
    {"messages": [{"role": "user", "content": "hi"}, {"role": "assistant", "content": "RESPONSE"}]}
    {"messages": [{"role": "user", "content": "hi"}, {"role": "assistant", "content": "RESPONSE"}]}
    {"messages": [{"role": "system", "content": "you are a helpful assistant"}, {"role": "user", "content": "hi"}, {"role": "assistant", "content": "RESPONSE"}]}
    """

    unroll_multiple_responses: bool = betterproto.bool_field(1)
    """
    When n > 1, if true, creates separate output records for each response; otherwise, includes all responses in one record.
    """


@dataclass(eq=False, repr=False)
class GetBatchInferenceJobRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the batch inference job."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class CreateBatchInferenceJobRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    
    """

    batch_inference_job: "BatchInferenceJob" = betterproto.message_field(2)
    """
    
    """

    batch_inference_job_id: str = betterproto.string_field(3)
    """ID of the batch inference job."""


@dataclass(eq=False, repr=False)
class ListBatchInferenceJobsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    
    """

    page_size: int = betterproto.int32_field(2)
    """
    The maximum number of batch inference jobs to return. The maximum page_size is 200,
    values above 200 will be coerced to 200.
    If unspecified, the default is 50.
    """

    page_token: str = betterproto.string_field(3)
    """
    A page token, received from a previous ListBatchInferenceJobs call. Provide this
    to retrieve the subsequent page. When paginating, all other parameters
    provided to ListBatchInferenceJobs must match the call that provided the page
    token.
    """

    filter: str = betterproto.string_field(4)
    """
    Only jobs satisfying the provided filter (if specified) will be
    returned. See https://google.aip.dev/160 for the filter grammar.
    """

    order_by: str = betterproto.string_field(5)
    """
    A comma-separated list of fields to order by. e.g. "foo,bar"
    The default sort order is ascending. To specify a descending order for a
    field, append a " desc" suffix. e.g. "foo desc,bar"
    Subfields are specified with a "." character. e.g. "foo.bar"
    If not specified, the default order is by "created_time".
    """

    show_internal: bool = betterproto.bool_field(6)
    """if showing internal resources"""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        7
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListBatchInferenceJobsResponse(betterproto.Message):
    """ """

    batch_inference_jobs: List["BatchInferenceJob"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of batch inference jobs."""


@dataclass(eq=False, repr=False)
class UpdateBatchInferenceJobRequest(betterproto.Message):
    """ """

    batch_inference_job: "BatchInferenceJob" = betterproto.message_field(1)
    """
    The properties of the batch inference job being updated. `batch_inference_job.name` must
    be populated with the updated resource's name.
    """

    update_mask: "betterproto_lib_google_protobuf.FieldMask" = (
        betterproto.message_field(2)
    )
    """List of field paths to be updated. If empty we replace all fields."""


@dataclass(eq=False, repr=False)
class DeleteBatchInferenceJobRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the batch inference job."""


@dataclass(eq=False, repr=False)
class GetBatchInferenceJobInputUploadEndpointRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """
    
    """

    filename_to_size: Dict[str, int] = betterproto.map_field(
        2, betterproto.TYPE_STRING, betterproto.TYPE_INT64
    )
    """
    A maping from file name to expected size, used for generating signed URLs
    for uploading the files.
    """


@dataclass(eq=False, repr=False)
class GetBatchInferenceJobInputUploadEndpointResponse(betterproto.Message):
    """ """

    filename_to_signed_urls: Dict[str, str] = betterproto.map_field(
        1, betterproto.TYPE_STRING, betterproto.TYPE_STRING
    )
    """Signed URLs for users to upload their input to GCS."""


@dataclass(eq=False, repr=False)
class ValidateBatchInferenceJobInputUploadRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """
    
    """


@dataclass(eq=False, repr=False)
class GetBatchInferenceJobOutputDownloadEndpointRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """
    
    """


@dataclass(eq=False, repr=False)
class GetBatchInferenceJobOutputDownloadEndpointResponse(betterproto.Message):
    """ """

    filename_to_signed_urls: Dict[str, str] = betterproto.map_field(
        1, betterproto.TYPE_STRING, betterproto.TYPE_STRING
    )
    """Signed URLs for users to download their input from GCS."""


@dataclass(eq=False, repr=False)
class BatchJob(betterproto.Message):
    """Next ID: 22"""

    name: str = betterproto.string_field(1)
    """
    The resource name of the batch job.
    e.g. accounts/my-account/clusters/my-cluster/batchJobs/123456789
    """

    display_name: str = betterproto.string_field(9)
    """
    Human-readable display name of the batch job. e.g. "My Batch Job"
    Must be fewer than 64 characters long.
    """

    create_time: datetime = betterproto.message_field(12)
    """The creation time of the batch job."""

    start_time: datetime = betterproto.message_field(14)
    """The time when the batch job started running."""

    end_time: datetime = betterproto.message_field(15)
    """The time when the batch job completed, failed, or was cancelled."""

    created_by: str = betterproto.string_field(13)
    """The email address of the user who created this batch job."""

    node_pool_id: str = betterproto.string_field(2)
    """
    The ID of the node pool that this batch job should use. e.g. my-node-pool
    """

    environment_id: str = betterproto.string_field(3)
    """
    The ID of the environment that this batch job should use. e.g. my-env
    If specified, image_ref must not be specified.
    """

    snapshot_id: str = betterproto.string_field(19)
    """
    The ID of the snapshot used by this batch job.
    If specified, environment_id must be specified and image_ref must not be
    specified.
    """

    num_ranks: int = betterproto.int32_field(11)
    """
    For GPU node pools: one GPU per rank w/ host packing,
    for CPU node pools: one host per rank.
    """

    env_vars: Dict[str, str] = betterproto.map_field(
        6, betterproto.TYPE_STRING, betterproto.TYPE_STRING
    )
    """Environment variables to be passed during this job's execution."""

    role: str = betterproto.string_field(17)
    """
    The ARN of the AWS IAM role that the batch job should assume.
    If not specified, the connection will fall back to the node
    pool's node_role.
    """

    python_executor: "PythonExecutor" = betterproto.message_field(
        7, group="executor_type"
    )
    """
    
    """

    notebook_executor: "NotebookExecutor" = betterproto.message_field(
        8, group="executor_type"
    )
    """
    
    """

    shell_executor: "ShellExecutor" = betterproto.message_field(
        16, group="executor_type"
    )
    """
    
    """

    image_ref: str = betterproto.string_field(10)
    """
    The container image used by this job. If specified, environment_id and
    snapshot_id must not be specified.
    """

    annotations: Dict[str, str] = betterproto.map_field(
        18, betterproto.TYPE_STRING, betterproto.TYPE_STRING
    )
    """
    Arbitrary, user-specified metadata.
    Keys and values must adhere to Kubernetes constraints: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/#syntax-and-character-set
    Additionally, the "fireworks.ai/" prefix is reserved.
    """

    state: "BatchJobState" = betterproto.enum_field(4)
    """The current state of the batch job."""

    status: str = betterproto.string_field(5)
    """Detailed information about the current status of the batch job."""

    shared: bool = betterproto.bool_field(20)
    """
    Whether the batch job is shared with all users in the account.
    This allows all users to update, delete, clone, and create environments
    using the batch job.
    """

    update_time: datetime = betterproto.message_field(21)
    """The update time for the batch job."""


@dataclass(eq=False, repr=False)
class CreateBatchJobRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The resource name of the parent cluster."""

    batch_job: "BatchJob" = betterproto.message_field(2)
    """The properties of the batch job being created."""


@dataclass(eq=False, repr=False)
class GetBatchJobRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the batch job."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListBatchJobsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """Resource name of the parent cluster."""

    page_size: int = betterproto.int32_field(2)
    """
    The maximum number of batch jobs to return. The maximum page_size is 200,
    values above 200 will be coerced to 200.
    If unspecified, the default is 50.
    """

    page_token: str = betterproto.string_field(3)
    """
    A page token, received from a previous ListBatchJobs call. Provide this
    to retrieve the subsequent page. When paginating, all other parameters
    provided to ListBatchJobs must match the call that provided the page
    token.
    """

    filter: str = betterproto.string_field(4)
    """
    Only batch jobs satisfying the provided filter (if specified) will be
    returned. See https://google.aip.dev/160 for the filter grammar.
    """

    order_by: str = betterproto.string_field(5)
    """
    A comma-separated list of fields to order by. e.g. "foo,bar"
    The default sort order is ascending. To specify a descending order for a
    field, append a " desc" suffix. e.g. "foo desc,bar"
    Subfields are specified with a "." character. e.g. "foo.bar"
    If not specified, the default order is by "create_time desc".
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListBatchJobsResponse(betterproto.Message):
    """ """

    batch_jobs: List["BatchJob"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of batch jobs."""


@dataclass(eq=False, repr=False)
class UpdateBatchJobRequest(betterproto.Message):
    """ """

    batch_job: "BatchJob" = betterproto.message_field(1)
    """
    The properties of the batch job being updated. `batch_job.name` must
    be populated with the updated resource's name.
    """

    update_mask: "betterproto_lib_google_protobuf.FieldMask" = (
        betterproto.message_field(2)
    )
    """List of field paths to be updated. If empty we replace all fields."""


@dataclass(eq=False, repr=False)
class DeleteBatchJobRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the batch job."""


@dataclass(eq=False, repr=False)
class BatchDeleteBatchJobsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The resource name of the parent cluster."""

    names: List[str] = betterproto.string_field(2)
    """The resource names of the batch jobs to delete."""


@dataclass(eq=False, repr=False)
class CancelBatchJobRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the batch job."""


@dataclass(eq=False, repr=False)
class GetBatchJobLogsRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the batch job."""

    ranks: List[int] = betterproto.int32_field(3)
    """Ranks, for which to fetch logs."""

    page_size: int = betterproto.int32_field(4)
    """
    The maximum number of log entries to return. The maximum page_size is 10,000,
    values above 10,000 will be coerced to 10,000.
    If unspecified, the default is 100.
    """

    page_token: str = betterproto.string_field(5)
    """
    A page token, received from a previous GetBatchJobLogsRequest call. Provide this
    to retrieve the subsequent page. When paginating, all other parameters
    provided to GetBatchJobLogsRequest must match the call that provided the page
    token.
    """

    start_time: datetime = betterproto.message_field(6)
    """
    Entries before this timestamp won't be returned.
    If not specified, up to page_size last records will be returned.
    """

    filter: str = betterproto.string_field(7)
    """
    Only entries matching this filter will be returned.
    Currently only basic substring match is performed.
    """

    start_from_head: bool = betterproto.bool_field(8)
    """
    Pagination direction, time-wise reverse direction by default (false).
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        9
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class GetBatchJobLogsResponse(betterproto.Message):
    """ """

    entries: List["LogEntry"] = betterproto.message_field(2)
    """
    
    """

    next_page_token: str = betterproto.string_field(3)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """


@dataclass(eq=False, repr=False)
class PythonExecutor(betterproto.Message):
    """Execute a Python process."""

    target_type: "PythonExecutorTargetType" = betterproto.enum_field(1)
    """The type of Python target to run."""

    target: str = betterproto.string_field(2)
    """A Python module or filename depending on TargetType."""

    args: List[str] = betterproto.string_field(3)
    """Command line arguments to pass to the Python process."""


@dataclass(eq=False, repr=False)
class ShellExecutor(betterproto.Message):
    """Execute a shell script."""

    command: str = betterproto.string_field(1)
    """Command we want to run for the shell script"""


@dataclass(eq=False, repr=False)
class NotebookExecutor(betterproto.Message):
    """Execute a notebook file."""

    notebook_filename: str = betterproto.string_field(1)
    """Path to a notebook file to be executed."""


@dataclass(eq=False, repr=False)
class LogEntry(betterproto.Message):
    """ """

    log_time: datetime = betterproto.message_field(1)
    """The timestamp of the log entry."""

    rank: int = betterproto.int32_field(2)
    """The rank which produced the log entry."""

    message: str = betterproto.string_field(3)
    """The log messsage."""


@dataclass(eq=False, repr=False)
class GetBalanceRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The account name of the customer."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class Balance(betterproto.Message):
    """ """

    money: "_google_type__.Money" = betterproto.message_field(1)
    """
    Current remaining balance of the developer for a particular currency.
    """


@dataclass(eq=False, repr=False)
class ListPaymentMethodsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The account name of the customer."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class StripeCheckoutSession(betterproto.Message):
    """ """

    id: str = betterproto.string_field(1)
    """ID of the checkout session."""

    checkout_url: str = betterproto.string_field(2)
    """
    The URL to the Checkout Session. Redirect customers to this URL to take them to Checkout.
    """

    mode: "StripeCheckoutSessionMode" = betterproto.enum_field(3)
    """
    
    """

    amount: "_google_type__.Money" = betterproto.message_field(4)
    """
    Amount intended to be collected by this checkout.
    Populated for PAYMENT mode.
    """

    create_time: datetime = betterproto.message_field(5)
    """
    
    """


@dataclass(eq=False, repr=False)
class ListPaymentMethodsResponse(betterproto.Message):
    """ """

    default_payment_method_id: str = betterproto.string_field(1)
    """
    
    """

    stripe_payment_methods: List["ListPaymentMethodsResponseStripePaymentMethod"] = (
        betterproto.message_field(2)
    )
    """
    
    """

    pending_checkout_sessions: List["StripeCheckoutSession"] = (
        betterproto.message_field(3)
    )
    """
    Pending checkout sessions that are still processing
    the payment methods.
    """


@dataclass(eq=False, repr=False)
class ListPaymentMethodsResponseCard(betterproto.Message):
    """ """

    brand: str = betterproto.string_field(1)
    """Credit card brand."""

    last4: str = betterproto.string_field(2)
    """Last 4 digits of the credit card."""

    exp_month: int = betterproto.int32_field(3)
    """Expiration month."""

    exp_year: int = betterproto.int32_field(4)
    """Expiration year."""


@dataclass(eq=False, repr=False)
class ListPaymentMethodsResponseUsBankAccount(betterproto.Message):
    """ """

    bank_name: str = betterproto.string_field(1)
    """
    
    """

    last4: str = betterproto.string_field(2)
    """Last four digits of the bank account number."""


@dataclass(eq=False, repr=False)
class ListPaymentMethodsResponseStripePaymentMethod(betterproto.Message):
    """ """

    id: str = betterproto.string_field(1)
    """Payment method ID."""

    card: "ListPaymentMethodsResponseCard" = betterproto.message_field(2, group="type")
    """Card used by the payment method."""

    us_bank_account: "ListPaymentMethodsResponseUsBankAccount" = (
        betterproto.message_field(3, group="type")
    )
    """ACH Direct Debit"""


@dataclass(eq=False, repr=False)
class ListCostsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The account name of the customer."""

    start_time: datetime = betterproto.message_field(2)
    """Costs returned are inclusive of `start_time`."""

    end_time: datetime = betterproto.message_field(3)
    """Costs returned are exclusive of `end_time`."""

    cumulative: bool = betterproto.bool_field(4)
    """
    If true, returns cumulative costs since the start of the
    billing period. Otherwise, will return day-by-day costs.
    """


@dataclass(eq=False, repr=False)
class ListCostsResponse(betterproto.Message):
    """ """

    cost_data_items: List["ListCostsResponseCostDataItem"] = betterproto.message_field(
        1
    )
    """
    
    """


@dataclass(eq=False, repr=False)
class ListCostsResponseCostDataItem(betterproto.Message):
    """ """

    subtotal: "_google_type__.Money" = betterproto.message_field(1)
    """The amount before any credits and discounts are applied."""

    total: "_google_type__.Money" = betterproto.message_field(2)
    """The total amount after any credits and discounts have been applied."""

    start_time: datetime = betterproto.message_field(3)
    """Costs returned are inclusive of `start_time`."""

    end_time: datetime = betterproto.message_field(4)
    """Costs returned are exclusive of `end_time`."""


@dataclass(eq=False, repr=False)
class ListInvoicesRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The account name of the customer."""

    pending: bool = betterproto.bool_field(2)
    """
    If true, will only return the upcoming invoices for
    the current billing period.
    Otherwise, returns all past and upcoming invoices.
    """

    page_size: int = betterproto.int32_field(3)
    """dummy fields to be compatible with list.ListAndPrint"""

    page_token: str = betterproto.string_field(4)
    """
    
    """

    filter: str = betterproto.string_field(5)
    """
    
    """

    order_by: str = betterproto.string_field(6)
    """
    
    """


@dataclass(eq=False, repr=False)
class Invoice(betterproto.Message):
    """ """

    id: str = betterproto.string_field(1)
    """ID of the invoice"""

    amount_due: "_google_type__.Money" = betterproto.message_field(2)
    """
    This is the final amount required to be charged to the customer
    after any credits, discounts and customer balance have been applied.
    """

    invoice_url: str = betterproto.string_field(3)
    """A URL for the invoice portal."""

    state: "InvoiceState" = betterproto.enum_field(4)
    """
    
    """

    target_time: datetime = betterproto.message_field(5)
    """The scheduled time of the invoice."""

    paid_time: datetime = betterproto.message_field(6)
    """The timestamp when the invoice was paid."""


@dataclass(eq=False, repr=False)
class ListInvoicesResponse(betterproto.Message):
    """ """

    invoices: List["Invoice"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """dummy fields to be compatible with list.ListAndPrint"""

    total_size: int = betterproto.int32_field(3)
    """
    
    """


@dataclass(eq=False, repr=False)
class SkuInfo(betterproto.Message):
    """ """

    sku: str = betterproto.string_field(1)
    """
    
    """

    amount: "_google_type__.Money" = betterproto.message_field(2)
    """
    
    """

    unit: str = betterproto.string_field(3)
    """
    e.g.
    1M tokens, hour
    """


@dataclass(eq=False, repr=False)
class ExportBillingMetricsRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The account name."""

    start_time: datetime = betterproto.message_field(2)
    """
    Only metrics starting from this time will be included.
    If not specified, the default is 24 hours before the end_time.
    """

    end_time: datetime = betterproto.message_field(3)
    """
    Only metrics up to this time will be included.
    If not specified, the default is the current time.
    """


@dataclass(eq=False, repr=False)
class ExportBillingMetricsResponse(betterproto.Message):
    """ """

    signed_urls: List[str] = betterproto.string_field(1)
    """
    The signed URL of the exported file(s).
    There will be exactly one file. This may change in the future.
    """


@dataclass(eq=False, repr=False)
class GetTotalHistoricalSpendRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the account."""


@dataclass(eq=False, repr=False)
class GetTotalHistoricalSpendResponse(betterproto.Message):
    """ """

    spend: "_google_type__.Money" = betterproto.message_field(1)
    """
    
    """


@dataclass(eq=False, repr=False)
class ListHuggingFaceBillingCostsRecords(betterproto.Message):
    """Request to get billing costs for specific request IDs"""

    parent: str = betterproto.string_field(1)
    """The account this request belongs to"""

    request_ids: List[str] = betterproto.string_field(2)
    """List of request IDs to get costs for"""


@dataclass(eq=False, repr=False)
class BillingRequestCostRecord(betterproto.Message):
    """Individual billing request cost Record"""

    request_id: str = betterproto.string_field(1)
    """Request ID"""

    cost_nano_usd: float = betterproto.double_field(2)
    """Cost"""


@dataclass(eq=False, repr=False)
class ListHuggingFaceBillingCostsResponse(betterproto.Message):
    """Response with billing costs for requested IDs"""

    requests: List["BillingRequestCostRecord"] = betterproto.message_field(1)
    """Records matching the requested IDs"""


@dataclass(eq=False, repr=False)
class GetAccountUsageRequest(betterproto.Message):
    """Request to get costs broken down by deployment type and model"""

    name: str = betterproto.string_field(1)
    """The account name of the customer."""

    start_time: datetime = betterproto.message_field(2)
    """Costs returned are inclusive of `start_time`."""

    end_time: datetime = betterproto.message_field(3)
    """Costs returned are exclusive of `end_time`."""


@dataclass(eq=False, repr=False)
class AccountUsage(betterproto.Message):
    """Response with model costs by deployment type"""

    serverless_costs: List["AccountUsageServerlessUsage"] = betterproto.message_field(1)
    """List of serverless cost data"""

    dedicated_costs: List["AccountUsageDedicatedDeploymentUsage"] = (
        betterproto.message_field(2)
    )
    """List of dedicated deployment cost data"""


@dataclass(eq=False, repr=False)
class AccountUsageServerlessUsage(betterproto.Message):
    """Raw data from BigQuery for serverless deployments"""

    model_name: str = betterproto.string_field(1)
    """The model name"""

    prompt_tokens: int = betterproto.int64_field(2)
    """Number of prompt tokens (for text inference)"""

    completion_tokens: int = betterproto.int64_field(3)
    """Number of completion tokens (for text inference)"""

    start_time: datetime = betterproto.message_field(4)
    """Start time of the usage"""

    end_time: datetime = betterproto.message_field(5)
    """End time of the usage"""

    audio_input_seconds: float = betterproto.double_field(6)
    """Audio input seconds (for audio inference)"""

    usage_type: str = betterproto.string_field(7)
    """Usage type to distinguish between different inference types"""


@dataclass(eq=False, repr=False)
class AccountUsageDedicatedDeploymentUsage(betterproto.Message):
    """Raw data from BigQuery for dedicated deployments"""

    deployment_id: str = betterproto.string_field(1)
    """The deployment ID"""

    accelerator_type: str = betterproto.string_field(2)
    """GPU type / accelerator type"""

    accelerator_seconds: float = betterproto.double_field(3)
    """Accelerator seconds"""

    start_time: datetime = betterproto.message_field(4)
    """Start time of the usage"""

    end_time: datetime = betterproto.message_field(5)
    """End time of the usage"""


@dataclass(eq=False, repr=False)
class Cluster(betterproto.Message):
    """Next ID: 15"""

    name: str = betterproto.string_field(1)
    """
    The resource name of the cluster. e.g. accounts/my-account/clusters/my-cluster
    """

    display_name: str = betterproto.string_field(6)
    """
    Human-readable display name of the cluster. e.g. "My Cluster"
    Must be fewer than 64 characters long.
    """

    create_time: datetime = betterproto.message_field(9)
    """The creation time of the cluster."""

    eks_cluster: "EksCluster" = betterproto.message_field(7, group="cluster_type")
    """
    
    """

    fake_cluster: "FakeCluster" = betterproto.message_field(3, group="cluster_type")
    """
    
    """

    annotations: Dict[str, str] = betterproto.map_field(
        10, betterproto.TYPE_STRING, betterproto.TYPE_STRING
    )
    """
    Arbitrary, user-specified metadata.
    Keys and values must adhere to Kubernetes constraints: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/#syntax-and-character-set
    Additionally, the "fireworks.ai/" prefix is reserved.
    """

    state: "ClusterState" = betterproto.enum_field(5)
    """The current state of the cluster."""

    status: "Status" = betterproto.message_field(8)
    """Detailed information about the current status of the cluster."""

    is_dlde: bool = betterproto.bool_field(11)
    """Whether this is a DLDE cluster. Defaults to false."""

    metering_key: str = betterproto.string_field(13)
    """The key used for tracking deployment usage on this cluster."""

    update_time: datetime = betterproto.message_field(14)
    """The update time for the cluster."""


@dataclass(eq=False, repr=False)
class EksCluster(betterproto.Message):
    """
    An Amazon Elastic Kubernetes Service cluster.
    Next ID: 16
    """

    aws_account_id: str = betterproto.string_field(9)
    """The 12-digit AWS account ID where this cluster lives."""

    fireworks_manager_role: str = betterproto.string_field(1)
    """
    The IAM role ARN used to manage Fireworks resources on AWS.
    If not specified, the default is arn:aws:iam::<aws_account_id>:role/FireworksManagerRole
    """

    region: str = betterproto.string_field(2)
    """
    The AWS region where this cluster lives. See https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.RegionsAndAvailabilityZones.html
    for a list of available regions.
    """

    cluster_role: str = betterproto.string_field(4)
    """
    The EKS cluster IAM role ARN used by the EKS control plane to manage
    your AWS resources. See https://docs.aws.amazon.com/eks/latest/userguide/service_IAM_role.html
    If not specified, the default is arn:aws:iam::<aws_account_id>:role/eksClusterRole
    """

    cluster_autoscaler_role: str = betterproto.string_field(10)
    """
    The IAM role ARN used by the EKS cluster autoscaler. The role must have
    the AmazonEKSClusterAutoscalerPolicy attached.
    If not specified, the default is arn:aws:iam::<aws_account_id>:role/AmazonEKSClusterAutoscalerRole
    """

    system_node_role: str = betterproto.string_field(7)
    """
    The IAM role ARN to associate with the system node group. The role must
    have the following IAM policies attached:
    - AmazonEKSWorkerNodePolicy
    - AmazonEC2ContainerRegistryReadOnly
    - AmazonEKS_CNI_Policy
    
    If not specified, the default is arn:aws:iam::<aws_account_id>:role/FireworksEKSNodeRole
    """

    subnet_ids: List[str] = betterproto.string_field(5)
    """
    A list of subnet IDs for your EKS nodes. Must specify subnets in at
    least two different availability zones.
    See https://docs.aws.amazon.com/eks/latest/APIReference/API_VpcConfigRequest.html#AmazonEKS-Type-VpcConfigRequest-subnetIds
    If not specified, the default subnets from the specified region will be used.
    """

    cluster_name: str = betterproto.string_field(3)
    """The EKS cluster name."""

    repository_name: str = betterproto.string_field(6)
    """The ECR repository name."""

    storage_bucket_name: str = betterproto.string_field(8)
    """The S3 bucket name."""

    node_security_group: str = betterproto.string_field(11)
    """Security group to use for cluster nodes in addition to default one."""

    metric_writer_role: str = betterproto.string_field(12)
    """
    The IAM role ARN used by Google Managed Prometheus role that will write metrics
    to Fireworks managed Prometheus. The role must be assumable by the
    `system:serviceaccount:gmp-system:collector` service account on the EKS cluster.
    If not specified, no metrics will be written to GCP.
    """

    load_balancer_controller_role: str = betterproto.string_field(13)
    """
    The IAM role ARN used by the EKS load balancer controller (i.e. the load balancer
    automatically created for the k8s gateway resource). If not specified, no gateway
    will be created.
    """

    workload_identity_pool_provider_id: str = betterproto.string_field(14)
    """
    The ID of the GCP workload identity pool provider in the Fireworks
    project for this cluster. The pool ID is assumed to be "byoc-pool"
    """

    inference_role: str = betterproto.string_field(15)
    """The IAM role ARN used by the inference pods on the cluster."""


@dataclass(eq=False, repr=False)
class FakeCluster(betterproto.Message):
    """
    A fake cluster using https://pkg.go.dev/k8s.io/client-go/kubernetes/fake
    """

    project_id: str = betterproto.string_field(1)
    """
    
    """

    location: str = betterproto.string_field(2)
    """
    
    """

    cluster_name: str = betterproto.string_field(3)
    """
    
    """


@dataclass(eq=False, repr=False)
class CreateClusterRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The resource name of the parent account."""

    cluster: "Cluster" = betterproto.message_field(2)
    """The properties of the cluster being created."""

    cluster_id: str = betterproto.string_field(3)
    """The cluster ID to use in the cluster name. e.g. my-cluster"""


@dataclass(eq=False, repr=False)
class GetClusterRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the cluster."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListClustersRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """Resource name of the parent account."""

    page_size: int = betterproto.int32_field(2)
    """
    The maximum number of clusters to return. The maximum page_size is 200,
    values above 200 will be coerced to 200.
    If unspecified, the default is 50.
    """

    page_token: str = betterproto.string_field(3)
    """
    A page token, received from a previous ListClusters call. Provide this
    to retrieve the subsequent page. When paginating, all other parameters
    provided to ListClusters must match the call that provided the page
    token.
    """

    filter: str = betterproto.string_field(4)
    """
    Only clusters satisfying the provided filter (if specified) will be
    returned. See https://google.aip.dev/160 for the filter grammar.
    """

    order_by: str = betterproto.string_field(5)
    """
    A comma-separated list of fields to order by. e.g. "foo,bar"
    The default sort order is ascending. To specify a descending order for a
    field, append a " desc" suffix. e.g. "foo desc,bar"
    Subfields are specified with a "." character. e.g. "foo.bar"
    If not specified, the default order is by "name".
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListClustersResponse(betterproto.Message):
    """ """

    clusters: List["Cluster"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of clusters."""


@dataclass(eq=False, repr=False)
class UpdateClusterRequest(betterproto.Message):
    """ """

    cluster: "Cluster" = betterproto.message_field(1)
    """
    The properties of the cluster being updated. `cluster.name` must
    be populated with the updated resource's name.
    """

    update_mask: "betterproto_lib_google_protobuf.FieldMask" = (
        betterproto.message_field(2)
    )
    """List of field paths to be updated. If empty we replace all fields."""


@dataclass(eq=False, repr=False)
class DeleteClusterRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the cluster."""


@dataclass(eq=False, repr=False)
class GetClusterConnectionInfoRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the cluster."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ClusterConnectionInfo(betterproto.Message):
    """ """

    endpoint: str = betterproto.string_field(1)
    """The cluster's Kubernetes API server endpoint."""

    ca_data: str = betterproto.string_field(2)
    """Base64-encoded cluster's CA certificate."""


@dataclass(eq=False, repr=False)
class Dataset(betterproto.Message):
    """Next ID: 22"""

    name: str = betterproto.string_field(1)
    """
    
    """

    display_name: str = betterproto.string_field(2)
    """
    
    """

    create_time: datetime = betterproto.message_field(3)
    """
    
    """

    state: "DatasetState" = betterproto.enum_field(4)
    """
    
    """

    status: "Status" = betterproto.message_field(6)
    """
    
    """

    example_count: int = betterproto.int64_field(7)
    """
    
    """

    access_policy: "DatasetAccessPolicy" = betterproto.enum_field(9)
    """
    
    """

    user_uploaded: "UserUploaded" = betterproto.message_field(11, group="data_source")
    """
    
    """

    evaluation_result: "EvaluationResult" = betterproto.message_field(
        15, group="data_source"
    )
    """
    
    """

    fireworks_traced: "FireworksTraced" = betterproto.message_field(
        12, group="data_source"
    )
    """
    
    """

    draft_model_states: "DraftModelStates" = betterproto.message_field(
        13, group="data_source"
    )
    """
    
    """

    transformed: "Transformed" = betterproto.message_field(18, group="data_source")
    """
    
    """

    splitted: "Splitted" = betterproto.message_field(19, group="data_source")
    """
    
    """

    external_url: str = betterproto.string_field(16)
    """The external URI of the dataset. e.g. gs://foo/bar/baz.jsonl"""

    format: "DatasetFormat" = betterproto.enum_field(10)
    """
    
    """

    created_by: str = betterproto.string_field(14)
    """The email address of the user who initiated this fine-tuning job."""

    update_time: datetime = betterproto.message_field(17)
    """The update time for the dataset."""

    source_job_name: str = betterproto.string_field(21)
    """
    The resource name of the job that created this dataset (e.g., batch inference job).
    Used for lineage tracking to understand dataset provenance.
    """


@dataclass(eq=False, repr=False)
class PreviewDatasetRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the dataset."""

    page_size: int = betterproto.int32_field(2)
    """The maximum number of examples to return per page."""

    page_token: str = betterproto.string_field(3)
    """
    A page token, received from a previous PreviewDataset call. Provide this to
    retrieve the subsequent page. When paginating, all other parameters
    provided to PreviewDataset must match the call that provided the page token.
    """

    filter: str = betterproto.string_field(4)
    """
    A filter expression to filter the results. See https://google.aip.dev/160
    for the filter grammar.
    """

    order_by: str = betterproto.string_field(5)
    """
    A comma-separated list of fields to order by. e.g., "foo,bar"
    The default sort order is ascending. To specify a descending order for a
    field, append a " desc" suffix. e.g., "foo desc,bar"
    Subfields are specified with a "." character. e.g., "foo.bar"
    """


@dataclass(eq=False, repr=False)
class PreviewDatasetResponse(betterproto.Message):
    """ """

    examples: List["Example"] = betterproto.message_field(1)
    """The list of examples in the dataset for the requested page."""

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_count: int = betterproto.int32_field(3)
    """The total number of examples in the dataset."""


@dataclass(eq=False, repr=False)
class Example(betterproto.Message):
    """ """

    content: str = betterproto.string_field(1)
    """
    
    """


@dataclass(eq=False, repr=False)
class UserUploaded(betterproto.Message):
    """ """

    pass


@dataclass(eq=False, repr=False)
class Transformed(betterproto.Message):
    """ """

    source_dataset_id: str = betterproto.string_field(1)
    """
    
    """

    filter: str = betterproto.string_field(2)
    """
    
    """

    original_format: "DatasetFormat" = betterproto.enum_field(3)
    """
    
    """


@dataclass(eq=False, repr=False)
class Splitted(betterproto.Message):
    """ """

    source_dataset_id: str = betterproto.string_field(1)
    """
    
    """


@dataclass(eq=False, repr=False)
class FireworksTraced(betterproto.Message):
    """ """

    model: str = betterproto.string_field(1)
    """The model that's traced."""

    base_model: str = betterproto.string_field(2)
    """
    The base model of the model that's traced. May be the same as `model`.
    """

    start_time: datetime = betterproto.message_field(3)
    """The start of the traced window of time (exclusive)."""

    end_time: datetime = betterproto.message_field(4)
    """The end of the traced window of time (exclusive)."""


@dataclass(eq=False, repr=False)
class DraftModelStates(betterproto.Message):
    """ """

    base_model: str = betterproto.string_field(1)
    """The base model of the model that's used to generate the data."""


@dataclass(eq=False, repr=False)
class EvaluationResult(betterproto.Message):
    """ """

    evaluation_job_id: str = betterproto.string_field(1)
    """
    
    """


@dataclass(eq=False, repr=False)
class GetDatasetRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the object."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class CreateDatasetRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    
    """

    dataset: "Dataset" = betterproto.message_field(2)
    """
    
    """

    dataset_id: str = betterproto.string_field(3)
    """
    
    """

    source_dataset_id: str = betterproto.string_field(4)
    """
    If set, indicates we are creating a new dataset by filtering this existing dataset ID
    """

    filter: str = betterproto.string_field(5)
    """
    Filter condition (SQL-like WHERE clause) to apply to the source dataset
    """


@dataclass(eq=False, repr=False)
class UpdateDatasetRequest(betterproto.Message):
    """ """

    dataset: "Dataset" = betterproto.message_field(1)
    """
    The properties of the Dataset being updated. `dataset.name` must
    be populated with the updated resource's name.
    """

    update_mask: "betterproto_lib_google_protobuf.FieldMask" = (
        betterproto.message_field(2)
    )
    """List of field paths to be updated. If empty we replace all fields."""


@dataclass(eq=False, repr=False)
class UploadDatasetRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """
    
    """

    filename_to_size: Dict[str, int] = betterproto.map_field(
        2, betterproto.TYPE_STRING, betterproto.TYPE_INT64
    )
    """
    
    """


@dataclass(eq=False, repr=False)
class UploadDatasetResponse(betterproto.Message):
    """ """

    filename_to_signed_urls: Dict[str, str] = betterproto.map_field(
        1, betterproto.TYPE_STRING, betterproto.TYPE_STRING
    )
    """Signed URLs for uploading dataset files"""


@dataclass(eq=False, repr=False)
class GetDatasetUploadEndpointRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the dataset."""

    filename_to_size: Dict[str, int] = betterproto.map_field(
        2, betterproto.TYPE_STRING, betterproto.TYPE_INT64
    )
    """A mapping from the file name to its size in bytes."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        3
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class GetDatasetUploadEndpointResponse(betterproto.Message):
    """ """

    filename_to_signed_urls: Dict[str, str] = betterproto.map_field(
        1, betterproto.TYPE_STRING, betterproto.TYPE_STRING
    )
    """Signed URLs for uploading dataset files"""


@dataclass(eq=False, repr=False)
class ValidateDatasetUploadRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """
    
    """


@dataclass(eq=False, repr=False)
class GetDatasetDownloadEndpointRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the dataset."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """

    download_lineage: bool = betterproto.bool_field(3)
    """
    If true, downloads entire lineage chain (all related datasets).
    Filenames will be prefixed with dataset IDs to avoid collisions.
    """


@dataclass(eq=False, repr=False)
class GetDatasetDownloadEndpointResponse(betterproto.Message):
    """ """

    filename_to_signed_urls: Dict[str, str] = betterproto.map_field(
        1, betterproto.TYPE_STRING, betterproto.TYPE_STRING
    )
    """Signed URLs for downloading dataset files"""


@dataclass(eq=False, repr=False)
class ListDatasetsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    
    """

    page_size: int = betterproto.int32_field(2)
    """
    The maximum number of datasets to return. The maximum page_size is 200,
    values above 200 will be coerced to 200.
    If unspecified, the default is 50.
    """

    page_token: str = betterproto.string_field(3)
    """
    A page token, received from a previous ListDatasets call. Provide this
    to retrieve the subsequent page. When paginating, all other parameters
    provided to ListDatasets must match the call that provided the page
    token.
    """

    filter: str = betterproto.string_field(4)
    """
    Only model satisfying the provided filter (if specified) will be
    returned. See https://google.aip.dev/160 for the filter grammar.
    """

    order_by: str = betterproto.string_field(5)
    """
    A comma-separated list of fields to order by. e.g. "foo,bar"
    The default sort order is ascending. To specify a descending order for a
    field, append a " desc" suffix. e.g. "foo desc,bar"
    Subfields are specified with a "." character. e.g. "foo.bar"
    If not specified, the default order is by "name".
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """

    show_internal: bool = betterproto.bool_field(7)
    """If true, the internal datasets will be included in the response."""


@dataclass(eq=False, repr=False)
class ListDatasetsResponse(betterproto.Message):
    """ """

    datasets: List["Dataset"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of datasets"""


@dataclass(eq=False, repr=False)
class DeleteDatasetRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the dataset."""


@dataclass(eq=False, repr=False)
class SplitDatasetRequest(betterproto.Message):
    """Request message for splitting a dataset into chunks"""

    name: str = betterproto.string_field(1)
    """
    Required. The resource name of the dataset to split.
    Format: accounts/{account}/datasets/{dataset}
    """

    chunk_size: int = betterproto.int32_field(2)
    """Required. The size of each chunk (minimum 200)"""

    parent: str = betterproto.string_field(3)
    """The parent account ID of the requester."""


@dataclass(eq=False, repr=False)
class SplitDatasetResponse(betterproto.Message):
    """Response message for dataset splitting"""

    chunk_dataset_names: List[str] = betterproto.string_field(1)
    """The resource names of the created chunk datasets"""

    chunks_created: int = betterproto.int32_field(2)
    """The number of chunks created"""

    total_examples: int = betterproto.int64_field(3)
    """The total number of examples processed"""


@dataclass(eq=False, repr=False)
class DatasetValidationJob(betterproto.Message):
    """Next ID: 15"""

    name: str = betterproto.string_field(1)
    """
    
    """

    display_name: str = betterproto.string_field(2)
    """
    
    """

    create_time: datetime = betterproto.message_field(3)
    """
    
    """

    created_by: str = betterproto.string_field(4)
    """
    
    """

    state: "JobState" = betterproto.enum_field(5)
    """
    
    """

    status: "Status" = betterproto.message_field(6)
    """
    
    """

    dataset_name: str = betterproto.string_field(7)
    """The name of the dataset to validate."""

    format: "DatasetValidationFormat" = betterproto.enum_field(8)
    """
    The format of the dataset. See DatasetValidationFormat for more details.
    """

    result: "DatasetValidationJobResult" = betterproto.enum_field(9)
    """
    
    """

    validation_error: str = betterproto.string_field(10)
    """
    
    """

    dataset_names: List[str] = betterproto.string_field(11)
    """The name of the dataset to validate."""

    update_time: datetime = betterproto.message_field(12)
    """The update time for the dataset validation job."""

    rewards: List[str] = betterproto.string_field(24)
    """A list of reward metrics to validate."""

    region: "Region" = betterproto.enum_field(13)
    """The region where the job is located."""

    custom_image_tag: str = betterproto.string_field(14)
    """Custom image tag, e.g. /train:dev-xyz."""


@dataclass(eq=False, repr=False)
class GetDatasetValidationJobRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """
    
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class CreateDatasetValidationJobRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    
    """

    dataset_validation_job: "DatasetValidationJob" = betterproto.message_field(2)
    """
    
    """

    dataset_validation_job_id: str = betterproto.string_field(3)
    """
    
    """


@dataclass(eq=False, repr=False)
class ListDatasetValidationJobsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    
    """

    page_size: int = betterproto.int32_field(2)
    """
    
    """

    page_token: str = betterproto.string_field(3)
    """
    
    """

    filter: str = betterproto.string_field(4)
    """
    
    """

    order_by: str = betterproto.string_field(5)
    """
    
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListDatasetValidationJobsResponse(betterproto.Message):
    """ """

    dataset_validation_jobs: List["DatasetValidationJob"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    
    """

    total_size: int = betterproto.int32_field(3)
    """
    
    """


@dataclass(eq=False, repr=False)
class DeleteDatasetValidationJobRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """
    
    """


@dataclass(eq=False, repr=False)
class DeployedModel(betterproto.Message):
    """Next ID: 17"""

    name: str = betterproto.string_field(1)
    """
    The resource name. e.g. accounts/my-account/deployedModels/my-deployed-model
    """

    display_name: str = betterproto.string_field(2)
    """
    
    """

    description: str = betterproto.string_field(3)
    """Description of the resource."""

    create_time: datetime = betterproto.message_field(4)
    """The creation time of the resource."""

    created_by: str = betterproto.string_field(5)
    """The email address of the user who created this deployed model."""

    model: str = betterproto.string_field(6)
    """
    The resource name of the model to be deployed.
    e.g. accounts/my-account/models/my-model
    """

    deployment: str = betterproto.string_field(7)
    """The resource name of the base deployment the model is deployed to."""

    default: bool = betterproto.bool_field(8)
    """
    If true, this is the default target when querying this model without
    the `#<deployment>` suffix.
    The first deployment a model is deployed to will have this field set to true.
    """

    state: "DeployedModelState" = betterproto.enum_field(9)
    """The state of the deployed model."""

    serverless: bool = betterproto.bool_field(10)
    """True if the underlying deployment is managed by Fireworks"""

    status: "Status" = betterproto.message_field(11)
    """Contains model deploy/undeploy details."""

    public: bool = betterproto.bool_field(12)
    """If true, the deployed model will be publicly reachable."""

    update_time: datetime = betterproto.message_field(13)
    """The update time for the deployed model."""

    load_balancer_name: str = betterproto.string_field(14)
    """The name of the load balancer associated with this deployed model."""

    load_balancer_replica_capacity: float = betterproto.float_field(16)
    """
    A multiplier for deployment weight in load balancer, proportional to replica capacity.
    If not specified or zero, defaults to 1.
    """

    is_load_balancer_sticky_session: bool = betterproto.bool_field(15)
    """
    Whether to enable sticky sessions for this deployed model's load balancer.
    This value is only used if default=true, as only the default deployment
    controls the load balancer configuration.
    """


@dataclass(eq=False, repr=False)
class DeployedModelRef(betterproto.Message):
    """Next ID: 6"""

    name: str = betterproto.string_field(1)
    """
    The resource name. e.g. accounts/my-account/deployedModels/my-deployed-model
    """

    deployment: str = betterproto.string_field(2)
    """The resource name of the base deployment the model is deployed to."""

    state: "DeployedModelState" = betterproto.enum_field(3)
    """The state of the deployed model."""

    default: bool = betterproto.bool_field(4)
    """
    If true, this is the default target when querying this model without
    the `#<deployment>` suffix.
    The first deployment a model is deployed to will have this field set to
    true automatically.
    """

    public: bool = betterproto.bool_field(5)
    """If true, the deployed model will be publicly reachable."""


@dataclass(eq=False, repr=False)
class CreateDeployedModelRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The resource name of the parent account."""

    deployed_model: "DeployedModel" = betterproto.message_field(2)
    """
    
    """


@dataclass(eq=False, repr=False)
class DeleteDeployedModelRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the deployed model."""


@dataclass(eq=False, repr=False)
class GetDeployedModelRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the deployed model."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListDeployedModelsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """Resource name of the parent account."""

    page_size: int = betterproto.int32_field(2)
    """
    The maximum number of deployed models to return. The maximum page_size is 200,
    values above 200 will be coerced to 200.
    If unspecified, the default is 50.
    """

    page_token: str = betterproto.string_field(3)
    """
    A page token, received from a previous ListDeployedModels call. Provide this
    to retrieve the subsequent page. When paginating, all other parameters
    provided to ListDeployedModels must match the call that provided the page
    token.
    """

    filter: str = betterproto.string_field(4)
    """
    Only depoyed models satisfying the provided filter (if specified) will be
    returned. See https://google.aip.dev/160 for the filter grammar.
    """

    order_by: str = betterproto.string_field(5)
    """
    A comma-separated list of fields to order by. e.g. "foo,bar"
    The default sort order is ascending. To specify a descending order for a
    field, append a " desc" suffix. e.g. "foo desc,bar"
    Subfields are specified with a "." character. e.g. "foo.bar"
    If not specified, the default order is by "name".
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """

    show_internal: bool = betterproto.bool_field(7)
    """
    If true, the internal deployed models will be included in the response.
    """


@dataclass(eq=False, repr=False)
class ListDeployedModelsResponse(betterproto.Message):
    """ """

    deployed_models: List["DeployedModel"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of deployed models"""


@dataclass(eq=False, repr=False)
class UpdateDeployedModelRequest(betterproto.Message):
    """ """

    deployed_model: "DeployedModel" = betterproto.message_field(1)
    """
    The properties of the deployed model being updated. `deployed_model.name` must
    be populated with the updated resource's name.
    """

    update_mask: "betterproto_lib_google_protobuf.FieldMask" = (
        betterproto.message_field(2)
    )
    """List of field paths to be updated. If empty we replace all fields."""


@dataclass(eq=False, repr=False)
class DeploymentTemplate(betterproto.Message):
    """Next ID: 41"""

    name: str = betterproto.string_field(1)
    """
    The resource name of the template. e.g. accounts/my-account/deploymentTemplates/my-template
    """

    display_name: str = betterproto.string_field(2)
    """
    Human-readable display name of the deployment template. e.g. "My Template"
    Must be fewer than 64 characters long.
    """

    description: str = betterproto.string_field(3)
    """Description of the deployment template."""

    create_time: datetime = betterproto.message_field(4)
    """The creation time of the deployment template."""

    created_by: str = betterproto.string_field(5)
    """The email address of the user who created this deployment template."""

    min_replica_count: Optional[int] = betterproto.int32_field(6, optional=True)
    """
    For the following fields, see the corresponding documentation in
    deployment.proto.
    """

    max_replica_count: Optional[int] = betterproto.int32_field(7, optional=True)
    """
    
    """

    autoscaling_policy: Optional["AutoscalingPolicy"] = betterproto.message_field(
        8, optional=True
    )
    """
    
    """

    base_model: Optional[str] = betterproto.string_field(9, optional=True)
    """
    
    """

    accelerator_count: Optional[int] = betterproto.int32_field(25, optional=True)
    """
    
    """

    accelerator_type: Optional["AcceleratorType"] = betterproto.enum_field(
        26, optional=True
    )
    """
    
    """

    world_size: Optional[int] = betterproto.int32_field(10, optional=True)
    """
    
    """

    generator_count: Optional[int] = betterproto.int32_field(16, optional=True)
    """
    
    """

    disaggregated_prefill_count: Optional[int] = betterproto.int32_field(
        11, optional=True
    )
    """
    
    """

    disaggregated_prefill_world_size: Optional[int] = betterproto.int32_field(
        12, optional=True
    )
    """
    
    """

    max_batch_size: Optional[int] = betterproto.int32_field(13, optional=True)
    """
    
    """

    max_peft_batch_size: Optional[int] = betterproto.int32_field(14, optional=True)
    """
    
    """

    kv_cache_memory_pct: Optional[int] = betterproto.int32_field(15, optional=True)
    """
    
    """

    enable_addons: Optional[bool] = betterproto.bool_field(27, optional=True)
    """
    
    """

    draft_model: Optional[str] = betterproto.string_field(20, optional=True)
    """
    
    """

    ngram_speculation_length: Optional[int] = betterproto.int32_field(29, optional=True)
    """
    
    """

    draft_token_count: Optional[int] = betterproto.int32_field(21, optional=True)
    """
    
    """

    enable_session_affinity: Optional[bool] = betterproto.bool_field(23, optional=True)
    """
    
    """

    image_tag: Optional[str] = betterproto.string_field(24, optional=True)
    """
    
    """

    region: Optional["Region"] = betterproto.enum_field(30, optional=True)
    """
    
    """

    direct_route_api_keys: List[str] = betterproto.string_field(31)
    """
    
    """

    direct_route_type: Optional["DirectRouteType"] = betterproto.enum_field(
        33, optional=True
    )
    """
    
    """

    precision: Optional["DeploymentPrecision"] = betterproto.enum_field(
        34, optional=True
    )
    """
    
    """

    extra_args: List[str] = betterproto.string_field(36)
    """A list of extra arguments that should be passed to the server."""

    extra_values: Dict[str, str] = betterproto.map_field(
        37, betterproto.TYPE_STRING, betterproto.TYPE_STRING
    )
    """
    A JSON object of extra values that should be passed to the helm chart when installed.
    """

    update_time: datetime = betterproto.message_field(35)
    """The update time for the deployment template."""

    max_context_length: Optional[int] = betterproto.int32_field(38, optional=True)
    """The max context length for the deployment template"""

    annotations: Dict[str, str] = betterproto.map_field(
        39, betterproto.TYPE_STRING, betterproto.TYPE_STRING
    )
    """
    Annotations to identify deployment template properties
    Key/value pairs may be used by external tools or other services
    """

    disable_deployment_size_validation: Optional[bool] = betterproto.bool_field(
        40, optional=True
    )
    """Whether the deployment size validation is disabled."""


@dataclass(eq=False, repr=False)
class CreateDeploymentTemplateRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The resource name of the parent account."""

    deployment_template: "DeploymentTemplate" = betterproto.message_field(2)
    """The properties of the deployment template being created."""

    deployment_template_id: str = betterproto.string_field(3)
    """ID of the deployment template."""


@dataclass(eq=False, repr=False)
class GetDeploymentTemplateRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the deployment template."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListDeploymentTemplatesRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """Resource name of the parent account."""

    page_size: int = betterproto.int32_field(2)
    """
    The maximum number of deployment templates to return. The maximum
    page_size is 200, values above 200 will be coerced to 200.
    If unspecified, the default is 50.
    """

    page_token: str = betterproto.string_field(3)
    """
    A page token, received from a previous ListDeploymentTemplates call.
    Provide this to retrieve the subsequent page. When paginating, all other
    parameters provided to ListDeployments must match the call that provided
    the page token.
    """

    filter: str = betterproto.string_field(4)
    """
    Only deployment template satisfying the provided filter (if specified)
    will be returned. See https://google.aip.dev/160 for the filter grammar.
    """

    order_by: str = betterproto.string_field(5)
    """
    A comma-separated list of fields to order by. e.g. "foo,bar"
    The default sort order is ascending. To specify a descending order for a
    field, append a " desc" suffix. e.g. "foo desc,bar"
    Subfields are specified with a "." character. e.g. "foo.bar"
    If not specified, the default order is by "name".
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListDeploymentTemplatesResponse(betterproto.Message):
    """ """

    deployment_templates: List["DeploymentTemplate"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of deployments"""


@dataclass(eq=False, repr=False)
class UpdateDeploymentTemplateRequest(betterproto.Message):
    """ """

    deployment_template: "DeploymentTemplate" = betterproto.message_field(1)
    """
    The properties of the deployment template being updated.
    deployment_template.name must be populated with the updated resource's
    name.
    """

    update_mask: "betterproto_lib_google_protobuf.FieldMask" = (
        betterproto.message_field(2)
    )
    """List of field paths to be updated. If empty we replace all fields."""


@dataclass(eq=False, repr=False)
class DeleteDeploymentTemplateRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the deployment template."""


@dataclass(eq=False, repr=False)
class EarlyStopConfig(betterproto.Message):
    """
    EarlyStopConfig controls whether or not to do early stop in a
    training job.
    """

    is_set: bool = betterproto.bool_field(1)
    """Whether the early stop config is set."""

    enabled: bool = betterproto.bool_field(2)
    """Whether to enable early stop."""


@dataclass(eq=False, repr=False)
class BaseTrainingConfig(betterproto.Message):
    """
    BaseTrainingConfig contains common configuration fields shared across
    different training job types.
    Next ID: 16
    """

    output_model: str = betterproto.string_field(1)
    """
    The model ID to be assigned to the resulting fine-tuned model. If not specified, the job ID will be used.
    """

    base_model: str = betterproto.string_field(2)
    """
    The name of the base model to be fine-tuned
    Only one of 'base_model' or 'warm_start_from' should be specified.
    """

    warm_start_from: str = betterproto.string_field(3)
    """
    The PEFT addon model in Fireworks format to be fine-tuned from
    Only one of 'base_model' or 'warm_start_from' should be specified.
    """

    jinja_template: str = betterproto.string_field(4)
    """
    The Jinja template for conversation formatting. If not specified, defaults to the base model's conversation template configuration
    """

    learning_rate: float = betterproto.float_field(5)
    """The learning rate used for training."""

    max_context_length: int = betterproto.int32_field(6)
    """The maximum context length to use with the model."""

    lora_rank: int = betterproto.int32_field(7)
    """The rank of the LoRA layers."""

    base_model_weight_precision: "WeightPrecision" = betterproto.enum_field(8)
    """The weight precision of the base model."""

    accelerator_type: "AcceleratorType" = betterproto.enum_field(9)
    """
    The type of accelerator to use.
    If not specified, the default is NVIDIA_A100_80GB.
    """

    accelerator_count: int = betterproto.int32_field(10)
    """
    The number of accelerators used for the fine-tuning job.
    If not specified, the default is the estimated minimum required by the
    base model.
    """

    region: "Region" = betterproto.enum_field(11)
    """The region where the fine-tuning job is located."""

    epochs: int = betterproto.int32_field(12)
    """The number of epochs to train for."""

    batch_size: int = betterproto.int32_field(13)
    """
    The maximum packed number of tokens per batch for training in sequence packing.
    """

    is_intermediate: bool = betterproto.bool_field(14)
    """If this training job is a intermediate step"""

    toleration: str = betterproto.string_field(15)
    """The taint key to tolerate for the training job."""


@dataclass(eq=False, repr=False)
class EagleTrainingJob(betterproto.Message):
    """Next ID: 24"""

    name: str = betterproto.string_field(1)
    """
    
    """

    display_name: str = betterproto.string_field(2)
    """
    
    """

    create_time: datetime = betterproto.message_field(3)
    """
    
    """

    expire_time: datetime = betterproto.message_field(4)
    """
    The time after which the EAGLE training job will give up if it has not finished running.
    """

    created_by: str = betterproto.string_field(5)
    """The email address of the user who created this EAGLE training job."""

    state: "JobState" = betterproto.enum_field(6)
    """State of the training job."""

    status: "Status" = betterproto.message_field(7)
    """Information describing success or failure of the training job."""

    input_draft_model: str = betterproto.string_field(8)
    """
    The name of a model with Kind=DRAFT_ADDON. Model architecture must
    be either Llama or Mixtral and compatible with the base model.
    Example: "accounts/example-account/models/example-draft-model".
    """

    training_dataset: str = betterproto.string_field(9)
    """
    The name of the dataset to use for training the eagle model.
    Example: "accounts/example-account/datasets/example-dataset".
    """

    base_model: str = betterproto.string_field(10)
    """
    The name of the base model to use for training the eagle model.
    Model architecture must be either Llama or Mixtral.
    Kind must be HF_BASE_MODEL.
    Example: "accounts/example-account/models/example-base-model".
    """

    output_draft_model: str = betterproto.string_field(11)
    """
    The name of the output draft model that is generated as the
    output of this job.
    Example: "accounts/example-account/models/example-draft-model".
    """

    epochs_count: float = betterproto.float_field(12)
    """
    Number of epochs to train for. If absent, it will be set
    automatically.
    """

    learning_rate: float = betterproto.float_field(13)
    """
    Learning rate for the EAGLE training job. If absent, it will be set
    automatically.
    """

    wandb_config: "WandbConfig" = betterproto.message_field(14)
    """
    The Weights & Biases team/user account for logging training progress.
    """

    early_stop_config: "EarlyStopConfig" = betterproto.message_field(15)
    """
    Controls whether or not to do early stop in a training job.
    If unset, early stop decision will be made automatically.
    """

    accelerator_type: "AcceleratorType" = betterproto.enum_field(20)
    """
    The type of accelerator to use.
    If not specified, the default is NVIDIA_A100_80GB.
    """

    accelerator_count: int = betterproto.int32_field(21)
    """
    The number of accelerators used per replica.
    If not specified, the default is the estimated minimum required by the
    base model.
    """

    update_time: datetime = betterproto.message_field(22)
    """The update time for the eagle training job."""

    region: "Region" = betterproto.enum_field(23)
    """The region where the job is located."""

    is_turbo: bool = betterproto.bool_field(24)
    """Whether to run the eagle training job in turbo mode."""


@dataclass(eq=False, repr=False)
class GetEagleTrainingJobRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """
    
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class CreateEagleTrainingJobRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    
    """

    eagle_training_job: "EagleTrainingJob" = betterproto.message_field(2)
    """
    
    """

    eagle_training_job_id: str = betterproto.string_field(3)
    """ID of the EAGLE training job."""


@dataclass(eq=False, repr=False)
class ListEagleTrainingJobsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    
    """

    page_size: int = betterproto.int32_field(2)
    """
    The maximum number of EAGLE training jobs to return. The maximum page_size is 200,
    values above 200 will be coerced to 200.
    If unspecified, the default is 50.
    """

    page_token: str = betterproto.string_field(3)
    """
    A page token, received from a previous ListEagleTrainingJobs call. Provide this
    to retrieve the subsequent page. When paginating, all other parameters
    provided to ListEagleTrainingJobs must match the call that provided the page
    token.
    """

    filter: str = betterproto.string_field(4)
    """
    Only jobs satisfying the provided filter (if specified) will be
    returned. See https://google.aip.dev/160 for the filter grammar.
    """

    order_by: str = betterproto.string_field(5)
    """
    A comma-separated list of fields to order by. e.g. "foo,bar"
    The default sort order is ascending. To specify a descending order for a
    field, append a " desc" suffix. e.g. "foo desc,bar"
    Subfields are specified with a "." character. e.g. "foo.bar"
    If not specified, the default order is by "create_time desc".
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListEagleTrainingJobsResponse(betterproto.Message):
    """ """

    eagle_training_jobs: List["EagleTrainingJob"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of EAGLE training jobs."""


@dataclass(eq=False, repr=False)
class UpdateEagleTrainingJobRequest(betterproto.Message):
    """ """

    eagle_training_job: "EagleTrainingJob" = betterproto.message_field(1)
    """
    The properties of the EAGLE training job being updated. `eagle_training_job.name` must
    be populated with the updated resource's name.
    """

    update_mask: "betterproto_lib_google_protobuf.FieldMask" = (
        betterproto.message_field(2)
    )
    """List of field paths to be updated. If empty we replace all fields."""


@dataclass(eq=False, repr=False)
class DeleteEagleTrainingJobRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the EAGLE training job."""


@dataclass(eq=False, repr=False)
class Environment(betterproto.Message):
    """Next ID: 14"""

    name: str = betterproto.string_field(1)
    """
    The resource name of the environment. e.g. accounts/my-account/clusters/my-cluster/environments/my-env
    """

    display_name: str = betterproto.string_field(3)
    """
    Human-readable display name of the environment. e.g. "My Environment"
    """

    create_time: datetime = betterproto.message_field(5)
    """The creation time of the environment."""

    created_by: str = betterproto.string_field(6)
    """The email address of the user who created this environment."""

    state: "EnvironmentState" = betterproto.enum_field(10)
    """The current state of the environment."""

    status: "Status" = betterproto.message_field(11)
    """The current error status of the environment."""

    connection: "EnvironmentConnection" = betterproto.message_field(2)
    """Information about the current environment connection."""

    base_image_ref: str = betterproto.string_field(7)
    """The URI of the base container image used for this environment."""

    image_ref: str = betterproto.string_field(4)
    """
    The URI of the container image used for this environment. This is a
    image is an immutable snapshot of the base_image_ref when the environment
    was created.
    """

    snapshot_image_ref: str = betterproto.string_field(8)
    """The URI of the latest container image snapshot for this environment."""

    shared: bool = betterproto.bool_field(12)
    """
    Whether the environment is shared with all users in the account.
    This allows all users to connect, disconnect, update, delete, clone, and
    create batch jobs using the environment.
    """

    annotations: Dict[str, str] = betterproto.map_field(
        9, betterproto.TYPE_STRING, betterproto.TYPE_STRING
    )
    """
    Arbitrary, user-specified metadata.
    Keys and values must adhere to Kubernetes constraints: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/#syntax-and-character-set
    Additionally, the "fireworks.ai/" prefix is reserved.
    """

    update_time: datetime = betterproto.message_field(13)
    """The update time for the environment."""


@dataclass(eq=False, repr=False)
class EnvironmentConnection(betterproto.Message):
    """Next ID: 8"""

    node_pool_id: str = betterproto.string_field(1)
    """The resource id of the node pool the environment is connected to."""

    num_ranks: int = betterproto.int32_field(4)
    """
    For GPU node pools: one GPU per rank w/ host packing,
    for CPU node pools: one host per rank.
    If not specified, the default is 1.
    """

    role: str = betterproto.string_field(6)
    """
    The ARN of the AWS IAM role that the connection should assume.
    If not specified, the connection will fall back to the node
    pool's node_role.
    """

    zone: str = betterproto.string_field(5)
    """
    Current for the last zone that this environment is connected to. We
    want to warn the users about cross zone migration latency when they are
    connecting to node pool in a different zone as their persistent volume.
    """

    use_local_storage: bool = betterproto.bool_field(7)
    """
    If true, the node's local storage will be mounted on /tmp. This flag has
    no effect if the node does not have local storage.
    """

    def __post_init__(self) -> None:
        super().__post_init__()
        if self.is_set("use_local_storage"):
            warnings.warn(
                "EnvironmentConnection.use_local_storage is deprecated",
                DeprecationWarning,
            )


@dataclass(eq=False, repr=False)
class CreateEnvironmentRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The resource name of the parent cluster."""

    environment: "Environment" = betterproto.message_field(2)
    """The properties of the Environment being created."""

    environment_id: str = betterproto.string_field(3)
    """The environment ID to use in the environment name. e.g. my-env"""


@dataclass(eq=False, repr=False)
class GetEnvironmentRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the environment."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListEnvironmentsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """Resource name of the parent cluster."""

    page_size: int = betterproto.int32_field(2)
    """
    The maximum number of environments to return. The maximum page_size is 200,
    values above 200 will be coerced to 200.
    If unspecified, the default is 50.
    """

    page_token: str = betterproto.string_field(3)
    """
    A page token, received from a previous ListEnvironments call. Provide this
    to retrieve the subsequent page. When paginating, all other parameters
    provided to ListEnvironments must match the call that provided the page
    token.
    """

    filter: str = betterproto.string_field(4)
    """
    Only environments satisfying the provided filter (if specified) will be
    returned. See https://google.aip.dev/160 for the filter grammar.
    """

    order_by: str = betterproto.string_field(5)
    """
    A comma-separated list of fields to order by. e.g. "foo,bar"
    The default sort order is ascending. To specify a descending order for a
    field, append a " desc" suffix. e.g. "foo desc,bar"
    Subfields are specified with a "." character. e.g. "foo.bar"
    If not specified, the default order is by "name".
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListEnvironmentsResponse(betterproto.Message):
    """ """

    environments: List["Environment"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of environments."""


@dataclass(eq=False, repr=False)
class UpdateEnvironmentRequest(betterproto.Message):
    """ """

    environment: "Environment" = betterproto.message_field(1)
    """
    The properties of the Environment being updated. `environment.name` must
    be populated with the updated resource's name.
    """

    update_mask: "betterproto_lib_google_protobuf.FieldMask" = (
        betterproto.message_field(2)
    )
    """List of field paths to be updated. If empty we replace all fields."""


@dataclass(eq=False, repr=False)
class DeleteEnvironmentRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the environment."""


@dataclass(eq=False, repr=False)
class BatchDeleteEnvironmentsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The resource name of the parent cluster."""

    names: List[str] = betterproto.string_field(2)
    """The resource names of the environments to delete."""


@dataclass(eq=False, repr=False)
class ConnectEnvironmentRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """Resource name of the environment."""

    connection: "EnvironmentConnection" = betterproto.message_field(2)
    """
    
    """

    vscode_version: str = betterproto.string_field(3)
    """VSCode version on the client side that initiated the connect request"""


@dataclass(eq=False, repr=False)
class DisconnectEnvironmentRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """Resource name of the environment."""

    force: bool = betterproto.bool_field(2)
    """
    Disconnect the environment even if snapshotting fails (e.g. due to pod
    failure). This flag should only be used if you are certain that the pod
    is gone.
    """

    reset_snapshots: bool = betterproto.bool_field(3)
    """
    Forces snapshots to be rebuilt.
    This can be used when there are too many snapshot layers
    or when an unforeseen snapshotting logic error has occurred.
    """


@dataclass(eq=False, repr=False)
class Evaluation(betterproto.Message):
    """Next ID: 11"""

    name: str = betterproto.string_field(1)
    """Current fields in your proto"""

    create_time: datetime = betterproto.message_field(2)
    """
    
    """

    created_by: str = betterproto.string_field(3)
    """
    
    """

    status: "Status" = betterproto.message_field(4)
    """
    
    """

    evaluation_type: str = betterproto.string_field(5)
    """string llm_evaluator_prompt = 6;"""

    description: str = betterproto.string_field(7)
    """Optional description of the evaluation"""

    providers: List["Provider"] = betterproto.message_field(8)
    """One or more providers to use"""

    assertions: List["Assertion"] = betterproto.message_field(9)
    """One or more assertions to evaluate"""

    update_time: datetime = betterproto.message_field(10)
    """
    TODO(xiaoyifan): renable this after checking in, disable to avoid db migration
    If true, the model will be publicly readable.
    bool public = 19 [(google.api.field_behavior) = OPTIONAL];
    
    The update time for the evaluation.
    """

    def __post_init__(self) -> None:
        warnings.warn("Evaluation is deprecated", DeprecationWarning)
        super().__post_init__()


@dataclass(eq=False, repr=False)
class Assertion(betterproto.Message):
    """
    We are doing auto generated GORM with JSON serializer and oneof doesn't work
    so I am doing enums + just flat fields
    """

    assertion_type: "AssertionAssertionType" = betterproto.enum_field(1)
    """
    
    """

    llm_assertion: "LlmAssertion" = betterproto.message_field(2)
    """
    
    """

    code_assertion: "CodeAssertion" = betterproto.message_field(3)
    """
    
    """

    metric_name: str = betterproto.string_field(4)
    """
    
    """


@dataclass(eq=False, repr=False)
class LlmAssertion(betterproto.Message):
    """ """

    llm_evaluator_prompt: str = betterproto.string_field(1)
    """Prompt used to evaluate the output"""

    providers: List["Provider"] = betterproto.message_field(2)
    """One or more providers to use"""

    prompts: List[str] = betterproto.string_field(3)
    """One or more prompts to evaluate"""

    evaluate_options: "EvaluateOptions" = betterproto.message_field(4)
    """Options for how to run the evaluation"""


@dataclass(eq=False, repr=False)
class CodeAssertion(betterproto.Message):
    """ """

    language: str = betterproto.string_field(1)
    """Language of the code (python/javascript)"""

    code: str = betterproto.string_field(2)
    """The code to execute"""

    expected_output: str = betterproto.string_field(3)
    """Optional expected output"""

    options: "CodeAssertionExecutionOptions" = betterproto.message_field(4)
    """
    
    """


@dataclass(eq=False, repr=False)
class CodeAssertionExecutionOptions(betterproto.Message):
    """Options for execution"""

    timeout_ms: int = betterproto.int32_field(1)
    """Timeout in milliseconds, max 5 minutes"""

    memory_limit_mb: int = betterproto.int32_field(2)
    """Memory limit in MB, max 1GB"""

    env_vars: Dict[str, str] = betterproto.map_field(
        3, betterproto.TYPE_STRING, betterproto.TYPE_STRING
    )
    """Environment variables"""


@dataclass(eq=False, repr=False)
class Provider(betterproto.Message):
    """Represents an LLM provider"""

    id: str = betterproto.string_field(1)
    """Provider ID (e.g., "openai:gpt-4")"""

    config: Dict[str, str] = betterproto.map_field(
        2, betterproto.TYPE_STRING, betterproto.TYPE_STRING
    )
    """Optional provider-specific configuration"""

    label: str = betterproto.string_field(3)
    """Optional label for the provider"""


@dataclass(eq=False, repr=False)
class EvaluateOptions(betterproto.Message):
    """Options for how to run the evaluation"""

    max_concurrency: int = betterproto.int32_field(1)
    """Maximum concurrent requests (default: 4)"""

    repeat: int = betterproto.int32_field(2)
    """Number of times to repeat each test case (default: 1)"""

    delay: int = betterproto.int32_field(3)
    """Delay (in ms) between API calls"""


@dataclass(eq=False, repr=False)
class GetEvaluationRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """
    
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class CreateEvaluationRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    
    """

    evaluation: "Evaluation" = betterproto.message_field(2)
    """
    
    """

    evaluation_id: str = betterproto.string_field(3)
    """
    
    """


@dataclass(eq=False, repr=False)
class ListEvaluationsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    
    """

    page_size: int = betterproto.int32_field(2)
    """
    
    """

    page_token: str = betterproto.string_field(3)
    """
    
    """

    filter: str = betterproto.string_field(4)
    """
    
    """

    order_by: str = betterproto.string_field(5)
    """
    
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListEvaluationsResponse(betterproto.Message):
    """ """

    evaluations: List["Evaluation"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    
    """

    total_size: int = betterproto.int32_field(3)
    """
    
    """


@dataclass(eq=False, repr=False)
class UpdateEvaluationRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """
    
    """

    evaluation: "Evaluation" = betterproto.message_field(2)
    """
    
    """

    update_mask: "betterproto_lib_google_protobuf.FieldMask" = (
        betterproto.message_field(3)
    )
    """
    
    """


@dataclass(eq=False, repr=False)
class DeleteEvaluationRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """
    
    """


@dataclass(eq=False, repr=False)
class TestEvaluationRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    
    """

    evaluation: "Evaluation" = betterproto.message_field(2)
    """The draft evaluation to test"""

    sample_data: str = betterproto.string_field(3)
    """Sample data in JSON format (array of samples)"""


@dataclass(eq=False, repr=False)
class ValidateAssertionsRequest(betterproto.Message):
    """
    Validate the code assertions. Recommended before creating the evaluation.
    """

    parent: str = betterproto.string_field(1)
    """
    
    """

    assertions: List["Assertion"] = betterproto.message_field(2)
    """
    
    """


@dataclass(eq=False, repr=False)
class ValidateAssertionsResponse(betterproto.Message):
    """
    Response for validating assertions. The metric_to_errors contains all metrics from request,
    and the error_messages contains all errors for the metric code. (could be empty which means no errors)
    """

    status: str = betterproto.string_field(1)
    """
    
    """

    metric_to_errors: Dict[str, "ValidateAssertionsResponseValidateAssertionError"] = (
        betterproto.map_field(2, betterproto.TYPE_STRING, betterproto.TYPE_MESSAGE)
    )
    """
    
    """


@dataclass(eq=False, repr=False)
class ValidateAssertionsResponseValidateAssertionError(betterproto.Message):
    """ """

    error_messages: List[str] = betterproto.string_field(1)
    """
    
    """


@dataclass(eq=False, repr=False)
class PreviewEvaluationRequest(betterproto.Message):
    """Request to preview an evaluation with sample data"""

    name: str = betterproto.string_field(1)
    """The evaluation resource name"""

    sample_data: str = betterproto.string_field(2)
    """Sample data in JSON format (array of samples)"""

    max_samples: int = betterproto.int32_field(3)
    """
    Maximum number of samples to evaluate (optional, default will be a small number like 5)
    """


@dataclass(eq=False, repr=False)
class PreviewEvaluationResult(betterproto.Message):
    """A single evaluation result from a preview"""

    success: bool = betterproto.bool_field(1)
    """The input sample"""

    reason: str = betterproto.string_field(2)
    """Output from the evaluation run"""

    score: float = betterproto.double_field(3)
    """
    Score (if applicable)
    Deprecated: Use metrics field instead.
    """

    messages: List["betterproto_lib_google_protobuf.Struct"] = (
        betterproto.message_field(4)
    )
    """messages, which can be any kind of object"""

    metrics: Dict[str, float] = betterproto.map_field(
        5, betterproto.TYPE_STRING, betterproto.TYPE_DOUBLE
    )
    """Metrics from the evaluation run"""

    def __post_init__(self) -> None:
        super().__post_init__()
        if self.is_set("score"):
            warnings.warn(
                "PreviewEvaluationResult.score is deprecated", DeprecationWarning
            )


@dataclass(eq=False, repr=False)
class PreviewEvaluationResponse(betterproto.Message):
    """Response for preview evaluation"""

    results: List["PreviewEvaluationResult"] = betterproto.message_field(1)
    """Results for each sample"""

    total_samples: int = betterproto.int32_field(2)
    """Summary statistics"""

    total_runtime_ms: int = betterproto.int64_field(3)
    """overalll runtime"""


@dataclass(eq=False, repr=False)
class EvaluationJob(betterproto.Message):
    """Next ID: 17"""

    name: str = betterproto.string_field(1)
    """
    
    """

    display_name: str = betterproto.string_field(2)
    """
    
    """

    create_time: datetime = betterproto.message_field(3)
    """
    
    """

    created_by: str = betterproto.string_field(4)
    """
    
    """

    state: "JobState" = betterproto.enum_field(5)
    """
    
    """

    status: "Status" = betterproto.message_field(6)
    """
    
    """

    evaluator: str = betterproto.string_field(7)
    """
    The fully-qualified resource name of the Evaluation used by this job.
    
    Format: accounts/{account_id}/evaluators/{evaluator_id}
    """

    input_dataset: str = betterproto.string_field(8)
    """
    The fully-qualified resource name of the input Dataset used by this job.
    
    Format: accounts/{account_id}/datasets/{dataset_id}
    """

    output_dataset: str = betterproto.string_field(10)
    """
    The fully-qualified resource name of the output Dataset created by this job.
    
    Format: accounts/{account_id}/datasets/{output_dataset_id}
    """

    metrics: Dict[str, float] = betterproto.map_field(
        9, betterproto.TYPE_STRING, betterproto.TYPE_DOUBLE
    )
    """
    
    """

    output_stats: str = betterproto.string_field(12)
    """The output dataset's aggregated stats for the evaluation job."""

    update_time: datetime = betterproto.message_field(11)
    """The update time for the evaluation job."""

    reinforcement_fine_tuning_epoch_id: str = betterproto.string_field(13)
    """The ID of the RFT epoch that this evaluation job belongs to."""

    skip_dataset_validation: bool = betterproto.bool_field(14)
    """Whether to skip dataset validation for the evaluation job."""

    job_progress: "JobProgress" = betterproto.message_field(15)
    """Job progress."""

    region: "Region" = betterproto.enum_field(16)
    """The region where the job is located."""


@dataclass(eq=False, repr=False)
class GetEvaluationJobRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """
    
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class CreateEvaluationJobRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    
    """

    evaluation_job: "EvaluationJob" = betterproto.message_field(2)
    """
    
    """

    evaluation_job_id: str = betterproto.string_field(3)
    """
    
    """


@dataclass(eq=False, repr=False)
class ListEvaluationJobsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    
    """

    page_size: int = betterproto.int32_field(2)
    """
    
    """

    page_token: str = betterproto.string_field(3)
    """
    
    """

    filter: str = betterproto.string_field(4)
    """
    
    """

    order_by: str = betterproto.string_field(5)
    """
    
    """

    show_internal: bool = betterproto.bool_field(6)
    """
    
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        7
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListEvaluationJobsResponse(betterproto.Message):
    """ """

    evaluation_jobs: List["EvaluationJob"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    
    """

    total_size: int = betterproto.int32_field(3)
    """
    
    """


@dataclass(eq=False, repr=False)
class DeleteEvaluationJobRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """
    
    """


@dataclass(eq=False, repr=False)
class Evaluator(betterproto.Message):
    """Next ID: 12"""

    name: str = betterproto.string_field(1)
    """
    
    """

    display_name: str = betterproto.string_field(2)
    """
    
    """

    description: str = betterproto.string_field(3)
    """
    
    """

    create_time: datetime = betterproto.message_field(4)
    """
    
    """

    created_by: str = betterproto.string_field(5)
    """
    
    """

    update_time: datetime = betterproto.message_field(6)
    """
    
    """

    state: "EvaluatorState" = betterproto.enum_field(7)
    """
    
    """

    multi_metrics: bool = betterproto.bool_field(8)
    """
    If true, the criteria will report multiple metric-score pairs
    Otherwise, each criteria will report the score assigned to the criteria name as metric.
    """

    criteria: List["Criterion"] = betterproto.message_field(9)
    """
    Criteria for the evaluator, it should produce a score for the metric (name of criteria)
    """

    requirements: str = betterproto.string_field(10)
    """Content for the requirements.txt for package installation"""

    rollup_settings: "RollupSettings" = betterproto.message_field(11)
    """
    Strategy for metrics reports summary/rollup.
    e.g. {metric1: 1, metric2: 0.3}, rollup_settings could be criteria_weights: {metric1: 0.5, metric2: 0.5}, then final score will be 0.5 * 1 + 0.5 * 0.3 = 0.65
    If skip_rollup is true, the rollup step will be skipped since the criteria will also report the rollup score and metrics altogether.
    """


@dataclass(eq=False, repr=False)
class Criterion(betterproto.Message):
    """ """

    type: "CriterionType" = betterproto.enum_field(1)
    """
    
    """

    name: str = betterproto.string_field(2)
    """
    
    """

    description: str = betterproto.string_field(3)
    """
    
    """

    code_snippets: "CodeSnippets" = betterproto.message_field(4)
    """Criteria for code snippet"""


@dataclass(eq=False, repr=False)
class CodeSnippets(betterproto.Message):
    """ """

    language: str = betterproto.string_field(1)
    """
    
    """

    file_contents: Dict[str, str] = betterproto.map_field(
        2, betterproto.TYPE_STRING, betterproto.TYPE_STRING
    )
    """File name to code snippet, default is main.py"""

    entry_file: str = betterproto.string_field(3)
    """
    
    """

    entry_func: str = betterproto.string_field(4)
    """
    
    """


@dataclass(eq=False, repr=False)
class RollupSettings(betterproto.Message):
    """ """

    criteria_weights: Dict[str, float] = betterproto.map_field(
        1, betterproto.TYPE_STRING, betterproto.TYPE_FLOAT
    )
    """from criteria name to weights in rollup score"""

    python_code: str = betterproto.string_field(2)
    """
    Python code for rollup score calculation, if this is provided, the criteria_weights will be ignored
    """

    success_threshold: float = betterproto.float_field(3)
    """rollup score's threshold for success/failure"""

    skip_rollup: bool = betterproto.bool_field(4)
    """If true, the rollup step will be skipped"""


@dataclass(eq=False, repr=False)
class GetEvaluatorRequest(betterproto.Message):
    """
    message CodeRepo {
      string repo_url = 1;
      enum UpdateType {
        UPDATE_TYPE_UNSPECIFIED = 0;
        BRANCH_PUSH = 1;
        TAG_PUSH = 2;
        MANUAL = 3;
      }
      UpdateType update_type = 2;
      string branch = 3;
      string tag = 4;
    }

    Backlog: API Criteria should be a POST request to url endpoint
    message APICriteria {
        string url = 1;
        map<string, string> headers = 2;
        map<string, string> extra_params = 3;
    }

    Backlog: We can add LLMCriteria
    message LLMCriteria {
        Provider provider = 1;
        string prompt = 2;
        string expected_output = 3;
    }

    TODO: add runtime options
    message RunTimeOptions {
    }
    """

    name: str = betterproto.string_field(1)
    """
    
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListEvaluatorsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    
    """

    page_size: int = betterproto.int32_field(2)
    """
    
    """

    page_token: str = betterproto.string_field(3)
    """
    
    """

    filter: str = betterproto.string_field(4)
    """
    
    """

    order_by: str = betterproto.string_field(5)
    """
    
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListEvaluatorsResponse(betterproto.Message):
    """ """

    evaluators: List["Evaluator"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    
    """

    total_size: int = betterproto.int32_field(3)
    """
    
    """


@dataclass(eq=False, repr=False)
class CreateEvaluatorRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    
    """

    evaluator: "Evaluator" = betterproto.message_field(2)
    """
    
    """

    evaluator_id: str = betterproto.string_field(3)
    """
    
    """


@dataclass(eq=False, repr=False)
class DeleteEvaluatorRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """
    
    """


@dataclass(eq=False, repr=False)
class PreviewEvaluatorRequest(betterproto.Message):
    """ """

    evaluator: "Evaluator" = betterproto.message_field(1)
    """The evaluator object to run preview on"""

    sample_data: List[str] = betterproto.string_field(2)
    """Sample data in JSON format (array of json formated samples)"""

    max_samples: int = betterproto.int32_field(3)
    """Maximum number of samples to evaluate, default is 10"""

    parent: str = betterproto.string_field(4)
    """The parent of the evaluator"""


@dataclass(eq=False, repr=False)
class PreviewEvaluatorSampleResult(betterproto.Message):
    """ """

    success: str = betterproto.string_field(1)
    """
    Overall eval success (true) or failure (false) on the sample, empty string means success not defined
    """

    score: float = betterproto.double_field(2)
    """Score (rollup score if applicable)"""

    per_metric_evals: Dict[str, "betterproto_lib_google_protobuf.Struct"] = (
        betterproto.map_field(3, betterproto.TYPE_STRING, betterproto.TYPE_MESSAGE)
    )
    """Per metric eval results"""

    reason: str = betterproto.string_field(4)
    """reason for the eval result"""


@dataclass(eq=False, repr=False)
class PreviewEvaluatorResponse(betterproto.Message):
    """ """

    results: List["PreviewEvaluatorSampleResult"] = betterproto.message_field(1)
    """
    
    """

    total_samples: int = betterproto.int32_field(2)
    """
    
    """

    total_runtime_ms: int = betterproto.int64_field(3)
    """
    
    """

    stdout: List[str] = betterproto.string_field(4)
    """
    
    """

    stderr: List[str] = betterproto.string_field(5)
    """
    
    """


@dataclass(eq=False, repr=False)
class FeatureFlag(betterproto.Message):
    """Next ID: 4"""

    name: str = betterproto.string_field(1)
    """The resource name, e.g. accounts/my-account/featureFlags/my-feature"""

    value: str = betterproto.string_field(2)
    """
    Additional human-readable feature value if needed.
    
    If not set, the default value is "true".
    """

    create_time: datetime = betterproto.message_field(3)
    """
    
    """


@dataclass(eq=False, repr=False)
class CreateFeatureFlagRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    
    """

    feature_flag: "FeatureFlag" = betterproto.message_field(2)
    """
    
    """

    feature_flag_id: str = betterproto.string_field(3)
    """
    
    """


@dataclass(eq=False, repr=False)
class GetFeatureFlagRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """
    
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListFeatureFlagsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    
    """

    page_size: int = betterproto.int32_field(2)
    """
    
    """

    page_token: str = betterproto.string_field(3)
    """
    
    """

    order_by: str = betterproto.string_field(4)
    """
    
    """

    filter: str = betterproto.string_field(5)
    """
    
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListFeatureFlagsResponse(betterproto.Message):
    """ """

    feature_flags: List["FeatureFlag"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    
    """

    total_size: int = betterproto.int32_field(3)
    """
    
    """


@dataclass(eq=False, repr=False)
class UpdateFeatureFlagRequest(betterproto.Message):
    """ """

    feature_flag: "FeatureFlag" = betterproto.message_field(1)
    """
    
    """

    update_mask: "betterproto_lib_google_protobuf.FieldMask" = (
        betterproto.message_field(2)
    )
    """
    
    """


@dataclass(eq=False, repr=False)
class DeleteFeatureFlagRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """
    
    """


@dataclass(eq=False, repr=False)
class FineTuningJob(betterproto.Message):
    """Next ID: 48"""

    name: str = betterproto.string_field(1)
    """
    
    """

    display_name: str = betterproto.string_field(2)
    """
    
    """

    create_time: datetime = betterproto.message_field(3)
    """
    
    """

    state: "FineTuningJobState" = betterproto.enum_field(4)
    """
    
    """

    dataset: str = betterproto.string_field(5)
    """
    The name of the dataset used for training. A dataset ID may also be supplied, in
    which case the ID will be normalized into the fully qualified dataset name using
    the parent of the job.
    """

    datasets: List["FineTuningJobDataset"] = betterproto.message_field(29)
    """
    
    """

    status: "Status" = betterproto.message_field(9)
    """
    
    """

    created_by: str = betterproto.string_field(10)
    """The email address of the user who created this fine tuning job."""

    container_version: str = betterproto.string_field(11)
    """
    
    """

    model_id: str = betterproto.string_field(13)
    """the model id to generate for training jobs."""

    legacy_job: "FineTuningJobLegacyJob" = betterproto.message_field(38, group="kind")
    """
    
    """

    text_completion: "FineTuningJobTextCompletion" = betterproto.message_field(
        15, group="kind"
    )
    """
    
    """

    text_classification: "FineTuningJobTextClassification" = betterproto.message_field(
        16, group="kind"
    )
    """
    
    """

    conversation: "FineTuningJobConversation" = betterproto.message_field(
        23, group="kind"
    )
    """
    
    """

    draft_model_data: "FineTuningJobDraftModelData" = betterproto.message_field(
        32, group="kind"
    )
    """
    
    """

    draft_model: "FineTuningJobDraftModel" = betterproto.message_field(24, group="kind")
    """
    
    """

    genie: "FineTuningJobGenie" = betterproto.message_field(27, group="kind")
    """
    
    """

    base_model: str = betterproto.string_field(17)
    """The name of the base model."""

    warm_start_from: str = betterproto.string_field(34)
    """
    peft addon model in fireworks format to warm start a fine-tuning job from.
    """

    early_stop: bool = betterproto.bool_field(46)
    """
    
    """

    epochs: float = betterproto.double_field(18)
    """The number of epochs to train for."""

    learning_rate: float = betterproto.double_field(19)
    """The learning rate used for training."""

    lr_scheduler_type: str = betterproto.string_field(44)
    """The learning rate scheduler used for training."""

    warmup_steps: int = betterproto.int32_field(45)
    """The warmup steps used for training."""

    lora_alpha: int = betterproto.int32_field(42)
    """The lora alpha used for training."""

    lora_rank: int = betterproto.int32_field(25)
    """The lora rank used for training."""

    lora_target_modules: List[str] = betterproto.string_field(43)
    """The lora target modules used for training."""

    batch_size: int = betterproto.int32_field(26)
    """The batch size of dataset used for training."""

    micro_batch_size: int = betterproto.int32_field(39)
    """The batch size of dataset used for training per accelerator."""

    mask_token: str = betterproto.string_field(35)
    """The token to mask out prompts, used by draft model data generation."""

    pad_token: str = betterproto.string_field(36)
    """The token for padding, used by draft model data generation."""

    cutoff_length: int = betterproto.int32_field(37)
    """
    The max length to cut off prompts, used by fine-tuning and draft model data generation.
    """

    wandb_url: str = betterproto.string_field(14)
    """The Weights & Biases url to see training progress."""

    wandb_entity: str = betterproto.string_field(20)
    """
    The Weights & Biases entity where training progress should be reported.
    If unspecified, then progress will not be reported to W&B.
    """

    wandb_api_key: str = betterproto.string_field(21)
    """
    The Weights & Biases API key associated with the entity.
    Required if and only if wandb_entity is specified.
    """

    wandb_project: str = betterproto.string_field(22)
    """
    The Weights & Biases project where training progress should be reported.
    Required if and only if wandb_entity is specified.
    """

    evaluation: bool = betterproto.bool_field(30)
    """
    
    """

    evaluation_split: float = betterproto.double_field(31)
    """the split flag to take from training dataset for evaluation."""

    evaluation_dataset: str = betterproto.string_field(41)
    """the dataset to use for evaluation."""

    dependent_jobs: List[str] = betterproto.string_field(33)
    """
    
    """

    def __post_init__(self) -> None:
        super().__post_init__()
        if self.is_set("draft_model_data"):
            warnings.warn(
                "FineTuningJob.draft_model_data is deprecated", DeprecationWarning
            )
        if self.is_set("draft_model"):
            warnings.warn("FineTuningJob.draft_model is deprecated", DeprecationWarning)
        if self.is_set("genie"):
            warnings.warn("FineTuningJob.genie is deprecated", DeprecationWarning)
        if self.is_set("evaluation"):
            warnings.warn("FineTuningJob.evaluation is deprecated", DeprecationWarning)


@dataclass(eq=False, repr=False)
class FineTuningJobDataset(betterproto.Message):
    """
    The list of datasets to be used for training.  The dataset IDs may also be
    supplied, in which case the ID will be normalized into the fully qualified
    dataset name using the parent of the job.
    TODO(shaunak): Once this is rolled out deprecate field 5 in favour of this.
    """

    dataset: str = betterproto.string_field(1)
    """
    
    """


@dataclass(eq=False, repr=False)
class FineTuningJobLegacyJob(betterproto.Message):
    """ """

    pass


@dataclass(eq=False, repr=False)
class FineTuningJobTextCompletion(betterproto.Message):
    """ """

    input_template: str = betterproto.string_field(1)
    """The template used to format the dataset input."""

    output_template: str = betterproto.string_field(2)
    """The template used to format the dataset output."""


@dataclass(eq=False, repr=False)
class FineTuningJobTextClassification(betterproto.Message):
    """ """

    text: str = betterproto.string_field(1)
    """The JSON dataset field that is to be classified."""

    label: str = betterproto.string_field(2)
    """The JSON dataset field that contains the classification label."""


@dataclass(eq=False, repr=False)
class FineTuningJobDraftModelData(betterproto.Message):
    """ """

    deployment_name: str = betterproto.string_field(1)
    """the model deployment where we generate responses from."""

    jinja_template: str = betterproto.string_field(2)
    """
    If not specified, default to the base model conversation_config.template, if exists.
    """

    cleanup_deployment: bool = betterproto.bool_field(30)
    """
    the boolean flag to cleanup the deployment after the data generation job is done.
    """


@dataclass(eq=False, repr=False)
class FineTuningJobDraftModel(betterproto.Message):
    """ """

    pass


@dataclass(eq=False, repr=False)
class FineTuningJobConversation(betterproto.Message):
    """ """

    jinja_template: str = betterproto.string_field(1)
    """
    If not specified, default to the base model conversation_config.template, if exists.
    """


@dataclass(eq=False, repr=False)
class FineTuningJobGenie(betterproto.Message):
    """ """

    pipeline_name: str = betterproto.string_field(1)
    """
    
    """

    def __post_init__(self) -> None:
        warnings.warn("FineTuningJobGenie is deprecated", DeprecationWarning)
        super().__post_init__()


@dataclass(eq=False, repr=False)
class GetFineTuningJobRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the fine-tuning job."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class CreateFineTuningJobRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    
    """

    fine_tuning_job: "FineTuningJob" = betterproto.message_field(2)
    """
    
    """

    debug: bool = betterproto.bool_field(3)
    """
    
    """

    fine_tuning_job_id: str = betterproto.string_field(4)
    """ID of the fine-tuning job."""

    update_time: datetime = betterproto.message_field(47)
    """The update time for the fine-tuning job."""


@dataclass(eq=False, repr=False)
class ListFineTuningJobsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    
    """

    page_size: int = betterproto.int32_field(2)
    """
    The maximum number of fine-tuning jobs to return. The maximum page_size is 200,
    values above 200 will be coerced to 200.
    If unspecified, the default is 50.
    """

    page_token: str = betterproto.string_field(3)
    """
    A page token, received from a previous ListFineTuningJobs call. Provide this
    to retrieve the subsequent page. When paginating, all other parameters
    provided to ListFineTuningJobs must match the call that provided the page
    token.
    """

    filter: str = betterproto.string_field(4)
    """
    Only model satisfying the provided filter (if specified) will be
    returned. See https://google.aip.dev/160 for the filter grammar.
    """

    order_by: str = betterproto.string_field(5)
    """
    A comma-separated list of fields to order by. e.g. "foo,bar"
    The default sort order is ascending. To specify a descending order for a
    field, append a " desc" suffix. e.g. "foo desc,bar"
    Subfields are specified with a "." character. e.g. "foo.bar"
    If not specified, the default order is by "name".
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListFineTuningJobsResponse(betterproto.Message):
    """ """

    fine_tuning_jobs: List["FineTuningJob"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of fine-tuning jobs"""


@dataclass(eq=False, repr=False)
class UpdateFineTuningJobRequest(betterproto.Message):
    """ """

    fine_tuning_job: "FineTuningJob" = betterproto.message_field(1)
    """
    The properties of the fine-tuning job being updated. `fine_tuning_job.name` must
    be populated with the updated resource's name.
    """

    update_mask: "betterproto_lib_google_protobuf.FieldMask" = (
        betterproto.message_field(2)
    )
    """List of field paths to be updated. If empty we replace all fields."""


@dataclass(eq=False, repr=False)
class DeleteFineTuningJobRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the fine-tuning job."""


@dataclass(eq=False, repr=False)
class IdentityProvider(betterproto.Message):
    """Next ID: 7"""

    name: str = betterproto.string_field(1)
    """
    The resource name of the identity provider.
    Format: accounts/{account}/identityProviders/{identity_provider}
    """

    display_name: str = betterproto.string_field(2)
    """Display name for the identity provider"""

    create_time: datetime = betterproto.message_field(3)
    """Creation timestamp"""

    update_time: datetime = betterproto.message_field(4)
    """Last update timestamp"""

    saml_config: "SamlConfig" = betterproto.message_field(5, group="config")
    """
    
    """

    oidc_config: "OidcConfig" = betterproto.message_field(6, group="config")
    """
    
    """


@dataclass(eq=False, repr=False)
class SamlConfig(betterproto.Message):
    """SAML Configuration"""

    metadata_url: str = betterproto.string_field(1)
    """SAML metadata URL or XML content"""


@dataclass(eq=False, repr=False)
class OidcConfig(betterproto.Message):
    """OIDC Configuration"""

    issuer_url: str = betterproto.string_field(1)
    """OIDC issuer URL"""

    client_id: str = betterproto.string_field(2)
    """Client ID"""

    client_secret: str = betterproto.string_field(3)
    """Client secret"""


@dataclass(eq=False, repr=False)
class CreateIdentityProviderRequest(betterproto.Message):
    """Request Messages"""

    parent: str = betterproto.string_field(1)
    """
    Parent account
    Format: accounts/{account}
    """

    identity_provider: "IdentityProvider" = betterproto.message_field(2)
    """Identity provider to create"""


@dataclass(eq=False, repr=False)
class GetIdentityProviderRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """
    Resource name of the identity provider
    Format: accounts/{account}/identityProviders/{identity_provider}
    """


@dataclass(eq=False, repr=False)
class ListIdentityProvidersRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    Parent account
    Format: accounts/{account}
    """

    page_size: int = betterproto.int32_field(2)
    """Page size"""

    page_token: str = betterproto.string_field(3)
    """Page token"""

    filter: str = betterproto.string_field(4)
    """Filter expression"""


@dataclass(eq=False, repr=False)
class ListIdentityProvidersResponse(betterproto.Message):
    """ """

    identity_providers: List["IdentityProvider"] = betterproto.message_field(1)
    """List of identity providers"""

    next_page_token: str = betterproto.string_field(2)
    """Next page token"""

    total_size: int = betterproto.int32_field(3)
    """Total count"""


@dataclass(eq=False, repr=False)
class UpdateIdentityProviderRequest(betterproto.Message):
    """ """

    identity_provider: "IdentityProvider" = betterproto.message_field(1)
    """Identity provider to update"""

    update_mask: "betterproto_lib_google_protobuf.FieldMask" = (
        betterproto.message_field(2)
    )
    """Update mask"""


@dataclass(eq=False, repr=False)
class DeleteIdentityProviderRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """
    Resource name of the identity provider
    Format: accounts/{account}/identityProviders/{identity_provider}
    """


@dataclass(eq=False, repr=False)
class InferenceLog(betterproto.Message):
    """Trace resource definition"""

    name: str = betterproto.string_field(1)
    """
    Resource name in the format "accounts/{account_id}/inference-logs/{inference_log_id}"
    """

    create_time: datetime = betterproto.message_field(2)
    """The time the inference log was created"""

    model: str = betterproto.string_field(3)
    """The model used for the inference"""

    request_type: str = betterproto.string_field(4)
    """Request type (chat, completion, embedding, etc.)"""

    input_content: str = betterproto.string_field(5)
    """The input content provided in the request"""

    output_content: str = betterproto.string_field(6)
    """The output content generated by the model"""

    duration_ms: int = betterproto.int64_field(7)
    """Duration of the request in milliseconds"""

    status_code: int = betterproto.int32_field(8)
    """Status code of the API call"""

    metadata: Dict[str, str] = betterproto.map_field(
        9, betterproto.TYPE_STRING, betterproto.TYPE_STRING
    )
    """Additional metadata about the log"""

    update_time: datetime = betterproto.message_field(10)
    """The update time for the inference log"""


@dataclass(eq=False, repr=False)
class GetInferenceLogRequest(betterproto.Message):
    """GetLogRequest for retrieving a single log"""

    name: str = betterproto.string_field(1)
    """The resource name of the inference log"""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class DeleteInferenceLogRequest(betterproto.Message):
    """
    DeleteInferenceLogRequest for deleting an inference log
    TODO: implement delete with filters
    """

    name: str = betterproto.string_field(1)
    """The resource name of the inference log"""


@dataclass(eq=False, repr=False)
class ListInferenceLogsRequest(betterproto.Message):
    """
    ListInferenceLogsRequest for retrieving inference logs with filtering
    """

    parent: str = betterproto.string_field(1)
    """The parent account resource name"""

    page_size: int = betterproto.int32_field(2)
    """The maximum number of logs to return per page"""

    page_token: str = betterproto.string_field(3)
    """A page token, received from a previous ListLogs call"""

    filter: str = betterproto.string_field(4)
    """
    A filter expression to filter results. See https://google.aip.dev/160
    """

    order_by: str = betterproto.string_field(5)
    """A comma-separated list of fields to order by"""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListInferenceLogsResponse(betterproto.Message):
    """ListInferenceLogsResponse returns the list of inference logs"""

    inference_logs: List["InferenceLog"] = betterproto.message_field(1)
    """The list of inference logs"""

    next_page_token: str = betterproto.string_field(2)
    """A token to retrieve the next page of results"""

    total_size: int = betterproto.int32_field(3)
    """The total number of inference logs matching the request"""


@dataclass(eq=False, repr=False)
class McpServer(betterproto.Message):
    """Next ID: 18"""

    name: str = betterproto.string_field(1)
    """The resource name of the mcp. e.g. accounts/my-account/mcps/my-mcp"""

    display_name: str = betterproto.string_field(2)
    """
    Human-readable display name of the mcp. e.g. "My Mcp"
    Must be fewer than 64 characters long.
    """

    description: str = betterproto.string_field(3)
    """The description of the mcp. Must be fewer than 4000 characters long."""

    create_time: datetime = betterproto.message_field(4)
    """The creation time of the mcp."""

    update_time: datetime = betterproto.message_field(5)
    """The update time for the mcp."""

    endpoint_url: str = betterproto.string_field(6)
    """
    The URL of the MCP server.
    Required if self_hosted is true. For managed MCPs, this will be populated
    after deployment.
    """

    api_key_secret: str = betterproto.string_field(7)
    """
    The resource name of the secret to use for authenticating with the MCP server.
    e.g. accounts/my-account/secrets/my-secret
    If provided for a remote-hosted MCP, the endpoint will be validated for connectivity
    during creation.
    """

    simulated: bool = betterproto.bool_field(8)
    """Whether this is a simulated MCP server."""

    state: "McpServerState" = betterproto.enum_field(10)
    """The state of the mcp."""

    status: "Status" = betterproto.message_field(11)
    """Contains detailed message when the last mcp operation fails."""

    remote_hosted: bool = betterproto.bool_field(12)
    """
    Whether this MCP is remote-hosted (true) or managed by Fireworks (false).
    """

    annotations: Dict[str, str] = betterproto.map_field(
        13, betterproto.TYPE_STRING, betterproto.TYPE_STRING
    )
    """
    Annotations to identify MCP properties.
    Key/value pairs may be used by external tools or other services.
    """

    public: bool = betterproto.bool_field(14)
    """
    Whether this MCP is publicly available to all Fireworks users.
    If false, only accessible to the account that created it.
    """

    authentication_type: "McpServerAuthenticationType" = betterproto.enum_field(15)
    """The authentication method required by this MCP server."""

    featured: bool = betterproto.bool_field(17)
    """
    Whether this MCP is featured/promoted (e.g., Fireworks-created or highlighted).
    """


@dataclass(eq=False, repr=False)
class CreateMcpServerRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The resource name of the parent account."""

    mcp_server: "McpServer" = betterproto.message_field(2)
    """The properties of the McpServer being created."""

    mcp_server_id: str = betterproto.string_field(3)
    """ID of the mcp server."""


@dataclass(eq=False, repr=False)
class GetMcpServerRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the mcp server."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListMcpServersRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """Resource name of the parent account."""

    page_size: int = betterproto.int32_field(2)
    """
    The maximum number of mcp servers to return. The maximum page_size is 200,
    values above 200 will be coerced to 200.
    If unspecified, the default is 50.
    """

    page_token: str = betterproto.string_field(3)
    """
    A page token, received from a previous ListMcpServers call. Provide this
    to retrieve the subsequent page. When paginating, all other parameters
    provided to ListMcpServers must match the call that provided the page
    token.
    """

    filter: str = betterproto.string_field(4)
    """
    Only mcp server satisfying the provided filter (if specified) will be
    returned. See https://google.aip.dev/160 for the filter grammar.
    """

    order_by: str = betterproto.string_field(5)
    """
    A comma-separated list of fields to order by. e.g. "foo,bar"
    The default sort order is ascending. To specify a descending order for a
    field, append a " desc" suffix. e.g. "foo desc,bar"
    Subfields are specified with a "." character. e.g. "foo.bar"
    If not specified, the default order is by "name".
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListMcpServersResponse(betterproto.Message):
    """ """

    mcp_servers: List["McpServer"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of mcp servers"""


@dataclass(eq=False, repr=False)
class UpdateMcpServerRequest(betterproto.Message):
    """ """

    mcp_server: "McpServer" = betterproto.message_field(1)
    """
    The properties of the mcp server being updated. `mcp_server.name` must
    be populated with the updated resource's name.
    """

    update_mask: "betterproto_lib_google_protobuf.FieldMask" = (
        betterproto.message_field(2)
    )
    """
    List of field paths to be updated. If empty only the fields present in mcp_server are updated
    """


@dataclass(eq=False, repr=False)
class DeleteMcpServerRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the mcp server."""


@dataclass(eq=False, repr=False)
class Model(betterproto.Message):
    """Next ID: 55"""

    name: str = betterproto.string_field(1)
    """
    The resource name of the model. e.g. accounts/my-account/models/my-model
    """

    display_name: str = betterproto.string_field(2)
    """
    TODO: add version number to the model
    
    Human-readable display name of the model. e.g. "My Model"
    Must be fewer than 64 characters long.
    """

    description: str = betterproto.string_field(20)
    """
    The description of the model. Must be fewer than 1000 characters long.
    """

    create_time: datetime = betterproto.message_field(3)
    """The creation time of the model."""

    created_by: str = betterproto.string_field(32)
    """The email address of the user who created this model."""

    state: "ModelState" = betterproto.enum_field(6)
    """The state of the model."""

    status: "Status" = betterproto.message_field(7)
    """Contains detailed message when the last model operation fails."""

    kind: "ModelKind" = betterproto.enum_field(4)
    """
    The kind of model.
    If not specified, the default is HF_PEFT_ADDON.
    """

    github_url: str = betterproto.string_field(21)
    """The URL to GitHub repository of the model."""

    hugging_face_url: str = betterproto.string_field(22)
    """The URL to the Hugging Face model."""

    base_model_details: "BaseModelDetails" = betterproto.message_field(23)
    """
    Base model details.
    Required if kind is HF_BASE_MODEL. Must not be set otherwise.
    """

    peft_details: "PeftDetails" = betterproto.message_field(16)
    """
    PEFT addon details.
    Required if kind is HF_PEFT_ADDON or HF_TEFT_ADDON.
    """

    teft_details: "TeftDetails" = betterproto.message_field(17)
    """
    TEFT addon details.
    Required if kind is HF_TEFT_ADDON. Must not be set otherwise.
    """

    public: bool = betterproto.bool_field(19)
    """If true, the model will be publicly readable."""

    conversation_config: "ConversationConfig" = betterproto.message_field(24)
    """If set, the Chat Completions API will be enabled for this model."""

    context_length: int = betterproto.int32_field(25)
    """The maximum context length supported by the model."""

    supports_image_input: bool = betterproto.bool_field(26)
    """If set, images can be provided as input to the model."""

    supports_tools: bool = betterproto.bool_field(27)
    """
    If set, tools (i.e. functions) can be provided as input to the model,
    and the model may respond with one or more tool calls.
    """

    imported_from: str = betterproto.string_field(28)
    """
    The name of the the model from which this was imported. This field is empty
    if the model was not imported.
    """

    tokens_per_second: int = betterproto.int32_field(29)
    """The approximate number of tokens/second this model can serve."""

    featured_priority: int = betterproto.int32_field(31)
    """
    If non-zero, this is the priority with which this model should be
    featured in the UI. Higher number is higher priority.
    """

    fine_tuning_job: str = betterproto.string_field(33)
    """
    If the model was created from a fine-tuning job, this is the fine-tuning
    job name.
    """

    sku_infos: List["SkuInfo"] = betterproto.message_field(34)
    """
    The pricing information of the model.
    TODO: Move this to DeployedModel.
    """

    default_draft_model: str = betterproto.string_field(35)
    """
    The default draft model to use when creating a deployment. If empty,
    speculative decoding is disabled by default.
    """

    default_draft_token_count: int = betterproto.int32_field(36)
    """
    The default draft token count to use when creating a deployment.
    Must be specified if default_draft_model is specified.
    """

    deployed_model_refs: List["DeployedModelRef"] = betterproto.message_field(37)
    """Populated from GetModel API call only."""

    cluster: str = betterproto.string_field(39)
    """
    The resource name of the BYOC cluster to which this model belongs.
    e.g. accounts/my-account/clusters/my-cluster. Empty if it belongs to
    a Fireworks cluster.
    """

    deprecation_date: "_google_type__.Date" = betterproto.message_field(40)
    """
    If specified, this is the date when the serverless deployment of the model will be taken down.
    """

    calibrated: bool = betterproto.bool_field(41)
    """
    If true, the model is calibrated and can be deployed to non-FP16 precisions.
    """

    tunable: bool = betterproto.bool_field(42)
    """
    If true, the model can be fine-tuned. The value will be true if the tunable field is true, and
    the model is validated against the model_type field.
    """

    supports_lora: bool = betterproto.bool_field(43)
    """Whether this model supports LoRA."""

    use_hf_apply_chat_template: bool = betterproto.bool_field(44)
    """
    If true, the model will use the Hugging Face apply_chat_template API to apply the chat template.
    """

    extra_deployment_args: List[str] = betterproto.string_field(45)
    """The arguments to pass when the model is deployed."""

    update_time: datetime = betterproto.message_field(46)
    """The update time for the model."""

    default_sampling_params: Dict[str, float] = betterproto.map_field(
        47, betterproto.TYPE_STRING, betterproto.TYPE_FLOAT
    )
    """
    A json object that contains the default sampling parameters for the model.
    """

    gcs_uri: str = betterproto.string_field(48)
    """
    The GCS URI where model files are stored. This is output-only and will only be populated
    if the model has been uploaded.
    """

    rl_tunable: bool = betterproto.bool_field(49)
    """If true, the model is RL tunable."""

    supported_precisions: List["DeploymentPrecision"] = betterproto.enum_field(51)
    """Supported precisions"""

    supported_precisions_with_calibration: List["DeploymentPrecision"] = (
        betterproto.enum_field(52)
    )
    """Supported precisions if calibrated"""

    training_context_length: int = betterproto.int32_field(50)
    """The maximum context length supported by the model."""

    image_tag: str = betterproto.string_field(53)
    """
    The container image tag to use. If not specified, the latest production
    version will be used.
    """

    annotations: Dict[str, str] = betterproto.map_field(
        54, betterproto.TYPE_STRING, betterproto.TYPE_STRING
    )
    """
    Annotations for the model. Used for storing metadata like image-tag-reason.
    """

    def __post_init__(self) -> None:
        super().__post_init__()
        if self.is_set("imported_from"):
            warnings.warn("Model.imported_from is deprecated", DeprecationWarning)


@dataclass(eq=False, repr=False)
class BaseModelDetails(betterproto.Message):
    """Next ID: 10"""

    world_size: int = betterproto.int32_field(1)
    """
    The default number of GPUs the model is served with.
    If not specified, the default is 1.
    """

    checkpoint_format: "BaseModelDetailsCheckpointFormat" = betterproto.enum_field(2)
    """
    
    """

    huggingface_files: List[str] = betterproto.string_field(3)
    """
    A list of Hugging Face files associated with this model. Specified if and only if
    the checkpoint_format is HUGGINGFACE.
    """

    parameter_count: int = betterproto.int64_field(4)
    """
    The number of model parameters. For serverless models, this determines the
    price per token.
    """

    moe: bool = betterproto.bool_field(5)
    """
    If true, this is a Mixture of Experts (MoE) model. For serverless models,
    this affects the price per token.
    """

    tunable: bool = betterproto.bool_field(6)
    """If true, this model is available for fine-tuning."""

    model_type: str = betterproto.string_field(7)
    """The type of the model."""

    supports_fireattention: bool = betterproto.bool_field(8)
    """Whether this model supports fireattention."""

    default_precision: "DeploymentPrecision" = betterproto.enum_field(9)
    """Default precision of the model."""

    def __post_init__(self) -> None:
        super().__post_init__()
        if self.is_set("tunable"):
            warnings.warn("BaseModelDetails.tunable is deprecated", DeprecationWarning)


@dataclass(eq=False, repr=False)
class PeftDetails(betterproto.Message):
    """
    PEFT addon details.
    Next ID: 6
    """

    base_model: str = betterproto.string_field(1)
    """The base model name. e.g. accounts/fireworks/models/falcon-7b"""

    r: int = betterproto.int32_field(2)
    """
    The rank of the update matrices.
    Must be between 4 and 64, inclusive.
    """

    target_modules: List[str] = betterproto.string_field(3)
    """
    This is the target modules for an adapter that we extract from
    for more information what target module means, check out
    https://huggingface.co/docs/peft/conceptual_guides/lora#common-lora-parameters-in-peft
    """

    base_model_type: str = betterproto.string_field(4)
    """The type of the model."""

    merge_addon_model_name: str = betterproto.string_field(5)
    """
    The resource name of the model to merge with base model, e.g accounts/fireworks/models/falcon-7b-lora
    """


@dataclass(eq=False, repr=False)
class TeftDetails(betterproto.Message):
    """ """

    pass


@dataclass(eq=False, repr=False)
class ConversationConfig(betterproto.Message):
    """ """

    style: str = betterproto.string_field(1)
    """The chat template to use."""

    system: str = betterproto.string_field(2)
    """The system prompt (if the chat style supports it)."""

    template: str = betterproto.string_field(3)
    """The Jinja template (if style is "jinja")."""


@dataclass(eq=False, repr=False)
class CreateModelRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The resource name of the parent account."""

    model: "Model" = betterproto.message_field(2)
    """The properties of the Model being created."""

    model_id: str = betterproto.string_field(3)
    """ID of the model."""

    cluster: str = betterproto.string_field(5)
    """
    The resource name of the BYOC cluster to which this model belongs.
    e.g. accounts/my-account/clusters/my-cluster. Empty if it belongs to
    a Fireworks cluster.
    """


@dataclass(eq=False, repr=False)
class GetModelRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the model."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class PrepareModelRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """
    resource name of the model to prepare, for now we will prepare everything in one
    request.
    """

    precision: "DeploymentPrecision" = betterproto.enum_field(2)
    """the precision with which the model will be prepared"""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        3
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    This is added as is used in getResource()
    """


@dataclass(eq=False, repr=False)
class GetModelUploadEndpointRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the model."""

    filename_to_size: Dict[str, int] = betterproto.map_field(
        2, betterproto.TYPE_STRING, betterproto.TYPE_INT64
    )
    """A mapping from the file name to its size in bytes."""

    enable_resumable_upload: bool = betterproto.bool_field(3)
    """If true, enable resumable upload instead of PUT."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        4
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class GetModelUploadEndpointResponse(betterproto.Message):
    """ """

    filename_to_signed_urls: Dict[str, str] = betterproto.map_field(
        5, betterproto.TYPE_STRING, betterproto.TYPE_STRING
    )
    """Signed URLs for uploading model files"""

    filename_to_unsigned_uris: Dict[str, str] = betterproto.map_field(
        6, betterproto.TYPE_STRING, betterproto.TYPE_STRING
    )
    """
    Unsigned URIs (e.g. s3://bucket/key, gs://bucket/key) for uploading model files.
    Returned when the caller has permission to upload to the URIs.
    """


@dataclass(eq=False, repr=False)
class GetModelDownloadEndpointRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the model."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class GetModelDownloadEndpointResponse(betterproto.Message):
    """ """

    filename_to_signed_urls: Dict[str, str] = betterproto.map_field(
        5, betterproto.TYPE_STRING, betterproto.TYPE_STRING
    )
    """Signed URLs for for downloading model files"""


@dataclass(eq=False, repr=False)
class ValidateModelUploadRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the model."""

    skip_hf_config_validation: bool = betterproto.bool_field(2)
    """If true, skip the Hugging Face config validation."""

    trust_remote_code: bool = betterproto.bool_field(3)
    """If true, trusts remote code when validating the Hugging Face config."""

    config_only: bool = betterproto.bool_field(4)
    """If true, skip tokenizer and parameter name validation."""


@dataclass(eq=False, repr=False)
class ListModelsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """Resource name of the parent account."""

    page_size: int = betterproto.int32_field(2)
    """
    The maximum number of models to return. The maximum page_size is 200,
    values above 200 will be coerced to 200.
    If unspecified, the default is 50.
    """

    page_token: str = betterproto.string_field(3)
    """
    A page token, received from a previous ListModels call. Provide this
    to retrieve the subsequent page. When paginating, all other parameters
    provided to ListModels must match the call that provided the page
    token.
    """

    filter: str = betterproto.string_field(4)
    """
    Only model satisfying the provided filter (if specified) will be
    returned. See https://google.aip.dev/160 for the filter grammar.
    """

    order_by: str = betterproto.string_field(5)
    """
    A comma-separated list of fields to order by. e.g. "foo,bar"
    The default sort order is ascending. To specify a descending order for a
    field, append a " desc" suffix. e.g. "foo desc,bar"
    Subfields are specified with a "." character. e.g. "foo.bar"
    If not specified, the default order is by "name".
    """

    include_deployed_model_refs: bool = betterproto.bool_field(6)
    """If true, will return deployed models info."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        7
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """

    show_internal: bool = betterproto.bool_field(8)
    """If true, will return internal models."""


@dataclass(eq=False, repr=False)
class ListModelsResponse(betterproto.Message):
    """ """

    models: List["Model"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of models"""


@dataclass(eq=False, repr=False)
class ListServerlessLoraModelsRequest(betterproto.Message):
    """
    Request message for ListServerlessLoraModels method

    response independent of the request
    """

    pass


@dataclass(eq=False, repr=False)
class ListServerlessLoraModelsResponse(betterproto.Message):
    """Response message for ListServerlessLoraModels method"""

    models: List[str] = betterproto.string_field(1)
    """List of model names that support serverless LoRA"""


@dataclass(eq=False, repr=False)
class ValidateModelConfigRequest(betterproto.Message):
    """ """

    config_json: str = betterproto.string_field(1)
    """The config JSON of the model."""

    tokenizer_config_json: str = betterproto.string_field(2)
    """The tokenizer config JSON of the model."""


@dataclass(eq=False, repr=False)
class UpdateModelRequest(betterproto.Message):
    """ """

    model: "Model" = betterproto.message_field(1)
    """
    The properties of the model being updated. `model.name` must
    be populated with the updated resource's name.
    """

    update_mask: "betterproto_lib_google_protobuf.FieldMask" = (
        betterproto.message_field(2)
    )
    """List of field paths to be updated. If empty we replace all fields."""


@dataclass(eq=False, repr=False)
class DeleteModelRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the model."""


@dataclass(eq=False, repr=False)
class AwsS3ModelSource(betterproto.Message):
    """ """

    s3_bucket: str = betterproto.string_field(1)
    """The S3 bucket name."""

    s3_path: str = betterproto.string_field(2)
    """The S3 path prefix."""

    role_arn: str = betterproto.string_field(3)
    """AWS role ARN for authentication"""

    access_key_id: str = betterproto.string_field(4)
    """AWS access key ID for authentication"""

    access_secret: str = betterproto.string_field(5)
    """AWS access secret for authentication"""


@dataclass(eq=False, repr=False)
class ImportModelRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the model."""

    aws_s3_source: "AwsS3ModelSource" = betterproto.message_field(2)
    """
    AWS S3 source details.
    Must be set when importing from AWS S3.
    """


@dataclass(eq=False, repr=False)
class NodePool(betterproto.Message):
    """Next ID: 16"""

    name: str = betterproto.string_field(1)
    """
    The resource name of the node pool. e.g. accounts/my-account/clusters/my-cluster/nodePools/my-pool
    """

    display_name: str = betterproto.string_field(6)
    """
    Human-readable display name of the node pool. e.g. "My Node Pool"
    Must be fewer than 64 characters long.
    """

    create_time: datetime = betterproto.message_field(9)
    """The creation time of the node pool."""

    min_node_count: int = betterproto.int32_field(10)
    """
    https://cloud.google.com/kubernetes-engine/quotas
    Minimum number of nodes in this node pool. Must be a non-negative integer
    less than or equal to max_node_count.
    If not specified, the default is 0.
    """

    max_node_count: int = betterproto.int32_field(11)
    """
    https://cloud.google.com/kubernetes-engine/quotas
    Maximum number of nodes in this node pool. Must be a positive integer
    greater than or equal to min_node_count.
    If not specified, the default is 1.
    """

    overprovision_node_count: int = betterproto.int32_field(12)
    """
    The number of nodes to overprovision by the autoscaler. Must be a
    non-negative integer and less than or equal to min_node_count and
    max_node_count-min_node_count.
    If not specified, the default is 0.
    """

    eks_node_pool: "EksNodePool" = betterproto.message_field(7, group="node_pool_type")
    """
    
    """

    fake_node_pool: "FakeNodePool" = betterproto.message_field(
        3, group="node_pool_type"
    )
    """
    
    """

    annotations: Dict[str, str] = betterproto.map_field(
        14, betterproto.TYPE_STRING, betterproto.TYPE_STRING
    )
    """
    Arbitrary, user-specified metadata.
    Keys and values must adhere to Kubernetes constraints: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/#syntax-and-character-set
    Additionally, the "fireworks.ai/" prefix is reserved.
    """

    state: "NodePoolState" = betterproto.enum_field(5)
    """The current state of the node pool."""

    status: "Status" = betterproto.message_field(8)
    """
    Contains detailed message when the last node pool operation fails, e.g.
    when node pool is in FAILED state or when last node pool update fails.
    """

    node_pool_stats: "NodePoolStats" = betterproto.message_field(13)
    """Live statistics of the node pool."""

    update_time: datetime = betterproto.message_field(15)
    """The update time for the node pool."""


@dataclass(eq=False, repr=False)
class EksNodePool(betterproto.Message):
    """
    An Amazon Elastic Kubernetes Service node pool.
    Next ID: 10
    """

    node_role: str = betterproto.string_field(1)
    """
    The IAM role ARN to associate with nodes. The role must have the
    following IAM policies attached:
    - AmazonEKSWorkerNodePolicy
    - AmazonEC2ContainerRegistryReadOnly
    - AmazonEKS_CNI_Policy
    
    If not specified, the parent cluster's system_node_group_role
    will be used.
    """

    instance_type: str = betterproto.string_field(2)
    """
    The type of instance used in this node pool. See https://aws.amazon.com/ec2/instance-types/
    for a list of valid instance types.
    """

    spot: bool = betterproto.bool_field(4)
    """
    If true, nodes are created as preemptible VM instances.
    See https://docs.aws.amazon.com/eks/latest/userguide/managed-node-groups.html#managed-node-group-capacity-types
    """

    node_group_name: str = betterproto.string_field(5)
    """
    The name of the node group.
    If not specified, the default is the node pool ID.
    """

    subnet_ids: List[str] = betterproto.string_field(6)
    """
    A list of subnet IDs for nodes in this node pool.
    If not specified, the parent cluster's default subnet IDs that matches the zone
    will be used. Note that all the subnets will need to be in the same zone.
    """

    zone: str = betterproto.string_field(7)
    """
    Zone for the node pool.
    If not specified, a random zone in the cluster's region will be selected.
    """

    placement_group: str = betterproto.string_field(8)
    """Cluster placement group to colocate hosts in this pool."""

    launch_template: str = betterproto.string_field(9)
    """Launch template to create for this node group."""


@dataclass(eq=False, repr=False)
class FakeNodePool(betterproto.Message):
    """A fake node pool to be used with FakeCluster."""

    machine_type: str = betterproto.string_field(1)
    """
    
    """

    num_nodes: int = betterproto.int32_field(2)
    """
    
    """

    service_account: str = betterproto.string_field(3)
    """
    
    """


@dataclass(eq=False, repr=False)
class NodePoolStats(betterproto.Message):
    """Next ID: 7"""

    node_count: int = betterproto.int32_field(1)
    """The number of nodes currently available in this pool."""

    ranks_per_node: int = betterproto.int32_field(2)
    """
    The number of ranks available per node. This is determined by the machine
    type of the nodes in this node pool.
    """

    environment_count: int = betterproto.int32_field(3)
    """The number of environments connected to this node pool."""

    environment_ranks: int = betterproto.int32_field(4)
    """
    The number of ranks in this node pool that are currently allocated
    to environment connections.
    """

    batch_job_count: Dict[str, int] = betterproto.map_field(
        5, betterproto.TYPE_STRING, betterproto.TYPE_INT32
    )
    """
    The key is the string representation of BatchJob.State (e.g. "RUNNING").
    The value is the number of batch jobs in that state allocated to this
    node pool.
    """

    batch_job_ranks: Dict[str, int] = betterproto.map_field(
        6, betterproto.TYPE_STRING, betterproto.TYPE_INT32
    )
    """
    The key is the string representation of BatchJob.State (e.g. "RUNNING").
    The value is the number of ranks allocated to batch jobs in that state in
    this node pool.
    """


@dataclass(eq=False, repr=False)
class CreateNodePoolRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The resource name of the parent cluster."""

    node_pool: "NodePool" = betterproto.message_field(2)
    """The properties of the NodePool being created."""

    node_pool_id: str = betterproto.string_field(3)
    """The node pool ID to use in the node pool name. e.g. my-pool"""


@dataclass(eq=False, repr=False)
class GetNodePoolRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the node pool."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListNodePoolsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """Resource name of the parent cluster."""

    page_size: int = betterproto.int32_field(2)
    """
    The maximum number of node pools to return. The maximum page_size is 200,
    values above 200 will be coerced to 200.
    If unspecified, the default is 50.
    """

    page_token: str = betterproto.string_field(3)
    """
    A page token, received from a previous ListNodePools call. Provide this
    to retrieve the subsequent page. When paginating, all other parameters
    provided to ListNodePools must match the call that provided the page
    token.
    """

    filter: str = betterproto.string_field(4)
    """
    Only node pools satisfying the provided filter (if specified) will be
    returned. See https://google.aip.dev/160 for the filter grammar.
    """

    order_by: str = betterproto.string_field(5)
    """
    A comma-separated list of fields to order by. e.g. "foo,bar"
    The default sort order is ascending. To specify a descending order for a
    field, append a " desc" suffix. e.g. "foo desc,bar"
    Subfields are specified with a "." character. e.g. "foo.bar"
    If not specified, the default order is by "name".
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListNodePoolsResponse(betterproto.Message):
    """ """

    node_pools: List["NodePool"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of node pools."""


@dataclass(eq=False, repr=False)
class UpdateNodePoolRequest(betterproto.Message):
    """ """

    node_pool: "NodePool" = betterproto.message_field(1)
    """
    The properties of the NodePool being updated. `node_pool.name` must
    be populated with the updated resource's name.
    """

    update_mask: "betterproto_lib_google_protobuf.FieldMask" = (
        betterproto.message_field(2)
    )
    """List of field paths to be updated. If empty we replace all fields."""


@dataclass(eq=False, repr=False)
class DeleteNodePoolRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the node pool."""


@dataclass(eq=False, repr=False)
class BatchDeleteNodePoolsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The resource name of the parent cluster."""

    names: List[str] = betterproto.string_field(2)
    """The resource names of the node pools to delete."""


@dataclass(eq=False, repr=False)
class GetNodePoolStatsRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the node pool."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class NodePoolBinding(betterproto.Message):
    """ """

    account_id: str = betterproto.string_field(1)
    """The account ID that this binding is associated with."""

    cluster_id: str = betterproto.string_field(2)
    """The cluster ID that this binding is associated with."""

    node_pool_id: str = betterproto.string_field(3)
    """The node pool ID that this binding is associated with."""

    create_time: datetime = betterproto.message_field(4)
    """The creation time of the node pool binding."""

    principal: str = betterproto.string_field(5)
    """
    The principal that is allowed use the node pool. This must be
    the email address of the user.
    """


@dataclass(eq=False, repr=False)
class CreateNodePoolBindingRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The resource name of the parent node pool."""

    node_pool_binding: "NodePoolBinding" = betterproto.message_field(2)
    """The properties of the node pool binding being created."""


@dataclass(eq=False, repr=False)
class ListNodePoolBindingsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The resource name of the parent node pool."""

    page_size: int = betterproto.int32_field(2)
    """
    The maximum number of bindings to return. The maximum page_size is 200,
    values above 200 will be coerced to 200.
    If unspecified, the default is 50.
    """

    page_token: str = betterproto.string_field(3)
    """
    A page token, received from a previous ListNodePoolBindings call.
    Provide this to retrieve the subsequent page. When paginating, all other
    parameters provided to ListNodePoolBindings must match the call that
    provided the page token.
    """

    filter: str = betterproto.string_field(4)
    """
    Only bindings satisfying the provided filter (if specified) will be
    returned. See https://google.aip.dev/160 for the filter grammar.
    """

    order_by: str = betterproto.string_field(5)
    """
    A comma-separated list of fields to order by. e.g. "foo,bar"
    The default sort order is ascending. To specify a descending order for a
    field, append a " desc" suffix. e.g. "foo desc,bar"
    Subfields are specified with a "." character. e.g. "foo.bar"
    If not specified, the default order is by "name".
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListNodePoolBindingsResponse(betterproto.Message):
    """ """

    node_pool_bindings: List["NodePoolBinding"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of node pool bindings."""


@dataclass(eq=False, repr=False)
class DeleteNodePoolBindingRequest(betterproto.Message):
    """ """

    node_pool_binding: "NodePoolBinding" = betterproto.message_field(2)
    """
    The node pool binding being deleted.
    Must specify account_id, cluster_id, node_pool_id, and principal.
    """


@dataclass(eq=False, repr=False)
class PeftMergeJob(betterproto.Message):
    """Next ID: 12"""

    name: str = betterproto.string_field(1)
    """
    
    """

    display_name: str = betterproto.string_field(2)
    """
    
    """

    create_time: datetime = betterproto.message_field(3)
    """
    
    """

    created_by: str = betterproto.string_field(4)
    """The email address of the user who created this peft merge job."""

    state: "JobState" = betterproto.enum_field(5)
    """
    
    """

    status: "Status" = betterproto.message_field(6)
    """
    
    """

    peft_model: str = betterproto.string_field(7)
    """
    
    """

    merged_model: str = betterproto.string_field(9)
    """
    
    """

    update_time: datetime = betterproto.message_field(11)
    """The update time for the peft merge job."""


@dataclass(eq=False, repr=False)
class GetPeftMergeJobRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """
    
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class CreatePeftMergeJobRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    
    """

    peft_merge_job: "PeftMergeJob" = betterproto.message_field(2)
    """
    
    """


@dataclass(eq=False, repr=False)
class ListPeftMergeJobsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    
    """

    page_size: int = betterproto.int32_field(2)
    """
    The maximum number of peft merge jobs to return. The maximum page_size is 200,
    values above 200 will be coerced to 200.
    If unspecified, the default is 50.
    """

    page_token: str = betterproto.string_field(3)
    """
    A page token, received from a previous ListPeftMergeJobs call. Provide this
    to retrieve the subsequent page. When paginating, all other parameters
    provided to ListPeftMergeJobs must match the call that provided the page
    token.
    """

    filter: str = betterproto.string_field(4)
    """
    Only jobs satisfying the provided filter (if specified) will be
    returned. See https://google.aip.dev/160 for the filter grammar.
    """

    order_by: str = betterproto.string_field(5)
    """
    A comma-separated list of fields to order by. e.g. "foo,bar"
    The default sort order is ascending. To specify a descending order for a
    field, append a " desc" suffix. e.g. "foo desc,bar"
    Subfields are specified with a "." character. e.g. "foo.bar"
    If not specified, the default order is by "created_time".
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListPeftMergeJobsResponse(betterproto.Message):
    """ """

    peft_merge_jobs: List["PeftMergeJob"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of peft merge jobs."""


@dataclass(eq=False, repr=False)
class DeletePeftMergeJobRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the peft merge job."""


@dataclass(eq=False, repr=False)
class Quota(betterproto.Message):
    """Next ID: 7"""

    name: str = betterproto.string_field(1)
    """
    The resource name of the quota, e.g. accounts/my-account/quotas/h100-us-iowa-1
    """

    value: int = betterproto.int64_field(2)
    """
    The value of the quota being enforced. This may be lower than the max_value
    if the user manually lowers it.
    """

    max_value: int = betterproto.int64_field(3)
    """The maximum approved value."""

    usage: float = betterproto.double_field(6)
    """The usage of the quota."""

    update_time: datetime = betterproto.message_field(4)
    """The update time for the quota."""

    create_time: datetime = betterproto.message_field(5)
    """The creation time for the quota."""


@dataclass(eq=False, repr=False)
class GetQuotaRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the quota."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListQuotasRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """Resource name of the parent account."""

    page_size: int = betterproto.int32_field(2)
    """
    The maximum number of quotas to return. The maximum page_size is 200,
    values above 200 will be coerced to 200.
    If unspecified, the default is 50.
    """

    page_token: str = betterproto.string_field(3)
    """
    A page token, received from a previous ListQuotas call. Provide this
    to retrieve the subsequent page. When paginating, all other parameters
    provided to ListQuotas must match the call that provided the page
    token.
    """

    filter: str = betterproto.string_field(4)
    """
    Only quota satisfying the provided filter (if specified) will be
    returned. See https://google.aip.dev/160 for the filter grammar.
    """

    order_by: str = betterproto.string_field(5)
    """
    A comma-separated list of fields to order by. e.g. "foo,bar"
    The default sort order is ascending. To specify a descending order for a
    field, append a " desc" suffix. e.g. "foo desc,bar"
    Subfields are specified with a "." character. e.g. "foo.bar"
    If not specified, the default order is by "name".
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class UpdateQuotaRequest(betterproto.Message):
    """ """

    quota: "Quota" = betterproto.message_field(1)
    """
    The properties of the quota being updated. `quota.name` must
    be populated with the updated resource's name.
    """

    update_mask: "betterproto_lib_google_protobuf.FieldMask" = (
        betterproto.message_field(2)
    )
    """List of field paths to be updated. If empty we replace all fields."""

    allow_missing: bool = betterproto.bool_field(3)
    """If true, and the quota does not exist, it will be created."""


@dataclass(eq=False, repr=False)
class ListQuotasResponse(betterproto.Message):
    """ """

    quotas: List["Quota"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of quotas"""


@dataclass(eq=False, repr=False)
class ReinforcementFineTuningEpoch(betterproto.Message):
    """Next ID: 19"""

    name: str = betterproto.string_field(1)
    """
    
    """

    create_time: datetime = betterproto.message_field(2)
    """
    
    """

    completed_time: datetime = betterproto.message_field(3)
    """
    
    """

    dataset: str = betterproto.string_field(4)
    """The name of the dataset used for training."""

    evaluation_dataset: str = betterproto.string_field(5)
    """The name of a separate dataset to use for evaluation."""

    eval_auto_carveout: bool = betterproto.bool_field(6)
    """Whether to auto-carve the dataset for eval."""

    state: "JobState" = betterproto.enum_field(7)
    """
    
    """

    status: "Status" = betterproto.message_field(8)
    """
    
    """

    created_by: str = betterproto.string_field(9)
    """The email address of the user who initiated this fine-tuning job."""

    update_time: datetime = betterproto.message_field(10)
    """The update time for the reinforcement fine-tuning epoch."""

    training_config: "BaseTrainingConfig" = betterproto.message_field(11)
    """Common training configurations."""

    evaluator: str = betterproto.string_field(12)
    """The evaluator resource name to use for RLOR epoch."""

    wandb_config: "WandbConfig" = betterproto.message_field(13)
    """
    The Weights & Biases team/user account for logging training progress.
    """

    rollout_n: int = betterproto.int32_field(14)
    """Number of response candidates to generate per example."""

    ending_assistant_messages: str = betterproto.string_field(15)
    """The ending assistant messages to use for the rollout."""

    reinforcement_fine_tuning_job_id: str = betterproto.string_field(16)
    """
    The ID of the reinforcement fine-tuning job that this epoch belongs to.
    """

    job_progress: "JobProgress" = betterproto.message_field(17)
    """Job progress."""

    inference_parameters: "InferenceParameters" = betterproto.message_field(18)
    """BIJ parameters."""


@dataclass(eq=False, repr=False)
class GetReinforcementFineTuningEpochRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the fine-tuning epoch."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class CreateReinforcementFineTuningEpochRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The resource name of the account."""

    reinforcement_fine_tuning_epoch: "ReinforcementFineTuningEpoch" = (
        betterproto.message_field(2)
    )
    """
    
    """

    debug: bool = betterproto.bool_field(3)
    """Whether to run the fine-tuning epoch in debug mode, superuser only."""

    reinforcement_fine_tuning_epoch_id: str = betterproto.string_field(4)
    """
    ID of the reinforcement fine-tuning epoch, a random UUID will be generated if not specified.
    """

    skip_validations: bool = betterproto.bool_field(5)
    """Whether to skip validation."""


@dataclass(eq=False, repr=False)
class ListReinforcementFineTuningEpochsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    
    """

    page_size: int = betterproto.int32_field(2)
    """
    The maximum number of fine-tuning epochs to return. The maximum page_size is 200,
    values above 200 will be coerced to 200.
    If unspecified, the default is 50.
    """

    page_token: str = betterproto.string_field(3)
    """
    A page token, received from a previous ListReinforcementFineTuningEpochs call. Provide this
    to retrieve the subsequent page. When paginating, all other parameters
    provided to ListReinforcementFineTuningEpochs must match the call that provided the page
    token.
    """

    filter: str = betterproto.string_field(4)
    """
    Filter criteria for the returned epochs. See https://google.aip.dev/160 for the filter syntax specification.
    """

    order_by: str = betterproto.string_field(5)
    """
    A comma-separated list of fields to order by. e.g. "foo,bar"
    The default sort order is ascending. To specify a descending order for a
    field, append a " desc" suffix. e.g. "foo desc,bar"
    Subfields are specified with a "." character. e.g. "foo.bar"
    If not specified, the default order is by "name".
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListReinforcementFineTuningEpochsResponse(betterproto.Message):
    """ """

    reinforcement_fine_tuning_epochs: List["ReinforcementFineTuningEpoch"] = (
        betterproto.message_field(1)
    )
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of fine-tuning epochs"""


@dataclass(eq=False, repr=False)
class DeleteReinforcementFineTuningEpochRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the reinforcement fine-tuning epoch."""


@dataclass(eq=False, repr=False)
class ReinforcementFineTuningJob(betterproto.Message):
    """Next ID: 21"""

    name: str = betterproto.string_field(1)
    """
    
    """

    display_name: str = betterproto.string_field(2)
    """
    
    """

    create_time: datetime = betterproto.message_field(3)
    """
    
    """

    completed_time: datetime = betterproto.message_field(4)
    """The completed time for the reinforcement fine-tuning job."""

    dataset: str = betterproto.string_field(5)
    """The name of the dataset used for training."""

    evaluation_dataset: str = betterproto.string_field(6)
    """The name of a separate dataset to use for evaluation."""

    eval_auto_carveout: bool = betterproto.bool_field(7)
    """Whether to auto-carve the dataset for eval."""

    state: "JobState" = betterproto.enum_field(8)
    """
    
    """

    status: "Status" = betterproto.message_field(9)
    """
    
    """

    created_by: str = betterproto.string_field(10)
    """The email address of the user who initiated this fine-tuning job."""

    training_config: "BaseTrainingConfig" = betterproto.message_field(11)
    """Common training configurations."""

    evaluator: str = betterproto.string_field(12)
    """The evaluator resource name to use for RLOR fine-tuning job."""

    wandb_config: "WandbConfig" = betterproto.message_field(14)
    """
    The Weights & Biases team/user account for logging training progress.
    """

    output_stats: str = betterproto.string_field(15)
    """The output dataset's aggregated stats for the evaluation job."""

    job_progress: "JobProgress" = betterproto.message_field(16)
    """Job progress."""

    inference_parameters: "InferenceParameters" = betterproto.message_field(17)
    """BIJ parameters."""

    chunk_size: int = betterproto.int32_field(18)
    """
    Data chunking for rollout, default size 200, enabled when dataset > 300.
    """

    output_stats_internal: str = betterproto.string_field(19)
    """The internal output stats for the evaluation job."""

    output_metrics: str = betterproto.string_field(20)
    """
    
    """

    mcp_server: str = betterproto.string_field(21)
    """
    
    """

    use_temporal_workflow: bool = betterproto.bool_field(22)
    """Whether to use the Temporal workflow for this job."""


@dataclass(eq=False, repr=False)
class GetReinforcementFineTuningJobRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the fine-tuning job."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class CreateReinforcementFineTuningJobRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The resource name of the account."""

    reinforcement_fine_tuning_job: "ReinforcementFineTuningJob" = (
        betterproto.message_field(2)
    )
    """
    
    """

    debug: bool = betterproto.bool_field(3)
    """Whether to run the fine-tuning job in debug mode, superuser only."""

    reinforcement_fine_tuning_job_id: str = betterproto.string_field(4)
    """
    ID of the reinforcement fine-tuning job, a random UUID will be generated if not specified.
    """

    skip_validations: bool = betterproto.bool_field(5)
    """Whether to skip validation."""


@dataclass(eq=False, repr=False)
class ListReinforcementFineTuningJobsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    
    """

    page_size: int = betterproto.int32_field(2)
    """
    The maximum number of fine-tuning jobs to return. The maximum page_size is 200,
    values above 200 will be coerced to 200.
    If unspecified, the default is 50.
    """

    page_token: str = betterproto.string_field(3)
    """
    A page token, received from a previous ListReinforcementLearningFineTuningJobs call. Provide this
    to retrieve the subsequent page. When paginating, all other parameters
    provided to ListReinforcementLearningFineTuningJobs must match the call that provided the page
    token.
    """

    filter: str = betterproto.string_field(4)
    """
    Filter criteria for the returned jobs. See https://google.aip.dev/160 for the filter syntax specification.
    """

    order_by: str = betterproto.string_field(5)
    """
    A comma-separated list of fields to order by. e.g. "foo,bar"
    The default sort order is ascending. To specify a descending order for a
    field, append a " desc" suffix. e.g. "foo desc,bar"
    Subfields are specified with a "." character. e.g. "foo.bar"
    If not specified, the default order is by "name".
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListReinforcementFineTuningJobsResponse(betterproto.Message):
    """ """

    reinforcement_fine_tuning_jobs: List["ReinforcementFineTuningJob"] = (
        betterproto.message_field(1)
    )
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of fine-tuning jobs"""


@dataclass(eq=False, repr=False)
class DeleteReinforcementFineTuningJobRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the reinforcement fine-tuning job."""


@dataclass(eq=False, repr=False)
class ResumeReinforcementFineTuningJobRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the reinforcement fine-tuning job."""


@dataclass(eq=False, repr=False)
class DebugReinforcementFineTuningJobRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the reinforcement fine-tuning job."""


@dataclass(eq=False, repr=False)
class DebugReinforcementFineTuningJobResponse(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the reinforcement fine-tuning job."""

    failed_job_name: str = betterproto.string_field(2)
    """
    
    """


@dataclass(eq=False, repr=False)
class Reservation(betterproto.Message):
    """Next ID: 16"""

    name: str = betterproto.string_field(1)
    """
    The resource name of the reservation. e.g. accounts/my-account/reservations/abcdef
    """

    display_name: str = betterproto.string_field(2)
    """
    Human-readable display name of the reservation. e.g. "My Reservation"
    Must be fewer than 64 characters long.
    """

    description: str = betterproto.string_field(3)
    """Description of the reservation."""

    create_time: datetime = betterproto.message_field(4)
    """The creation time of the reservation."""

    created_by: str = betterproto.string_field(5)
    """The email address of the user who created this reservation."""

    region: "Region" = betterproto.enum_field(13)
    """
    The region for this reservation. Exactly one of region or multi_region must
    be specified.
    """

    multi_region: "MultiRegion" = betterproto.enum_field(15)
    """
    The multi-region for this reservation. Exactly one of region or
    multi_region must be specified.
    """

    accelerator_type: "AcceleratorType" = betterproto.enum_field(6)
    """The type of accelerator for this reservation."""

    reserved_count: int = betterproto.int32_field(7)
    """The number of accelerators reserved."""

    start_time: datetime = betterproto.message_field(8)
    """
    The timestamp at which the reservation starts (inclusive).
    If unspecified, this is midnight of the following calendar day (UTC).
    """

    end_time: datetime = betterproto.message_field(9)
    """
    The timestamp at which the reservation ends (exclusive).
    If unspecified, this will be 1 calendar year after the start time.
    """

    contract: str = betterproto.string_field(12)
    """
    An internal link or description of the contract this reservation is
    associated with.
    """

    update_time: datetime = betterproto.message_field(14)
    """The update time for the reservation."""


@dataclass(eq=False, repr=False)
class GetReservationRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the reservation."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListReservationsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """Resource name of the parent reservation."""

    page_size: int = betterproto.int32_field(2)
    """
    The maximum number of reservations to return. The maximum page_size is 200,
    values above 200 will be coerced to 200.
    If unspecified, the default is 50.
    """

    page_token: str = betterproto.string_field(3)
    """
    A page token, received from a previous ListReservations call. Provide this
    to retrieve the subsequent page. When paginating, all other parameters
    provided to ListReservations must match the call that provided the page
    token.
    """

    filter: str = betterproto.string_field(4)
    """
    Only reservations satisfying the provided filter (if specified) will be
    returned. See https://google.aip.dev/160 for the filter grammar.
    """

    order_by: str = betterproto.string_field(5)
    """
    A comma-separated list of fields to order by. e.g. "foo,bar"
    The default sort order is ascending. To specify a descending order for a
    field, append a " desc" suffix. e.g. "foo desc,bar"
    Subfields are specified with a "." character. e.g. "foo.bar"
    If not specified, the default order is by "start_time".
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListReservationsResponse(betterproto.Message):
    """ """

    reservations: List["Reservation"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of reservations."""


@dataclass(eq=False, repr=False)
class RlorTrainerJob(betterproto.Message):
    """Next ID: 16"""

    name: str = betterproto.string_field(1)
    """
    
    """

    display_name: str = betterproto.string_field(2)
    """
    
    """

    create_time: datetime = betterproto.message_field(3)
    """
    
    """

    completed_time: datetime = betterproto.message_field(4)
    """
    
    """

    dataset: str = betterproto.string_field(5)
    """The name of the dataset used for training."""

    evaluation_dataset: str = betterproto.string_field(6)
    """The name of a separate dataset to use for evaluation."""

    eval_auto_carveout: bool = betterproto.bool_field(7)
    """Whether to auto-carve the dataset for eval."""

    state: "JobState" = betterproto.enum_field(8)
    """
    
    """

    status: "Status" = betterproto.message_field(9)
    """
    
    """

    created_by: str = betterproto.string_field(10)
    """The email address of the user who initiated this fine-tuning job."""

    training_config: "BaseTrainingConfig" = betterproto.message_field(11)
    """Common training configurations."""

    reward_weights: List[str] = betterproto.string_field(12)
    """
    A list of reward metrics to use for training in format of "<reward_name>=<weight>".
    """

    wandb_config: "WandbConfig" = betterproto.message_field(13)
    """
    The Weights & Biases team/user account for logging training progress.
    """

    reinforcement_fine_tuning_epoch_id: str = betterproto.string_field(14)
    """The ID of the RFT epoch that this RLOR trainer job belongs to."""

    job_progress: "JobProgress" = betterproto.message_field(15)
    """Job progress."""

    def __post_init__(self) -> None:
        super().__post_init__()
        if self.is_set("reward_weights"):
            warnings.warn(
                "RlorTrainerJob.reward_weights is deprecated", DeprecationWarning
            )


@dataclass(eq=False, repr=False)
class GetRlorTrainerJobRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the fine-tuning job."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class CreateRlorTrainerJobRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The resource name of the account."""

    rlor_trainer_job: "RlorTrainerJob" = betterproto.message_field(2)
    """
    
    """

    debug: bool = betterproto.bool_field(3)
    """Whether to run the fine-tuning job in debug mode, superuser only."""

    rlor_trainer_job_id: str = betterproto.string_field(4)
    """
    ID of the RLOR trainer job, a random UUID will be generated if not specified.
    """

    skip_validations: bool = betterproto.bool_field(5)
    """Whether to skip validation."""


@dataclass(eq=False, repr=False)
class ListRlorTrainerJobsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    
    """

    page_size: int = betterproto.int32_field(2)
    """
    The maximum number of fine-tuning jobs to return. The maximum page_size is 200,
    values above 200 will be coerced to 200.
    If unspecified, the default is 50.
    """

    page_token: str = betterproto.string_field(3)
    """
    A page token, received from a previous ListRlorTuningJobs call. Provide this
    to retrieve the subsequent page. When paginating, all other parameters
    provided to ListRlorTuningJobs must match the call that provided the page
    token.
    """

    filter: str = betterproto.string_field(4)
    """
    Filter criteria for the returned jobs. See https://google.aip.dev/160 for the filter syntax specification.
    """

    order_by: str = betterproto.string_field(5)
    """
    A comma-separated list of fields to order by. e.g. "foo,bar"
    The default sort order is ascending. To specify a descending order for a
    field, append a " desc" suffix. e.g. "foo desc,bar"
    Subfields are specified with a "." character. e.g. "foo.bar"
    If not specified, the default order is by "name".
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListRlorTrainerJobsResponse(betterproto.Message):
    """ """

    rlor_trainer_jobs: List["RlorTrainerJob"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of fine-tuning jobs"""


@dataclass(eq=False, repr=False)
class DeleteRlorTrainerJobRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the rlor trainer job."""


@dataclass(eq=False, repr=False)
class Secret(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """
    name follows the convention
    accounts/account-id/secrets/unkey-key-id
    """

    key_name: str = betterproto.string_field(2)
    """name of the key. In this case, it can be WOLFRAM_ALPHA_API_KEY"""

    value: str = betterproto.string_field(3)
    """
    
    """


@dataclass(eq=False, repr=False)
class CreateSecretRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    
    """

    secret: "Secret" = betterproto.message_field(2)
    """
    
    """


@dataclass(eq=False, repr=False)
class GetSecretRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """
    
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListSecretsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    
    """

    page_size: int = betterproto.int32_field(2)
    """
    
    """

    page_token: str = betterproto.string_field(3)
    """
    
    """

    filter: str = betterproto.string_field(4)
    """Unused but required to use existing ListRequest functionality."""

    order_by: str = betterproto.string_field(5)
    """Unused but required to use existing ListRequest functionality."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListSecretsResponse(betterproto.Message):
    """ """

    secrets: List["Secret"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of secrets."""


@dataclass(eq=False, repr=False)
class UpdateSecretRequest(betterproto.Message):
    """ """

    secret: "Secret" = betterproto.message_field(1)
    """
    
    """


@dataclass(eq=False, repr=False)
class DeleteSecretRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """
    
    """


@dataclass(eq=False, repr=False)
class GetOAuthArgumentsRequest(betterproto.Message):
    """ """

    account_id: str = betterproto.string_field(1)
    """
    
    """


@dataclass(eq=False, repr=False)
class GetOAuthArgumentsResponse(betterproto.Message):
    """ """

    issuer_url: str = betterproto.string_field(1)
    """
    
    """

    client_id: str = betterproto.string_field(2)
    """
    
    """

    cognito_domain: str = betterproto.string_field(3)
    """
    
    """


@dataclass(eq=False, repr=False)
class Snapshot(betterproto.Message):
    """Next ID: 7"""

    name: str = betterproto.string_field(1)
    """
    The resource name of the snapshot.
    e.g. accounts/my-account/clusters/my-cluster/environments/my-env/snapshots/1
    """

    create_time: datetime = betterproto.message_field(2)
    """The creation time of the snapshot."""

    state: "SnapshotState" = betterproto.enum_field(3)
    """The state of the snapshot."""

    status: "Status" = betterproto.message_field(4)
    """The status code and message of the snapshot."""

    image_ref: str = betterproto.string_field(5)
    """The URI of the container image for this snapshot."""

    update_time: datetime = betterproto.message_field(6)
    """The update time for the snapshot."""


@dataclass(eq=False, repr=False)
class CreateSnapshotRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The resource name of the parent environment."""

    snapshot: "Snapshot" = betterproto.message_field(2)
    """The properties of the snapshot being created."""


@dataclass(eq=False, repr=False)
class GetSnapshotRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the snapshot."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListSnapshotsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """Resource name of the parent environment."""

    page_size: int = betterproto.int32_field(2)
    """
    The maximum number of snapshots to return. The maximum page_size is 200,
    values above 200 will be coerced to 200.
    If unspecified, the default is 50.
    """

    page_token: str = betterproto.string_field(3)
    """
    A page token, received from a previous ListEnvironments call. Provide this
    to retrieve the subsequent page. When paginating, all other parameters
    provided to ListEnvironments must match the call that provided the page
    token.
    """

    filter: str = betterproto.string_field(4)
    """
    Only snapshots satisfying the provided filter (if specified) will be
    returned. See https://google.aip.dev/160 for the filter grammar.
    """

    order_by: str = betterproto.string_field(5)
    """
    A comma-separated list of fields to order by. e.g. "foo,bar"
    The default sort order is ascending. To specify a descending order for a
    field, append a " desc" suffix. e.g. "foo desc,bar"
    Subfields are specified with a "." character. e.g. "foo.bar"
    If not specified, the default order is by "create_time".
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListSnapshotsResponse(betterproto.Message):
    """ """

    snapshots: List["Snapshot"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of snapshots."""


@dataclass(eq=False, repr=False)
class DeleteSnapshotRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the snapshot."""


@dataclass(eq=False, repr=False)
class SupervisedFineTuningJob(betterproto.Message):
    """Next ID: 37"""

    name: str = betterproto.string_field(1)
    """
    
    """

    display_name: str = betterproto.string_field(2)
    """
    
    """

    create_time: datetime = betterproto.message_field(3)
    """
    
    """

    completed_time: datetime = betterproto.message_field(23)
    """
    
    """

    dataset: str = betterproto.string_field(4)
    """The name of the dataset used for training."""

    state: "JobState" = betterproto.enum_field(5)
    """
    
    """

    status: "Status" = betterproto.message_field(6)
    """
    
    """

    created_by: str = betterproto.string_field(7)
    """The email address of the user who initiated this fine-tuning job."""

    output_model: str = betterproto.string_field(8)
    """
    The model ID to be assigned to the resulting fine-tuned model. If not specified, the job ID will be used.
    """

    base_model: str = betterproto.string_field(9)
    """
    The name of the base model to be fine-tuned
    Only one of 'base_model' or 'warm_start_from' should be specified.
    """

    warm_start_from: str = betterproto.string_field(10)
    """
    The PEFT addon model in Fireworks format to be fine-tuned from
    Only one of 'base_model' or 'warm_start_from' should be specified.
    """

    jinja_template: str = betterproto.string_field(11)
    """
    The Jinja template for conversation formatting. If not specified, defaults to the base model's conversation template configuration
    """

    early_stop: bool = betterproto.bool_field(12)
    """
    Whether to stop training early if the validation loss does not improve.
    """

    epochs: int = betterproto.int32_field(13)
    """The number of epochs to train for."""

    learning_rate: float = betterproto.float_field(14)
    """The learning rate used for training."""

    max_context_length: int = betterproto.int32_field(15)
    """The maximum context length to use with the model."""

    lora_rank: int = betterproto.int32_field(16)
    """The rank of the LoRA layers."""

    base_model_weight_precision: "SupervisedFineTuningJobWeightPrecision" = (
        betterproto.enum_field(17)
    )
    """The weight precision of the base model."""

    wandb_config: "WandbConfig" = betterproto.message_field(18)
    """
    The Weights & Biases team/user account for logging training progress.
    """

    evaluation_dataset: str = betterproto.string_field(19)
    """The name of a separate dataset to use for evaluation."""

    accelerator_type: "AcceleratorType" = betterproto.enum_field(20)
    """
    The type of accelerator to use.
    If not specified, the default is NVIDIA_A100_80GB.
    """

    accelerator_count: int = betterproto.int32_field(21)
    """
    The number of accelerators used for the fine-tuning job.
    If not specified, the default is the estimated minimum required by the
    base model.
    """

    is_turbo: bool = betterproto.bool_field(22)
    """Whether to run the fine-tuning job in turbo mode."""

    eval_auto_carveout: bool = betterproto.bool_field(24)
    """Whether to auto-carve the dataset for eval."""

    region: "Region" = betterproto.enum_field(25)
    """The region where the fine-tuning job is located."""

    update_time: datetime = betterproto.message_field(26)
    """The update time for the supervised fine-tuning job."""

    nodes: int = betterproto.int32_field(27)
    """The number of nodes to use for the fine-tuning job."""

    batch_size: int = betterproto.int32_field(28)
    """The batch size for sequence packing in training"""

    mtp_enabled: bool = betterproto.bool_field(29)
    """Whether to enable MTP (Model-Token-Prediction) mode"""

    mtp_num_draft_tokens: int = betterproto.int32_field(30)
    """Number of draft tokens to use in MTP mode"""

    mtp_freeze_base_model: bool = betterproto.bool_field(31)
    """Whether to freeze the base model parameters during MTP training"""

    job_progress: "JobProgress" = betterproto.message_field(32)
    """Job progress."""

    custom_image_tag: str = betterproto.string_field(33)
    """Custom image tag, e.g. /train:dev-xyz."""

    precision: "SupervisedFineTuningJobWeightPrecision" = betterproto.enum_field(34)
    """Model precision."""

    extra_args: List[str] = betterproto.string_field(35)
    """A list of extra arguments that should be passed to the trainer job."""

    metrics_file_signed_url: str = betterproto.string_field(36)
    """The signed URL for the metrics file"""


@dataclass(eq=False, repr=False)
class GetSupervisedFineTuningJobRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the fine-tuning job."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class CreateSupervisedFineTuningJobRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The resource name of the account."""

    supervised_fine_tuning_job: "SupervisedFineTuningJob" = betterproto.message_field(2)
    """
    
    """

    debug: bool = betterproto.bool_field(3)
    """Whether to run the fine-tuning job in debug mode, superuser only."""

    supervised_fine_tuning_job_id: str = betterproto.string_field(4)
    """
    ID of the supervised fine-tuning job, a random UUID will be generated if not specified.
    """


@dataclass(eq=False, repr=False)
class ListSupervisedFineTuningJobsRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """
    
    """

    page_size: int = betterproto.int32_field(2)
    """
    The maximum number of fine-tuning jobs to return. The maximum page_size is 200,
    values above 200 will be coerced to 200.
    If unspecified, the default is 50.
    """

    page_token: str = betterproto.string_field(3)
    """
    A page token, received from a previous ListSupervisedFineTuningJobs call. Provide this
    to retrieve the subsequent page. When paginating, all other parameters
    provided to ListSupervisedFineTuningJobs must match the call that provided the page
    token.
    """

    filter: str = betterproto.string_field(4)
    """
    Filter criteria for the returned jobs. See https://google.aip.dev/160 for the filter syntax specification.
    """

    order_by: str = betterproto.string_field(5)
    """
    A comma-separated list of fields to order by. e.g. "foo,bar"
    The default sort order is ascending. To specify a descending order for a
    field, append a " desc" suffix. e.g. "foo desc,bar"
    Subfields are specified with a "." character. e.g. "foo.bar"
    If not specified, the default order is by "name".
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListSupervisedFineTuningJobsResponse(betterproto.Message):
    """ """

    supervised_fine_tuning_jobs: List["SupervisedFineTuningJob"] = (
        betterproto.message_field(1)
    )
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of fine-tuning jobs"""


@dataclass(eq=False, repr=False)
class DeleteSupervisedFineTuningJobRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the supervised fine-tuning job."""


@dataclass(eq=False, repr=False)
class Workload(betterproto.Message):
    """Next ID: 20"""

    name: str = betterproto.string_field(1)
    """
    The resource name of the workload. e.g. accounts/my-account/workloads/my-workload
    """

    display_name: str = betterproto.string_field(2)
    """
    Human-readable display name of the workload. e.g. "My Workload"
    Must be fewer than 64 characters long.
    """

    description: str = betterproto.string_field(3)
    """Description of the workload."""

    create_time: datetime = betterproto.message_field(4)
    """The creation time of the workload."""

    update_time: datetime = betterproto.message_field(5)
    """The update time for the workload."""

    expire_time: datetime = betterproto.message_field(6)
    """The time at which this workload will automatically be deleted."""

    purge_time: datetime = betterproto.message_field(7)
    """The time at which the resource will be hard deleted."""

    delete_time: datetime = betterproto.message_field(8)
    """The time at which the resource will be soft deleted."""

    created_by: str = betterproto.string_field(9)
    """The email address of the user who created this workload."""

    state: "WorkloadState" = betterproto.enum_field(10)
    """The state of the workload."""

    status: "Status" = betterproto.message_field(11)
    """Detailed status information regarding the most recent operation."""

    annotations: Dict[str, str] = betterproto.map_field(
        12, betterproto.TYPE_STRING, betterproto.TYPE_STRING
    )
    """
    Annotations to identify workload properties.
    Key/value pairs may be used by external tools or other services.
    """

    placement: "Placement" = betterproto.message_field(13)
    """
    The desired geographic region where the workload must be placed.
    If unspecified, the default is the GLOBAL multi-region.
    """

    min_replica_count: int = betterproto.int32_field(14)
    """
    The minimum number of replicas.
    If not specified, the default is 0.
    """

    max_replica_count: int = betterproto.int32_field(15)
    """
    The maximum number of replicas.
    If not specified, the default is max(min_replica_count, 1).
    May be set to 0 to downscale the workload to 0.
    """

    desired_replica_count: int = betterproto.int32_field(16)
    """
    The desired number of replicas.
    The number is determined by the autoscaler.
    """

    autoscaling_policy: "AutoscalingPolicy" = betterproto.message_field(17)
    """
    
    """

    workload_shape: str = betterproto.string_field(18)
    """Shape for the workload."""

    disable_accounting: bool = betterproto.bool_field(19)
    """
    If true, billing is disabled for this workload and it will not count
    towards quotas. If specified, expire_time must also be set.
    This flag should only be used for internal test workloads, proof-of-
    concepts, etc.
    """

    for_training: bool = betterproto.bool_field(20)
    """Whether this workload is for training."""


@dataclass(eq=False, repr=False)
class CreateWorkloadRequest(betterproto.Message):
    """Next ID: 4"""

    parent: str = betterproto.string_field(1)
    """The resource name of the parent account."""

    workload: "Workload" = betterproto.message_field(2)
    """The properties of the workload being created."""

    workload_id: str = betterproto.string_field(3)
    """
    The ID of the workload. If not specified, a random ID will be generated.
    """


@dataclass(eq=False, repr=False)
class GetWorkloadRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the workload."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListWorkloadsRequest(betterproto.Message):
    """Next ID: 9"""

    parent: str = betterproto.string_field(1)
    """Resource name of the parent workload."""

    page_size: int = betterproto.int32_field(2)
    """
    The maximum number of workloads to return. The maximum page_size is 200,
    values above 200 will be coerced to 200.
    If unspecified, the default is 50.
    """

    page_token: str = betterproto.string_field(3)
    """
    A page token, received from a previous ListWorkloads call. Provide this
    to retrieve the subsequent page. When paginating, all other parameters
    provided to ListWorkloads must match the call that provided the page
    token.
    """

    filter: str = betterproto.string_field(4)
    """
    Only workload satisfying the provided filter (if specified) will be
    returned. See https://google.aip.dev/160 for the filter grammar.
    """

    order_by: str = betterproto.string_field(5)
    """
    A comma-separated list of fields to order by. e.g. "foo,bar"
    The default sort order is ascending. To specify a descending order for a
    field, append a " desc" suffix. e.g. "foo desc,bar"
    Subfields are specified with a "." character. e.g. "foo.bar"
    If not specified, the default order is by "create_time".
    """

    show_deleted: bool = betterproto.bool_field(6)
    """If set, DELETED workloads will be included."""

    show_internal: bool = betterproto.bool_field(7)
    """If set, internal resources will be included."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        8
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListWorkloadsResponse(betterproto.Message):
    """ """

    workloads: List["Workload"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of workloads."""


@dataclass(eq=False, repr=False)
class UpdateWorkloadRequest(betterproto.Message):
    """ """

    workload: "Workload" = betterproto.message_field(1)
    """
    The properties of the workload being updated. `workload.name` must
    be populated with the updated resource's name.
    """

    update_mask: "betterproto_lib_google_protobuf.FieldMask" = (
        betterproto.message_field(2)
    )
    """List of field paths to be updated. If empty we replace all fields."""


@dataclass(eq=False, repr=False)
class DeleteWorkloadRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the workload."""

    hard: bool = betterproto.bool_field(2)
    """If true, this will perform a hard deletion."""

    ignore_checks: bool = betterproto.bool_field(3)
    """
    If true, this will ignore checks and force the deletion of a workload that is currently
    deployed and is in use.
    """


@dataclass(eq=False, repr=False)
class WorkloadShape(betterproto.Message):
    """
    A workload shape is a set of parameters that define the shape of a workload.
    Workloads are created from a workload shape.
    Next ID: 27
    """

    name: str = betterproto.string_field(1)
    """
    The resource name of the workload shape. e.g. accounts/my-account/workloadShapes/my-workload-shape
    """

    display_name: str = betterproto.string_field(2)
    """
    Human-readable display name of the workload shape. e.g. "My Workload Shape"
    Must be fewer than 64 characters long.
    """

    description: str = betterproto.string_field(3)
    """
    The description of the workload shape. Must be fewer than 1000 characters long.
    """

    create_time: datetime = betterproto.message_field(4)
    """The creation time of the workload shape."""

    update_time: datetime = betterproto.message_field(5)
    """The update time for the workload shape."""

    created_by: str = betterproto.string_field(6)
    """The email address of the user who created this workload shape."""

    annotations: Dict[str, str] = betterproto.map_field(
        7, betterproto.TYPE_STRING, betterproto.TYPE_STRING
    )
    """
    Annotations to identify workload shape properties.
    Key/value pairs may be used by external tools or other services.
    """

    base_model: str = betterproto.string_field(8)
    """The base model name. e.g. accounts/fireworks/models/falcon-7b"""

    accelerator_count: int = betterproto.int32_field(9)
    """
    The number of accelerators used per replica.
    If not specified, the default is the estimated minimum required by the base model.
    """

    accelerator_type: "AcceleratorType" = betterproto.enum_field(10)
    """
    The type of accelerator to use.
    If not specified, the default is NVIDIA_A100_80GB.
    """

    precision: "DeploymentPrecision" = betterproto.enum_field(11)
    """
    The precision with which the model should be served.
    TODO: Make the default value FP16 once legacy models are fixed.
    """

    world_size: int = betterproto.int32_field(12)
    """
    The number of accelerators the base model is served with. Must only be
    specified if accelerator_count is not specified.
    The default is the estimated minimum required to serve the base model if
    accelerator_count is 0. Otherwise, it is accelerator_count/2 if
    disaggregated prefill is enabled.
    """

    generator_count: int = betterproto.int32_field(13)
    """
    The number of generator groups, for multi-node workloads. Then world_size is the number of GPUs per generator group.
    """

    disaggregated_prefill_count: int = betterproto.int32_field(14)
    """
    The number of copies of the model that should be used for disaggregated
    prefill. Must only be specified if accelerator_count is not specified.
    The default is 1 if auto_tune.long_prompt is true and the base model is
    small enough to support disaggregated prefill within the
    accelerator_count constraint, else 0.
    """

    disaggregated_prefill_world_size: int = betterproto.int32_field(15)
    """
    The number of accelerators used for disaggregated prefill. Must only be
    specified if accelerator_count is not specified.
    The default is world_size if disaggregated_prefill_count is non-zero.
    """

    max_batch_size: int = betterproto.int32_field(16)
    """
    The maximum batch size supported by the server.
    If not specified, the default is 16.
    """

    enable_addons: bool = betterproto.bool_field(17)
    """
    If true, LORA addons are enabled for workloads created from this shape.
    """

    draft_token_count: int = betterproto.int32_field(18)
    """
    The number of candidate tokens to generate per step for speculative
    decoding.
    Default is the base model's draft_token_count.
    """

    draft_model: str = betterproto.string_field(19)
    """
    The draft model name for speculative decoding. e.g. accounts/fireworks/models/my-draft-model
    If empty, speculative decoding using a draft model is disabled.
    Default is the base model's default_draft_model.
    this behavior.
    """

    ngram_speculation_length: int = betterproto.int32_field(20)
    """
    The length of previous input sequence to be considered for N-gram speculation.
    """

    max_lora_batch_size: int = betterproto.int32_field(21)
    """
    The maximum LORA batch size supported by the server.
    If not specified, the default is 16. This cannot exceed max_batch_size.
    """

    kv_cache_memory_pct: int = betterproto.int32_field(22)
    """
    Percentage of remaiming memory to allocate for KV cache.
    If not specified, the default is 80.
    """

    enable_session_affinity: bool = betterproto.bool_field(23)
    """Whether to apply sticky routing based on `user` field."""

    image_tag: str = betterproto.string_field(24)
    """
    The container image tag to use. If not specified, the latest production
    version will be used.
    """

    num_lora_device_cached: int = betterproto.int32_field(25)
    """How many LORA adapters to keep on GPU side for caching"""

    extra_args: List[str] = betterproto.string_field(26)
    """A list of extra arguments that should be passed to the server."""

    max_context_length: int = betterproto.int32_field(27)
    """
    The maximum context length supported by the model (context window).
    If not specified, the model's default maximum context length will be used.
    """

    extra_values: Dict[str, str] = betterproto.map_field(
        28, betterproto.TYPE_STRING, betterproto.TYPE_STRING
    )
    """
    A JSON object of extra values that should be passed to the helm chart when installed.
    """

    engine: "DeploymentEngine" = betterproto.enum_field(29)
    """
    Which engine the workload should be created with: FIREATTENTION, VLLM, or NIM.
    If unspecified, the default is FIREATTENTION.
    """


@dataclass(eq=False, repr=False)
class CreateWorkloadShapeRequest(betterproto.Message):
    """ """

    parent: str = betterproto.string_field(1)
    """The resource name of the parent account."""

    workload_shape: "WorkloadShape" = betterproto.message_field(2)
    """The properties of the workload shape being created."""

    workload_shape_id: str = betterproto.string_field(3)
    """
    The ID of the workload shape. If not specified, a random ID will be generated.
    """

    disable_size_validation: bool = betterproto.bool_field(4)
    """Whether to disable the size validation for the workload shape."""


@dataclass(eq=False, repr=False)
class GetWorkloadShapeRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the workload shape."""

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        2
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListWorkloadShapesRequest(betterproto.Message):
    """Next ID: 7"""

    parent: str = betterproto.string_field(1)
    """Resource name of the parent account."""

    page_size: int = betterproto.int32_field(2)
    """
    The maximum number of workloads to return. The maximum page_size is 200,
    values above 200 will be coerced to 200.
    If unspecified, the default is 50.
    """

    page_token: str = betterproto.string_field(3)
    """
    A page token, received from a previous ListWorkloads call. Provide this
    to retrieve the subsequent page. When paginating, all other parameters
    provided to ListWorkloads must match the call that provided the page
    token.
    """

    filter: str = betterproto.string_field(4)
    """
    Only workload satisfying the provided filter (if specified) will be
    returned. See https://google.aip.dev/160 for the filter grammar.
    """

    order_by: str = betterproto.string_field(5)
    """
    A comma-separated list of fields to order by. e.g. "foo,bar"
    The default sort order is ascending. To specify a descending order for a
    field, append a " desc" suffix. e.g. "foo desc,bar"
    Subfields are specified with a "." character. e.g. "foo.bar"
    If not specified, the default order is by "create_time".
    """

    read_mask: "betterproto_lib_google_protobuf.FieldMask" = betterproto.message_field(
        6
    )
    """
    The fields to be returned in the response. If empty or "*", all fields will be returned.
    """


@dataclass(eq=False, repr=False)
class ListWorkloadShapesResponse(betterproto.Message):
    """ """

    workload_shapes: List["WorkloadShape"] = betterproto.message_field(1)
    """
    
    """

    next_page_token: str = betterproto.string_field(2)
    """
    A token, which can be sent as `page_token` to retrieve the next page.
    If this field is omitted, there are no subsequent pages.
    """

    total_size: int = betterproto.int32_field(3)
    """The total number of workload shapes."""


@dataclass(eq=False, repr=False)
class UpdateWorkloadShapeRequest(betterproto.Message):
    """ """

    workload_shape: "WorkloadShape" = betterproto.message_field(1)
    """
    The properties of the workload shape being updated. `workload_shape.name` must
    be populated with the updated resource's name.
    """

    update_mask: "betterproto_lib_google_protobuf.FieldMask" = (
        betterproto.message_field(2)
    )
    """List of field paths to be updated. If empty we replace all fields."""

    disable_size_validation: bool = betterproto.bool_field(3)
    """Whether to disable the size validation for the workload shape."""


@dataclass(eq=False, repr=False)
class DeleteWorkloadShapeRequest(betterproto.Message):
    """ """

    name: str = betterproto.string_field(1)
    """The resource name of the workload shape."""


class GatewayStub(betterproto.ServiceStub):
    """ """

    async def get_o_auth_arguments(
        self,
        get_o_auth_arguments_request: "GetOAuthArgumentsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "GetOAuthArgumentsResponse":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/GetOAuthArguments",
            get_o_auth_arguments_request,
            GetOAuthArgumentsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_account(
        self,
        create_account_request: "CreateAccountRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Account":
        """
        CRUD APIs for Accounts

        Create Account
        """

        return await self._unary_unary(
            "/gateway.Gateway/CreateAccount",
            create_account_request,
            Account,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_account(
        self,
        get_account_request: "GetAccountRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Account":
        """Get Account"""

        return await self._unary_unary(
            "/gateway.Gateway/GetAccount",
            get_account_request,
            Account,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_accounts(
        self,
        list_accounts_request: "ListAccountsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListAccountsResponse":
        """List Accounts"""

        return await self._unary_unary(
            "/gateway.Gateway/ListAccounts",
            list_accounts_request,
            ListAccountsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def update_account(
        self,
        update_account_request: "UpdateAccountRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Account":
        """Update Account"""

        return await self._unary_unary(
            "/gateway.Gateway/UpdateAccount",
            update_account_request,
            Account,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_account(
        self,
        delete_account_request: "DeleteAccountRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/DeleteAccount",
            delete_account_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_balance(
        self,
        get_balance_request: "GetBalanceRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Balance":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/GetBalance",
            get_balance_request,
            Balance,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_payment_methods(
        self,
        list_payment_methods_request: "ListPaymentMethodsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListPaymentMethodsResponse":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/ListPaymentMethods",
            list_payment_methods_request,
            ListPaymentMethodsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_costs(
        self,
        list_costs_request: "ListCostsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListCostsResponse":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/ListCosts",
            list_costs_request,
            ListCostsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_invoices(
        self,
        list_invoices_request: "ListInvoicesRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListInvoicesResponse":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/ListInvoices",
            list_invoices_request,
            ListInvoicesResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def export_billing_metrics(
        self,
        export_billing_metrics_request: "ExportBillingMetricsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ExportBillingMetricsResponse":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/ExportBillingMetrics",
            export_billing_metrics_request,
            ExportBillingMetricsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_total_historical_spend(
        self,
        get_total_historical_spend_request: "GetTotalHistoricalSpendRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "GetTotalHistoricalSpendResponse":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/GetTotalHistoricalSpend",
            get_total_historical_spend_request,
            GetTotalHistoricalSpendResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_account_usage(
        self,
        get_account_usage_request: "GetAccountUsageRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "AccountUsage":
        """Get account usage (serverless and on-demand)"""

        return await self._unary_unary(
            "/gateway.Gateway/GetAccountUsage",
            get_account_usage_request,
            AccountUsage,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_batch_job(
        self,
        create_batch_job_request: "CreateBatchJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "BatchJob":
        """
        CRUD APIs for batch jobs.

        Create Batch Job
        """

        return await self._unary_unary(
            "/gateway.Gateway/CreateBatchJob",
            create_batch_job_request,
            BatchJob,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_batch_job(
        self,
        get_batch_job_request: "GetBatchJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "BatchJob":
        """Get Batch Job"""

        return await self._unary_unary(
            "/gateway.Gateway/GetBatchJob",
            get_batch_job_request,
            BatchJob,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_batch_jobs(
        self,
        list_batch_jobs_request: "ListBatchJobsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListBatchJobsResponse":
        """List Batch Jobs"""

        return await self._unary_unary(
            "/gateway.Gateway/ListBatchJobs",
            list_batch_jobs_request,
            ListBatchJobsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def update_batch_job(
        self,
        update_batch_job_request: "UpdateBatchJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "BatchJob":
        """Update Batch Job"""

        return await self._unary_unary(
            "/gateway.Gateway/UpdateBatchJob",
            update_batch_job_request,
            BatchJob,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_batch_job(
        self,
        delete_batch_job_request: "DeleteBatchJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Batch Job"""

        return await self._unary_unary(
            "/gateway.Gateway/DeleteBatchJob",
            delete_batch_job_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def batch_delete_batch_jobs(
        self,
        batch_delete_batch_jobs_request: "BatchDeleteBatchJobsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Batch Delete Batch Jobs"""

        return await self._unary_unary(
            "/gateway.Gateway/BatchDeleteBatchJobs",
            batch_delete_batch_jobs_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def cancel_batch_job(
        self,
        cancel_batch_job_request: "CancelBatchJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """
        Cancel Batch Job

        Cancels an existing batch job if it is queued, pending, or running.
        """

        return await self._unary_unary(
            "/gateway.Gateway/CancelBatchJob",
            cancel_batch_job_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_cluster(
        self,
        create_cluster_request: "CreateClusterRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Cluster":
        """
        CRUD APIs for clusters.

        Create Cluster
        """

        return await self._unary_unary(
            "/gateway.Gateway/CreateCluster",
            create_cluster_request,
            Cluster,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_cluster(
        self,
        get_cluster_request: "GetClusterRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Cluster":
        """Get Cluster"""

        return await self._unary_unary(
            "/gateway.Gateway/GetCluster",
            get_cluster_request,
            Cluster,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_clusters(
        self,
        list_clusters_request: "ListClustersRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListClustersResponse":
        """List Clusters"""

        return await self._unary_unary(
            "/gateway.Gateway/ListClusters",
            list_clusters_request,
            ListClustersResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def update_cluster(
        self,
        update_cluster_request: "UpdateClusterRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Cluster":
        """Update Cluster"""

        return await self._unary_unary(
            "/gateway.Gateway/UpdateCluster",
            update_cluster_request,
            Cluster,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_cluster(
        self,
        delete_cluster_request: "DeleteClusterRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Cluster"""

        return await self._unary_unary(
            "/gateway.Gateway/DeleteCluster",
            delete_cluster_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_cluster_connection_info(
        self,
        get_cluster_connection_info_request: "GetClusterConnectionInfoRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ClusterConnectionInfo":
        """
        Get Cluster Connection Info

        Retrieve connection settings for the cluster to be put in kubeconfig
        """

        return await self._unary_unary(
            "/gateway.Gateway/GetClusterConnectionInfo",
            get_cluster_connection_info_request,
            ClusterConnectionInfo,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_environment(
        self,
        create_environment_request: "CreateEnvironmentRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Environment":
        """
        CRUD APIs for environments.

        Create Environment
        """

        return await self._unary_unary(
            "/gateway.Gateway/CreateEnvironment",
            create_environment_request,
            Environment,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_environment(
        self,
        get_environment_request: "GetEnvironmentRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Environment":
        """Get Environment"""

        return await self._unary_unary(
            "/gateway.Gateway/GetEnvironment",
            get_environment_request,
            Environment,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_environments(
        self,
        list_environments_request: "ListEnvironmentsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListEnvironmentsResponse":
        """List Environments"""

        return await self._unary_unary(
            "/gateway.Gateway/ListEnvironments",
            list_environments_request,
            ListEnvironmentsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def update_environment(
        self,
        update_environment_request: "UpdateEnvironmentRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Environment":
        """Update Environment"""

        return await self._unary_unary(
            "/gateway.Gateway/UpdateEnvironment",
            update_environment_request,
            Environment,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_environment(
        self,
        delete_environment_request: "DeleteEnvironmentRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Environment"""

        return await self._unary_unary(
            "/gateway.Gateway/DeleteEnvironment",
            delete_environment_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def batch_delete_environments(
        self,
        batch_delete_environments_request: "BatchDeleteEnvironmentsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Batch Delete Environments"""

        return await self._unary_unary(
            "/gateway.Gateway/BatchDeleteEnvironments",
            batch_delete_environments_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def connect_environment(
        self,
        connect_environment_request: "ConnectEnvironmentRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """
        Connect Environment

        Connects the environment to a node pool.
        Returns an error if there is an existing pending connection.
        """

        return await self._unary_unary(
            "/gateway.Gateway/ConnectEnvironment",
            connect_environment_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def disconnect_environment(
        self,
        disconnect_environment_request: "DisconnectEnvironmentRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """
        Disconnect Environment

        Disconnects the environment from the node pool. Returns an error
        if the environment is not connected to a node pool.
        """

        return await self._unary_unary(
            "/gateway.Gateway/DisconnectEnvironment",
            disconnect_environment_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_feature_flag(
        self,
        get_feature_flag_request: "GetFeatureFlagRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "FeatureFlag":
        """CRUD APIs for account feature flags."""

        return await self._unary_unary(
            "/gateway.Gateway/GetFeatureFlag",
            get_feature_flag_request,
            FeatureFlag,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_feature_flags(
        self,
        list_feature_flags_request: "ListFeatureFlagsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListFeatureFlagsResponse":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/ListFeatureFlags",
            list_feature_flags_request,
            ListFeatureFlagsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_snapshot(
        self,
        create_snapshot_request: "CreateSnapshotRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Snapshot":
        """
        CRUD APIs for snapshots.

        Create Snapshot
        """

        return await self._unary_unary(
            "/gateway.Gateway/CreateSnapshot",
            create_snapshot_request,
            Snapshot,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_snapshot(
        self,
        get_snapshot_request: "GetSnapshotRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Snapshot":
        """Get Snapshot"""

        return await self._unary_unary(
            "/gateway.Gateway/GetSnapshot",
            get_snapshot_request,
            Snapshot,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_snapshots(
        self,
        list_snapshots_request: "ListSnapshotsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListSnapshotsResponse":
        """List Snapshots"""

        return await self._unary_unary(
            "/gateway.Gateway/ListSnapshots",
            list_snapshots_request,
            ListSnapshotsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_snapshot(
        self,
        delete_snapshot_request: "DeleteSnapshotRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Snapshot"""

        return await self._unary_unary(
            "/gateway.Gateway/DeleteSnapshot",
            delete_snapshot_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_batch_job_logs(
        self,
        get_batch_job_logs_request: "GetBatchJobLogsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "GetBatchJobLogsResponse":
        """Get Batch Job Logs"""

        return await self._unary_unary(
            "/gateway.Gateway/GetBatchJobLogs",
            get_batch_job_logs_request,
            GetBatchJobLogsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_node_pool(
        self,
        create_node_pool_request: "CreateNodePoolRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "NodePool":
        """
        CRUD APIs for node pools.

        Create Node Pool
        """

        return await self._unary_unary(
            "/gateway.Gateway/CreateNodePool",
            create_node_pool_request,
            NodePool,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_node_pool(
        self,
        get_node_pool_request: "GetNodePoolRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "NodePool":
        """Get Node Pool"""

        return await self._unary_unary(
            "/gateway.Gateway/GetNodePool",
            get_node_pool_request,
            NodePool,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_node_pools(
        self,
        list_node_pools_request: "ListNodePoolsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListNodePoolsResponse":
        """List Node Pools"""

        return await self._unary_unary(
            "/gateway.Gateway/ListNodePools",
            list_node_pools_request,
            ListNodePoolsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def update_node_pool(
        self,
        update_node_pool_request: "UpdateNodePoolRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "NodePool":
        """Update Node Pool"""

        return await self._unary_unary(
            "/gateway.Gateway/UpdateNodePool",
            update_node_pool_request,
            NodePool,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_node_pool(
        self,
        delete_node_pool_request: "DeleteNodePoolRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Node Pool"""

        return await self._unary_unary(
            "/gateway.Gateway/DeleteNodePool",
            delete_node_pool_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def batch_delete_node_pools(
        self,
        batch_delete_node_pools_request: "BatchDeleteNodePoolsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Batch Delete Node Pools"""

        return await self._unary_unary(
            "/gateway.Gateway/BatchDeleteNodePools",
            batch_delete_node_pools_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_node_pool_stats(
        self,
        get_node_pool_stats_request: "GetNodePoolStatsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "NodePoolStats":
        """Get Node Pool Stats"""

        return await self._unary_unary(
            "/gateway.Gateway/GetNodePoolStats",
            get_node_pool_stats_request,
            NodePoolStats,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_user(
        self,
        create_user_request: "CreateUserRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "User":
        """
        CRUD APIs for users.

        Create User
        """

        return await self._unary_unary(
            "/gateway.Gateway/CreateUser",
            create_user_request,
            User,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_user(
        self,
        get_user_request: "GetUserRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "User":
        """Get User"""

        return await self._unary_unary(
            "/gateway.Gateway/GetUser",
            get_user_request,
            User,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_users(
        self,
        list_users_request: "ListUsersRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListUsersResponse":
        """List Users"""

        return await self._unary_unary(
            "/gateway.Gateway/ListUsers",
            list_users_request,
            ListUsersResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def update_user(
        self,
        update_user_request: "UpdateUserRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "User":
        """Update User"""

        return await self._unary_unary(
            "/gateway.Gateway/UpdateUser",
            update_user_request,
            User,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_user(
        self,
        delete_user_request: "DeleteUserRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/DeleteUser",
            delete_user_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_audit_logs(
        self,
        list_audit_logs_request: "ListAuditLogsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListAuditLogsResponse":
        """List User Audit Logs"""

        return await self._unary_unary(
            "/gateway.Gateway/ListAuditLogs",
            list_audit_logs_request,
            ListAuditLogsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_api_key(
        self,
        create_api_key_request: "CreateApiKeyRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ApiKey":
        """
        CRUD APIs for API keys.

        Create API Key
        """

        return await self._unary_unary(
            "/gateway.Gateway/CreateApiKey",
            create_api_key_request,
            ApiKey,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_api_keys(
        self,
        list_api_keys_request: "ListApiKeysRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListApiKeysResponse":
        """List API Keys"""

        return await self._unary_unary(
            "/gateway.Gateway/ListApiKeys",
            list_api_keys_request,
            ListApiKeysResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_api_key(
        self,
        delete_api_key_request: "DeleteApiKeyRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete API Key"""

        return await self._unary_unary(
            "/gateway.Gateway/DeleteApiKey",
            delete_api_key_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_internal_api_key(
        self,
        get_internal_api_key_request: "GetInternalApiKeyRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ApiKey":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/GetInternalApiKey",
            get_internal_api_key_request,
            ApiKey,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_model(
        self,
        create_model_request: "CreateModelRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Model":
        """
        CRUD APIs for models.

        Create Model
        """

        return await self._unary_unary(
            "/gateway.Gateway/CreateModel",
            create_model_request,
            Model,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_model(
        self,
        get_model_request: "GetModelRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Model":
        """Get Model"""

        return await self._unary_unary(
            "/gateway.Gateway/GetModel",
            get_model_request,
            Model,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_models(
        self,
        list_models_request: "ListModelsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListModelsResponse":
        """List Models"""

        return await self._unary_unary(
            "/gateway.Gateway/ListModels",
            list_models_request,
            ListModelsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_serverless_lora_models(
        self,
        list_serverless_lora_models_request: "ListServerlessLoraModelsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListServerlessLoraModelsResponse":
        """List Serverless Lora Models"""

        return await self._unary_unary(
            "/gateway.Gateway/ListServerlessLoraModels",
            list_serverless_lora_models_request,
            ListServerlessLoraModelsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def update_model(
        self,
        update_model_request: "UpdateModelRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Model":
        """Update Model"""

        return await self._unary_unary(
            "/gateway.Gateway/UpdateModel",
            update_model_request,
            Model,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_model(
        self,
        delete_model_request: "DeleteModelRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Model"""

        return await self._unary_unary(
            "/gateway.Gateway/DeleteModel",
            delete_model_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_model_upload_endpoint(
        self,
        get_model_upload_endpoint_request: "GetModelUploadEndpointRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "GetModelUploadEndpointResponse":
        """Get Model Upload Endpoint"""

        return await self._unary_unary(
            "/gateway.Gateway/GetModelUploadEndpoint",
            get_model_upload_endpoint_request,
            GetModelUploadEndpointResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_model_download_endpoint(
        self,
        get_model_download_endpoint_request: "GetModelDownloadEndpointRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "GetModelDownloadEndpointResponse":
        """Get Model Download Endpoint"""

        return await self._unary_unary(
            "/gateway.Gateway/GetModelDownloadEndpoint",
            get_model_download_endpoint_request,
            GetModelDownloadEndpointResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def validate_model_upload(
        self,
        validate_model_upload_request: "ValidateModelUploadRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Validate Model Upload"""

        return await self._unary_unary(
            "/gateway.Gateway/ValidateModelUpload",
            validate_model_upload_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def validate_model_config(
        self,
        validate_model_config_request: "ValidateModelConfigRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Validate Model Config"""

        return await self._unary_unary(
            "/gateway.Gateway/ValidateModelConfig",
            validate_model_config_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def import_model(
        self,
        import_model_request: "ImportModelRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "_google_longrunning__.Operation":
        """Transfer model from S3 to GCP storage"""

        return await self._unary_unary(
            "/gateway.Gateway/ImportModel",
            import_model_request,
            _google_longrunning__.Operation,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_deployment(
        self,
        create_deployment_request: "CreateDeploymentRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Deployment":
        """
        CRUD APIs for deployments.

        Create Deployment
        """

        return await self._unary_unary(
            "/gateway.Gateway/CreateDeployment",
            create_deployment_request,
            Deployment,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_deployment(
        self,
        get_deployment_request: "GetDeploymentRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Deployment":
        """Get Deployment"""

        return await self._unary_unary(
            "/gateway.Gateway/GetDeployment",
            get_deployment_request,
            Deployment,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_deployments(
        self,
        list_deployments_request: "ListDeploymentsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListDeploymentsResponse":
        """List Deployments"""

        return await self._unary_unary(
            "/gateway.Gateway/ListDeployments",
            list_deployments_request,
            ListDeploymentsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def update_deployment(
        self,
        update_deployment_request: "UpdateDeploymentRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Deployment":
        """Update Deployment"""

        return await self._unary_unary(
            "/gateway.Gateway/UpdateDeployment",
            update_deployment_request,
            Deployment,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_deployment(
        self,
        delete_deployment_request: "DeleteDeploymentRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Deployment"""

        return await self._unary_unary(
            "/gateway.Gateway/DeleteDeployment",
            delete_deployment_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def undelete_deployment(
        self,
        undelete_deployment_request: "UndeleteDeploymentRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Deployment":
        """Undelete Deployment"""

        return await self._unary_unary(
            "/gateway.Gateway/UndeleteDeployment",
            undelete_deployment_request,
            Deployment,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def scale_deployment(
        self,
        scale_deployment_request: "ScaleDeploymentRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Scale Deployment to a specific number of replicas or to zero"""

        return await self._unary_unary(
            "/gateway.Gateway/ScaleDeployment",
            scale_deployment_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_deployment_metrics(
        self,
        get_deployment_metrics_request: "GetDeploymentMetricsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "GetDeploymentMetricsResponse":
        """Get Deployment Metrics (Deprecated)"""

        return await self._unary_unary(
            "/gateway.Gateway/GetDeploymentMetrics",
            get_deployment_metrics_request,
            GetDeploymentMetricsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_deployment_metrics(
        self,
        list_deployment_metrics_request: "ListDeploymentMetricsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListDeploymentMetricsResponse":
        """Get Deployment Metrics"""

        return await self._unary_unary(
            "/gateway.Gateway/ListDeploymentMetrics",
            list_deployment_metrics_request,
            ListDeploymentMetricsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_deployment_template(
        self,
        create_deployment_template_request: "CreateDeploymentTemplateRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "DeploymentTemplate":
        """CRUD APIs for deployment templates."""

        return await self._unary_unary(
            "/gateway.Gateway/CreateDeploymentTemplate",
            create_deployment_template_request,
            DeploymentTemplate,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_deployment_template(
        self,
        get_deployment_template_request: "GetDeploymentTemplateRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "DeploymentTemplate":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/GetDeploymentTemplate",
            get_deployment_template_request,
            DeploymentTemplate,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_deployment_templates(
        self,
        list_deployment_templates_request: "ListDeploymentTemplatesRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListDeploymentTemplatesResponse":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/ListDeploymentTemplates",
            list_deployment_templates_request,
            ListDeploymentTemplatesResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def update_deployment_template(
        self,
        update_deployment_template_request: "UpdateDeploymentTemplateRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "DeploymentTemplate":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/UpdateDeploymentTemplate",
            update_deployment_template_request,
            DeploymentTemplate,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_deployment_template(
        self,
        delete_deployment_template_request: "DeleteDeploymentTemplateRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/DeleteDeploymentTemplate",
            delete_deployment_template_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_deployed_model(
        self,
        create_deployed_model_request: "CreateDeployedModelRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "DeployedModel":
        """
        CRUD APIs for deployed models.

        Load LoRA
        """

        return await self._unary_unary(
            "/gateway.Gateway/CreateDeployedModel",
            create_deployed_model_request,
            DeployedModel,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_deployed_model(
        self,
        get_deployed_model_request: "GetDeployedModelRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "DeployedModel":
        """Get LoRA"""

        return await self._unary_unary(
            "/gateway.Gateway/GetDeployedModel",
            get_deployed_model_request,
            DeployedModel,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_deployed_models(
        self,
        list_deployed_models_request: "ListDeployedModelsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListDeployedModelsResponse":
        """List LoRAs"""

        return await self._unary_unary(
            "/gateway.Gateway/ListDeployedModels",
            list_deployed_models_request,
            ListDeployedModelsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def update_deployed_model(
        self,
        update_deployed_model_request: "UpdateDeployedModelRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "DeployedModel":
        """Update LoRA"""

        return await self._unary_unary(
            "/gateway.Gateway/UpdateDeployedModel",
            update_deployed_model_request,
            DeployedModel,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_deployed_model(
        self,
        delete_deployed_model_request: "DeleteDeployedModelRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Unload LoRA"""

        return await self._unary_unary(
            "/gateway.Gateway/DeleteDeployedModel",
            delete_deployed_model_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_aws_iam_role_binding(
        self,
        create_aws_iam_role_binding_request: "CreateAwsIamRoleBindingRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "AwsIamRoleBinding":
        """
        CRUD APIs for AWS IAM role bindings.

        Create Aws Iam Role Binding
        """

        return await self._unary_unary(
            "/gateway.Gateway/CreateAwsIamRoleBinding",
            create_aws_iam_role_binding_request,
            AwsIamRoleBinding,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_aws_iam_role_bindings(
        self,
        list_aws_iam_role_bindings_request: "ListAwsIamRoleBindingsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListAwsIamRoleBindingsResponse":
        """List Aws Iam Role Bindings"""

        return await self._unary_unary(
            "/gateway.Gateway/ListAwsIamRoleBindings",
            list_aws_iam_role_bindings_request,
            ListAwsIamRoleBindingsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_aws_iam_role_binding(
        self,
        delete_aws_iam_role_binding_request: "DeleteAwsIamRoleBindingRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Aws Iam Role Binding"""

        return await self._unary_unary(
            "/gateway.Gateway/DeleteAwsIamRoleBinding",
            delete_aws_iam_role_binding_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_node_pool_binding(
        self,
        create_node_pool_binding_request: "CreateNodePoolBindingRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "NodePoolBinding":
        """
        CRUD APIs for node pool bindings.

        Create Node Pool Binding
        """

        return await self._unary_unary(
            "/gateway.Gateway/CreateNodePoolBinding",
            create_node_pool_binding_request,
            NodePoolBinding,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_node_pool_bindings(
        self,
        list_node_pool_bindings_request: "ListNodePoolBindingsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListNodePoolBindingsResponse":
        """List Node Pool Bindings"""

        return await self._unary_unary(
            "/gateway.Gateway/ListNodePoolBindings",
            list_node_pool_bindings_request,
            ListNodePoolBindingsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_node_pool_binding(
        self,
        delete_node_pool_binding_request: "DeleteNodePoolBindingRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Node Pool Binding"""

        return await self._unary_unary(
            "/gateway.Gateway/DeleteNodePoolBinding",
            delete_node_pool_binding_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_dataset(
        self,
        create_dataset_request: "CreateDatasetRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Dataset":
        """
        CRUD APIs for datasets.

        Create Dataset
        """

        return await self._unary_unary(
            "/gateway.Gateway/CreateDataset",
            create_dataset_request,
            Dataset,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_dataset(
        self,
        get_dataset_request: "GetDatasetRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Dataset":
        """Get Dataset"""

        return await self._unary_unary(
            "/gateway.Gateway/GetDataset",
            get_dataset_request,
            Dataset,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_datasets(
        self,
        list_datasets_request: "ListDatasetsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListDatasetsResponse":
        """List Datasets"""

        return await self._unary_unary(
            "/gateway.Gateway/ListDatasets",
            list_datasets_request,
            ListDatasetsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def update_dataset(
        self,
        update_dataset_request: "UpdateDatasetRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Dataset":
        """Update Dataset"""

        return await self._unary_unary(
            "/gateway.Gateway/UpdateDataset",
            update_dataset_request,
            Dataset,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_dataset(
        self,
        delete_dataset_request: "DeleteDatasetRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Dataset"""

        return await self._unary_unary(
            "/gateway.Gateway/DeleteDataset",
            delete_dataset_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def upload_dataset(
        self,
        upload_dataset_request: "UploadDatasetRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "UploadDatasetResponse":
        """
        Upload and verify files for datasets.

        Upload Dataset (Deprecated)
        """

        return await self._unary_unary(
            "/gateway.Gateway/UploadDataset",
            upload_dataset_request,
            UploadDatasetResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_dataset_upload_endpoint(
        self,
        get_dataset_upload_endpoint_request: "GetDatasetUploadEndpointRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "GetDatasetUploadEndpointResponse":
        """Get Dataset Upload Endpoint"""

        return await self._unary_unary(
            "/gateway.Gateway/GetDatasetUploadEndpoint",
            get_dataset_upload_endpoint_request,
            GetDatasetUploadEndpointResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def validate_dataset_upload(
        self,
        validate_dataset_upload_request: "ValidateDatasetUploadRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Validate Dataset Upload"""

        return await self._unary_unary(
            "/gateway.Gateway/ValidateDatasetUpload",
            validate_dataset_upload_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_dataset_download_endpoint(
        self,
        get_dataset_download_endpoint_request: "GetDatasetDownloadEndpointRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "GetDatasetDownloadEndpointResponse":
        """Get Dataset Download Endpoint"""

        return await self._unary_unary(
            "/gateway.Gateway/GetDatasetDownloadEndpoint",
            get_dataset_download_endpoint_request,
            GetDatasetDownloadEndpointResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def preview_dataset(
        self,
        preview_dataset_request: "PreviewDatasetRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "PreviewDatasetResponse":
        """
        Preview Dataset, will contain the content of the dataset row by row
        """

        return await self._unary_unary(
            "/gateway.Gateway/PreviewDataset",
            preview_dataset_request,
            PreviewDatasetResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_evaluator(
        self,
        create_evaluator_request: "CreateEvaluatorRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Evaluator":
        """CRUD APIs for evaluations."""

        return await self._unary_unary(
            "/gateway.Gateway/CreateEvaluator",
            create_evaluator_request,
            Evaluator,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_evaluator(
        self,
        get_evaluator_request: "GetEvaluatorRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Evaluator":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/GetEvaluator",
            get_evaluator_request,
            Evaluator,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_evaluators(
        self,
        list_evaluators_request: "ListEvaluatorsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListEvaluatorsResponse":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/ListEvaluators",
            list_evaluators_request,
            ListEvaluatorsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_evaluator(
        self,
        delete_evaluator_request: "DeleteEvaluatorRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/DeleteEvaluator",
            delete_evaluator_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_evaluation(
        self,
        create_evaluation_request: "CreateEvaluationRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Evaluation":
        """Create Evaluation"""

        return await self._unary_unary(
            "/gateway.Gateway/CreateEvaluation",
            create_evaluation_request,
            Evaluation,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_evaluation(
        self,
        get_evaluation_request: "GetEvaluationRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Evaluation":
        """Get Evaluation"""

        return await self._unary_unary(
            "/gateway.Gateway/GetEvaluation",
            get_evaluation_request,
            Evaluation,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_evaluations(
        self,
        list_evaluations_request: "ListEvaluationsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListEvaluationsResponse":
        """List Evaluations"""

        return await self._unary_unary(
            "/gateway.Gateway/ListEvaluations",
            list_evaluations_request,
            ListEvaluationsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_evaluation(
        self,
        delete_evaluation_request: "DeleteEvaluationRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """
        TODO: Add Update Evaluation
        Update Evaluation
        rpc UpdateEvaluation(UpdateEvaluationRequest) returns (Evaluation) {
          option (google.api.http) = {
            patch: "/v1/{evaluation.name=accounts/*/evaluations/*}"
            body: "evaluation"
          };
        }
        Delete Evaluation
        """

        return await self._unary_unary(
            "/gateway.Gateway/DeleteEvaluation",
            delete_evaluation_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_evaluation_job(
        self,
        create_evaluation_job_request: "CreateEvaluationJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "EvaluationJob":
        """
        CRUD APIs for evaluation jobs.

        Create Evaluation Job
        """

        return await self._unary_unary(
            "/gateway.Gateway/CreateEvaluationJob",
            create_evaluation_job_request,
            EvaluationJob,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_evaluation_job(
        self,
        get_evaluation_job_request: "GetEvaluationJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "EvaluationJob":
        """Get Evaluation Job"""

        return await self._unary_unary(
            "/gateway.Gateway/GetEvaluationJob",
            get_evaluation_job_request,
            EvaluationJob,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_evaluation_jobs(
        self,
        list_evaluation_jobs_request: "ListEvaluationJobsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListEvaluationJobsResponse":
        """List Evaluation Jobs"""

        return await self._unary_unary(
            "/gateway.Gateway/ListEvaluationJobs",
            list_evaluation_jobs_request,
            ListEvaluationJobsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_evaluation_job(
        self,
        delete_evaluation_job_request: "DeleteEvaluationJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Evaluation Job"""

        return await self._unary_unary(
            "/gateway.Gateway/DeleteEvaluationJob",
            delete_evaluation_job_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_fine_tuning_job(
        self,
        create_fine_tuning_job_request: "CreateFineTuningJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "FineTuningJob":
        """
        CRUD APIs for fine-tune jobs.

        Create Fine-tuning Job
        """

        return await self._unary_unary(
            "/gateway.Gateway/CreateFineTuningJob",
            create_fine_tuning_job_request,
            FineTuningJob,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_fine_tuning_job(
        self,
        get_fine_tuning_job_request: "GetFineTuningJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "FineTuningJob":
        """Get Fine-tuning Job"""

        return await self._unary_unary(
            "/gateway.Gateway/GetFineTuningJob",
            get_fine_tuning_job_request,
            FineTuningJob,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_fine_tuning_jobs(
        self,
        list_fine_tuning_jobs_request: "ListFineTuningJobsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListFineTuningJobsResponse":
        """List Fine-tuning Jobs"""

        return await self._unary_unary(
            "/gateway.Gateway/ListFineTuningJobs",
            list_fine_tuning_jobs_request,
            ListFineTuningJobsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def update_fine_tuning_job(
        self,
        update_fine_tuning_job_request: "UpdateFineTuningJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "FineTuningJob":
        """Update Fine-tuning Job"""

        return await self._unary_unary(
            "/gateway.Gateway/UpdateFineTuningJob",
            update_fine_tuning_job_request,
            FineTuningJob,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_fine_tuning_job(
        self,
        delete_fine_tuning_job_request: "DeleteFineTuningJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Fine-tuning Job"""

        return await self._unary_unary(
            "/gateway.Gateway/DeleteFineTuningJob",
            delete_fine_tuning_job_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_supervised_fine_tuning_job(
        self,
        create_supervised_fine_tuning_job_request: "CreateSupervisedFineTuningJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "SupervisedFineTuningJob":
        """
        CRUD APIs for supervised fine-tune jobs.

        Create Supervised Fine-tuning Job
        """

        return await self._unary_unary(
            "/gateway.Gateway/CreateSupervisedFineTuningJob",
            create_supervised_fine_tuning_job_request,
            SupervisedFineTuningJob,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_supervised_fine_tuning_job(
        self,
        get_supervised_fine_tuning_job_request: "GetSupervisedFineTuningJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "SupervisedFineTuningJob":
        """Get Supervised Fine-tuning Job"""

        return await self._unary_unary(
            "/gateway.Gateway/GetSupervisedFineTuningJob",
            get_supervised_fine_tuning_job_request,
            SupervisedFineTuningJob,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_supervised_fine_tuning_jobs(
        self,
        list_supervised_fine_tuning_jobs_request: "ListSupervisedFineTuningJobsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListSupervisedFineTuningJobsResponse":
        """List Supervised Fine-tuning Jobs"""

        return await self._unary_unary(
            "/gateway.Gateway/ListSupervisedFineTuningJobs",
            list_supervised_fine_tuning_jobs_request,
            ListSupervisedFineTuningJobsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_supervised_fine_tuning_job(
        self,
        delete_supervised_fine_tuning_job_request: "DeleteSupervisedFineTuningJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Supervised Fine-tuning Job"""

        return await self._unary_unary(
            "/gateway.Gateway/DeleteSupervisedFineTuningJob",
            delete_supervised_fine_tuning_job_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_reinforcement_fine_tuning_job(
        self,
        create_reinforcement_fine_tuning_job_request: "CreateReinforcementFineTuningJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ReinforcementFineTuningJob":
        """
        CRUD APIs for reinforcement learning fine-tune jobs.

        Create Reinforcement Fine-tuning Job
        """

        return await self._unary_unary(
            "/gateway.Gateway/CreateReinforcementFineTuningJob",
            create_reinforcement_fine_tuning_job_request,
            ReinforcementFineTuningJob,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_reinforcement_fine_tuning_job(
        self,
        get_reinforcement_fine_tuning_job_request: "GetReinforcementFineTuningJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ReinforcementFineTuningJob":
        """Get Reinforcement Fine-tuning Job"""

        return await self._unary_unary(
            "/gateway.Gateway/GetReinforcementFineTuningJob",
            get_reinforcement_fine_tuning_job_request,
            ReinforcementFineTuningJob,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_reinforcement_fine_tuning_jobs(
        self,
        list_reinforcement_fine_tuning_jobs_request: "ListReinforcementFineTuningJobsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListReinforcementFineTuningJobsResponse":
        """List Reinforcement Fine-tuning Jobs"""

        return await self._unary_unary(
            "/gateway.Gateway/ListReinforcementFineTuningJobs",
            list_reinforcement_fine_tuning_jobs_request,
            ListReinforcementFineTuningJobsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_reinforcement_fine_tuning_job(
        self,
        delete_reinforcement_fine_tuning_job_request: "DeleteReinforcementFineTuningJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Reinforcement Fine-tuning Job"""

        return await self._unary_unary(
            "/gateway.Gateway/DeleteReinforcementFineTuningJob",
            delete_reinforcement_fine_tuning_job_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def resume_reinforcement_fine_tuning_job(
        self,
        resume_reinforcement_fine_tuning_job_request: "ResumeReinforcementFineTuningJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ReinforcementFineTuningJob":
        """Resume Reinforcement Fine-tuning Job"""

        return await self._unary_unary(
            "/gateway.Gateway/ResumeReinforcementFineTuningJob",
            resume_reinforcement_fine_tuning_job_request,
            ReinforcementFineTuningJob,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def debug_reinforcement_fine_tuning_job(
        self,
        debug_reinforcement_fine_tuning_job_request: "DebugReinforcementFineTuningJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "DebugReinforcementFineTuningJobResponse":
        """Debug Reinforcement Fine-tuning Job"""

        return await self._unary_unary(
            "/gateway.Gateway/DebugReinforcementFineTuningJob",
            debug_reinforcement_fine_tuning_job_request,
            DebugReinforcementFineTuningJobResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_reinforcement_fine_tuning_epoch(
        self,
        create_reinforcement_fine_tuning_epoch_request: "CreateReinforcementFineTuningEpochRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ReinforcementFineTuningEpoch":
        """
        CRUD APIs for reinforcement learning fine-tuning epochs.

        Create Reinforcement Fine-tuning Epoch
        """

        return await self._unary_unary(
            "/gateway.Gateway/CreateReinforcementFineTuningEpoch",
            create_reinforcement_fine_tuning_epoch_request,
            ReinforcementFineTuningEpoch,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_reinforcement_fine_tuning_epoch(
        self,
        get_reinforcement_fine_tuning_epoch_request: "GetReinforcementFineTuningEpochRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ReinforcementFineTuningEpoch":
        """Get Reinforcement Fine-tuning Epoch"""

        return await self._unary_unary(
            "/gateway.Gateway/GetReinforcementFineTuningEpoch",
            get_reinforcement_fine_tuning_epoch_request,
            ReinforcementFineTuningEpoch,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_reinforcement_fine_tuning_epochs(
        self,
        list_reinforcement_fine_tuning_epochs_request: "ListReinforcementFineTuningEpochsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListReinforcementFineTuningEpochsResponse":
        """List Reinforcement Fine-tuning Epochs"""

        return await self._unary_unary(
            "/gateway.Gateway/ListReinforcementFineTuningEpochs",
            list_reinforcement_fine_tuning_epochs_request,
            ListReinforcementFineTuningEpochsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_reinforcement_fine_tuning_epoch(
        self,
        delete_reinforcement_fine_tuning_epoch_request: "DeleteReinforcementFineTuningEpochRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Reinforcement Fine-tuning Epoch"""

        return await self._unary_unary(
            "/gateway.Gateway/DeleteReinforcementFineTuningEpoch",
            delete_reinforcement_fine_tuning_epoch_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_rlor_trainer_job(
        self,
        create_rlor_trainer_job_request: "CreateRlorTrainerJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "RlorTrainerJob":
        """
        CRUD APIs for rlor trainer jobs.

        Create Rlor Trainer Job
        """

        return await self._unary_unary(
            "/gateway.Gateway/CreateRlorTrainerJob",
            create_rlor_trainer_job_request,
            RlorTrainerJob,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_rlor_trainer_job(
        self,
        get_rlor_trainer_job_request: "GetRlorTrainerJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "RlorTrainerJob":
        """Get Rlor Trainer Job"""

        return await self._unary_unary(
            "/gateway.Gateway/GetRlorTrainerJob",
            get_rlor_trainer_job_request,
            RlorTrainerJob,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_rlor_trainer_jobs(
        self,
        list_rlor_trainer_jobs_request: "ListRlorTrainerJobsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListRlorTrainerJobsResponse":
        """List Rlor Trainer Jobs"""

        return await self._unary_unary(
            "/gateway.Gateway/ListRlorTrainerJobs",
            list_rlor_trainer_jobs_request,
            ListRlorTrainerJobsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_rlor_trainer_job(
        self,
        delete_rlor_trainer_job_request: "DeleteRlorTrainerJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Rlor Trainer Job"""

        return await self._unary_unary(
            "/gateway.Gateway/DeleteRlorTrainerJob",
            delete_rlor_trainer_job_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_peft_merge_job(
        self,
        create_peft_merge_job_request: "CreatePeftMergeJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "PeftMergeJob":
        """
        CRUD APIs for peft merge jobs.

        Create Peft-Merge Job
        """

        return await self._unary_unary(
            "/gateway.Gateway/CreatePeftMergeJob",
            create_peft_merge_job_request,
            PeftMergeJob,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_peft_merge_job(
        self,
        get_peft_merge_job_request: "GetPeftMergeJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "PeftMergeJob":
        """Get Peft-Merge Job"""

        return await self._unary_unary(
            "/gateway.Gateway/GetPeftMergeJob",
            get_peft_merge_job_request,
            PeftMergeJob,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_peft_merge_jobs(
        self,
        list_peft_merge_jobs_request: "ListPeftMergeJobsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListPeftMergeJobsResponse":
        """List Peft-Merge Jobs"""

        return await self._unary_unary(
            "/gateway.Gateway/ListPeftMergeJobs",
            list_peft_merge_jobs_request,
            ListPeftMergeJobsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_peft_merge_job(
        self,
        delete_peft_merge_job_request: "DeletePeftMergeJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Peft-Merge Job"""

        return await self._unary_unary(
            "/gateway.Gateway/DeletePeftMergeJob",
            delete_peft_merge_job_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_quota(
        self,
        get_quota_request: "GetQuotaRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Quota":
        """CRUD APIs for quotas."""

        return await self._unary_unary(
            "/gateway.Gateway/GetQuota",
            get_quota_request,
            Quota,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def update_quota(
        self,
        update_quota_request: "UpdateQuotaRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Quota":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/UpdateQuota",
            update_quota_request,
            Quota,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_quotas(
        self,
        list_quotas_request: "ListQuotasRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListQuotasResponse":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/ListQuotas",
            list_quotas_request,
            ListQuotasResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_secret(
        self,
        create_secret_request: "CreateSecretRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Secret":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/CreateSecret",
            create_secret_request,
            Secret,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_secret(
        self,
        get_secret_request: "GetSecretRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Secret":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/GetSecret",
            get_secret_request,
            Secret,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_secrets(
        self,
        list_secrets_request: "ListSecretsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListSecretsResponse":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/ListSecrets",
            list_secrets_request,
            ListSecretsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def update_secret(
        self,
        update_secret_request: "UpdateSecretRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Secret":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/UpdateSecret",
            update_secret_request,
            Secret,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_secret(
        self,
        delete_secret_request: "DeleteSecretRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/DeleteSecret",
            delete_secret_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_reservation(
        self,
        get_reservation_request: "GetReservationRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Reservation":
        """CRUD APIs for reservations."""

        return await self._unary_unary(
            "/gateway.Gateway/GetReservation",
            get_reservation_request,
            Reservation,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_reservations(
        self,
        list_reservations_request: "ListReservationsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListReservationsResponse":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/ListReservations",
            list_reservations_request,
            ListReservationsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def prepare_model(
        self,
        prepare_model_request: "PrepareModelRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Prepare Model for different precisions"""

        return await self._unary_unary(
            "/gateway.Gateway/PrepareModel",
            prepare_model_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_batch_inference_job(
        self,
        create_batch_inference_job_request: "CreateBatchInferenceJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "BatchInferenceJob":
        """Create Batch Inference Job"""

        return await self._unary_unary(
            "/gateway.Gateway/CreateBatchInferenceJob",
            create_batch_inference_job_request,
            BatchInferenceJob,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_batch_inference_job(
        self,
        get_batch_inference_job_request: "GetBatchInferenceJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "BatchInferenceJob":
        """Get Batch Inference Job"""

        return await self._unary_unary(
            "/gateway.Gateway/GetBatchInferenceJob",
            get_batch_inference_job_request,
            BatchInferenceJob,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_batch_inference_jobs(
        self,
        list_batch_inference_jobs_request: "ListBatchInferenceJobsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListBatchInferenceJobsResponse":
        """List Batch Inference Jobs"""

        return await self._unary_unary(
            "/gateway.Gateway/ListBatchInferenceJobs",
            list_batch_inference_jobs_request,
            ListBatchInferenceJobsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def update_batch_inference_job(
        self,
        update_batch_inference_job_request: "UpdateBatchInferenceJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "BatchInferenceJob":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/UpdateBatchInferenceJob",
            update_batch_inference_job_request,
            BatchInferenceJob,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_batch_inference_job(
        self,
        delete_batch_inference_job_request: "DeleteBatchInferenceJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Batch Inference Job"""

        return await self._unary_unary(
            "/gateway.Gateway/DeleteBatchInferenceJob",
            delete_batch_inference_job_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_eagle_training_job(
        self,
        create_eagle_training_job_request: "CreateEagleTrainingJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "EagleTrainingJob":
        """CRUD APIs for EAGLE training jobs."""

        return await self._unary_unary(
            "/gateway.Gateway/CreateEagleTrainingJob",
            create_eagle_training_job_request,
            EagleTrainingJob,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_eagle_training_job(
        self,
        get_eagle_training_job_request: "GetEagleTrainingJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "EagleTrainingJob":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/GetEagleTrainingJob",
            get_eagle_training_job_request,
            EagleTrainingJob,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_eagle_training_jobs(
        self,
        list_eagle_training_jobs_request: "ListEagleTrainingJobsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListEagleTrainingJobsResponse":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/ListEagleTrainingJobs",
            list_eagle_training_jobs_request,
            ListEagleTrainingJobsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_eagle_training_job(
        self,
        delete_eagle_training_job_request: "DeleteEagleTrainingJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/DeleteEagleTrainingJob",
            delete_eagle_training_job_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_batch_inference_job_input_upload_endpoint(
        self,
        get_batch_inference_job_input_upload_endpoint_request: "GetBatchInferenceJobInputUploadEndpointRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "GetBatchInferenceJobInputUploadEndpointResponse":
        """Upload, download and verify files for batch inference jobs."""

        return await self._unary_unary(
            "/gateway.Gateway/GetBatchInferenceJobInputUploadEndpoint",
            get_batch_inference_job_input_upload_endpoint_request,
            GetBatchInferenceJobInputUploadEndpointResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_batch_inference_job_output_download_endpoint(
        self,
        get_batch_inference_job_output_download_endpoint_request: "GetBatchInferenceJobOutputDownloadEndpointRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "GetBatchInferenceJobOutputDownloadEndpointResponse":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/GetBatchInferenceJobOutputDownloadEndpoint",
            get_batch_inference_job_output_download_endpoint_request,
            GetBatchInferenceJobOutputDownloadEndpointResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def validate_batch_inference_job_input_upload(
        self,
        validate_batch_inference_job_input_upload_request: "ValidateBatchInferenceJobInputUploadRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/ValidateBatchInferenceJobInputUpload",
            validate_batch_inference_job_input_upload_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_dataset_validation_job(
        self,
        create_dataset_validation_job_request: "CreateDatasetValidationJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "DatasetValidationJob":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/CreateDatasetValidationJob",
            create_dataset_validation_job_request,
            DatasetValidationJob,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_dataset_validation_job(
        self,
        get_dataset_validation_job_request: "GetDatasetValidationJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "DatasetValidationJob":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/GetDatasetValidationJob",
            get_dataset_validation_job_request,
            DatasetValidationJob,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_dataset_validation_jobs(
        self,
        list_dataset_validation_jobs_request: "ListDatasetValidationJobsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListDatasetValidationJobsResponse":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/ListDatasetValidationJobs",
            list_dataset_validation_jobs_request,
            ListDatasetValidationJobsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_dataset_validation_job(
        self,
        delete_dataset_validation_job_request: "DeleteDatasetValidationJobRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/DeleteDatasetValidationJob",
            delete_dataset_validation_job_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def split_dataset(
        self,
        split_dataset_request: "SplitDatasetRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "SplitDatasetResponse":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/SplitDataset",
            split_dataset_request,
            SplitDatasetResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def validate_assertions(
        self,
        validate_assertions_request: "ValidateAssertionsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ValidateAssertionsResponse":
        """Validate evaluation assertions"""

        return await self._unary_unary(
            "/gateway.Gateway/ValidateAssertions",
            validate_assertions_request,
            ValidateAssertionsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def preview_evaluator(
        self,
        preview_evaluator_request: "PreviewEvaluatorRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "PreviewEvaluatorResponse":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/PreviewEvaluator",
            preview_evaluator_request,
            PreviewEvaluatorResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def preview_evaluation(
        self,
        preview_evaluation_request: "PreviewEvaluationRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "PreviewEvaluationResponse":
        """Preview an evaluation with sample data"""

        return await self._unary_unary(
            "/gateway.Gateway/PreviewEvaluation",
            preview_evaluation_request,
            PreviewEvaluationResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def test_evaluation(
        self,
        test_evaluation_request: "TestEvaluationRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "PreviewEvaluationResponse":
        """
        Similar to preview evaluation, but no need to create the evaluation entry first.
        """

        return await self._unary_unary(
            "/gateway.Gateway/TestEvaluation",
            test_evaluation_request,
            PreviewEvaluationResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_inference_log(
        self,
        get_inference_log_request: "GetInferenceLogRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "InferenceLog":
        """CRUD APIs for inference logs."""

        return await self._unary_unary(
            "/gateway.Gateway/GetInferenceLog",
            get_inference_log_request,
            InferenceLog,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_inference_logs(
        self,
        list_inference_logs_request: "ListInferenceLogsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListInferenceLogsResponse":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/ListInferenceLogs",
            list_inference_logs_request,
            ListInferenceLogsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_inference_log(
        self,
        delete_inference_log_request: "DeleteInferenceLogRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """ """

        return await self._unary_unary(
            "/gateway.Gateway/DeleteInferenceLog",
            delete_inference_log_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_deployment_prerequisites(
        self,
        get_deployment_prerequisites_request: "GetDeploymentPrerequisitesRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "DeploymentPrerequisites":
        """
        GetDeploymentPrerequisites returns the validation criteria for creating a particular deployment
        """

        return await self._unary_unary(
            "/gateway.Gateway/GetDeploymentPrerequisites",
            get_deployment_prerequisites_request,
            DeploymentPrerequisites,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_workload_shape(
        self,
        create_workload_shape_request: "CreateWorkloadShapeRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "WorkloadShape":
        """
        CRUD APIs for workload shapes.
        Create Workload Shape
        """

        return await self._unary_unary(
            "/gateway.Gateway/CreateWorkloadShape",
            create_workload_shape_request,
            WorkloadShape,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_workload_shape(
        self,
        get_workload_shape_request: "GetWorkloadShapeRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "WorkloadShape":
        """Get Workload Shape"""

        return await self._unary_unary(
            "/gateway.Gateway/GetWorkloadShape",
            get_workload_shape_request,
            WorkloadShape,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_workload_shapes(
        self,
        list_workload_shapes_request: "ListWorkloadShapesRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListWorkloadShapesResponse":
        """List Workload Shapes"""

        return await self._unary_unary(
            "/gateway.Gateway/ListWorkloadShapes",
            list_workload_shapes_request,
            ListWorkloadShapesResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def update_workload_shape(
        self,
        update_workload_shape_request: "UpdateWorkloadShapeRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "WorkloadShape":
        """Update Workload Shape"""

        return await self._unary_unary(
            "/gateway.Gateway/UpdateWorkloadShape",
            update_workload_shape_request,
            WorkloadShape,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_workload_shape(
        self,
        delete_workload_shape_request: "DeleteWorkloadShapeRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Workload Shape"""

        return await self._unary_unary(
            "/gateway.Gateway/DeleteWorkloadShape",
            delete_workload_shape_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_workload(
        self,
        create_workload_request: "CreateWorkloadRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Workload":
        """
        CRUD APIs for workloads.
        Create Workload
        """

        return await self._unary_unary(
            "/gateway.Gateway/CreateWorkload",
            create_workload_request,
            Workload,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_workload(
        self,
        get_workload_request: "GetWorkloadRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Workload":
        """Get Workload"""

        return await self._unary_unary(
            "/gateway.Gateway/GetWorkload",
            get_workload_request,
            Workload,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_workloads(
        self,
        list_workloads_request: "ListWorkloadsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListWorkloadsResponse":
        """List Workloads"""

        return await self._unary_unary(
            "/gateway.Gateway/ListWorkloads",
            list_workloads_request,
            ListWorkloadsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def update_workload(
        self,
        update_workload_request: "UpdateWorkloadRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "Workload":
        """Update Workload"""

        return await self._unary_unary(
            "/gateway.Gateway/UpdateWorkload",
            update_workload_request,
            Workload,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_workload(
        self,
        delete_workload_request: "DeleteWorkloadRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Workload"""

        return await self._unary_unary(
            "/gateway.Gateway/DeleteWorkload",
            delete_workload_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_identity_provider(
        self,
        create_identity_provider_request: "CreateIdentityProviderRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "IdentityProvider":
        """
        SSO / Identity Provider Management APIs

        Create Identity Provider
        """

        return await self._unary_unary(
            "/gateway.Gateway/CreateIdentityProvider",
            create_identity_provider_request,
            IdentityProvider,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_identity_provider(
        self,
        get_identity_provider_request: "GetIdentityProviderRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "IdentityProvider":
        """Get Identity Provider"""

        return await self._unary_unary(
            "/gateway.Gateway/GetIdentityProvider",
            get_identity_provider_request,
            IdentityProvider,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_identity_providers(
        self,
        list_identity_providers_request: "ListIdentityProvidersRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListIdentityProvidersResponse":
        """List Identity Providers"""

        return await self._unary_unary(
            "/gateway.Gateway/ListIdentityProviders",
            list_identity_providers_request,
            ListIdentityProvidersResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def update_identity_provider(
        self,
        update_identity_provider_request: "UpdateIdentityProviderRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "IdentityProvider":
        """Update Identity Provider"""

        return await self._unary_unary(
            "/gateway.Gateway/UpdateIdentityProvider",
            update_identity_provider_request,
            IdentityProvider,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_identity_provider(
        self,
        delete_identity_provider_request: "DeleteIdentityProviderRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Identity Provider"""

        return await self._unary_unary(
            "/gateway.Gateway/DeleteIdentityProvider",
            delete_identity_provider_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_mcp_server(
        self,
        create_mcp_server_request: "CreateMcpServerRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "McpServer":
        """
        CRUD APIs for MCP Servers

        Create MCP Server
        """

        return await self._unary_unary(
            "/gateway.Gateway/CreateMcpServer",
            create_mcp_server_request,
            McpServer,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_mcp_server(
        self,
        get_mcp_server_request: "GetMcpServerRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "McpServer":
        """Get MCP Server"""

        return await self._unary_unary(
            "/gateway.Gateway/GetMcpServer",
            get_mcp_server_request,
            McpServer,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_mcp_servers(
        self,
        list_mcp_servers_request: "ListMcpServersRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "ListMcpServersResponse":
        """List MCP Servers"""

        return await self._unary_unary(
            "/gateway.Gateway/ListMcpServers",
            list_mcp_servers_request,
            ListMcpServersResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def update_mcp_server(
        self,
        update_mcp_server_request: "UpdateMcpServerRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "McpServer":
        """Update MCP Server"""

        return await self._unary_unary(
            "/gateway.Gateway/UpdateMcpServer",
            update_mcp_server_request,
            McpServer,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def delete_mcp_server(
        self,
        delete_mcp_server_request: "DeleteMcpServerRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None,
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete MCP Server"""

        return await self._unary_unary(
            "/gateway.Gateway/DeleteMcpServer",
            delete_mcp_server_request,
            betterproto_lib_google_protobuf.Empty,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )


import betterproto.lib.google.protobuf as betterproto_lib_google_protobuf

from ..google import longrunning as _google_longrunning__
from ..google import type as _google_type__


class GatewayBase(ServiceBase):
    """ """

    async def get_o_auth_arguments(
        self, get_o_auth_arguments_request: "GetOAuthArgumentsRequest"
    ) -> "GetOAuthArgumentsResponse":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_account(
        self, create_account_request: "CreateAccountRequest"
    ) -> "Account":
        """
        CRUD APIs for Accounts

        Create Account
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_account(self, get_account_request: "GetAccountRequest") -> "Account":
        """Get Account"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_accounts(
        self, list_accounts_request: "ListAccountsRequest"
    ) -> "ListAccountsResponse":
        """List Accounts"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def update_account(
        self, update_account_request: "UpdateAccountRequest"
    ) -> "Account":
        """Update Account"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_account(
        self, delete_account_request: "DeleteAccountRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_balance(self, get_balance_request: "GetBalanceRequest") -> "Balance":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_payment_methods(
        self, list_payment_methods_request: "ListPaymentMethodsRequest"
    ) -> "ListPaymentMethodsResponse":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_costs(
        self, list_costs_request: "ListCostsRequest"
    ) -> "ListCostsResponse":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_invoices(
        self, list_invoices_request: "ListInvoicesRequest"
    ) -> "ListInvoicesResponse":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def export_billing_metrics(
        self, export_billing_metrics_request: "ExportBillingMetricsRequest"
    ) -> "ExportBillingMetricsResponse":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_total_historical_spend(
        self, get_total_historical_spend_request: "GetTotalHistoricalSpendRequest"
    ) -> "GetTotalHistoricalSpendResponse":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_account_usage(
        self, get_account_usage_request: "GetAccountUsageRequest"
    ) -> "AccountUsage":
        """Get account usage (serverless and on-demand)"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_batch_job(
        self, create_batch_job_request: "CreateBatchJobRequest"
    ) -> "BatchJob":
        """
        CRUD APIs for batch jobs.

        Create Batch Job
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_batch_job(
        self, get_batch_job_request: "GetBatchJobRequest"
    ) -> "BatchJob":
        """Get Batch Job"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_batch_jobs(
        self, list_batch_jobs_request: "ListBatchJobsRequest"
    ) -> "ListBatchJobsResponse":
        """List Batch Jobs"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def update_batch_job(
        self, update_batch_job_request: "UpdateBatchJobRequest"
    ) -> "BatchJob":
        """Update Batch Job"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_batch_job(
        self, delete_batch_job_request: "DeleteBatchJobRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Batch Job"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def batch_delete_batch_jobs(
        self, batch_delete_batch_jobs_request: "BatchDeleteBatchJobsRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Batch Delete Batch Jobs"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def cancel_batch_job(
        self, cancel_batch_job_request: "CancelBatchJobRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """
        Cancel Batch Job

        Cancels an existing batch job if it is queued, pending, or running.
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_cluster(
        self, create_cluster_request: "CreateClusterRequest"
    ) -> "Cluster":
        """
        CRUD APIs for clusters.

        Create Cluster
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_cluster(self, get_cluster_request: "GetClusterRequest") -> "Cluster":
        """Get Cluster"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_clusters(
        self, list_clusters_request: "ListClustersRequest"
    ) -> "ListClustersResponse":
        """List Clusters"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def update_cluster(
        self, update_cluster_request: "UpdateClusterRequest"
    ) -> "Cluster":
        """Update Cluster"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_cluster(
        self, delete_cluster_request: "DeleteClusterRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Cluster"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_cluster_connection_info(
        self, get_cluster_connection_info_request: "GetClusterConnectionInfoRequest"
    ) -> "ClusterConnectionInfo":
        """
        Get Cluster Connection Info

        Retrieve connection settings for the cluster to be put in kubeconfig
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_environment(
        self, create_environment_request: "CreateEnvironmentRequest"
    ) -> "Environment":
        """
        CRUD APIs for environments.

        Create Environment
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_environment(
        self, get_environment_request: "GetEnvironmentRequest"
    ) -> "Environment":
        """Get Environment"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_environments(
        self, list_environments_request: "ListEnvironmentsRequest"
    ) -> "ListEnvironmentsResponse":
        """List Environments"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def update_environment(
        self, update_environment_request: "UpdateEnvironmentRequest"
    ) -> "Environment":
        """Update Environment"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_environment(
        self, delete_environment_request: "DeleteEnvironmentRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Environment"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def batch_delete_environments(
        self, batch_delete_environments_request: "BatchDeleteEnvironmentsRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Batch Delete Environments"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def connect_environment(
        self, connect_environment_request: "ConnectEnvironmentRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """
        Connect Environment

        Connects the environment to a node pool.
        Returns an error if there is an existing pending connection.
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def disconnect_environment(
        self, disconnect_environment_request: "DisconnectEnvironmentRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """
        Disconnect Environment

        Disconnects the environment from the node pool. Returns an error
        if the environment is not connected to a node pool.
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_feature_flag(
        self, get_feature_flag_request: "GetFeatureFlagRequest"
    ) -> "FeatureFlag":
        """CRUD APIs for account feature flags."""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_feature_flags(
        self, list_feature_flags_request: "ListFeatureFlagsRequest"
    ) -> "ListFeatureFlagsResponse":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_snapshot(
        self, create_snapshot_request: "CreateSnapshotRequest"
    ) -> "Snapshot":
        """
        CRUD APIs for snapshots.

        Create Snapshot
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_snapshot(
        self, get_snapshot_request: "GetSnapshotRequest"
    ) -> "Snapshot":
        """Get Snapshot"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_snapshots(
        self, list_snapshots_request: "ListSnapshotsRequest"
    ) -> "ListSnapshotsResponse":
        """List Snapshots"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_snapshot(
        self, delete_snapshot_request: "DeleteSnapshotRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Snapshot"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_batch_job_logs(
        self, get_batch_job_logs_request: "GetBatchJobLogsRequest"
    ) -> "GetBatchJobLogsResponse":
        """Get Batch Job Logs"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_node_pool(
        self, create_node_pool_request: "CreateNodePoolRequest"
    ) -> "NodePool":
        """
        CRUD APIs for node pools.

        Create Node Pool
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_node_pool(
        self, get_node_pool_request: "GetNodePoolRequest"
    ) -> "NodePool":
        """Get Node Pool"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_node_pools(
        self, list_node_pools_request: "ListNodePoolsRequest"
    ) -> "ListNodePoolsResponse":
        """List Node Pools"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def update_node_pool(
        self, update_node_pool_request: "UpdateNodePoolRequest"
    ) -> "NodePool":
        """Update Node Pool"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_node_pool(
        self, delete_node_pool_request: "DeleteNodePoolRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Node Pool"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def batch_delete_node_pools(
        self, batch_delete_node_pools_request: "BatchDeleteNodePoolsRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Batch Delete Node Pools"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_node_pool_stats(
        self, get_node_pool_stats_request: "GetNodePoolStatsRequest"
    ) -> "NodePoolStats":
        """Get Node Pool Stats"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_user(self, create_user_request: "CreateUserRequest") -> "User":
        """
        CRUD APIs for users.

        Create User
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_user(self, get_user_request: "GetUserRequest") -> "User":
        """Get User"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_users(
        self, list_users_request: "ListUsersRequest"
    ) -> "ListUsersResponse":
        """List Users"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def update_user(self, update_user_request: "UpdateUserRequest") -> "User":
        """Update User"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_user(
        self, delete_user_request: "DeleteUserRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_audit_logs(
        self, list_audit_logs_request: "ListAuditLogsRequest"
    ) -> "ListAuditLogsResponse":
        """List User Audit Logs"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_api_key(
        self, create_api_key_request: "CreateApiKeyRequest"
    ) -> "ApiKey":
        """
        CRUD APIs for API keys.

        Create API Key
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_api_keys(
        self, list_api_keys_request: "ListApiKeysRequest"
    ) -> "ListApiKeysResponse":
        """List API Keys"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_api_key(
        self, delete_api_key_request: "DeleteApiKeyRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete API Key"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_internal_api_key(
        self, get_internal_api_key_request: "GetInternalApiKeyRequest"
    ) -> "ApiKey":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_model(self, create_model_request: "CreateModelRequest") -> "Model":
        """
        CRUD APIs for models.

        Create Model
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_model(self, get_model_request: "GetModelRequest") -> "Model":
        """Get Model"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_models(
        self, list_models_request: "ListModelsRequest"
    ) -> "ListModelsResponse":
        """List Models"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_serverless_lora_models(
        self, list_serverless_lora_models_request: "ListServerlessLoraModelsRequest"
    ) -> "ListServerlessLoraModelsResponse":
        """List Serverless Lora Models"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def update_model(self, update_model_request: "UpdateModelRequest") -> "Model":
        """Update Model"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_model(
        self, delete_model_request: "DeleteModelRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Model"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_model_upload_endpoint(
        self, get_model_upload_endpoint_request: "GetModelUploadEndpointRequest"
    ) -> "GetModelUploadEndpointResponse":
        """Get Model Upload Endpoint"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_model_download_endpoint(
        self, get_model_download_endpoint_request: "GetModelDownloadEndpointRequest"
    ) -> "GetModelDownloadEndpointResponse":
        """Get Model Download Endpoint"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def validate_model_upload(
        self, validate_model_upload_request: "ValidateModelUploadRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Validate Model Upload"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def validate_model_config(
        self, validate_model_config_request: "ValidateModelConfigRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Validate Model Config"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def import_model(
        self, import_model_request: "ImportModelRequest"
    ) -> "_google_longrunning__.Operation":
        """Transfer model from S3 to GCP storage"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_deployment(
        self, create_deployment_request: "CreateDeploymentRequest"
    ) -> "Deployment":
        """
        CRUD APIs for deployments.

        Create Deployment
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_deployment(
        self, get_deployment_request: "GetDeploymentRequest"
    ) -> "Deployment":
        """Get Deployment"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_deployments(
        self, list_deployments_request: "ListDeploymentsRequest"
    ) -> "ListDeploymentsResponse":
        """List Deployments"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def update_deployment(
        self, update_deployment_request: "UpdateDeploymentRequest"
    ) -> "Deployment":
        """Update Deployment"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_deployment(
        self, delete_deployment_request: "DeleteDeploymentRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Deployment"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def undelete_deployment(
        self, undelete_deployment_request: "UndeleteDeploymentRequest"
    ) -> "Deployment":
        """Undelete Deployment"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def scale_deployment(
        self, scale_deployment_request: "ScaleDeploymentRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Scale Deployment to a specific number of replicas or to zero"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_deployment_metrics(
        self, get_deployment_metrics_request: "GetDeploymentMetricsRequest"
    ) -> "GetDeploymentMetricsResponse":
        """Get Deployment Metrics (Deprecated)"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_deployment_metrics(
        self, list_deployment_metrics_request: "ListDeploymentMetricsRequest"
    ) -> "ListDeploymentMetricsResponse":
        """Get Deployment Metrics"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_deployment_template(
        self, create_deployment_template_request: "CreateDeploymentTemplateRequest"
    ) -> "DeploymentTemplate":
        """CRUD APIs for deployment templates."""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_deployment_template(
        self, get_deployment_template_request: "GetDeploymentTemplateRequest"
    ) -> "DeploymentTemplate":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_deployment_templates(
        self, list_deployment_templates_request: "ListDeploymentTemplatesRequest"
    ) -> "ListDeploymentTemplatesResponse":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def update_deployment_template(
        self, update_deployment_template_request: "UpdateDeploymentTemplateRequest"
    ) -> "DeploymentTemplate":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_deployment_template(
        self, delete_deployment_template_request: "DeleteDeploymentTemplateRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_deployed_model(
        self, create_deployed_model_request: "CreateDeployedModelRequest"
    ) -> "DeployedModel":
        """
        CRUD APIs for deployed models.

        Load LoRA
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_deployed_model(
        self, get_deployed_model_request: "GetDeployedModelRequest"
    ) -> "DeployedModel":
        """Get LoRA"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_deployed_models(
        self, list_deployed_models_request: "ListDeployedModelsRequest"
    ) -> "ListDeployedModelsResponse":
        """List LoRAs"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def update_deployed_model(
        self, update_deployed_model_request: "UpdateDeployedModelRequest"
    ) -> "DeployedModel":
        """Update LoRA"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_deployed_model(
        self, delete_deployed_model_request: "DeleteDeployedModelRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Unload LoRA"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_aws_iam_role_binding(
        self, create_aws_iam_role_binding_request: "CreateAwsIamRoleBindingRequest"
    ) -> "AwsIamRoleBinding":
        """
        CRUD APIs for AWS IAM role bindings.

        Create Aws Iam Role Binding
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_aws_iam_role_bindings(
        self, list_aws_iam_role_bindings_request: "ListAwsIamRoleBindingsRequest"
    ) -> "ListAwsIamRoleBindingsResponse":
        """List Aws Iam Role Bindings"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_aws_iam_role_binding(
        self, delete_aws_iam_role_binding_request: "DeleteAwsIamRoleBindingRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Aws Iam Role Binding"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_node_pool_binding(
        self, create_node_pool_binding_request: "CreateNodePoolBindingRequest"
    ) -> "NodePoolBinding":
        """
        CRUD APIs for node pool bindings.

        Create Node Pool Binding
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_node_pool_bindings(
        self, list_node_pool_bindings_request: "ListNodePoolBindingsRequest"
    ) -> "ListNodePoolBindingsResponse":
        """List Node Pool Bindings"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_node_pool_binding(
        self, delete_node_pool_binding_request: "DeleteNodePoolBindingRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Node Pool Binding"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_dataset(
        self, create_dataset_request: "CreateDatasetRequest"
    ) -> "Dataset":
        """
        CRUD APIs for datasets.

        Create Dataset
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_dataset(self, get_dataset_request: "GetDatasetRequest") -> "Dataset":
        """Get Dataset"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_datasets(
        self, list_datasets_request: "ListDatasetsRequest"
    ) -> "ListDatasetsResponse":
        """List Datasets"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def update_dataset(
        self, update_dataset_request: "UpdateDatasetRequest"
    ) -> "Dataset":
        """Update Dataset"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_dataset(
        self, delete_dataset_request: "DeleteDatasetRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Dataset"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def upload_dataset(
        self, upload_dataset_request: "UploadDatasetRequest"
    ) -> "UploadDatasetResponse":
        """
        Upload and verify files for datasets.

        Upload Dataset (Deprecated)
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_dataset_upload_endpoint(
        self, get_dataset_upload_endpoint_request: "GetDatasetUploadEndpointRequest"
    ) -> "GetDatasetUploadEndpointResponse":
        """Get Dataset Upload Endpoint"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def validate_dataset_upload(
        self, validate_dataset_upload_request: "ValidateDatasetUploadRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Validate Dataset Upload"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_dataset_download_endpoint(
        self, get_dataset_download_endpoint_request: "GetDatasetDownloadEndpointRequest"
    ) -> "GetDatasetDownloadEndpointResponse":
        """Get Dataset Download Endpoint"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def preview_dataset(
        self, preview_dataset_request: "PreviewDatasetRequest"
    ) -> "PreviewDatasetResponse":
        """
        Preview Dataset, will contain the content of the dataset row by row
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_evaluator(
        self, create_evaluator_request: "CreateEvaluatorRequest"
    ) -> "Evaluator":
        """CRUD APIs for evaluations."""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_evaluator(
        self, get_evaluator_request: "GetEvaluatorRequest"
    ) -> "Evaluator":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_evaluators(
        self, list_evaluators_request: "ListEvaluatorsRequest"
    ) -> "ListEvaluatorsResponse":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_evaluator(
        self, delete_evaluator_request: "DeleteEvaluatorRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_evaluation(
        self, create_evaluation_request: "CreateEvaluationRequest"
    ) -> "Evaluation":
        """Create Evaluation"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_evaluation(
        self, get_evaluation_request: "GetEvaluationRequest"
    ) -> "Evaluation":
        """Get Evaluation"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_evaluations(
        self, list_evaluations_request: "ListEvaluationsRequest"
    ) -> "ListEvaluationsResponse":
        """List Evaluations"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_evaluation(
        self, delete_evaluation_request: "DeleteEvaluationRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """
        TODO: Add Update Evaluation
        Update Evaluation
        rpc UpdateEvaluation(UpdateEvaluationRequest) returns (Evaluation) {
          option (google.api.http) = {
            patch: "/v1/{evaluation.name=accounts/*/evaluations/*}"
            body: "evaluation"
          };
        }
        Delete Evaluation
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_evaluation_job(
        self, create_evaluation_job_request: "CreateEvaluationJobRequest"
    ) -> "EvaluationJob":
        """
        CRUD APIs for evaluation jobs.

        Create Evaluation Job
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_evaluation_job(
        self, get_evaluation_job_request: "GetEvaluationJobRequest"
    ) -> "EvaluationJob":
        """Get Evaluation Job"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_evaluation_jobs(
        self, list_evaluation_jobs_request: "ListEvaluationJobsRequest"
    ) -> "ListEvaluationJobsResponse":
        """List Evaluation Jobs"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_evaluation_job(
        self, delete_evaluation_job_request: "DeleteEvaluationJobRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Evaluation Job"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_fine_tuning_job(
        self, create_fine_tuning_job_request: "CreateFineTuningJobRequest"
    ) -> "FineTuningJob":
        """
        CRUD APIs for fine-tune jobs.

        Create Fine-tuning Job
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_fine_tuning_job(
        self, get_fine_tuning_job_request: "GetFineTuningJobRequest"
    ) -> "FineTuningJob":
        """Get Fine-tuning Job"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_fine_tuning_jobs(
        self, list_fine_tuning_jobs_request: "ListFineTuningJobsRequest"
    ) -> "ListFineTuningJobsResponse":
        """List Fine-tuning Jobs"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def update_fine_tuning_job(
        self, update_fine_tuning_job_request: "UpdateFineTuningJobRequest"
    ) -> "FineTuningJob":
        """Update Fine-tuning Job"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_fine_tuning_job(
        self, delete_fine_tuning_job_request: "DeleteFineTuningJobRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Fine-tuning Job"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_supervised_fine_tuning_job(
        self,
        create_supervised_fine_tuning_job_request: "CreateSupervisedFineTuningJobRequest",
    ) -> "SupervisedFineTuningJob":
        """
        CRUD APIs for supervised fine-tune jobs.

        Create Supervised Fine-tuning Job
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_supervised_fine_tuning_job(
        self,
        get_supervised_fine_tuning_job_request: "GetSupervisedFineTuningJobRequest",
    ) -> "SupervisedFineTuningJob":
        """Get Supervised Fine-tuning Job"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_supervised_fine_tuning_jobs(
        self,
        list_supervised_fine_tuning_jobs_request: "ListSupervisedFineTuningJobsRequest",
    ) -> "ListSupervisedFineTuningJobsResponse":
        """List Supervised Fine-tuning Jobs"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_supervised_fine_tuning_job(
        self,
        delete_supervised_fine_tuning_job_request: "DeleteSupervisedFineTuningJobRequest",
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Supervised Fine-tuning Job"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_reinforcement_fine_tuning_job(
        self,
        create_reinforcement_fine_tuning_job_request: "CreateReinforcementFineTuningJobRequest",
    ) -> "ReinforcementFineTuningJob":
        """
        CRUD APIs for reinforcement learning fine-tune jobs.

        Create Reinforcement Fine-tuning Job
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_reinforcement_fine_tuning_job(
        self,
        get_reinforcement_fine_tuning_job_request: "GetReinforcementFineTuningJobRequest",
    ) -> "ReinforcementFineTuningJob":
        """Get Reinforcement Fine-tuning Job"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_reinforcement_fine_tuning_jobs(
        self,
        list_reinforcement_fine_tuning_jobs_request: "ListReinforcementFineTuningJobsRequest",
    ) -> "ListReinforcementFineTuningJobsResponse":
        """List Reinforcement Fine-tuning Jobs"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_reinforcement_fine_tuning_job(
        self,
        delete_reinforcement_fine_tuning_job_request: "DeleteReinforcementFineTuningJobRequest",
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Reinforcement Fine-tuning Job"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def resume_reinforcement_fine_tuning_job(
        self,
        resume_reinforcement_fine_tuning_job_request: "ResumeReinforcementFineTuningJobRequest",
    ) -> "ReinforcementFineTuningJob":
        """Resume Reinforcement Fine-tuning Job"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def debug_reinforcement_fine_tuning_job(
        self,
        debug_reinforcement_fine_tuning_job_request: "DebugReinforcementFineTuningJobRequest",
    ) -> "DebugReinforcementFineTuningJobResponse":
        """Debug Reinforcement Fine-tuning Job"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_reinforcement_fine_tuning_epoch(
        self,
        create_reinforcement_fine_tuning_epoch_request: "CreateReinforcementFineTuningEpochRequest",
    ) -> "ReinforcementFineTuningEpoch":
        """
        CRUD APIs for reinforcement learning fine-tuning epochs.

        Create Reinforcement Fine-tuning Epoch
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_reinforcement_fine_tuning_epoch(
        self,
        get_reinforcement_fine_tuning_epoch_request: "GetReinforcementFineTuningEpochRequest",
    ) -> "ReinforcementFineTuningEpoch":
        """Get Reinforcement Fine-tuning Epoch"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_reinforcement_fine_tuning_epochs(
        self,
        list_reinforcement_fine_tuning_epochs_request: "ListReinforcementFineTuningEpochsRequest",
    ) -> "ListReinforcementFineTuningEpochsResponse":
        """List Reinforcement Fine-tuning Epochs"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_reinforcement_fine_tuning_epoch(
        self,
        delete_reinforcement_fine_tuning_epoch_request: "DeleteReinforcementFineTuningEpochRequest",
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Reinforcement Fine-tuning Epoch"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_rlor_trainer_job(
        self, create_rlor_trainer_job_request: "CreateRlorTrainerJobRequest"
    ) -> "RlorTrainerJob":
        """
        CRUD APIs for rlor trainer jobs.

        Create Rlor Trainer Job
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_rlor_trainer_job(
        self, get_rlor_trainer_job_request: "GetRlorTrainerJobRequest"
    ) -> "RlorTrainerJob":
        """Get Rlor Trainer Job"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_rlor_trainer_jobs(
        self, list_rlor_trainer_jobs_request: "ListRlorTrainerJobsRequest"
    ) -> "ListRlorTrainerJobsResponse":
        """List Rlor Trainer Jobs"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_rlor_trainer_job(
        self, delete_rlor_trainer_job_request: "DeleteRlorTrainerJobRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Rlor Trainer Job"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_peft_merge_job(
        self, create_peft_merge_job_request: "CreatePeftMergeJobRequest"
    ) -> "PeftMergeJob":
        """
        CRUD APIs for peft merge jobs.

        Create Peft-Merge Job
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_peft_merge_job(
        self, get_peft_merge_job_request: "GetPeftMergeJobRequest"
    ) -> "PeftMergeJob":
        """Get Peft-Merge Job"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_peft_merge_jobs(
        self, list_peft_merge_jobs_request: "ListPeftMergeJobsRequest"
    ) -> "ListPeftMergeJobsResponse":
        """List Peft-Merge Jobs"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_peft_merge_job(
        self, delete_peft_merge_job_request: "DeletePeftMergeJobRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Peft-Merge Job"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_quota(self, get_quota_request: "GetQuotaRequest") -> "Quota":
        """CRUD APIs for quotas."""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def update_quota(self, update_quota_request: "UpdateQuotaRequest") -> "Quota":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_quotas(
        self, list_quotas_request: "ListQuotasRequest"
    ) -> "ListQuotasResponse":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_secret(
        self, create_secret_request: "CreateSecretRequest"
    ) -> "Secret":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_secret(self, get_secret_request: "GetSecretRequest") -> "Secret":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_secrets(
        self, list_secrets_request: "ListSecretsRequest"
    ) -> "ListSecretsResponse":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def update_secret(
        self, update_secret_request: "UpdateSecretRequest"
    ) -> "Secret":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_secret(
        self, delete_secret_request: "DeleteSecretRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_reservation(
        self, get_reservation_request: "GetReservationRequest"
    ) -> "Reservation":
        """CRUD APIs for reservations."""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_reservations(
        self, list_reservations_request: "ListReservationsRequest"
    ) -> "ListReservationsResponse":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def prepare_model(
        self, prepare_model_request: "PrepareModelRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Prepare Model for different precisions"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_batch_inference_job(
        self, create_batch_inference_job_request: "CreateBatchInferenceJobRequest"
    ) -> "BatchInferenceJob":
        """Create Batch Inference Job"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_batch_inference_job(
        self, get_batch_inference_job_request: "GetBatchInferenceJobRequest"
    ) -> "BatchInferenceJob":
        """Get Batch Inference Job"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_batch_inference_jobs(
        self, list_batch_inference_jobs_request: "ListBatchInferenceJobsRequest"
    ) -> "ListBatchInferenceJobsResponse":
        """List Batch Inference Jobs"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def update_batch_inference_job(
        self, update_batch_inference_job_request: "UpdateBatchInferenceJobRequest"
    ) -> "BatchInferenceJob":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_batch_inference_job(
        self, delete_batch_inference_job_request: "DeleteBatchInferenceJobRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Batch Inference Job"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_eagle_training_job(
        self, create_eagle_training_job_request: "CreateEagleTrainingJobRequest"
    ) -> "EagleTrainingJob":
        """CRUD APIs for EAGLE training jobs."""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_eagle_training_job(
        self, get_eagle_training_job_request: "GetEagleTrainingJobRequest"
    ) -> "EagleTrainingJob":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_eagle_training_jobs(
        self, list_eagle_training_jobs_request: "ListEagleTrainingJobsRequest"
    ) -> "ListEagleTrainingJobsResponse":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_eagle_training_job(
        self, delete_eagle_training_job_request: "DeleteEagleTrainingJobRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_batch_inference_job_input_upload_endpoint(
        self,
        get_batch_inference_job_input_upload_endpoint_request: "GetBatchInferenceJobInputUploadEndpointRequest",
    ) -> "GetBatchInferenceJobInputUploadEndpointResponse":
        """Upload, download and verify files for batch inference jobs."""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_batch_inference_job_output_download_endpoint(
        self,
        get_batch_inference_job_output_download_endpoint_request: "GetBatchInferenceJobOutputDownloadEndpointRequest",
    ) -> "GetBatchInferenceJobOutputDownloadEndpointResponse":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def validate_batch_inference_job_input_upload(
        self,
        validate_batch_inference_job_input_upload_request: "ValidateBatchInferenceJobInputUploadRequest",
    ) -> "betterproto_lib_google_protobuf.Empty":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_dataset_validation_job(
        self, create_dataset_validation_job_request: "CreateDatasetValidationJobRequest"
    ) -> "DatasetValidationJob":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_dataset_validation_job(
        self, get_dataset_validation_job_request: "GetDatasetValidationJobRequest"
    ) -> "DatasetValidationJob":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_dataset_validation_jobs(
        self, list_dataset_validation_jobs_request: "ListDatasetValidationJobsRequest"
    ) -> "ListDatasetValidationJobsResponse":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_dataset_validation_job(
        self, delete_dataset_validation_job_request: "DeleteDatasetValidationJobRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def split_dataset(
        self, split_dataset_request: "SplitDatasetRequest"
    ) -> "SplitDatasetResponse":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def validate_assertions(
        self, validate_assertions_request: "ValidateAssertionsRequest"
    ) -> "ValidateAssertionsResponse":
        """Validate evaluation assertions"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def preview_evaluator(
        self, preview_evaluator_request: "PreviewEvaluatorRequest"
    ) -> "PreviewEvaluatorResponse":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def preview_evaluation(
        self, preview_evaluation_request: "PreviewEvaluationRequest"
    ) -> "PreviewEvaluationResponse":
        """Preview an evaluation with sample data"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def test_evaluation(
        self, test_evaluation_request: "TestEvaluationRequest"
    ) -> "PreviewEvaluationResponse":
        """
        Similar to preview evaluation, but no need to create the evaluation entry first.
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_inference_log(
        self, get_inference_log_request: "GetInferenceLogRequest"
    ) -> "InferenceLog":
        """CRUD APIs for inference logs."""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_inference_logs(
        self, list_inference_logs_request: "ListInferenceLogsRequest"
    ) -> "ListInferenceLogsResponse":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_inference_log(
        self, delete_inference_log_request: "DeleteInferenceLogRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """ """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_deployment_prerequisites(
        self, get_deployment_prerequisites_request: "GetDeploymentPrerequisitesRequest"
    ) -> "DeploymentPrerequisites":
        """
        GetDeploymentPrerequisites returns the validation criteria for creating a particular deployment
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_workload_shape(
        self, create_workload_shape_request: "CreateWorkloadShapeRequest"
    ) -> "WorkloadShape":
        """
        CRUD APIs for workload shapes.
        Create Workload Shape
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_workload_shape(
        self, get_workload_shape_request: "GetWorkloadShapeRequest"
    ) -> "WorkloadShape":
        """Get Workload Shape"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_workload_shapes(
        self, list_workload_shapes_request: "ListWorkloadShapesRequest"
    ) -> "ListWorkloadShapesResponse":
        """List Workload Shapes"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def update_workload_shape(
        self, update_workload_shape_request: "UpdateWorkloadShapeRequest"
    ) -> "WorkloadShape":
        """Update Workload Shape"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_workload_shape(
        self, delete_workload_shape_request: "DeleteWorkloadShapeRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Workload Shape"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_workload(
        self, create_workload_request: "CreateWorkloadRequest"
    ) -> "Workload":
        """
        CRUD APIs for workloads.
        Create Workload
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_workload(
        self, get_workload_request: "GetWorkloadRequest"
    ) -> "Workload":
        """Get Workload"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_workloads(
        self, list_workloads_request: "ListWorkloadsRequest"
    ) -> "ListWorkloadsResponse":
        """List Workloads"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def update_workload(
        self, update_workload_request: "UpdateWorkloadRequest"
    ) -> "Workload":
        """Update Workload"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_workload(
        self, delete_workload_request: "DeleteWorkloadRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Workload"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_identity_provider(
        self, create_identity_provider_request: "CreateIdentityProviderRequest"
    ) -> "IdentityProvider":
        """
        SSO / Identity Provider Management APIs

        Create Identity Provider
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_identity_provider(
        self, get_identity_provider_request: "GetIdentityProviderRequest"
    ) -> "IdentityProvider":
        """Get Identity Provider"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_identity_providers(
        self, list_identity_providers_request: "ListIdentityProvidersRequest"
    ) -> "ListIdentityProvidersResponse":
        """List Identity Providers"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def update_identity_provider(
        self, update_identity_provider_request: "UpdateIdentityProviderRequest"
    ) -> "IdentityProvider":
        """Update Identity Provider"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_identity_provider(
        self, delete_identity_provider_request: "DeleteIdentityProviderRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete Identity Provider"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_mcp_server(
        self, create_mcp_server_request: "CreateMcpServerRequest"
    ) -> "McpServer":
        """
        CRUD APIs for MCP Servers

        Create MCP Server
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_mcp_server(
        self, get_mcp_server_request: "GetMcpServerRequest"
    ) -> "McpServer":
        """Get MCP Server"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_mcp_servers(
        self, list_mcp_servers_request: "ListMcpServersRequest"
    ) -> "ListMcpServersResponse":
        """List MCP Servers"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def update_mcp_server(
        self, update_mcp_server_request: "UpdateMcpServerRequest"
    ) -> "McpServer":
        """Update MCP Server"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def delete_mcp_server(
        self, delete_mcp_server_request: "DeleteMcpServerRequest"
    ) -> "betterproto_lib_google_protobuf.Empty":
        """Delete MCP Server"""

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def __rpc_get_o_auth_arguments(
        self,
        stream: "grpclib.server.Stream[GetOAuthArgumentsRequest, GetOAuthArgumentsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_o_auth_arguments(request)
        await stream.send_message(response)

    async def __rpc_create_account(
        self, stream: "grpclib.server.Stream[CreateAccountRequest, Account]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_account(request)
        await stream.send_message(response)

    async def __rpc_get_account(
        self, stream: "grpclib.server.Stream[GetAccountRequest, Account]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_account(request)
        await stream.send_message(response)

    async def __rpc_list_accounts(
        self, stream: "grpclib.server.Stream[ListAccountsRequest, ListAccountsResponse]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_accounts(request)
        await stream.send_message(response)

    async def __rpc_update_account(
        self, stream: "grpclib.server.Stream[UpdateAccountRequest, Account]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.update_account(request)
        await stream.send_message(response)

    async def __rpc_delete_account(
        self,
        stream: "grpclib.server.Stream[DeleteAccountRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_account(request)
        await stream.send_message(response)

    async def __rpc_get_balance(
        self, stream: "grpclib.server.Stream[GetBalanceRequest, Balance]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_balance(request)
        await stream.send_message(response)

    async def __rpc_list_payment_methods(
        self,
        stream: "grpclib.server.Stream[ListPaymentMethodsRequest, ListPaymentMethodsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_payment_methods(request)
        await stream.send_message(response)

    async def __rpc_list_costs(
        self, stream: "grpclib.server.Stream[ListCostsRequest, ListCostsResponse]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_costs(request)
        await stream.send_message(response)

    async def __rpc_list_invoices(
        self, stream: "grpclib.server.Stream[ListInvoicesRequest, ListInvoicesResponse]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_invoices(request)
        await stream.send_message(response)

    async def __rpc_export_billing_metrics(
        self,
        stream: "grpclib.server.Stream[ExportBillingMetricsRequest, ExportBillingMetricsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.export_billing_metrics(request)
        await stream.send_message(response)

    async def __rpc_get_total_historical_spend(
        self,
        stream: "grpclib.server.Stream[GetTotalHistoricalSpendRequest, GetTotalHistoricalSpendResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_total_historical_spend(request)
        await stream.send_message(response)

    async def __rpc_get_account_usage(
        self, stream: "grpclib.server.Stream[GetAccountUsageRequest, AccountUsage]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_account_usage(request)
        await stream.send_message(response)

    async def __rpc_create_batch_job(
        self, stream: "grpclib.server.Stream[CreateBatchJobRequest, BatchJob]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_batch_job(request)
        await stream.send_message(response)

    async def __rpc_get_batch_job(
        self, stream: "grpclib.server.Stream[GetBatchJobRequest, BatchJob]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_batch_job(request)
        await stream.send_message(response)

    async def __rpc_list_batch_jobs(
        self,
        stream: "grpclib.server.Stream[ListBatchJobsRequest, ListBatchJobsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_batch_jobs(request)
        await stream.send_message(response)

    async def __rpc_update_batch_job(
        self, stream: "grpclib.server.Stream[UpdateBatchJobRequest, BatchJob]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.update_batch_job(request)
        await stream.send_message(response)

    async def __rpc_delete_batch_job(
        self,
        stream: "grpclib.server.Stream[DeleteBatchJobRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_batch_job(request)
        await stream.send_message(response)

    async def __rpc_batch_delete_batch_jobs(
        self,
        stream: "grpclib.server.Stream[BatchDeleteBatchJobsRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.batch_delete_batch_jobs(request)
        await stream.send_message(response)

    async def __rpc_cancel_batch_job(
        self,
        stream: "grpclib.server.Stream[CancelBatchJobRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.cancel_batch_job(request)
        await stream.send_message(response)

    async def __rpc_create_cluster(
        self, stream: "grpclib.server.Stream[CreateClusterRequest, Cluster]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_cluster(request)
        await stream.send_message(response)

    async def __rpc_get_cluster(
        self, stream: "grpclib.server.Stream[GetClusterRequest, Cluster]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_cluster(request)
        await stream.send_message(response)

    async def __rpc_list_clusters(
        self, stream: "grpclib.server.Stream[ListClustersRequest, ListClustersResponse]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_clusters(request)
        await stream.send_message(response)

    async def __rpc_update_cluster(
        self, stream: "grpclib.server.Stream[UpdateClusterRequest, Cluster]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.update_cluster(request)
        await stream.send_message(response)

    async def __rpc_delete_cluster(
        self,
        stream: "grpclib.server.Stream[DeleteClusterRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_cluster(request)
        await stream.send_message(response)

    async def __rpc_get_cluster_connection_info(
        self,
        stream: "grpclib.server.Stream[GetClusterConnectionInfoRequest, ClusterConnectionInfo]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_cluster_connection_info(request)
        await stream.send_message(response)

    async def __rpc_create_environment(
        self, stream: "grpclib.server.Stream[CreateEnvironmentRequest, Environment]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_environment(request)
        await stream.send_message(response)

    async def __rpc_get_environment(
        self, stream: "grpclib.server.Stream[GetEnvironmentRequest, Environment]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_environment(request)
        await stream.send_message(response)

    async def __rpc_list_environments(
        self,
        stream: "grpclib.server.Stream[ListEnvironmentsRequest, ListEnvironmentsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_environments(request)
        await stream.send_message(response)

    async def __rpc_update_environment(
        self, stream: "grpclib.server.Stream[UpdateEnvironmentRequest, Environment]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.update_environment(request)
        await stream.send_message(response)

    async def __rpc_delete_environment(
        self,
        stream: "grpclib.server.Stream[DeleteEnvironmentRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_environment(request)
        await stream.send_message(response)

    async def __rpc_batch_delete_environments(
        self,
        stream: "grpclib.server.Stream[BatchDeleteEnvironmentsRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.batch_delete_environments(request)
        await stream.send_message(response)

    async def __rpc_connect_environment(
        self,
        stream: "grpclib.server.Stream[ConnectEnvironmentRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.connect_environment(request)
        await stream.send_message(response)

    async def __rpc_disconnect_environment(
        self,
        stream: "grpclib.server.Stream[DisconnectEnvironmentRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.disconnect_environment(request)
        await stream.send_message(response)

    async def __rpc_get_feature_flag(
        self, stream: "grpclib.server.Stream[GetFeatureFlagRequest, FeatureFlag]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_feature_flag(request)
        await stream.send_message(response)

    async def __rpc_list_feature_flags(
        self,
        stream: "grpclib.server.Stream[ListFeatureFlagsRequest, ListFeatureFlagsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_feature_flags(request)
        await stream.send_message(response)

    async def __rpc_create_snapshot(
        self, stream: "grpclib.server.Stream[CreateSnapshotRequest, Snapshot]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_snapshot(request)
        await stream.send_message(response)

    async def __rpc_get_snapshot(
        self, stream: "grpclib.server.Stream[GetSnapshotRequest, Snapshot]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_snapshot(request)
        await stream.send_message(response)

    async def __rpc_list_snapshots(
        self,
        stream: "grpclib.server.Stream[ListSnapshotsRequest, ListSnapshotsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_snapshots(request)
        await stream.send_message(response)

    async def __rpc_delete_snapshot(
        self,
        stream: "grpclib.server.Stream[DeleteSnapshotRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_snapshot(request)
        await stream.send_message(response)

    async def __rpc_get_batch_job_logs(
        self,
        stream: "grpclib.server.Stream[GetBatchJobLogsRequest, GetBatchJobLogsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_batch_job_logs(request)
        await stream.send_message(response)

    async def __rpc_create_node_pool(
        self, stream: "grpclib.server.Stream[CreateNodePoolRequest, NodePool]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_node_pool(request)
        await stream.send_message(response)

    async def __rpc_get_node_pool(
        self, stream: "grpclib.server.Stream[GetNodePoolRequest, NodePool]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_node_pool(request)
        await stream.send_message(response)

    async def __rpc_list_node_pools(
        self,
        stream: "grpclib.server.Stream[ListNodePoolsRequest, ListNodePoolsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_node_pools(request)
        await stream.send_message(response)

    async def __rpc_update_node_pool(
        self, stream: "grpclib.server.Stream[UpdateNodePoolRequest, NodePool]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.update_node_pool(request)
        await stream.send_message(response)

    async def __rpc_delete_node_pool(
        self,
        stream: "grpclib.server.Stream[DeleteNodePoolRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_node_pool(request)
        await stream.send_message(response)

    async def __rpc_batch_delete_node_pools(
        self,
        stream: "grpclib.server.Stream[BatchDeleteNodePoolsRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.batch_delete_node_pools(request)
        await stream.send_message(response)

    async def __rpc_get_node_pool_stats(
        self, stream: "grpclib.server.Stream[GetNodePoolStatsRequest, NodePoolStats]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_node_pool_stats(request)
        await stream.send_message(response)

    async def __rpc_create_user(
        self, stream: "grpclib.server.Stream[CreateUserRequest, User]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_user(request)
        await stream.send_message(response)

    async def __rpc_get_user(
        self, stream: "grpclib.server.Stream[GetUserRequest, User]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_user(request)
        await stream.send_message(response)

    async def __rpc_list_users(
        self, stream: "grpclib.server.Stream[ListUsersRequest, ListUsersResponse]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_users(request)
        await stream.send_message(response)

    async def __rpc_update_user(
        self, stream: "grpclib.server.Stream[UpdateUserRequest, User]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.update_user(request)
        await stream.send_message(response)

    async def __rpc_delete_user(
        self,
        stream: "grpclib.server.Stream[DeleteUserRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_user(request)
        await stream.send_message(response)

    async def __rpc_list_audit_logs(
        self,
        stream: "grpclib.server.Stream[ListAuditLogsRequest, ListAuditLogsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_audit_logs(request)
        await stream.send_message(response)

    async def __rpc_create_api_key(
        self, stream: "grpclib.server.Stream[CreateApiKeyRequest, ApiKey]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_api_key(request)
        await stream.send_message(response)

    async def __rpc_list_api_keys(
        self, stream: "grpclib.server.Stream[ListApiKeysRequest, ListApiKeysResponse]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_api_keys(request)
        await stream.send_message(response)

    async def __rpc_delete_api_key(
        self,
        stream: "grpclib.server.Stream[DeleteApiKeyRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_api_key(request)
        await stream.send_message(response)

    async def __rpc_get_internal_api_key(
        self, stream: "grpclib.server.Stream[GetInternalApiKeyRequest, ApiKey]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_internal_api_key(request)
        await stream.send_message(response)

    async def __rpc_create_model(
        self, stream: "grpclib.server.Stream[CreateModelRequest, Model]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_model(request)
        await stream.send_message(response)

    async def __rpc_get_model(
        self, stream: "grpclib.server.Stream[GetModelRequest, Model]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_model(request)
        await stream.send_message(response)

    async def __rpc_list_models(
        self, stream: "grpclib.server.Stream[ListModelsRequest, ListModelsResponse]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_models(request)
        await stream.send_message(response)

    async def __rpc_list_serverless_lora_models(
        self,
        stream: "grpclib.server.Stream[ListServerlessLoraModelsRequest, ListServerlessLoraModelsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_serverless_lora_models(request)
        await stream.send_message(response)

    async def __rpc_update_model(
        self, stream: "grpclib.server.Stream[UpdateModelRequest, Model]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.update_model(request)
        await stream.send_message(response)

    async def __rpc_delete_model(
        self,
        stream: "grpclib.server.Stream[DeleteModelRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_model(request)
        await stream.send_message(response)

    async def __rpc_get_model_upload_endpoint(
        self,
        stream: "grpclib.server.Stream[GetModelUploadEndpointRequest, GetModelUploadEndpointResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_model_upload_endpoint(request)
        await stream.send_message(response)

    async def __rpc_get_model_download_endpoint(
        self,
        stream: "grpclib.server.Stream[GetModelDownloadEndpointRequest, GetModelDownloadEndpointResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_model_download_endpoint(request)
        await stream.send_message(response)

    async def __rpc_validate_model_upload(
        self,
        stream: "grpclib.server.Stream[ValidateModelUploadRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.validate_model_upload(request)
        await stream.send_message(response)

    async def __rpc_validate_model_config(
        self,
        stream: "grpclib.server.Stream[ValidateModelConfigRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.validate_model_config(request)
        await stream.send_message(response)

    async def __rpc_import_model(
        self,
        stream: "grpclib.server.Stream[ImportModelRequest, _google_longrunning__.Operation]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.import_model(request)
        await stream.send_message(response)

    async def __rpc_create_deployment(
        self, stream: "grpclib.server.Stream[CreateDeploymentRequest, Deployment]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_deployment(request)
        await stream.send_message(response)

    async def __rpc_get_deployment(
        self, stream: "grpclib.server.Stream[GetDeploymentRequest, Deployment]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_deployment(request)
        await stream.send_message(response)

    async def __rpc_list_deployments(
        self,
        stream: "grpclib.server.Stream[ListDeploymentsRequest, ListDeploymentsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_deployments(request)
        await stream.send_message(response)

    async def __rpc_update_deployment(
        self, stream: "grpclib.server.Stream[UpdateDeploymentRequest, Deployment]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.update_deployment(request)
        await stream.send_message(response)

    async def __rpc_delete_deployment(
        self,
        stream: "grpclib.server.Stream[DeleteDeploymentRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_deployment(request)
        await stream.send_message(response)

    async def __rpc_undelete_deployment(
        self, stream: "grpclib.server.Stream[UndeleteDeploymentRequest, Deployment]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.undelete_deployment(request)
        await stream.send_message(response)

    async def __rpc_scale_deployment(
        self,
        stream: "grpclib.server.Stream[ScaleDeploymentRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.scale_deployment(request)
        await stream.send_message(response)

    async def __rpc_get_deployment_metrics(
        self,
        stream: "grpclib.server.Stream[GetDeploymentMetricsRequest, GetDeploymentMetricsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_deployment_metrics(request)
        await stream.send_message(response)

    async def __rpc_list_deployment_metrics(
        self,
        stream: "grpclib.server.Stream[ListDeploymentMetricsRequest, ListDeploymentMetricsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_deployment_metrics(request)
        await stream.send_message(response)

    async def __rpc_create_deployment_template(
        self,
        stream: "grpclib.server.Stream[CreateDeploymentTemplateRequest, DeploymentTemplate]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_deployment_template(request)
        await stream.send_message(response)

    async def __rpc_get_deployment_template(
        self,
        stream: "grpclib.server.Stream[GetDeploymentTemplateRequest, DeploymentTemplate]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_deployment_template(request)
        await stream.send_message(response)

    async def __rpc_list_deployment_templates(
        self,
        stream: "grpclib.server.Stream[ListDeploymentTemplatesRequest, ListDeploymentTemplatesResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_deployment_templates(request)
        await stream.send_message(response)

    async def __rpc_update_deployment_template(
        self,
        stream: "grpclib.server.Stream[UpdateDeploymentTemplateRequest, DeploymentTemplate]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.update_deployment_template(request)
        await stream.send_message(response)

    async def __rpc_delete_deployment_template(
        self,
        stream: "grpclib.server.Stream[DeleteDeploymentTemplateRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_deployment_template(request)
        await stream.send_message(response)

    async def __rpc_create_deployed_model(
        self, stream: "grpclib.server.Stream[CreateDeployedModelRequest, DeployedModel]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_deployed_model(request)
        await stream.send_message(response)

    async def __rpc_get_deployed_model(
        self, stream: "grpclib.server.Stream[GetDeployedModelRequest, DeployedModel]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_deployed_model(request)
        await stream.send_message(response)

    async def __rpc_list_deployed_models(
        self,
        stream: "grpclib.server.Stream[ListDeployedModelsRequest, ListDeployedModelsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_deployed_models(request)
        await stream.send_message(response)

    async def __rpc_update_deployed_model(
        self, stream: "grpclib.server.Stream[UpdateDeployedModelRequest, DeployedModel]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.update_deployed_model(request)
        await stream.send_message(response)

    async def __rpc_delete_deployed_model(
        self,
        stream: "grpclib.server.Stream[DeleteDeployedModelRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_deployed_model(request)
        await stream.send_message(response)

    async def __rpc_create_aws_iam_role_binding(
        self,
        stream: "grpclib.server.Stream[CreateAwsIamRoleBindingRequest, AwsIamRoleBinding]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_aws_iam_role_binding(request)
        await stream.send_message(response)

    async def __rpc_list_aws_iam_role_bindings(
        self,
        stream: "grpclib.server.Stream[ListAwsIamRoleBindingsRequest, ListAwsIamRoleBindingsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_aws_iam_role_bindings(request)
        await stream.send_message(response)

    async def __rpc_delete_aws_iam_role_binding(
        self,
        stream: "grpclib.server.Stream[DeleteAwsIamRoleBindingRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_aws_iam_role_binding(request)
        await stream.send_message(response)

    async def __rpc_create_node_pool_binding(
        self,
        stream: "grpclib.server.Stream[CreateNodePoolBindingRequest, NodePoolBinding]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_node_pool_binding(request)
        await stream.send_message(response)

    async def __rpc_list_node_pool_bindings(
        self,
        stream: "grpclib.server.Stream[ListNodePoolBindingsRequest, ListNodePoolBindingsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_node_pool_bindings(request)
        await stream.send_message(response)

    async def __rpc_delete_node_pool_binding(
        self,
        stream: "grpclib.server.Stream[DeleteNodePoolBindingRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_node_pool_binding(request)
        await stream.send_message(response)

    async def __rpc_create_dataset(
        self, stream: "grpclib.server.Stream[CreateDatasetRequest, Dataset]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_dataset(request)
        await stream.send_message(response)

    async def __rpc_get_dataset(
        self, stream: "grpclib.server.Stream[GetDatasetRequest, Dataset]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_dataset(request)
        await stream.send_message(response)

    async def __rpc_list_datasets(
        self, stream: "grpclib.server.Stream[ListDatasetsRequest, ListDatasetsResponse]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_datasets(request)
        await stream.send_message(response)

    async def __rpc_update_dataset(
        self, stream: "grpclib.server.Stream[UpdateDatasetRequest, Dataset]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.update_dataset(request)
        await stream.send_message(response)

    async def __rpc_delete_dataset(
        self,
        stream: "grpclib.server.Stream[DeleteDatasetRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_dataset(request)
        await stream.send_message(response)

    async def __rpc_upload_dataset(
        self,
        stream: "grpclib.server.Stream[UploadDatasetRequest, UploadDatasetResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.upload_dataset(request)
        await stream.send_message(response)

    async def __rpc_get_dataset_upload_endpoint(
        self,
        stream: "grpclib.server.Stream[GetDatasetUploadEndpointRequest, GetDatasetUploadEndpointResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_dataset_upload_endpoint(request)
        await stream.send_message(response)

    async def __rpc_validate_dataset_upload(
        self,
        stream: "grpclib.server.Stream[ValidateDatasetUploadRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.validate_dataset_upload(request)
        await stream.send_message(response)

    async def __rpc_get_dataset_download_endpoint(
        self,
        stream: "grpclib.server.Stream[GetDatasetDownloadEndpointRequest, GetDatasetDownloadEndpointResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_dataset_download_endpoint(request)
        await stream.send_message(response)

    async def __rpc_preview_dataset(
        self,
        stream: "grpclib.server.Stream[PreviewDatasetRequest, PreviewDatasetResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.preview_dataset(request)
        await stream.send_message(response)

    async def __rpc_create_evaluator(
        self, stream: "grpclib.server.Stream[CreateEvaluatorRequest, Evaluator]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_evaluator(request)
        await stream.send_message(response)

    async def __rpc_get_evaluator(
        self, stream: "grpclib.server.Stream[GetEvaluatorRequest, Evaluator]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_evaluator(request)
        await stream.send_message(response)

    async def __rpc_list_evaluators(
        self,
        stream: "grpclib.server.Stream[ListEvaluatorsRequest, ListEvaluatorsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_evaluators(request)
        await stream.send_message(response)

    async def __rpc_delete_evaluator(
        self,
        stream: "grpclib.server.Stream[DeleteEvaluatorRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_evaluator(request)
        await stream.send_message(response)

    async def __rpc_create_evaluation(
        self, stream: "grpclib.server.Stream[CreateEvaluationRequest, Evaluation]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_evaluation(request)
        await stream.send_message(response)

    async def __rpc_get_evaluation(
        self, stream: "grpclib.server.Stream[GetEvaluationRequest, Evaluation]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_evaluation(request)
        await stream.send_message(response)

    async def __rpc_list_evaluations(
        self,
        stream: "grpclib.server.Stream[ListEvaluationsRequest, ListEvaluationsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_evaluations(request)
        await stream.send_message(response)

    async def __rpc_delete_evaluation(
        self,
        stream: "grpclib.server.Stream[DeleteEvaluationRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_evaluation(request)
        await stream.send_message(response)

    async def __rpc_create_evaluation_job(
        self, stream: "grpclib.server.Stream[CreateEvaluationJobRequest, EvaluationJob]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_evaluation_job(request)
        await stream.send_message(response)

    async def __rpc_get_evaluation_job(
        self, stream: "grpclib.server.Stream[GetEvaluationJobRequest, EvaluationJob]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_evaluation_job(request)
        await stream.send_message(response)

    async def __rpc_list_evaluation_jobs(
        self,
        stream: "grpclib.server.Stream[ListEvaluationJobsRequest, ListEvaluationJobsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_evaluation_jobs(request)
        await stream.send_message(response)

    async def __rpc_delete_evaluation_job(
        self,
        stream: "grpclib.server.Stream[DeleteEvaluationJobRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_evaluation_job(request)
        await stream.send_message(response)

    async def __rpc_create_fine_tuning_job(
        self, stream: "grpclib.server.Stream[CreateFineTuningJobRequest, FineTuningJob]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_fine_tuning_job(request)
        await stream.send_message(response)

    async def __rpc_get_fine_tuning_job(
        self, stream: "grpclib.server.Stream[GetFineTuningJobRequest, FineTuningJob]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_fine_tuning_job(request)
        await stream.send_message(response)

    async def __rpc_list_fine_tuning_jobs(
        self,
        stream: "grpclib.server.Stream[ListFineTuningJobsRequest, ListFineTuningJobsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_fine_tuning_jobs(request)
        await stream.send_message(response)

    async def __rpc_update_fine_tuning_job(
        self, stream: "grpclib.server.Stream[UpdateFineTuningJobRequest, FineTuningJob]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.update_fine_tuning_job(request)
        await stream.send_message(response)

    async def __rpc_delete_fine_tuning_job(
        self,
        stream: "grpclib.server.Stream[DeleteFineTuningJobRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_fine_tuning_job(request)
        await stream.send_message(response)

    async def __rpc_create_supervised_fine_tuning_job(
        self,
        stream: "grpclib.server.Stream[CreateSupervisedFineTuningJobRequest, SupervisedFineTuningJob]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_supervised_fine_tuning_job(request)
        await stream.send_message(response)

    async def __rpc_get_supervised_fine_tuning_job(
        self,
        stream: "grpclib.server.Stream[GetSupervisedFineTuningJobRequest, SupervisedFineTuningJob]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_supervised_fine_tuning_job(request)
        await stream.send_message(response)

    async def __rpc_list_supervised_fine_tuning_jobs(
        self,
        stream: "grpclib.server.Stream[ListSupervisedFineTuningJobsRequest, ListSupervisedFineTuningJobsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_supervised_fine_tuning_jobs(request)
        await stream.send_message(response)

    async def __rpc_delete_supervised_fine_tuning_job(
        self,
        stream: "grpclib.server.Stream[DeleteSupervisedFineTuningJobRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_supervised_fine_tuning_job(request)
        await stream.send_message(response)

    async def __rpc_create_reinforcement_fine_tuning_job(
        self,
        stream: "grpclib.server.Stream[CreateReinforcementFineTuningJobRequest, ReinforcementFineTuningJob]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_reinforcement_fine_tuning_job(request)
        await stream.send_message(response)

    async def __rpc_get_reinforcement_fine_tuning_job(
        self,
        stream: "grpclib.server.Stream[GetReinforcementFineTuningJobRequest, ReinforcementFineTuningJob]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_reinforcement_fine_tuning_job(request)
        await stream.send_message(response)

    async def __rpc_list_reinforcement_fine_tuning_jobs(
        self,
        stream: "grpclib.server.Stream[ListReinforcementFineTuningJobsRequest, ListReinforcementFineTuningJobsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_reinforcement_fine_tuning_jobs(request)
        await stream.send_message(response)

    async def __rpc_delete_reinforcement_fine_tuning_job(
        self,
        stream: "grpclib.server.Stream[DeleteReinforcementFineTuningJobRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_reinforcement_fine_tuning_job(request)
        await stream.send_message(response)

    async def __rpc_resume_reinforcement_fine_tuning_job(
        self,
        stream: "grpclib.server.Stream[ResumeReinforcementFineTuningJobRequest, ReinforcementFineTuningJob]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.resume_reinforcement_fine_tuning_job(request)
        await stream.send_message(response)

    async def __rpc_debug_reinforcement_fine_tuning_job(
        self,
        stream: "grpclib.server.Stream[DebugReinforcementFineTuningJobRequest, DebugReinforcementFineTuningJobResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.debug_reinforcement_fine_tuning_job(request)
        await stream.send_message(response)

    async def __rpc_create_reinforcement_fine_tuning_epoch(
        self,
        stream: "grpclib.server.Stream[CreateReinforcementFineTuningEpochRequest, ReinforcementFineTuningEpoch]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_reinforcement_fine_tuning_epoch(request)
        await stream.send_message(response)

    async def __rpc_get_reinforcement_fine_tuning_epoch(
        self,
        stream: "grpclib.server.Stream[GetReinforcementFineTuningEpochRequest, ReinforcementFineTuningEpoch]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_reinforcement_fine_tuning_epoch(request)
        await stream.send_message(response)

    async def __rpc_list_reinforcement_fine_tuning_epochs(
        self,
        stream: "grpclib.server.Stream[ListReinforcementFineTuningEpochsRequest, ListReinforcementFineTuningEpochsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_reinforcement_fine_tuning_epochs(request)
        await stream.send_message(response)

    async def __rpc_delete_reinforcement_fine_tuning_epoch(
        self,
        stream: "grpclib.server.Stream[DeleteReinforcementFineTuningEpochRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_reinforcement_fine_tuning_epoch(request)
        await stream.send_message(response)

    async def __rpc_create_rlor_trainer_job(
        self,
        stream: "grpclib.server.Stream[CreateRlorTrainerJobRequest, RlorTrainerJob]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_rlor_trainer_job(request)
        await stream.send_message(response)

    async def __rpc_get_rlor_trainer_job(
        self, stream: "grpclib.server.Stream[GetRlorTrainerJobRequest, RlorTrainerJob]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_rlor_trainer_job(request)
        await stream.send_message(response)

    async def __rpc_list_rlor_trainer_jobs(
        self,
        stream: "grpclib.server.Stream[ListRlorTrainerJobsRequest, ListRlorTrainerJobsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_rlor_trainer_jobs(request)
        await stream.send_message(response)

    async def __rpc_delete_rlor_trainer_job(
        self,
        stream: "grpclib.server.Stream[DeleteRlorTrainerJobRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_rlor_trainer_job(request)
        await stream.send_message(response)

    async def __rpc_create_peft_merge_job(
        self, stream: "grpclib.server.Stream[CreatePeftMergeJobRequest, PeftMergeJob]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_peft_merge_job(request)
        await stream.send_message(response)

    async def __rpc_get_peft_merge_job(
        self, stream: "grpclib.server.Stream[GetPeftMergeJobRequest, PeftMergeJob]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_peft_merge_job(request)
        await stream.send_message(response)

    async def __rpc_list_peft_merge_jobs(
        self,
        stream: "grpclib.server.Stream[ListPeftMergeJobsRequest, ListPeftMergeJobsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_peft_merge_jobs(request)
        await stream.send_message(response)

    async def __rpc_delete_peft_merge_job(
        self,
        stream: "grpclib.server.Stream[DeletePeftMergeJobRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_peft_merge_job(request)
        await stream.send_message(response)

    async def __rpc_get_quota(
        self, stream: "grpclib.server.Stream[GetQuotaRequest, Quota]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_quota(request)
        await stream.send_message(response)

    async def __rpc_update_quota(
        self, stream: "grpclib.server.Stream[UpdateQuotaRequest, Quota]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.update_quota(request)
        await stream.send_message(response)

    async def __rpc_list_quotas(
        self, stream: "grpclib.server.Stream[ListQuotasRequest, ListQuotasResponse]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_quotas(request)
        await stream.send_message(response)

    async def __rpc_create_secret(
        self, stream: "grpclib.server.Stream[CreateSecretRequest, Secret]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_secret(request)
        await stream.send_message(response)

    async def __rpc_get_secret(
        self, stream: "grpclib.server.Stream[GetSecretRequest, Secret]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_secret(request)
        await stream.send_message(response)

    async def __rpc_list_secrets(
        self, stream: "grpclib.server.Stream[ListSecretsRequest, ListSecretsResponse]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_secrets(request)
        await stream.send_message(response)

    async def __rpc_update_secret(
        self, stream: "grpclib.server.Stream[UpdateSecretRequest, Secret]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.update_secret(request)
        await stream.send_message(response)

    async def __rpc_delete_secret(
        self,
        stream: "grpclib.server.Stream[DeleteSecretRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_secret(request)
        await stream.send_message(response)

    async def __rpc_get_reservation(
        self, stream: "grpclib.server.Stream[GetReservationRequest, Reservation]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_reservation(request)
        await stream.send_message(response)

    async def __rpc_list_reservations(
        self,
        stream: "grpclib.server.Stream[ListReservationsRequest, ListReservationsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_reservations(request)
        await stream.send_message(response)

    async def __rpc_prepare_model(
        self,
        stream: "grpclib.server.Stream[PrepareModelRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.prepare_model(request)
        await stream.send_message(response)

    async def __rpc_create_batch_inference_job(
        self,
        stream: "grpclib.server.Stream[CreateBatchInferenceJobRequest, BatchInferenceJob]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_batch_inference_job(request)
        await stream.send_message(response)

    async def __rpc_get_batch_inference_job(
        self,
        stream: "grpclib.server.Stream[GetBatchInferenceJobRequest, BatchInferenceJob]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_batch_inference_job(request)
        await stream.send_message(response)

    async def __rpc_list_batch_inference_jobs(
        self,
        stream: "grpclib.server.Stream[ListBatchInferenceJobsRequest, ListBatchInferenceJobsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_batch_inference_jobs(request)
        await stream.send_message(response)

    async def __rpc_update_batch_inference_job(
        self,
        stream: "grpclib.server.Stream[UpdateBatchInferenceJobRequest, BatchInferenceJob]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.update_batch_inference_job(request)
        await stream.send_message(response)

    async def __rpc_delete_batch_inference_job(
        self,
        stream: "grpclib.server.Stream[DeleteBatchInferenceJobRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_batch_inference_job(request)
        await stream.send_message(response)

    async def __rpc_create_eagle_training_job(
        self,
        stream: "grpclib.server.Stream[CreateEagleTrainingJobRequest, EagleTrainingJob]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_eagle_training_job(request)
        await stream.send_message(response)

    async def __rpc_get_eagle_training_job(
        self,
        stream: "grpclib.server.Stream[GetEagleTrainingJobRequest, EagleTrainingJob]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_eagle_training_job(request)
        await stream.send_message(response)

    async def __rpc_list_eagle_training_jobs(
        self,
        stream: "grpclib.server.Stream[ListEagleTrainingJobsRequest, ListEagleTrainingJobsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_eagle_training_jobs(request)
        await stream.send_message(response)

    async def __rpc_delete_eagle_training_job(
        self,
        stream: "grpclib.server.Stream[DeleteEagleTrainingJobRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_eagle_training_job(request)
        await stream.send_message(response)

    async def __rpc_get_batch_inference_job_input_upload_endpoint(
        self,
        stream: "grpclib.server.Stream[GetBatchInferenceJobInputUploadEndpointRequest, GetBatchInferenceJobInputUploadEndpointResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_batch_inference_job_input_upload_endpoint(request)
        await stream.send_message(response)

    async def __rpc_get_batch_inference_job_output_download_endpoint(
        self,
        stream: "grpclib.server.Stream[GetBatchInferenceJobOutputDownloadEndpointRequest, GetBatchInferenceJobOutputDownloadEndpointResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_batch_inference_job_output_download_endpoint(request)
        await stream.send_message(response)

    async def __rpc_validate_batch_inference_job_input_upload(
        self,
        stream: "grpclib.server.Stream[ValidateBatchInferenceJobInputUploadRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.validate_batch_inference_job_input_upload(request)
        await stream.send_message(response)

    async def __rpc_create_dataset_validation_job(
        self,
        stream: "grpclib.server.Stream[CreateDatasetValidationJobRequest, DatasetValidationJob]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_dataset_validation_job(request)
        await stream.send_message(response)

    async def __rpc_get_dataset_validation_job(
        self,
        stream: "grpclib.server.Stream[GetDatasetValidationJobRequest, DatasetValidationJob]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_dataset_validation_job(request)
        await stream.send_message(response)

    async def __rpc_list_dataset_validation_jobs(
        self,
        stream: "grpclib.server.Stream[ListDatasetValidationJobsRequest, ListDatasetValidationJobsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_dataset_validation_jobs(request)
        await stream.send_message(response)

    async def __rpc_delete_dataset_validation_job(
        self,
        stream: "grpclib.server.Stream[DeleteDatasetValidationJobRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_dataset_validation_job(request)
        await stream.send_message(response)

    async def __rpc_split_dataset(
        self, stream: "grpclib.server.Stream[SplitDatasetRequest, SplitDatasetResponse]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.split_dataset(request)
        await stream.send_message(response)

    async def __rpc_validate_assertions(
        self,
        stream: "grpclib.server.Stream[ValidateAssertionsRequest, ValidateAssertionsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.validate_assertions(request)
        await stream.send_message(response)

    async def __rpc_preview_evaluator(
        self,
        stream: "grpclib.server.Stream[PreviewEvaluatorRequest, PreviewEvaluatorResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.preview_evaluator(request)
        await stream.send_message(response)

    async def __rpc_preview_evaluation(
        self,
        stream: "grpclib.server.Stream[PreviewEvaluationRequest, PreviewEvaluationResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.preview_evaluation(request)
        await stream.send_message(response)

    async def __rpc_test_evaluation(
        self,
        stream: "grpclib.server.Stream[TestEvaluationRequest, PreviewEvaluationResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.test_evaluation(request)
        await stream.send_message(response)

    async def __rpc_get_inference_log(
        self, stream: "grpclib.server.Stream[GetInferenceLogRequest, InferenceLog]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_inference_log(request)
        await stream.send_message(response)

    async def __rpc_list_inference_logs(
        self,
        stream: "grpclib.server.Stream[ListInferenceLogsRequest, ListInferenceLogsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_inference_logs(request)
        await stream.send_message(response)

    async def __rpc_delete_inference_log(
        self,
        stream: "grpclib.server.Stream[DeleteInferenceLogRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_inference_log(request)
        await stream.send_message(response)

    async def __rpc_get_deployment_prerequisites(
        self,
        stream: "grpclib.server.Stream[GetDeploymentPrerequisitesRequest, DeploymentPrerequisites]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_deployment_prerequisites(request)
        await stream.send_message(response)

    async def __rpc_create_workload_shape(
        self, stream: "grpclib.server.Stream[CreateWorkloadShapeRequest, WorkloadShape]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_workload_shape(request)
        await stream.send_message(response)

    async def __rpc_get_workload_shape(
        self, stream: "grpclib.server.Stream[GetWorkloadShapeRequest, WorkloadShape]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_workload_shape(request)
        await stream.send_message(response)

    async def __rpc_list_workload_shapes(
        self,
        stream: "grpclib.server.Stream[ListWorkloadShapesRequest, ListWorkloadShapesResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_workload_shapes(request)
        await stream.send_message(response)

    async def __rpc_update_workload_shape(
        self, stream: "grpclib.server.Stream[UpdateWorkloadShapeRequest, WorkloadShape]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.update_workload_shape(request)
        await stream.send_message(response)

    async def __rpc_delete_workload_shape(
        self,
        stream: "grpclib.server.Stream[DeleteWorkloadShapeRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_workload_shape(request)
        await stream.send_message(response)

    async def __rpc_create_workload(
        self, stream: "grpclib.server.Stream[CreateWorkloadRequest, Workload]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_workload(request)
        await stream.send_message(response)

    async def __rpc_get_workload(
        self, stream: "grpclib.server.Stream[GetWorkloadRequest, Workload]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_workload(request)
        await stream.send_message(response)

    async def __rpc_list_workloads(
        self,
        stream: "grpclib.server.Stream[ListWorkloadsRequest, ListWorkloadsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_workloads(request)
        await stream.send_message(response)

    async def __rpc_update_workload(
        self, stream: "grpclib.server.Stream[UpdateWorkloadRequest, Workload]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.update_workload(request)
        await stream.send_message(response)

    async def __rpc_delete_workload(
        self,
        stream: "grpclib.server.Stream[DeleteWorkloadRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_workload(request)
        await stream.send_message(response)

    async def __rpc_create_identity_provider(
        self,
        stream: "grpclib.server.Stream[CreateIdentityProviderRequest, IdentityProvider]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_identity_provider(request)
        await stream.send_message(response)

    async def __rpc_get_identity_provider(
        self,
        stream: "grpclib.server.Stream[GetIdentityProviderRequest, IdentityProvider]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_identity_provider(request)
        await stream.send_message(response)

    async def __rpc_list_identity_providers(
        self,
        stream: "grpclib.server.Stream[ListIdentityProvidersRequest, ListIdentityProvidersResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_identity_providers(request)
        await stream.send_message(response)

    async def __rpc_update_identity_provider(
        self,
        stream: "grpclib.server.Stream[UpdateIdentityProviderRequest, IdentityProvider]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.update_identity_provider(request)
        await stream.send_message(response)

    async def __rpc_delete_identity_provider(
        self,
        stream: "grpclib.server.Stream[DeleteIdentityProviderRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_identity_provider(request)
        await stream.send_message(response)

    async def __rpc_create_mcp_server(
        self, stream: "grpclib.server.Stream[CreateMcpServerRequest, McpServer]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_mcp_server(request)
        await stream.send_message(response)

    async def __rpc_get_mcp_server(
        self, stream: "grpclib.server.Stream[GetMcpServerRequest, McpServer]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_mcp_server(request)
        await stream.send_message(response)

    async def __rpc_list_mcp_servers(
        self,
        stream: "grpclib.server.Stream[ListMcpServersRequest, ListMcpServersResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_mcp_servers(request)
        await stream.send_message(response)

    async def __rpc_update_mcp_server(
        self, stream: "grpclib.server.Stream[UpdateMcpServerRequest, McpServer]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.update_mcp_server(request)
        await stream.send_message(response)

    async def __rpc_delete_mcp_server(
        self,
        stream: "grpclib.server.Stream[DeleteMcpServerRequest, betterproto_lib_google_protobuf.Empty]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.delete_mcp_server(request)
        await stream.send_message(response)

    def __mapping__(self) -> Dict[str, grpclib.const.Handler]:
        return {
            "/gateway.Gateway/GetOAuthArguments": grpclib.const.Handler(
                self.__rpc_get_o_auth_arguments,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetOAuthArgumentsRequest,
                GetOAuthArgumentsResponse,
            ),
            "/gateway.Gateway/CreateAccount": grpclib.const.Handler(
                self.__rpc_create_account,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateAccountRequest,
                Account,
            ),
            "/gateway.Gateway/GetAccount": grpclib.const.Handler(
                self.__rpc_get_account,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetAccountRequest,
                Account,
            ),
            "/gateway.Gateway/ListAccounts": grpclib.const.Handler(
                self.__rpc_list_accounts,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListAccountsRequest,
                ListAccountsResponse,
            ),
            "/gateway.Gateway/UpdateAccount": grpclib.const.Handler(
                self.__rpc_update_account,
                grpclib.const.Cardinality.UNARY_UNARY,
                UpdateAccountRequest,
                Account,
            ),
            "/gateway.Gateway/DeleteAccount": grpclib.const.Handler(
                self.__rpc_delete_account,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteAccountRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/GetBalance": grpclib.const.Handler(
                self.__rpc_get_balance,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetBalanceRequest,
                Balance,
            ),
            "/gateway.Gateway/ListPaymentMethods": grpclib.const.Handler(
                self.__rpc_list_payment_methods,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListPaymentMethodsRequest,
                ListPaymentMethodsResponse,
            ),
            "/gateway.Gateway/ListCosts": grpclib.const.Handler(
                self.__rpc_list_costs,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListCostsRequest,
                ListCostsResponse,
            ),
            "/gateway.Gateway/ListInvoices": grpclib.const.Handler(
                self.__rpc_list_invoices,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListInvoicesRequest,
                ListInvoicesResponse,
            ),
            "/gateway.Gateway/ExportBillingMetrics": grpclib.const.Handler(
                self.__rpc_export_billing_metrics,
                grpclib.const.Cardinality.UNARY_UNARY,
                ExportBillingMetricsRequest,
                ExportBillingMetricsResponse,
            ),
            "/gateway.Gateway/GetTotalHistoricalSpend": grpclib.const.Handler(
                self.__rpc_get_total_historical_spend,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetTotalHistoricalSpendRequest,
                GetTotalHistoricalSpendResponse,
            ),
            "/gateway.Gateway/GetAccountUsage": grpclib.const.Handler(
                self.__rpc_get_account_usage,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetAccountUsageRequest,
                AccountUsage,
            ),
            "/gateway.Gateway/CreateBatchJob": grpclib.const.Handler(
                self.__rpc_create_batch_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateBatchJobRequest,
                BatchJob,
            ),
            "/gateway.Gateway/GetBatchJob": grpclib.const.Handler(
                self.__rpc_get_batch_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetBatchJobRequest,
                BatchJob,
            ),
            "/gateway.Gateway/ListBatchJobs": grpclib.const.Handler(
                self.__rpc_list_batch_jobs,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListBatchJobsRequest,
                ListBatchJobsResponse,
            ),
            "/gateway.Gateway/UpdateBatchJob": grpclib.const.Handler(
                self.__rpc_update_batch_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                UpdateBatchJobRequest,
                BatchJob,
            ),
            "/gateway.Gateway/DeleteBatchJob": grpclib.const.Handler(
                self.__rpc_delete_batch_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteBatchJobRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/BatchDeleteBatchJobs": grpclib.const.Handler(
                self.__rpc_batch_delete_batch_jobs,
                grpclib.const.Cardinality.UNARY_UNARY,
                BatchDeleteBatchJobsRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/CancelBatchJob": grpclib.const.Handler(
                self.__rpc_cancel_batch_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                CancelBatchJobRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/CreateCluster": grpclib.const.Handler(
                self.__rpc_create_cluster,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateClusterRequest,
                Cluster,
            ),
            "/gateway.Gateway/GetCluster": grpclib.const.Handler(
                self.__rpc_get_cluster,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetClusterRequest,
                Cluster,
            ),
            "/gateway.Gateway/ListClusters": grpclib.const.Handler(
                self.__rpc_list_clusters,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListClustersRequest,
                ListClustersResponse,
            ),
            "/gateway.Gateway/UpdateCluster": grpclib.const.Handler(
                self.__rpc_update_cluster,
                grpclib.const.Cardinality.UNARY_UNARY,
                UpdateClusterRequest,
                Cluster,
            ),
            "/gateway.Gateway/DeleteCluster": grpclib.const.Handler(
                self.__rpc_delete_cluster,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteClusterRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/GetClusterConnectionInfo": grpclib.const.Handler(
                self.__rpc_get_cluster_connection_info,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetClusterConnectionInfoRequest,
                ClusterConnectionInfo,
            ),
            "/gateway.Gateway/CreateEnvironment": grpclib.const.Handler(
                self.__rpc_create_environment,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateEnvironmentRequest,
                Environment,
            ),
            "/gateway.Gateway/GetEnvironment": grpclib.const.Handler(
                self.__rpc_get_environment,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetEnvironmentRequest,
                Environment,
            ),
            "/gateway.Gateway/ListEnvironments": grpclib.const.Handler(
                self.__rpc_list_environments,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListEnvironmentsRequest,
                ListEnvironmentsResponse,
            ),
            "/gateway.Gateway/UpdateEnvironment": grpclib.const.Handler(
                self.__rpc_update_environment,
                grpclib.const.Cardinality.UNARY_UNARY,
                UpdateEnvironmentRequest,
                Environment,
            ),
            "/gateway.Gateway/DeleteEnvironment": grpclib.const.Handler(
                self.__rpc_delete_environment,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteEnvironmentRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/BatchDeleteEnvironments": grpclib.const.Handler(
                self.__rpc_batch_delete_environments,
                grpclib.const.Cardinality.UNARY_UNARY,
                BatchDeleteEnvironmentsRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/ConnectEnvironment": grpclib.const.Handler(
                self.__rpc_connect_environment,
                grpclib.const.Cardinality.UNARY_UNARY,
                ConnectEnvironmentRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/DisconnectEnvironment": grpclib.const.Handler(
                self.__rpc_disconnect_environment,
                grpclib.const.Cardinality.UNARY_UNARY,
                DisconnectEnvironmentRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/GetFeatureFlag": grpclib.const.Handler(
                self.__rpc_get_feature_flag,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetFeatureFlagRequest,
                FeatureFlag,
            ),
            "/gateway.Gateway/ListFeatureFlags": grpclib.const.Handler(
                self.__rpc_list_feature_flags,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListFeatureFlagsRequest,
                ListFeatureFlagsResponse,
            ),
            "/gateway.Gateway/CreateSnapshot": grpclib.const.Handler(
                self.__rpc_create_snapshot,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateSnapshotRequest,
                Snapshot,
            ),
            "/gateway.Gateway/GetSnapshot": grpclib.const.Handler(
                self.__rpc_get_snapshot,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetSnapshotRequest,
                Snapshot,
            ),
            "/gateway.Gateway/ListSnapshots": grpclib.const.Handler(
                self.__rpc_list_snapshots,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListSnapshotsRequest,
                ListSnapshotsResponse,
            ),
            "/gateway.Gateway/DeleteSnapshot": grpclib.const.Handler(
                self.__rpc_delete_snapshot,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteSnapshotRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/GetBatchJobLogs": grpclib.const.Handler(
                self.__rpc_get_batch_job_logs,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetBatchJobLogsRequest,
                GetBatchJobLogsResponse,
            ),
            "/gateway.Gateway/CreateNodePool": grpclib.const.Handler(
                self.__rpc_create_node_pool,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateNodePoolRequest,
                NodePool,
            ),
            "/gateway.Gateway/GetNodePool": grpclib.const.Handler(
                self.__rpc_get_node_pool,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetNodePoolRequest,
                NodePool,
            ),
            "/gateway.Gateway/ListNodePools": grpclib.const.Handler(
                self.__rpc_list_node_pools,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListNodePoolsRequest,
                ListNodePoolsResponse,
            ),
            "/gateway.Gateway/UpdateNodePool": grpclib.const.Handler(
                self.__rpc_update_node_pool,
                grpclib.const.Cardinality.UNARY_UNARY,
                UpdateNodePoolRequest,
                NodePool,
            ),
            "/gateway.Gateway/DeleteNodePool": grpclib.const.Handler(
                self.__rpc_delete_node_pool,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteNodePoolRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/BatchDeleteNodePools": grpclib.const.Handler(
                self.__rpc_batch_delete_node_pools,
                grpclib.const.Cardinality.UNARY_UNARY,
                BatchDeleteNodePoolsRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/GetNodePoolStats": grpclib.const.Handler(
                self.__rpc_get_node_pool_stats,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetNodePoolStatsRequest,
                NodePoolStats,
            ),
            "/gateway.Gateway/CreateUser": grpclib.const.Handler(
                self.__rpc_create_user,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateUserRequest,
                User,
            ),
            "/gateway.Gateway/GetUser": grpclib.const.Handler(
                self.__rpc_get_user,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetUserRequest,
                User,
            ),
            "/gateway.Gateway/ListUsers": grpclib.const.Handler(
                self.__rpc_list_users,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListUsersRequest,
                ListUsersResponse,
            ),
            "/gateway.Gateway/UpdateUser": grpclib.const.Handler(
                self.__rpc_update_user,
                grpclib.const.Cardinality.UNARY_UNARY,
                UpdateUserRequest,
                User,
            ),
            "/gateway.Gateway/DeleteUser": grpclib.const.Handler(
                self.__rpc_delete_user,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteUserRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/ListAuditLogs": grpclib.const.Handler(
                self.__rpc_list_audit_logs,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListAuditLogsRequest,
                ListAuditLogsResponse,
            ),
            "/gateway.Gateway/CreateApiKey": grpclib.const.Handler(
                self.__rpc_create_api_key,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateApiKeyRequest,
                ApiKey,
            ),
            "/gateway.Gateway/ListApiKeys": grpclib.const.Handler(
                self.__rpc_list_api_keys,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListApiKeysRequest,
                ListApiKeysResponse,
            ),
            "/gateway.Gateway/DeleteApiKey": grpclib.const.Handler(
                self.__rpc_delete_api_key,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteApiKeyRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/GetInternalApiKey": grpclib.const.Handler(
                self.__rpc_get_internal_api_key,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetInternalApiKeyRequest,
                ApiKey,
            ),
            "/gateway.Gateway/CreateModel": grpclib.const.Handler(
                self.__rpc_create_model,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateModelRequest,
                Model,
            ),
            "/gateway.Gateway/GetModel": grpclib.const.Handler(
                self.__rpc_get_model,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetModelRequest,
                Model,
            ),
            "/gateway.Gateway/ListModels": grpclib.const.Handler(
                self.__rpc_list_models,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListModelsRequest,
                ListModelsResponse,
            ),
            "/gateway.Gateway/ListServerlessLoraModels": grpclib.const.Handler(
                self.__rpc_list_serverless_lora_models,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListServerlessLoraModelsRequest,
                ListServerlessLoraModelsResponse,
            ),
            "/gateway.Gateway/UpdateModel": grpclib.const.Handler(
                self.__rpc_update_model,
                grpclib.const.Cardinality.UNARY_UNARY,
                UpdateModelRequest,
                Model,
            ),
            "/gateway.Gateway/DeleteModel": grpclib.const.Handler(
                self.__rpc_delete_model,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteModelRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/GetModelUploadEndpoint": grpclib.const.Handler(
                self.__rpc_get_model_upload_endpoint,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetModelUploadEndpointRequest,
                GetModelUploadEndpointResponse,
            ),
            "/gateway.Gateway/GetModelDownloadEndpoint": grpclib.const.Handler(
                self.__rpc_get_model_download_endpoint,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetModelDownloadEndpointRequest,
                GetModelDownloadEndpointResponse,
            ),
            "/gateway.Gateway/ValidateModelUpload": grpclib.const.Handler(
                self.__rpc_validate_model_upload,
                grpclib.const.Cardinality.UNARY_UNARY,
                ValidateModelUploadRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/ValidateModelConfig": grpclib.const.Handler(
                self.__rpc_validate_model_config,
                grpclib.const.Cardinality.UNARY_UNARY,
                ValidateModelConfigRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/ImportModel": grpclib.const.Handler(
                self.__rpc_import_model,
                grpclib.const.Cardinality.UNARY_UNARY,
                ImportModelRequest,
                _google_longrunning__.Operation,
            ),
            "/gateway.Gateway/CreateDeployment": grpclib.const.Handler(
                self.__rpc_create_deployment,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateDeploymentRequest,
                Deployment,
            ),
            "/gateway.Gateway/GetDeployment": grpclib.const.Handler(
                self.__rpc_get_deployment,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetDeploymentRequest,
                Deployment,
            ),
            "/gateway.Gateway/ListDeployments": grpclib.const.Handler(
                self.__rpc_list_deployments,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListDeploymentsRequest,
                ListDeploymentsResponse,
            ),
            "/gateway.Gateway/UpdateDeployment": grpclib.const.Handler(
                self.__rpc_update_deployment,
                grpclib.const.Cardinality.UNARY_UNARY,
                UpdateDeploymentRequest,
                Deployment,
            ),
            "/gateway.Gateway/DeleteDeployment": grpclib.const.Handler(
                self.__rpc_delete_deployment,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteDeploymentRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/UndeleteDeployment": grpclib.const.Handler(
                self.__rpc_undelete_deployment,
                grpclib.const.Cardinality.UNARY_UNARY,
                UndeleteDeploymentRequest,
                Deployment,
            ),
            "/gateway.Gateway/ScaleDeployment": grpclib.const.Handler(
                self.__rpc_scale_deployment,
                grpclib.const.Cardinality.UNARY_UNARY,
                ScaleDeploymentRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/GetDeploymentMetrics": grpclib.const.Handler(
                self.__rpc_get_deployment_metrics,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetDeploymentMetricsRequest,
                GetDeploymentMetricsResponse,
            ),
            "/gateway.Gateway/ListDeploymentMetrics": grpclib.const.Handler(
                self.__rpc_list_deployment_metrics,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListDeploymentMetricsRequest,
                ListDeploymentMetricsResponse,
            ),
            "/gateway.Gateway/CreateDeploymentTemplate": grpclib.const.Handler(
                self.__rpc_create_deployment_template,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateDeploymentTemplateRequest,
                DeploymentTemplate,
            ),
            "/gateway.Gateway/GetDeploymentTemplate": grpclib.const.Handler(
                self.__rpc_get_deployment_template,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetDeploymentTemplateRequest,
                DeploymentTemplate,
            ),
            "/gateway.Gateway/ListDeploymentTemplates": grpclib.const.Handler(
                self.__rpc_list_deployment_templates,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListDeploymentTemplatesRequest,
                ListDeploymentTemplatesResponse,
            ),
            "/gateway.Gateway/UpdateDeploymentTemplate": grpclib.const.Handler(
                self.__rpc_update_deployment_template,
                grpclib.const.Cardinality.UNARY_UNARY,
                UpdateDeploymentTemplateRequest,
                DeploymentTemplate,
            ),
            "/gateway.Gateway/DeleteDeploymentTemplate": grpclib.const.Handler(
                self.__rpc_delete_deployment_template,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteDeploymentTemplateRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/CreateDeployedModel": grpclib.const.Handler(
                self.__rpc_create_deployed_model,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateDeployedModelRequest,
                DeployedModel,
            ),
            "/gateway.Gateway/GetDeployedModel": grpclib.const.Handler(
                self.__rpc_get_deployed_model,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetDeployedModelRequest,
                DeployedModel,
            ),
            "/gateway.Gateway/ListDeployedModels": grpclib.const.Handler(
                self.__rpc_list_deployed_models,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListDeployedModelsRequest,
                ListDeployedModelsResponse,
            ),
            "/gateway.Gateway/UpdateDeployedModel": grpclib.const.Handler(
                self.__rpc_update_deployed_model,
                grpclib.const.Cardinality.UNARY_UNARY,
                UpdateDeployedModelRequest,
                DeployedModel,
            ),
            "/gateway.Gateway/DeleteDeployedModel": grpclib.const.Handler(
                self.__rpc_delete_deployed_model,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteDeployedModelRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/CreateAwsIamRoleBinding": grpclib.const.Handler(
                self.__rpc_create_aws_iam_role_binding,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateAwsIamRoleBindingRequest,
                AwsIamRoleBinding,
            ),
            "/gateway.Gateway/ListAwsIamRoleBindings": grpclib.const.Handler(
                self.__rpc_list_aws_iam_role_bindings,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListAwsIamRoleBindingsRequest,
                ListAwsIamRoleBindingsResponse,
            ),
            "/gateway.Gateway/DeleteAwsIamRoleBinding": grpclib.const.Handler(
                self.__rpc_delete_aws_iam_role_binding,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteAwsIamRoleBindingRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/CreateNodePoolBinding": grpclib.const.Handler(
                self.__rpc_create_node_pool_binding,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateNodePoolBindingRequest,
                NodePoolBinding,
            ),
            "/gateway.Gateway/ListNodePoolBindings": grpclib.const.Handler(
                self.__rpc_list_node_pool_bindings,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListNodePoolBindingsRequest,
                ListNodePoolBindingsResponse,
            ),
            "/gateway.Gateway/DeleteNodePoolBinding": grpclib.const.Handler(
                self.__rpc_delete_node_pool_binding,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteNodePoolBindingRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/CreateDataset": grpclib.const.Handler(
                self.__rpc_create_dataset,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateDatasetRequest,
                Dataset,
            ),
            "/gateway.Gateway/GetDataset": grpclib.const.Handler(
                self.__rpc_get_dataset,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetDatasetRequest,
                Dataset,
            ),
            "/gateway.Gateway/ListDatasets": grpclib.const.Handler(
                self.__rpc_list_datasets,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListDatasetsRequest,
                ListDatasetsResponse,
            ),
            "/gateway.Gateway/UpdateDataset": grpclib.const.Handler(
                self.__rpc_update_dataset,
                grpclib.const.Cardinality.UNARY_UNARY,
                UpdateDatasetRequest,
                Dataset,
            ),
            "/gateway.Gateway/DeleteDataset": grpclib.const.Handler(
                self.__rpc_delete_dataset,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteDatasetRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/UploadDataset": grpclib.const.Handler(
                self.__rpc_upload_dataset,
                grpclib.const.Cardinality.UNARY_UNARY,
                UploadDatasetRequest,
                UploadDatasetResponse,
            ),
            "/gateway.Gateway/GetDatasetUploadEndpoint": grpclib.const.Handler(
                self.__rpc_get_dataset_upload_endpoint,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetDatasetUploadEndpointRequest,
                GetDatasetUploadEndpointResponse,
            ),
            "/gateway.Gateway/ValidateDatasetUpload": grpclib.const.Handler(
                self.__rpc_validate_dataset_upload,
                grpclib.const.Cardinality.UNARY_UNARY,
                ValidateDatasetUploadRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/GetDatasetDownloadEndpoint": grpclib.const.Handler(
                self.__rpc_get_dataset_download_endpoint,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetDatasetDownloadEndpointRequest,
                GetDatasetDownloadEndpointResponse,
            ),
            "/gateway.Gateway/PreviewDataset": grpclib.const.Handler(
                self.__rpc_preview_dataset,
                grpclib.const.Cardinality.UNARY_UNARY,
                PreviewDatasetRequest,
                PreviewDatasetResponse,
            ),
            "/gateway.Gateway/CreateEvaluator": grpclib.const.Handler(
                self.__rpc_create_evaluator,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateEvaluatorRequest,
                Evaluator,
            ),
            "/gateway.Gateway/GetEvaluator": grpclib.const.Handler(
                self.__rpc_get_evaluator,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetEvaluatorRequest,
                Evaluator,
            ),
            "/gateway.Gateway/ListEvaluators": grpclib.const.Handler(
                self.__rpc_list_evaluators,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListEvaluatorsRequest,
                ListEvaluatorsResponse,
            ),
            "/gateway.Gateway/DeleteEvaluator": grpclib.const.Handler(
                self.__rpc_delete_evaluator,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteEvaluatorRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/CreateEvaluation": grpclib.const.Handler(
                self.__rpc_create_evaluation,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateEvaluationRequest,
                Evaluation,
            ),
            "/gateway.Gateway/GetEvaluation": grpclib.const.Handler(
                self.__rpc_get_evaluation,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetEvaluationRequest,
                Evaluation,
            ),
            "/gateway.Gateway/ListEvaluations": grpclib.const.Handler(
                self.__rpc_list_evaluations,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListEvaluationsRequest,
                ListEvaluationsResponse,
            ),
            "/gateway.Gateway/DeleteEvaluation": grpclib.const.Handler(
                self.__rpc_delete_evaluation,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteEvaluationRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/CreateEvaluationJob": grpclib.const.Handler(
                self.__rpc_create_evaluation_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateEvaluationJobRequest,
                EvaluationJob,
            ),
            "/gateway.Gateway/GetEvaluationJob": grpclib.const.Handler(
                self.__rpc_get_evaluation_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetEvaluationJobRequest,
                EvaluationJob,
            ),
            "/gateway.Gateway/ListEvaluationJobs": grpclib.const.Handler(
                self.__rpc_list_evaluation_jobs,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListEvaluationJobsRequest,
                ListEvaluationJobsResponse,
            ),
            "/gateway.Gateway/DeleteEvaluationJob": grpclib.const.Handler(
                self.__rpc_delete_evaluation_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteEvaluationJobRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/CreateFineTuningJob": grpclib.const.Handler(
                self.__rpc_create_fine_tuning_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateFineTuningJobRequest,
                FineTuningJob,
            ),
            "/gateway.Gateway/GetFineTuningJob": grpclib.const.Handler(
                self.__rpc_get_fine_tuning_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetFineTuningJobRequest,
                FineTuningJob,
            ),
            "/gateway.Gateway/ListFineTuningJobs": grpclib.const.Handler(
                self.__rpc_list_fine_tuning_jobs,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListFineTuningJobsRequest,
                ListFineTuningJobsResponse,
            ),
            "/gateway.Gateway/UpdateFineTuningJob": grpclib.const.Handler(
                self.__rpc_update_fine_tuning_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                UpdateFineTuningJobRequest,
                FineTuningJob,
            ),
            "/gateway.Gateway/DeleteFineTuningJob": grpclib.const.Handler(
                self.__rpc_delete_fine_tuning_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteFineTuningJobRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/CreateSupervisedFineTuningJob": grpclib.const.Handler(
                self.__rpc_create_supervised_fine_tuning_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateSupervisedFineTuningJobRequest,
                SupervisedFineTuningJob,
            ),
            "/gateway.Gateway/GetSupervisedFineTuningJob": grpclib.const.Handler(
                self.__rpc_get_supervised_fine_tuning_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetSupervisedFineTuningJobRequest,
                SupervisedFineTuningJob,
            ),
            "/gateway.Gateway/ListSupervisedFineTuningJobs": grpclib.const.Handler(
                self.__rpc_list_supervised_fine_tuning_jobs,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListSupervisedFineTuningJobsRequest,
                ListSupervisedFineTuningJobsResponse,
            ),
            "/gateway.Gateway/DeleteSupervisedFineTuningJob": grpclib.const.Handler(
                self.__rpc_delete_supervised_fine_tuning_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteSupervisedFineTuningJobRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/CreateReinforcementFineTuningJob": grpclib.const.Handler(
                self.__rpc_create_reinforcement_fine_tuning_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateReinforcementFineTuningJobRequest,
                ReinforcementFineTuningJob,
            ),
            "/gateway.Gateway/GetReinforcementFineTuningJob": grpclib.const.Handler(
                self.__rpc_get_reinforcement_fine_tuning_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetReinforcementFineTuningJobRequest,
                ReinforcementFineTuningJob,
            ),
            "/gateway.Gateway/ListReinforcementFineTuningJobs": grpclib.const.Handler(
                self.__rpc_list_reinforcement_fine_tuning_jobs,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListReinforcementFineTuningJobsRequest,
                ListReinforcementFineTuningJobsResponse,
            ),
            "/gateway.Gateway/DeleteReinforcementFineTuningJob": grpclib.const.Handler(
                self.__rpc_delete_reinforcement_fine_tuning_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteReinforcementFineTuningJobRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/ResumeReinforcementFineTuningJob": grpclib.const.Handler(
                self.__rpc_resume_reinforcement_fine_tuning_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                ResumeReinforcementFineTuningJobRequest,
                ReinforcementFineTuningJob,
            ),
            "/gateway.Gateway/DebugReinforcementFineTuningJob": grpclib.const.Handler(
                self.__rpc_debug_reinforcement_fine_tuning_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                DebugReinforcementFineTuningJobRequest,
                DebugReinforcementFineTuningJobResponse,
            ),
            "/gateway.Gateway/CreateReinforcementFineTuningEpoch": grpclib.const.Handler(
                self.__rpc_create_reinforcement_fine_tuning_epoch,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateReinforcementFineTuningEpochRequest,
                ReinforcementFineTuningEpoch,
            ),
            "/gateway.Gateway/GetReinforcementFineTuningEpoch": grpclib.const.Handler(
                self.__rpc_get_reinforcement_fine_tuning_epoch,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetReinforcementFineTuningEpochRequest,
                ReinforcementFineTuningEpoch,
            ),
            "/gateway.Gateway/ListReinforcementFineTuningEpochs": grpclib.const.Handler(
                self.__rpc_list_reinforcement_fine_tuning_epochs,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListReinforcementFineTuningEpochsRequest,
                ListReinforcementFineTuningEpochsResponse,
            ),
            "/gateway.Gateway/DeleteReinforcementFineTuningEpoch": grpclib.const.Handler(
                self.__rpc_delete_reinforcement_fine_tuning_epoch,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteReinforcementFineTuningEpochRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/CreateRlorTrainerJob": grpclib.const.Handler(
                self.__rpc_create_rlor_trainer_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateRlorTrainerJobRequest,
                RlorTrainerJob,
            ),
            "/gateway.Gateway/GetRlorTrainerJob": grpclib.const.Handler(
                self.__rpc_get_rlor_trainer_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetRlorTrainerJobRequest,
                RlorTrainerJob,
            ),
            "/gateway.Gateway/ListRlorTrainerJobs": grpclib.const.Handler(
                self.__rpc_list_rlor_trainer_jobs,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListRlorTrainerJobsRequest,
                ListRlorTrainerJobsResponse,
            ),
            "/gateway.Gateway/DeleteRlorTrainerJob": grpclib.const.Handler(
                self.__rpc_delete_rlor_trainer_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteRlorTrainerJobRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/CreatePeftMergeJob": grpclib.const.Handler(
                self.__rpc_create_peft_merge_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreatePeftMergeJobRequest,
                PeftMergeJob,
            ),
            "/gateway.Gateway/GetPeftMergeJob": grpclib.const.Handler(
                self.__rpc_get_peft_merge_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetPeftMergeJobRequest,
                PeftMergeJob,
            ),
            "/gateway.Gateway/ListPeftMergeJobs": grpclib.const.Handler(
                self.__rpc_list_peft_merge_jobs,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListPeftMergeJobsRequest,
                ListPeftMergeJobsResponse,
            ),
            "/gateway.Gateway/DeletePeftMergeJob": grpclib.const.Handler(
                self.__rpc_delete_peft_merge_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeletePeftMergeJobRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/GetQuota": grpclib.const.Handler(
                self.__rpc_get_quota,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetQuotaRequest,
                Quota,
            ),
            "/gateway.Gateway/UpdateQuota": grpclib.const.Handler(
                self.__rpc_update_quota,
                grpclib.const.Cardinality.UNARY_UNARY,
                UpdateQuotaRequest,
                Quota,
            ),
            "/gateway.Gateway/ListQuotas": grpclib.const.Handler(
                self.__rpc_list_quotas,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListQuotasRequest,
                ListQuotasResponse,
            ),
            "/gateway.Gateway/CreateSecret": grpclib.const.Handler(
                self.__rpc_create_secret,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateSecretRequest,
                Secret,
            ),
            "/gateway.Gateway/GetSecret": grpclib.const.Handler(
                self.__rpc_get_secret,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetSecretRequest,
                Secret,
            ),
            "/gateway.Gateway/ListSecrets": grpclib.const.Handler(
                self.__rpc_list_secrets,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListSecretsRequest,
                ListSecretsResponse,
            ),
            "/gateway.Gateway/UpdateSecret": grpclib.const.Handler(
                self.__rpc_update_secret,
                grpclib.const.Cardinality.UNARY_UNARY,
                UpdateSecretRequest,
                Secret,
            ),
            "/gateway.Gateway/DeleteSecret": grpclib.const.Handler(
                self.__rpc_delete_secret,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteSecretRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/GetReservation": grpclib.const.Handler(
                self.__rpc_get_reservation,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetReservationRequest,
                Reservation,
            ),
            "/gateway.Gateway/ListReservations": grpclib.const.Handler(
                self.__rpc_list_reservations,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListReservationsRequest,
                ListReservationsResponse,
            ),
            "/gateway.Gateway/PrepareModel": grpclib.const.Handler(
                self.__rpc_prepare_model,
                grpclib.const.Cardinality.UNARY_UNARY,
                PrepareModelRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/CreateBatchInferenceJob": grpclib.const.Handler(
                self.__rpc_create_batch_inference_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateBatchInferenceJobRequest,
                BatchInferenceJob,
            ),
            "/gateway.Gateway/GetBatchInferenceJob": grpclib.const.Handler(
                self.__rpc_get_batch_inference_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetBatchInferenceJobRequest,
                BatchInferenceJob,
            ),
            "/gateway.Gateway/ListBatchInferenceJobs": grpclib.const.Handler(
                self.__rpc_list_batch_inference_jobs,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListBatchInferenceJobsRequest,
                ListBatchInferenceJobsResponse,
            ),
            "/gateway.Gateway/UpdateBatchInferenceJob": grpclib.const.Handler(
                self.__rpc_update_batch_inference_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                UpdateBatchInferenceJobRequest,
                BatchInferenceJob,
            ),
            "/gateway.Gateway/DeleteBatchInferenceJob": grpclib.const.Handler(
                self.__rpc_delete_batch_inference_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteBatchInferenceJobRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/CreateEagleTrainingJob": grpclib.const.Handler(
                self.__rpc_create_eagle_training_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateEagleTrainingJobRequest,
                EagleTrainingJob,
            ),
            "/gateway.Gateway/GetEagleTrainingJob": grpclib.const.Handler(
                self.__rpc_get_eagle_training_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetEagleTrainingJobRequest,
                EagleTrainingJob,
            ),
            "/gateway.Gateway/ListEagleTrainingJobs": grpclib.const.Handler(
                self.__rpc_list_eagle_training_jobs,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListEagleTrainingJobsRequest,
                ListEagleTrainingJobsResponse,
            ),
            "/gateway.Gateway/DeleteEagleTrainingJob": grpclib.const.Handler(
                self.__rpc_delete_eagle_training_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteEagleTrainingJobRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/GetBatchInferenceJobInputUploadEndpoint": grpclib.const.Handler(
                self.__rpc_get_batch_inference_job_input_upload_endpoint,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetBatchInferenceJobInputUploadEndpointRequest,
                GetBatchInferenceJobInputUploadEndpointResponse,
            ),
            "/gateway.Gateway/GetBatchInferenceJobOutputDownloadEndpoint": grpclib.const.Handler(
                self.__rpc_get_batch_inference_job_output_download_endpoint,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetBatchInferenceJobOutputDownloadEndpointRequest,
                GetBatchInferenceJobOutputDownloadEndpointResponse,
            ),
            "/gateway.Gateway/ValidateBatchInferenceJobInputUpload": grpclib.const.Handler(
                self.__rpc_validate_batch_inference_job_input_upload,
                grpclib.const.Cardinality.UNARY_UNARY,
                ValidateBatchInferenceJobInputUploadRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/CreateDatasetValidationJob": grpclib.const.Handler(
                self.__rpc_create_dataset_validation_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateDatasetValidationJobRequest,
                DatasetValidationJob,
            ),
            "/gateway.Gateway/GetDatasetValidationJob": grpclib.const.Handler(
                self.__rpc_get_dataset_validation_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetDatasetValidationJobRequest,
                DatasetValidationJob,
            ),
            "/gateway.Gateway/ListDatasetValidationJobs": grpclib.const.Handler(
                self.__rpc_list_dataset_validation_jobs,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListDatasetValidationJobsRequest,
                ListDatasetValidationJobsResponse,
            ),
            "/gateway.Gateway/DeleteDatasetValidationJob": grpclib.const.Handler(
                self.__rpc_delete_dataset_validation_job,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteDatasetValidationJobRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/SplitDataset": grpclib.const.Handler(
                self.__rpc_split_dataset,
                grpclib.const.Cardinality.UNARY_UNARY,
                SplitDatasetRequest,
                SplitDatasetResponse,
            ),
            "/gateway.Gateway/ValidateAssertions": grpclib.const.Handler(
                self.__rpc_validate_assertions,
                grpclib.const.Cardinality.UNARY_UNARY,
                ValidateAssertionsRequest,
                ValidateAssertionsResponse,
            ),
            "/gateway.Gateway/PreviewEvaluator": grpclib.const.Handler(
                self.__rpc_preview_evaluator,
                grpclib.const.Cardinality.UNARY_UNARY,
                PreviewEvaluatorRequest,
                PreviewEvaluatorResponse,
            ),
            "/gateway.Gateway/PreviewEvaluation": grpclib.const.Handler(
                self.__rpc_preview_evaluation,
                grpclib.const.Cardinality.UNARY_UNARY,
                PreviewEvaluationRequest,
                PreviewEvaluationResponse,
            ),
            "/gateway.Gateway/TestEvaluation": grpclib.const.Handler(
                self.__rpc_test_evaluation,
                grpclib.const.Cardinality.UNARY_UNARY,
                TestEvaluationRequest,
                PreviewEvaluationResponse,
            ),
            "/gateway.Gateway/GetInferenceLog": grpclib.const.Handler(
                self.__rpc_get_inference_log,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetInferenceLogRequest,
                InferenceLog,
            ),
            "/gateway.Gateway/ListInferenceLogs": grpclib.const.Handler(
                self.__rpc_list_inference_logs,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListInferenceLogsRequest,
                ListInferenceLogsResponse,
            ),
            "/gateway.Gateway/DeleteInferenceLog": grpclib.const.Handler(
                self.__rpc_delete_inference_log,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteInferenceLogRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/GetDeploymentPrerequisites": grpclib.const.Handler(
                self.__rpc_get_deployment_prerequisites,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetDeploymentPrerequisitesRequest,
                DeploymentPrerequisites,
            ),
            "/gateway.Gateway/CreateWorkloadShape": grpclib.const.Handler(
                self.__rpc_create_workload_shape,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateWorkloadShapeRequest,
                WorkloadShape,
            ),
            "/gateway.Gateway/GetWorkloadShape": grpclib.const.Handler(
                self.__rpc_get_workload_shape,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetWorkloadShapeRequest,
                WorkloadShape,
            ),
            "/gateway.Gateway/ListWorkloadShapes": grpclib.const.Handler(
                self.__rpc_list_workload_shapes,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListWorkloadShapesRequest,
                ListWorkloadShapesResponse,
            ),
            "/gateway.Gateway/UpdateWorkloadShape": grpclib.const.Handler(
                self.__rpc_update_workload_shape,
                grpclib.const.Cardinality.UNARY_UNARY,
                UpdateWorkloadShapeRequest,
                WorkloadShape,
            ),
            "/gateway.Gateway/DeleteWorkloadShape": grpclib.const.Handler(
                self.__rpc_delete_workload_shape,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteWorkloadShapeRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/CreateWorkload": grpclib.const.Handler(
                self.__rpc_create_workload,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateWorkloadRequest,
                Workload,
            ),
            "/gateway.Gateway/GetWorkload": grpclib.const.Handler(
                self.__rpc_get_workload,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetWorkloadRequest,
                Workload,
            ),
            "/gateway.Gateway/ListWorkloads": grpclib.const.Handler(
                self.__rpc_list_workloads,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListWorkloadsRequest,
                ListWorkloadsResponse,
            ),
            "/gateway.Gateway/UpdateWorkload": grpclib.const.Handler(
                self.__rpc_update_workload,
                grpclib.const.Cardinality.UNARY_UNARY,
                UpdateWorkloadRequest,
                Workload,
            ),
            "/gateway.Gateway/DeleteWorkload": grpclib.const.Handler(
                self.__rpc_delete_workload,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteWorkloadRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/CreateIdentityProvider": grpclib.const.Handler(
                self.__rpc_create_identity_provider,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateIdentityProviderRequest,
                IdentityProvider,
            ),
            "/gateway.Gateway/GetIdentityProvider": grpclib.const.Handler(
                self.__rpc_get_identity_provider,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetIdentityProviderRequest,
                IdentityProvider,
            ),
            "/gateway.Gateway/ListIdentityProviders": grpclib.const.Handler(
                self.__rpc_list_identity_providers,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListIdentityProvidersRequest,
                ListIdentityProvidersResponse,
            ),
            "/gateway.Gateway/UpdateIdentityProvider": grpclib.const.Handler(
                self.__rpc_update_identity_provider,
                grpclib.const.Cardinality.UNARY_UNARY,
                UpdateIdentityProviderRequest,
                IdentityProvider,
            ),
            "/gateway.Gateway/DeleteIdentityProvider": grpclib.const.Handler(
                self.__rpc_delete_identity_provider,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteIdentityProviderRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
            "/gateway.Gateway/CreateMcpServer": grpclib.const.Handler(
                self.__rpc_create_mcp_server,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateMcpServerRequest,
                McpServer,
            ),
            "/gateway.Gateway/GetMcpServer": grpclib.const.Handler(
                self.__rpc_get_mcp_server,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetMcpServerRequest,
                McpServer,
            ),
            "/gateway.Gateway/ListMcpServers": grpclib.const.Handler(
                self.__rpc_list_mcp_servers,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListMcpServersRequest,
                ListMcpServersResponse,
            ),
            "/gateway.Gateway/UpdateMcpServer": grpclib.const.Handler(
                self.__rpc_update_mcp_server,
                grpclib.const.Cardinality.UNARY_UNARY,
                UpdateMcpServerRequest,
                McpServer,
            ),
            "/gateway.Gateway/DeleteMcpServer": grpclib.const.Handler(
                self.__rpc_delete_mcp_server,
                grpclib.const.Cardinality.UNARY_UNARY,
                DeleteMcpServerRequest,
                betterproto_lib_google_protobuf.Empty,
            ),
        }
