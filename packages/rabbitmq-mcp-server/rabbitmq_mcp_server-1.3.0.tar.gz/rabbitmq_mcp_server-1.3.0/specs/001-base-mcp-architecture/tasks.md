# Implementation Tasks: Base MCP Architecture

**Feature**: Base MCP Architecture  
**Date**: 2025-10-09  
**Status**: Ready for Implementation  
**Branch**: `feature/001-base-architecture`

## Overview

Este documento organiza as tarefas de implementa√ß√£o baseadas nas User Stories do [spec.md](./spec.md). As tarefas est√£o agrupadas por fase, com cada User Story formando uma entrega independente e test√°vel.

**Total Tasks**: 73 tarefas (56 originais + 17 novas: T004a, T008a, T019.1, T035.1, T050a, T057-T068)  
**Parallelizable**: 32 tarefas marcadas com [P] (21 originais + 11 novas)  
**Estimated Duration**: 7-9 semanas (console client + multilingual inclu√≠dos conforme constitution)

**Novas Tasks Adicionadas**:
- **An√°lise /speckit.analyze**: T004a, T008a, T019.1, T035.1, T050a (gaps de valida√ß√£o)
- **Constitution Compliance (CC3/CC4)**: T057-T068 (console client + multilingual - ADR-002)

**Breakdown**:
- T004a: Testes de valida√ß√£o de logging JSON e sanitiza√ß√£o - 19 patterns (CC5)
- T008a: Gera√ß√£o de schemas para m√∫ltiplas vers√µes de OpenAPI com fallback (U4)
- T019.1: Teste espec√≠fico de threshold 0.7 com exemplos reais (C1, A2)
- T035.1: Teste de timeout + pagination para listagens >1000 items ou >50MB (C2, A1)
- T050a: Teste de integra√ß√£o OpenTelemetry end-to-end com m√©trica 95% (C3)
- T057-T068: Console client + i18n 20 idiomas (constitution ¬ßVIII mandatory - ADR-002)

## Task Organization

- **Phase 1**: Setup (T001-T006) - Configura√ß√£o inicial do projeto
- **Phase 2**: Foundational (T007-T013f) - Pr√©-requisitos bloqueantes + AMQP
- **Phase 3**: User Story 1 - Descobrir Opera√ß√µes (T014-T021) - üîç Busca sem√¢ntica
- **Phase 4**: User Story 2 - Obter Detalhes (T022-T026) - üìã Documenta√ß√£o de opera√ß√µes
- **Phase 5**: User Story 3 - Executar Opera√ß√µes (T027-T042) - ‚ö° Execu√ß√£o validada
- **Phase 6**: User Story 4 - Feedback de Erros (T043-T047) - üõ°Ô∏è Error handling
- **Phase 6.5**: Console Client & i18n (T057-T068) - üñ•Ô∏è CLI + 20 idiomas (constitution ¬ßVIII)
- **Phase 7**: Polish & Integration (T048-T056) - Finaliza√ß√£o e testes adicionais

---

## Phase 1: Setup & Project Initialization

**Goal**: Configurar estrutura de projeto, depend√™ncias e CI/CD b√°sico  
**Duration**: 1-2 dias  
**Prerequisites**: Nenhum

### T001: Inicializar estrutura de projeto Python

**User Story**: Setup  
**File**: `pyproject.toml`, `README.md`, `.gitignore`  
**Description**: Criar estrutura base do projeto com Poetry, Python 3.12+, configura√ß√µes iniciais
**Status**: [X] Completed

**Steps**:
1. Criar `pyproject.toml` com metadados do projeto
2. Configurar Poetry com Python 3.12+
3. Adicionar depend√™ncias principais: mcp, pydantic, jsonschema, pyyaml, httpx
4. Criar `README.md` b√°sico com instru√ß√µes de instala√ß√£o
5. Configurar `.gitignore` para Python

**Acceptance Criteria**:
- ‚úÖ Poetry instalado e configurado
- ‚úÖ `poetry install` executa sem erros
- ‚úÖ Python 3.12+ configurado como vers√£o m√≠nima
- ‚úÖ README cont√©m instru√ß√µes claras de setup

**Parallel**: ‚ùå (bloqueia outras tasks de setup)

---

### T002: Configurar depend√™ncias de desenvolvimento

**User Story**: Setup  
**File**: `pyproject.toml`  
**Description**: Adicionar ferramentas de desenvolvimento, testing e code quality
**Status**: [X] Completed

**Steps**:
1. Adicionar pytest, pytest-asyncio, pytest-cov, pytest-mock
2. Adicionar testcontainers para integra√ß√£o com RabbitMQ
3. Adicionar datamodel-code-generator para gera√ß√£o de schemas
4. Adicionar black, ruff, mypy para code quality
5. Configurar scripts Poetry para comandos comuns

**Acceptance Criteria**:
- ‚úÖ Todas as deps de dev instaladas
- ‚úÖ `poetry run pytest` executa (mesmo sem testes ainda)
- ‚úÖ `poetry run black .` executa
- ‚úÖ `poetry run mypy .` executa

**Parallel**: ‚ùå (depende de T001)

---

### T003: Criar estrutura de diret√≥rios

**User Story**: Setup  
**File**: Estrutura de pastas  
**Description**: Criar estrutura de diret√≥rios conforme plan.md
**Status**: [X] Completed

**Steps**:
1. Criar `src/mcp_server/` com `__init__.py`
2. Criar subpastas: `tools/`, `openapi/`, `operations/`, `vector_db/`, `schemas/`, `utils/`
3. Criar `scripts/` para gera√ß√£o de artefatos
4. Criar `tests/` com subpastas: `contract/`, `integration/`, `unit/`
5. Criar `data/` para SQLite databases
6. Criar `config/` para arquivos de configura√ß√£o
7. Criar `logs/` para logs estruturados

**Acceptance Criteria**:
- ‚úÖ Estrutura de diret√≥rios criada conforme plan.md
- ‚úÖ Cada diret√≥rio Python tem `__init__.py`
- ‚úÖ Estrutura de testes reflete estrutura de c√≥digo

**Parallel**: ‚úÖ [P] (pode rodar em paralelo com T002)

---

### T004: Configurar logging estruturado

**User Story**: Setup  
**File**: `src/mcp_server/utils/logging.py`, `config/config.yaml`  
**Description**: Implementar logging estruturado com structlog e JSON output

**Steps**:
1. Criar `utils/logging.py` com configura√ß√£o structlog
2. Configurar JSON renderer para production
3. Configurar n√≠veis de log (DEBUG, INFO, WARNING, ERROR, CRITICAL)
4. Adicionar reda√ß√£o autom√°tica de credenciais (formato: "***") para patterns: `password`, `passwd`, `pwd`, `token`, `secret`, `api_key`, `apikey`, `auth`, `authorization`, `credentials`, `private_key`, `access_token`, `refresh_token`, `bearer`, `jwt`, `session_id`, `cookie`, `client_secret` (19 patterns total, case-insensitive matching)
5. Configurar rota√ß√£o de logs: daily rotation, max 100MB/file, retention (30 days info/debug, 90 days error/warn, 1 year audit), gzip compression, automatic cleanup
6. Adicionar suporte a vari√°vel de ambiente `LOG_LEVEL`

**Acceptance Criteria**:
- ‚úÖ Logs em formato JSON
- ‚úÖ N√≠veis de log configur√°veis via env var
- ‚úÖ Credenciais redatadas automaticamente (todos os patterns listados acima)
- ‚úÖ Logs escritos em `logs/rabbitmq-mcp-{date}.log`

**Parallel**: ‚úÖ [P] (independente de outras tasks de setup)

---

### T004a: Escrever testes de valida√ß√£o de logging

**User Story**: Setup  
**File**: `tests/unit/test_logging.py`  
**Description**: Validar formato JSON de logs e sanitiza√ß√£o de credenciais

**Steps**:
1. Criar teste que valida logs s√£o JSON v√°lidos
2. Testar que credenciais s√£o redatadas para todos os 19 patterns: password, passwd, pwd, token, secret, api_key, apikey, auth, authorization, credentials, private_key, access_token, refresh_token, bearer, jwt, session_id, cookie, client_secret (case-insensitive)
3. Testar que n√≠veis de log (DEBUG, INFO, WARNING, ERROR, CRITICAL) funcionam
4. Testar que campos obrigat√≥rios est√£o presentes (timestamp, level, message)
5. Testar que logs de erro incluem contexto suficiente
6. Validar que dados sens√≠veis n√£o aparecem em logs (case-insensitive pattern matching)
7. Testar log rotation policies (daily, 100MB max, retention periods)

**Acceptance Criteria**:
- ‚úÖ Logs em formato JSON validados
- ‚úÖ Credenciais redatadas corretamente para todos os patterns listados (ex: password: "***", token: "***", api_key: "***")
- ‚úÖ Todos os n√≠veis de log funcionam
- ‚úÖ Campos obrigat√≥rios presentes

**Parallel**: ‚úÖ [P] (pode rodar em paralelo com T005)

---

### T005: Configurar OpenTelemetry instrumenta√ß√£o

**User Story**: Setup  
**File**: `src/mcp_server/utils/telemetry.py`, `config/config.yaml`  
**Description**: Implementar instrumenta√ß√£o completa com traces, metrics e logs correlacionados

**Steps**:
1. Criar `utils/telemetry.py` com setup OpenTelemetry
2. Configurar OTLP exporter
3. Adicionar auto-instrumentation para HTTP e database
4. Configurar m√©tricas: lat√™ncia, error rate, cache hits/misses
5. Correlacionar logs com trace IDs
6. Adicionar configura√ß√£o para endpoint do exporter

**Acceptance Criteria**:
- ‚úÖ OpenTelemetry SDK configurado
- ‚úÖ Traces gerados para opera√ß√µes
- ‚úÖ M√©tricas expostas via OTLP
- ‚úÖ Logs correlacionados com trace IDs

**Parallel**: ‚úÖ [P] (independente de outras tasks de setup)

---

### T006: Configurar gerenciamento de configura√ß√£o

**User Story**: Setup  
**File**: `config/config.yaml`, `src/mcp_server/config.py`  
**Description**: Implementar configura√ß√£o via YAML + env vars com pydantic-settings

**Steps**:
1. Criar `config/config.yaml` com estrutura de configura√ß√£o
2. Criar `src/mcp_server/config.py` com Pydantic models
3. Implementar substitui√ß√£o de env vars em YAML (${VAR})
4. Validar configura√ß√µes obrigat√≥rias no startup
5. Documentar vari√°veis de ambiente em README

**Acceptance Criteria**:
- ‚úÖ Configura√ß√£o carregada de YAML + env vars
- ‚úÖ Valida√ß√£o com Pydantic models
- ‚úÖ Env vars substitu√≠das corretamente
- ‚úÖ Erros claros para configs inv√°lidas

**Parallel**: ‚úÖ [P] (independente de outras tasks de setup)

---

## Phase 2: Foundational - Prerequisites for All User Stories

**Goal**: Implementar componentes fundamentais que TODAS as user stories dependem  
**Duration**: 2-3 dias  
**Prerequisites**: Phase 1 completa

‚ö†Ô∏è **CHECKPOINT**: Nenhuma User Story pode come√ßar antes desta fase estar completa.

### T007: Implementar parser de OpenAPI

**User Story**: Foundational  
**File**: `src/mcp_server/openapi/parser.py`  
**Description**: Parser para especifica√ß√£o OpenAPI do RabbitMQ HTTP API

**Steps**:
1. Criar `openapi/parser.py` com fun√ß√£o de parsing YAML
2. Extrair opera√ß√µes com IDs, paths, m√©todos HTTP
3. Extrair schemas de request e response
4. Extrair tags (namespaces) e descriptions
5. Validar estrutura do OpenAPI spec
6. Implementar cache de parsing

**Acceptance Criteria**:
- ‚úÖ Parser carrega `.specify/memory/rabbitmq-http-api-openapi.yaml`
- ‚úÖ Extrai opera√ß√µes, schemas, tags corretamente
- ‚úÖ Valida estrutura do OpenAPI
- ‚úÖ Parsing em <100ms

**Parallel**: ‚ùå (bloqueia gera√ß√£o de schemas e operations)

---

### T008: Implementar gera√ß√£o de registry de opera√ß√µes

**User Story**: Foundational  
**File**: `scripts/generate_operations.py`, `src/mcp_server/openapi/operation_registry.py`  
**Description**: Gerar e popular SQLite database com registro de opera√ß√µes

**Steps**:
1. Criar schema SQLite conforme data-model.md
2. Criar script `generate_operations.py`
3. Extrair opera√ß√µes do OpenAPI via parser
4. Popular tabelas: `namespaces`, `operations`, `metadata`
5. Gerar IDs no formato `{namespace}.{name}`
6. Adicionar √≠ndices para performance
7. Implementar `operation_registry.py` para queries

**Acceptance Criteria**:
- ‚úÖ SQLite database criado em `data/rabbitmq_operations.db`
- ‚úÖ ~150-300 opera√ß√µes registradas
- ‚úÖ Namespaces populados corretamente
- ‚úÖ Registry queryable via API Python

**Parallel**: ‚ùå (depende de T007, bloqueia embeddings e tools)

---

### T008a: Gerar schemas para m√∫ltiplas vers√µes de OpenAPI

**User Story**: Foundational  
**File**: `scripts/generate_operations.py` (atualiza√ß√£o), `data/rabbitmq_operations_*.db`  
**Description**: Suportar m√∫ltiplas vers√µes de OpenAPI (3.11, 3.12, 3.13) geradas em build time

**Steps**:
1. Atualizar script para aceitar vers√£o como par√¢metro
2. Gerar registries separados: `rabbitmq_operations_3.11.db`, `rabbitmq_operations_3.12.db`, `rabbitmq_operations_3.13.db`
3. Cada registry cont√©m opera√ß√µes espec√≠ficas da vers√£o
4. Runtime carrega apenas vers√£o especificada via RABBITMQ_API_VERSION
5. Adicionar valida√ß√£o de vers√£o suportada com fallback claro: erro "Unsupported version: X.Y" + listar vers√µes dispon√≠veis "Supported: 3.11, 3.12, 3.13" + sugerir "Set RABBITMQ_API_VERSION to one of the supported versions"
6. Documentar vers√µes dispon√≠veis em README

**Acceptance Criteria**:
- ‚úÖ M√∫ltiplos registries gerados (um por vers√£o)
- ‚úÖ Runtime carrega vers√£o correta baseado em env var
- ‚úÖ Erro claro para vers√µes n√£o suportadas
- ‚úÖ Documenta√ß√£o de vers√µes completa

**Parallel**: ‚úÖ [P] (pode rodar ap√≥s T008 inicial)

---

### T009: Implementar gera√ß√£o de schemas Pydantic

**User Story**: Foundational  
**File**: `scripts/generate_schemas.py`, `src/mcp_server/schemas/`  
**Description**: Gerar modelos Pydantic a partir de OpenAPI schemas

**Steps**:
1. Criar script `generate_schemas.py` usando datamodel-code-generator
2. Processar OpenAPI components/schemas
3. Gerar arquivos Python em `schemas/` (auto-generated)
4. Adicionar header "DO NOT EDIT" em arquivos gerados
5. Criar `schemas/__init__.py` com exports
6. Validar que modelos s√£o type-safe

**Acceptance Criteria**:
- ‚úÖ Schemas gerados em `src/mcp_server/schemas/`
- ‚úÖ Modelos Pydantic type-safe e valid√°veis
- ‚úÖ Generation script execut√°vel
- ‚úÖ Schemas commitados no repo

**Parallel**: ‚úÖ [P] (depende de T007 mas paralelo com T008)

---

### T010: Implementar valida√ß√£o de schemas

**User Story**: Foundational  
**File**: `src/mcp_server/openapi/validator.py`  
**Description**: Valida√ß√£o de par√¢metros usando jsonschema + Pydantic

**Steps**:
1. Criar `openapi/validator.py` com fun√ß√µes de valida√ß√£o
2. Implementar valida√ß√£o contra request_schema (jsonschema)
3. Implementar valida√ß√£o contra response_schema
4. Gerar mensagens de erro detalhadas listando campos faltantes/inv√°lidos
5. Garantir overhead <10ms (constitutional requirement)
6. Adicionar suporte a valida√ß√£o de pagination params

**Acceptance Criteria**:
- ‚úÖ Valida√ß√£o de par√¢metros funcional
- ‚úÖ Overhead de valida√ß√£o <10ms
- ‚úÖ Erros detalhados com campos espec√≠ficos
- ‚úÖ Suporta valida√ß√£o din√¢mica de qualquer schema

**Parallel**: ‚úÖ [P] (depende de T007 mas paralelo com T008)

---

### T011: Implementar gera√ß√£o de embeddings

**User Story**: Foundational  
**File**: `scripts/generate_embeddings.py`, `src/mcp_server/vector_db/embeddings.py`  
**Description**: Gerar embeddings ML para todas as opera√ß√µes

**Steps**:
1. Criar `vector_db/embeddings.py` com sentence-transformers
2. Baixar modelo `all-MiniLM-L6-v2` (384 dims)
3. Criar script `generate_embeddings.py`
4. Para cada opera√ß√£o: concatenar description + examples ‚Üí gerar embedding
5. Popular tabela `embeddings` no SQLite
6. Adicionar metadata: model_name, model_version
7. Validar que todos os embeddings t√™m 384 dimens√µes

**Acceptance Criteria**:
- ‚úÖ Modelo ML baixado e cached
- ‚úÖ Embeddings gerados para ~150-300 opera√ß√µes
- ‚úÖ Embeddings salvos no SQLite
- ‚úÖ Todos os vetores t√™m 384 dimens√µes

**Parallel**: ‚ùå (depende de T008)

---

### T012: Implementar busca sem√¢ntica por similaridade

**User Story**: Foundational  
**File**: `src/mcp_server/vector_db/search.py`  
**Description**: Motor de busca sem√¢ntica usando embeddings

**Steps**:
1. Criar `vector_db/search.py` com fun√ß√£o de busca
2. Implementar c√°lculo de cosine similarity
3. Aplicar threshold 0.7 para filtragem
4. Ordenar resultados por similarity_score DESC
5. Implementar pagination dos resultados
6. Otimizar para <100ms de lat√™ncia

**Acceptance Criteria**:
- ‚úÖ Busca sem√¢ntica funcional
- ‚úÖ Threshold 0.7 aplicado corretamente
- ‚úÖ Resultados ordenados por relev√¢ncia
- ‚úÖ Lat√™ncia <100ms

**Parallel**: ‚ùå (depende de T011)

---

### T013: Implementar rate limiting por cliente

**User Story**: Foundational  
**File**: `src/mcp_server/utils/rate_limit.py`  
**Description**: Rate limiting b√°sico usando slowapi (100 req/min por cliente)

**Steps**:
1. Criar `utils/rate_limit.py` com configura√ß√£o slowapi
2. Implementar rate limiter in-memory
3. Extrair client ID do contexto MCP
4. Configurar limite padr√£o: 100 req/min (configur√°vel via RATE_LIMIT_RPM)
5. Retornar HTTP 429 com header Retry-After
6. Adicionar m√©tricas de rate limit hits

**Acceptance Criteria**:
- ‚úÖ Rate limiting funcional por cliente
- ‚úÖ 100 req/min padr√£o configur√°vel
- ‚úÖ HTTP 429 retornado quando excedido
- ‚úÖ Retry-After header presente

**Parallel**: ‚úÖ [P] (independente de outras foundational tasks)

---

### T013a: Implementar cliente AMQP com pika

**User Story**: Foundational  
**File**: `src/mcp_server/amqp/client.py`  
**Description**: Cliente AMQP para opera√ß√µes de protocolo n√£o cobertas pela HTTP API

**Steps**:
1. Criar `amqp/client.py` com classe AmqpClient usando pika
2. Implementar connection pooling para AMQP
3. Configurar autentica√ß√£o (username/password de env vars)
4. Implementar channel management
5. Adicionar health checks de conex√£o AMQP
6. Configurar timeout de 30 segundos para opera√ß√µes
7. Implementar fail-fast (sem retry autom√°tico)

**Acceptance Criteria**:
- ‚úÖ Cliente AMQP async funcional com pika
- ‚úÖ Connection pooling implementado
- ‚úÖ Autentica√ß√£o via env vars
- ‚úÖ Timeout de 30s respeitado
- ‚úÖ Fail-fast implementado

**Parallel**: ‚úÖ [P] (independente de HTTP operations)

---

### T013b: Implementar schemas AMQP manuais

**User Story**: Foundational  
**File**: `src/mcp_server/schemas/amqp_operations.py`  
**Description**: Schemas Pydantic para opera√ß√µes AMQP (n√£o geradas por OpenAPI)

**Steps**:
1. Criar `schemas/amqp_operations.py` com modelos Pydantic
2. Definir PublishMessageSchema (exchange, routing_key, body, properties)
3. Definir ConsumeMessageSchema (queue, consumer_tag, auto_ack)
4. Definir AckMessageSchema (delivery_tag, multiple)
5. Definir NackMessageSchema (delivery_tag, multiple, requeue)
6. Definir RejectMessageSchema (delivery_tag, requeue)
7. Adicionar documenta√ß√£o de cada campo

**Acceptance Criteria**:
- ‚úÖ Schemas AMQP completos e valid√°veis
- ‚úÖ Todos os campos documentados
- ‚úÖ Tipos de dados corretos
- ‚úÖ Valida√ß√£o com Pydantic funcional

**Parallel**: ‚úÖ [P] (independente de cliente AMQP)

---

### T013c: Adicionar opera√ß√µes AMQP ao registry

**User Story**: Foundational  
**File**: `scripts/register_amqp_operations.py`, `src/mcp_server/openapi/operation_registry.py`  
**Description**: Registrar opera√ß√µes AMQP no SQLite para descoberta via search-ids

**Steps**:
1. Criar script `register_amqp_operations.py`
2. Definir operation IDs: amqp.publish, amqp.consume, amqp.ack, amqp.nack, amqp.reject
3. Criar namespace "amqp" no registry
4. Popular metadados: description, examples, parameters
5. Linkar schemas manuais (T013b) aos operation IDs
6. Adicionar flag is_amqp=true para diferenciar de HTTP ops
7. Executar script durante build/setup

**Acceptance Criteria**:
- ‚úÖ 5 opera√ß√µes AMQP registradas no SQLite
- ‚úÖ Namespace "amqp" criado
- ‚úÖ Metadados completos e precisos
- ‚úÖ Schemas linkados corretamente

**Parallel**: ‚ùå (depende de T008 e T013b)

---

### T013d: Adicionar opera√ß√µes AMQP ao vector database

**User Story**: Foundational  
**File**: `scripts/generate_embeddings.py` (atualiza√ß√£o)  
**Description**: Gerar embeddings para opera√ß√µes AMQP para busca sem√¢ntica

**Steps**:
1. Atualizar `generate_embeddings.py` para incluir AMQP
2. Para cada opera√ß√£o AMQP: criar description rica otimizada para busca sem√¢ntica
3. amqp.publish: "Publish message to exchange with routing key" (queries esperadas: "send message", "publish to exchange", "post to rabbitmq")
4. amqp.consume: "Subscribe to queue and receive messages" (queries esperadas: "consume queue", "listen to messages", "receive from queue")
5. amqp.ack: "Acknowledge message processing success" (queries esperadas: "acknowledge message", "confirm processing", "ack message")
6. amqp.nack: "Negative acknowledge - trigger retry or DLQ" (queries esperadas: "reject message", "nack message", "retry failed message")
7. amqp.reject: "Reject message - send to DLQ immediately" (queries esperadas: "reject message", "send to dlq", "discard message")
8. Gerar embeddings e adicionar ao SQLite

**Acceptance Criteria**:
- ‚úÖ Embeddings gerados para 5 opera√ß√µes AMQP
- ‚úÖ Descriptions otimizadas para busca sem√¢ntica
- ‚úÖ Embeddings adicionados ao vector database
- ‚úÖ Busca por "publish message" retorna amqp.publish

**Parallel**: ‚ùå (depende de T011 e T013c)

---

### T013e: Implementar executores de opera√ß√µes AMQP

**User Story**: Foundational  
**File**: `src/mcp_server/operations/amqp.py`  
**Description**: Implementar execu√ß√£o de opera√ß√µes AMQP via call-id tool

**Steps**:
1. Criar `operations/amqp.py` com classe AmqpExecutor
2. Implementar execute_publish (basic_publish via pika)
3. Implementar execute_consume (basic_consume com callback)
4. Implementar execute_ack (basic_ack)
5. Implementar execute_nack (basic_nack)
6. Implementar execute_reject (basic_reject)
7. Integrar com call-id tool via operation registry
8. Adicionar error handling espec√≠fico AMQP

**Acceptance Criteria**:
- ‚úÖ 5 opera√ß√µes AMQP execut√°veis
- ‚úÖ Integra√ß√£o com call-id funcional
- ‚úÖ Error handling robusto
- ‚úÖ Valida√ß√£o de par√¢metros funcional

**Parallel**: ‚ùå (depende de T013a e T013c)

---

### T013f: Escrever testes de integra√ß√£o AMQP

**User Story**: Foundational  
**File**: `tests/integration/test_amqp_operations.py`  
**Description**: Testes end-to-end com RabbitMQ via AMQP

**Steps**:
1. Criar fixture de RabbitMQ container para AMQP
2. Testar amqp.publish envia mensagem corretamente
3. Testar amqp.consume recebe mensagem
4. Testar amqp.ack confirma processamento
5. Testar amqp.nack move para retry ou DLQ
6. Testar amqp.reject move para DLQ imediatamente
7. Validar mensagens realmente trafegam via AMQP
8. Cleanup autom√°tico ap√≥s testes

**Acceptance Criteria**:
- ‚úÖ Testes AMQP funcionais com RabbitMQ real
- ‚úÖ Publish/consume testados end-to-end
- ‚úÖ Ack/nack/reject testados
- ‚úÖ Cleanup autom√°tico

**Parallel**: ‚úÖ [P] (independente de outras tasks de teste)

---

‚ö†Ô∏è **CHECKPOINT FOUNDATIONAL + AMQP**: Todas as tasks T007-T013f devem estar completas antes de iniciar User Stories. **TDD OBRIGAT√ìRIO**: Escrever testes (T013f) ANTES de implementar executores (T013e).

---

## Phase 3: User Story 1 - Descobrir Opera√ß√µes Dispon√≠veis (P1)

**Goal**: Implementar busca sem√¢ntica de opera√ß√µes via ferramenta `search-ids`  
**Duration**: 2-3 dias  
**Prerequisites**: Phase 2 completa  
**Priority**: P1 (Cr√≠tico - sem isso, usu√°rios n√£o podem navegar pelas capacidades)

üîç **User Story**: Como desenvolvedor integrando com RabbitMQ, preciso buscar opera√ß√µes relevantes usando linguagem natural, para que eu possa encontrar rapidamente a funcionalidade que preciso sem conhecer todos os endpoints dispon√≠veis.

**Independent Test Criteria**: Enviar consultas em linguagem natural (ex: "listar filas") e verificar se opera√ß√µes relevantes s√£o retornadas com descri√ß√µes claras.

‚ö†Ô∏è **TDD CHECKPOINT US1**: Para cada task de implementa√ß√£o (T014-T018), escrever testes PRIMEIRO (T019-T021) antes de implementar a funcionalidade. Red ‚Üí Green ‚Üí Refactor.

### T014: Implementar ferramenta search-ids - interface MCP

**User Story**: US1  
**File**: `src/mcp_server/tools/search_ids.py`  
**Description**: Implementar interface MCP da ferramenta search-ids

**Steps**:
1. Criar `tools/search_ids.py` com classe SearchIdsTool
2. Implementar schema de input conforme contract (query, pagination)
3. Implementar schema de output (items, pagination metadata)
4. Registrar tool no MCP server
5. Validar inputs usando Pydantic
6. Adicionar documenta√ß√£o da ferramenta

**Acceptance Criteria**:
- ‚úÖ Tool registrada no MCP server
- ‚úÖ Input schema validado
- ‚úÖ Output schema conforme contrato
- ‚úÖ Documenta√ß√£o completa

**Parallel**: ‚ùå (primeira task da US1)

---

### T015: Conectar search-ids ao motor de busca sem√¢ntica

**User Story**: US1  
**File**: `src/mcp_server/tools/search_ids.py`  
**Description**: Integrar busca sem√¢ntica ao tool search-ids

**Steps**:
1. Importar `vector_db/search.py`
2. Converter query em embedding usando modelo ML
3. Executar busca por similaridade
4. Filtrar resultados com threshold 0.7
5. Aplicar pagination aos resultados
6. Formatar response conforme schema

**Acceptance Criteria**:
- ‚úÖ Query convertida em embedding
- ‚úÖ Busca sem√¢ntica executada
- ‚úÖ Resultados filtrados e paginados
- ‚úÖ Response formatado corretamente

**Parallel**: ‚ùå (depende de T014)

---

### T016: Adicionar parameter hints aos resultados

**User Story**: US1  
**File**: `src/mcp_server/tools/search_ids.py`  
**Description**: Gerar hints de par√¢metros principais para cada resultado

**Steps**:
1. Para cada opera√ß√£o encontrada, carregar request_schema
2. Extrair campos obrigat√≥rios (required)
3. Extrair 2-3 campos opcionais mais importantes
4. Formatar como string: "vhost (required), page, pageSize"
5. Limitar a 100 caracteres
6. Adicionar ao campo `parameter_hint`

**Acceptance Criteria**:
- ‚úÖ Parameter hints gerados para todos os resultados
- ‚úÖ Campos obrigat√≥rios marcados como "(required)"
- ‚úÖ Hints limitados a 100 caracteres
- ‚úÖ Hints s√£o informativos e √∫teis

**Parallel**: ‚úÖ [P] (pode rodar em paralelo com T017)

---

### T017: Adicionar tratamento de erros ao search-ids

**User Story**: US1  
**File**: `src/mcp_server/tools/search_ids.py`  
**Description**: Implementar error handling robusto para search-ids

**Steps**:
1. Validar query length (min: 3, max: 200)
2. Validar pagination params (page >= 1, pageSize 1-25)
3. Capturar erro de vector database unavailable
4. Retornar erros no formato JSON-RPC 2.0
5. Usar c√≥digos de erro corretos (-32602, -32603)
6. Adicionar logging estruturado de erros

**Acceptance Criteria**:
- ‚úÖ Valida√ß√£o de inputs completa
- ‚úÖ Erros formatados como JSON-RPC 2.0
- ‚úÖ C√≥digos de erro corretos
- ‚úÖ Erros logados estruturadamente

**Parallel**: ‚úÖ [P] (pode rodar em paralelo com T016)

---

### T018: Otimizar performance do search-ids

**User Story**: US1  
**File**: `src/mcp_server/tools/search_ids.py`, `src/mcp_server/vector_db/search.py`  
**Description**: Otimizar para lat√™ncia <100ms por p√°gina

**Steps**:
1. Adicionar cache de embeddings de queries comuns (TTL 5min)
2. Otimizar c√°lculo de cosine similarity (numpy vectorization)
3. Implementar early exit se threshold n√£o atingido
4. Adicionar √≠ndices SQLite otimizados
5. Medir lat√™ncia com OpenTelemetry spans
6. Validar que 95% das buscas s√£o <100ms

**Acceptance Criteria**:
- ‚úÖ Lat√™ncia <100ms para 95% das queries
- ‚úÖ Cache funcional com TTL
- ‚úÖ M√©tricas de lat√™ncia dispon√≠veis
- ‚úÖ Otimiza√ß√µes validadas com testes de performance

**Parallel**: ‚úÖ [P] (pode rodar em paralelo com T019)

---

### T019: Escrever testes unit√°rios para search-ids

**User Story**: US1  
**File**: `tests/unit/test_search_ids.py`  
**Description**: Cobertura de testes para search-ids tool

**Steps**:
1. Criar fixtures de opera√ß√µes e embeddings mock
2. Testar busca com query v√°lida retorna resultados
3. Testar threshold filtering (apenas >= 0.7)
4. Testar ordena√ß√£o por similarity_score DESC
5. Testar pagination funciona corretamente
6. Testar valida√ß√£o de inputs (query length, pageSize)
7. Testar erros (query muito curta, vector db unavailable)
8. Atingir cobertura >80%

**Acceptance Criteria**:
- ‚úÖ Cobertura de testes >80%
- ‚úÖ Todos os cen√°rios de sucesso testados
- ‚úÖ Todos os cen√°rios de erro testados
- ‚úÖ Testes executam em <5s

**Parallel**: ‚úÖ [P] (independente de otimiza√ß√µes)

---

### T019.1: Escrever teste espec√≠fico de threshold 0.7

**User Story**: US1  
**File**: `tests/unit/test_search_ids_threshold.py`  
**Description**: Validar que threshold 0.7 de similaridade √© aplicado corretamente (FR-006)

**Steps**:
1. Criar fixtures com queries de diferentes similaridades
2. Query "criar fila" ‚Üí validar "queues.create" score ‚â•0.7 (esperado ~0.95) ACEITO
3. Query "criar fila" ‚Üí validar "users.create" score <0.7 (esperado ~0.32) REJEITADO
4. Query irrelevante "xyz123" ‚Üí validar retorna lista vazia
5. Validar que todos os resultados retornados t√™m score ‚â•0.7
6. Testar queries com exatamente threshold 0.7 (boundary test)
7. Testar comportamento quando 0 resultados acima threshold (sugest√£o: "Try broader search terms")

**Acceptance Criteria**:
- ‚úÖ Threshold 0.7 aplicado corretamente a todas as queries
- ‚úÖ Scores testados com exemplos reais (conforme FR-006)
- ‚úÖ Boundary cases testados (score = 0.7 exato)
- ‚úÖ Zero results retorna sugest√£o √∫til

**Parallel**: ‚úÖ [P] (independente de T020)

---

### T020: Escrever testes de integra√ß√£o para search-ids

**User Story**: US1  
**File**: `tests/integration/test_search_ids_integration.py`  
**Description**: Testes end-to-end com database real

**Steps**:
1. Criar fixture de SQLite database populado
2. Testar busca por "list queues" retorna opera√ß√µes de filas
3. Testar busca por "create exchange" retorna opera√ß√µes de exchanges
4. Testar busca gen√©rica retorna m√∫ltiplos namespaces
5. Testar busca sem resultados (query irrelevante)
6. Testar pagination com m√∫ltiplas p√°ginas
7. Validar performance com database real

**Acceptance Criteria**:
- ‚úÖ Integra√ß√£o com SQLite funcional
- ‚úÖ Cen√°rios de uso real testados
- ‚úÖ Pagination testada com dados reais
- ‚úÖ Performance validada

**Parallel**: ‚úÖ [P] (independente de testes unit√°rios)

---

### T021: Escrever testes de contrato MCP para search-ids

**User Story**: US1  
**File**: `tests/contract/test_search_ids_contract.py`  
**Description**: Validar compliance com protocolo MCP

**Steps**:
1. Validar tool registration no MCP server
2. Validar input schema √© JSON Schema v√°lido
3. Validar output schema √© JSON Schema v√°lido
4. Validar request/response seguem JSON-RPC 2.0
5. Validar c√≥digos de erro seguem padr√£o MCP
6. Validar examples do contrato funcionam
7. Comparar com `contracts/search-ids.json`

**Acceptance Criteria**:
- ‚úÖ 100% compliance com MCP protocol
- ‚úÖ Schemas v√°lidos
- ‚úÖ Examples executam com sucesso
- ‚úÖ Contrato JSON validado

**Parallel**: ‚úÖ [P] (independente de outros testes)

---

‚ö†Ô∏è **CHECKPOINT US1**: Todas as tasks T014-T021 devem estar completas e testes passando antes de iniciar User Story 2.

---

## Phase 4: User Story 2 - Obter Detalhes de Opera√ß√£o (P1)

**Goal**: Implementar consulta de documenta√ß√£o via ferramenta `get-id`  
**Duration**: 1-2 dias  
**Prerequisites**: Phase 2 e US1 completas  
**Priority**: P1 (Cr√≠tico - usu√°rios precisam entender opera√ß√µes antes de executar)

üìã **User Story**: Como desenvolvedor, preciso consultar a documenta√ß√£o completa e esquema de par√¢metros de uma opera√ß√£o espec√≠fica, para que eu possa entender exatamente como utiliz√°-la antes de execut√°-la.

**Independent Test Criteria**: Solicitar detalhes de uma opera√ß√£o conhecida e verificar se esquema de par√¢metros, tipos de dados e documenta√ß√£o s√£o retornados.

‚ö†Ô∏è **TDD CHECKPOINT US2**: Escrever testes (T025-T026) ANTES de implementar cache e otimiza√ß√µes (T024). Red ‚Üí Green ‚Üí Refactor.

### T022: Implementar ferramenta get-id - interface MCP

**User Story**: US2  
**File**: `src/mcp_server/tools/get_id.py`  
**Description**: Implementar interface MCP da ferramenta get-id

**Steps**:
1. Criar `tools/get_id.py` com classe GetIdTool
2. Implementar schema de input (endpoint_id)
3. Validar endpoint_id pattern: `^[a-z-]+\.[a-z-]+$`
4. Implementar schema de output conforme contract
5. Registrar tool no MCP server
6. Adicionar documenta√ß√£o da ferramenta

**Acceptance Criteria**:
- ‚úÖ Tool registrada no MCP server
- ‚úÖ Input validation funcional
- ‚úÖ Output schema conforme contrato
- ‚úÖ Pattern validation de endpoint_id

**Parallel**: ‚ùå (primeira task da US2)

---

### T023: Conectar get-id ao operation registry

**User Story**: US2  
**File**: `src/mcp_server/tools/get_id.py`  
**Description**: Buscar opera√ß√£o no registry e retornar detalhes completos

**Steps**:
1. Importar `operation_registry.py`
2. Buscar opera√ß√£o por ID no SQLite
3. Carregar request_schema e response_schema
4. Carregar examples se dispon√≠veis
5. Carregar error_scenarios comuns
6. Formatar response completo
7. Retornar erro -32601 se opera√ß√£o n√£o existe

**Acceptance Criteria**:
- ‚úÖ Opera√ß√£o buscada corretamente no registry
- ‚úÖ Schemas carregados e formatados
- ‚úÖ Examples inclu√≠dos quando dispon√≠veis
- ‚úÖ Erro claro para opera√ß√£o inexistente

**Parallel**: ‚ùå (depende de T022)

---

### T024: Implementar cache de detalhes de opera√ß√£o

**User Story**: US2  
**File**: `src/mcp_server/tools/get_id.py`  
**Description**: Cache em mem√≥ria com TTL de 5 minutos

**Steps**:
1. Criar cache dictionary thread-safe (asyncio.Lock)
2. Cache key: endpoint_id
3. Cache value: operation details completo
4. TTL: 5 minutos (300 segundos)
5. Invalidar cache automaticamente ap√≥s TTL
6. Adicionar m√©tricas de cache hits/misses

**Acceptance Criteria**:
- ‚úÖ Cache funcional e thread-safe
- ‚úÖ TTL de 5 minutos respeitado
- ‚úÖ M√©tricas de cache dispon√≠veis
- ‚úÖ Performance melhorada para opera√ß√µes frequentes

**Parallel**: ‚úÖ [P] (pode rodar em paralelo com T025)

---

### T025: Escrever testes unit√°rios para get-id

**User Story**: US2  
**File**: `tests/unit/test_get_id.py`  
**Description**: Cobertura de testes para get-id tool

**Steps**:
1. Criar fixtures de operation registry mock
2. Testar busca por opera√ß√£o v√°lida retorna detalhes
3. Testar schemas s√£o retornados corretamente
4. Testar examples s√£o inclu√≠dos
5. Testar erro para endpoint_id inv√°lido (pattern)
6. Testar erro para opera√ß√£o n√£o encontrada (-32601)
7. Testar cache hits e misses
8. Atingir cobertura >80%

**Acceptance Criteria**:
- ‚úÖ Cobertura >80%
- ‚úÖ Cen√°rios de sucesso testados
- ‚úÖ Cen√°rios de erro testados
- ‚úÖ Cache behavior validado

**Parallel**: ‚úÖ [P] (independente de cache implementation)

---

### T026: Escrever testes de contrato MCP para get-id

**User Story**: US2  
**File**: `tests/contract/test_get_id_contract.py`  
**Description**: Validar compliance com protocolo MCP

**Steps**:
1. Validar tool registration
2. Validar input/output schemas
3. Validar JSON-RPC 2.0 compliance
4. Validar c√≥digos de erro
5. Validar examples do contract funcionam
6. Comparar com `contracts/get-id.json`
7. Validar lat√™ncia <50ms (target do contract)

**Acceptance Criteria**:
- ‚úÖ 100% MCP compliance
- ‚úÖ Schemas v√°lidos
- ‚úÖ Examples funcionam
- ‚úÖ Lat√™ncia <50ms validada

**Parallel**: ‚úÖ [P] (independente de testes unit√°rios)

---

‚ö†Ô∏è **CHECKPOINT US2**: Todas as tasks T022-T026 devem estar completas e testes passando antes de iniciar User Story 3.

---

## Phase 5: User Story 3 - Executar Opera√ß√µes RabbitMQ (P1)

**Goal**: Implementar execu√ß√£o validada de opera√ß√µes via ferramenta `call-id`  
**Duration**: 3-4 dias  
**Prerequisites**: Phase 2, US1, US2 completas  
**Priority**: P1 (Cr√≠tico - funcionalidade principal de valor)

‚ö° **User Story**: Como desenvolvedor, preciso executar opera√ß√µes RabbitMQ passando par√¢metros validados, para que eu possa gerenciar recursos (filas, exchanges, bindings) de forma program√°tica e confi√°vel.

**Independent Test Criteria**: Executar opera√ß√µes conhecidas com par√¢metros v√°lidos e verificar se a√ß√µes s√£o realizadas no RabbitMQ e resultados corretos s√£o retornados.

‚ö†Ô∏è **TDD CHECKPOINT US3**: Escrever testes (T036-T039) ANTES de implementar funcionalidades (T027-T035). Para cada componente: escrever teste unit√°rio ‚Üí implementar ‚Üí validar teste de integra√ß√£o. Red ‚Üí Green ‚Üí Refactor.

### T027: Implementar ferramenta call-id - interface MCP

**User Story**: US3  
**File**: `src/mcp_server/tools/call_id.py`  
**Description**: Implementar interface MCP da ferramenta call-id

**Steps**:
1. Criar `tools/call_id.py` com classe CallIdTool
2. Implementar schema de input (endpoint_id, params, pagination)
3. Validar endpoint_id pattern
4. Implementar schema de output (result, metadata)
5. Registrar tool no MCP server
6. Adicionar documenta√ß√£o da ferramenta

**Acceptance Criteria**:
- ‚úÖ Tool registrada no MCP server
- ‚úÖ Input schemas definidos
- ‚úÖ Output schema com result + metadata
- ‚úÖ Documenta√ß√£o completa

**Parallel**: ‚ùå (primeira task da US3)

---

### T028: Implementar cliente HTTP RabbitMQ

**User Story**: US3  
**File**: `src/mcp_server/operations/executor.py`  
**Description**: Cliente async HTTP para RabbitMQ Management API

**Steps**:
1. Criar `operations/executor.py` com classe BaseExecutor
2. Configurar httpx.AsyncClient com connection pooling
3. Implementar autentica√ß√£o b√°sica (username/password)
4. Configurar timeout de 30 segundos
5. Implementar retry l√≥gica (fail-fast: sem retry autom√°tico)
6. Adicionar logging de requisi√ß√µes
7. Adicionar OpenTelemetry spans para cada chamada

**Acceptance Criteria**:
- ‚úÖ Cliente HTTP async funcional
- ‚úÖ Autentica√ß√£o configurada
- ‚úÖ Timeout de 30s respeitado
- ‚úÖ Fail-fast (sem retry) implementado

**Parallel**: ‚ùå (depende de T027)

---

### T029: Implementar valida√ß√£o de par√¢metros pr√©-execu√ß√£o

**User Story**: US3  
**File**: `src/mcp_server/tools/call_id.py`  
**Description**: Validar params contra request_schema antes de executar

**Steps**:
1. Buscar opera√ß√£o no registry
2. Carregar request_schema
3. Validar params usando `validator.py`
4. Validar campos obrigat√≥rios est√£o presentes
5. Validar tipos de dados
6. Gerar erro detalhado listando missing/invalid fields
7. Garantir valida√ß√£o em <10ms

**Acceptance Criteria**:
- ‚úÖ Valida√ß√£o completa pr√©-execu√ß√£o
- ‚úÖ Erro detalhado com fields missing/invalid
- ‚úÖ Valida√ß√£o em <10ms
- ‚úÖ Nenhuma tentativa de execu√ß√£o se valida√ß√£o falhar

**Parallel**: ‚úÖ [P] (pode rodar em paralelo com T028)

---

### T030: Conectar call-id ao executor de opera√ß√µes

**User Story**: US3  
**File**: `src/mcp_server/tools/call_id.py`, `src/mcp_server/operations/executor.py`  
**Description**: Executar opera√ß√£o RabbitMQ via HTTP API

**Steps**:
1. Buscar opera√ß√£o no registry
2. Validar params (T029)
3. Construir HTTP request (method, path, body)
4. Substituir path params (ex: {vhost})
5. Executar via BaseExecutor
6. Capturar response ou erro
7. Validar response contra response_schema
8. Formatar resultado final

**Acceptance Criteria**:
- ‚úÖ Opera√ß√£o executada no RabbitMQ
- ‚úÖ Path params substitu√≠dos corretamente
- ‚úÖ Response validado contra schema
- ‚úÖ Resultado formatado conforme output schema

**Parallel**: ‚ùå (depende de T028 e T029)

---

### T031: Implementar tratamento de timeouts

**User Story**: US3  
**File**: `src/mcp_server/operations/executor.py`  
**Description**: Abortar opera√ß√µes que excedem 30 segundos

**Steps**:
1. Adicionar timeout de 30s em httpx.AsyncClient
2. Capturar httpx.TimeoutException
3. Retornar erro -32001 (Timeout error)
4. Incluir detalhes: operation_id, timeout_seconds
5. Adicionar sugest√£o de resolu√ß√£o
6. Logar timeout events

**Acceptance Criteria**:
- ‚úÖ Timeouts detectados corretamente
- ‚úÖ Erro -32001 retornado
- ‚úÖ Mensagem descritiva com sugest√µes
- ‚úÖ Opera√ß√£o abortada ap√≥s 30s

**Parallel**: ‚úÖ [P] (pode rodar em paralelo com T032)

---

### T032: Implementar tratamento de erros de conex√£o

**User Story**: US3  
**File**: `src/mcp_server/operations/executor.py`  
**Description**: Fail-fast para erros de conex√£o com RabbitMQ

**Steps**:
1. Capturar erros de conex√£o (httpx.ConnectError, etc)
2. Retornar erro -32000 (Server error)
3. Incluir detalhes: rabbitmq_host, reason
4. Adicionar resolu√ß√£o sugerida
5. N√£o implementar retry autom√°tico (fail-fast)
6. Logar connection errors

**Acceptance Criteria**:
- ‚úÖ Erros de conex√£o detectados
- ‚úÖ Erro -32000 retornado
- ‚úÖ Fail-fast (sem retry)
- ‚úÖ Mensagem descritiva

**Parallel**: ‚úÖ [P] (pode rodar em paralelo com T031)

---

### T033: Implementar tratamento de respostas malformadas

**User Story**: US3  
**File**: `src/mcp_server/operations/executor.py`  
**Description**: Detectar e reportar respostas em formato inesperado

**Steps**:
1. Validar response √© JSON v√°lido
2. Validar response contra response_schema
3. Capturar erros de parsing (json.JSONDecodeError)
4. Capturar erros de valida√ß√£o (jsonschema.ValidationError)
5. Retornar erro descritivo sem expor stack traces
6. Logar parsing errors para debug

**Acceptance Criteria**:
- ‚úÖ Respostas inv√°lidas detectadas
- ‚úÖ Erro descritivo retornado
- ‚úÖ Stack traces n√£o expostos ao cliente
- ‚úÖ Errors logados para troubleshooting

**Parallel**: ‚úÖ [P] (pode rodar em paralelo com T034)

---

### T034: Adicionar metadata de execu√ß√£o √†s respostas

**User Story**: US3  
**File**: `src/mcp_server/tools/call_id.py`  
**Description**: Incluir informa√ß√µes √∫teis de debug e observability

**Steps**:
1. Capturar timestamp de in√≠cio e fim
2. Calcular duration_ms
3. Incluir operation_id executado
4. Incluir OpenTelemetry trace_id
5. Adicionar status (success/error/timeout)
6. Formatar metadata section na response

**Acceptance Criteria**:
- ‚úÖ Metadata inclu√≠do em todas as responses
- ‚úÖ duration_ms preciso
- ‚úÖ trace_id correlacion√°vel com logs
- ‚úÖ Status claro

**Parallel**: ‚úÖ [P] (pode rodar em paralelo com T035)

---

### T035: Implementar suporte a pagination em opera√ß√µes

**User Story**: US3  
**File**: `src/mcp_server/tools/call_id.py`  
**Description**: Suporte a pagination para opera√ß√µes de listagem

**Steps**:
1. Detectar se opera√ß√£o suporta pagination (flag no registry)
2. Aceitar pagination params (page, pageSize)
3. Validar pageSize <= 200 (constitutional limit)
4. Adicionar params ao request RabbitMQ
5. Formatar response paginada com metadata
6. Incluir hasNextPage, hasPreviousPage

**Acceptance Criteria**:
- ‚úÖ Pagination funcional para opera√ß√µes que suportam
- ‚úÖ pageSize limitado a 200
- ‚úÖ Metadata de pagination completo
- ‚úÖ Navega√ß√£o entre p√°ginas funcional

**Parallel**: ‚úÖ [P] (independente de outros tratamentos de erro)

---

### T035.1: Escrever teste de timeout + pagination para listagens grandes

**User Story**: US3  
**File**: `tests/integration/test_call_id_large_lists.py`  
**Description**: Validar timeout 30s com pagination obrigat√≥ria para listagens >1000 items ou >50MB (FR-014)

**Steps**:
1. Criar fixture de RabbitMQ com >1000 filas simuladas
2. Testar listagem sem pagination ‚Üí validar pageSize for√ßado ‚â§200
3. Testar que opera√ß√£o completa dentro de 30s com pagination
4. Testar que timeout √© respeitado (aborta ap√≥s 30s se n√£o usar pagination)
5. Validar metadata de pagination correto (hasNextPage, totalItems)
6. Testar com diferentes tamanhos de resposta (10MB, 50MB, >50MB)
7. Validar erro claro quando timeout ocorre

**Acceptance Criteria**:
- ‚úÖ Listagens grandes (>1000 items) for√ßam pagination pageSize‚â§200
- ‚úÖ Timeout 30s respeitado com pagination
- ‚úÖ Metadata de pagination completo e correto
- ‚úÖ Erro de timeout claro e descritivo

**Parallel**: ‚úÖ [P] (independente de T036)

---

### T036: Escrever testes unit√°rios para call-id

**User Story**: US3  
**File**: `tests/unit/test_call_id.py`  
**Description**: Cobertura de testes para call-id tool

**Steps**:
1. Criar fixtures de RabbitMQ API mock
2. Testar execu√ß√£o com params v√°lidos retorna sucesso
3. Testar valida√ß√£o pr√©-execu√ß√£o detecta params inv√°lidos
4. Testar timeout ap√≥s 30s
5. Testar erro de conex√£o retorna -32000
6. Testar resposta malformada √© detectada
7. Testar metadata √© inclu√≠do corretamente
8. Testar pagination params funcionam
9. Atingir cobertura >80%

**Acceptance Criteria**:
- ‚úÖ Cobertura >80%
- ‚úÖ Todos os cen√°rios testados
- ‚úÖ Mocks realistas de RabbitMQ API
- ‚úÖ Edge cases cobertos

**Parallel**: ‚úÖ [P] (pode come√ßar ap√≥s T027 estar completo)

---

### T037: Escrever testes de integra√ß√£o com RabbitMQ real

**User Story**: US3  
**File**: `tests/integration/test_call_id_rabbitmq.py`  
**Description**: Testes end-to-end com RabbitMQ em container

**Steps**:
1. Criar fixture de RabbitMQ container (testcontainers)
2. Testar criar fila e verificar no RabbitMQ
3. Testar criar exchange e verificar
4. Testar criar binding e verificar
5. Testar listar recursos criados
6. Testar deletar recursos
7. Validar opera√ß√µes realmente executam no RabbitMQ
8. Cleanup autom√°tico ap√≥s testes

**Acceptance Criteria**:
- ‚úÖ RabbitMQ container funcional
- ‚úÖ Opera√ß√µes realmente executadas
- ‚úÖ Resultados verific√°veis no RabbitMQ
- ‚úÖ Cleanup autom√°tico

**Parallel**: ‚ùå (requer infraestrutura de testes configurada)

---

### T038: Escrever testes de contrato MCP para call-id

**User Story**: US3  
**File**: `tests/contract/test_call_id_contract.py`  
**Description**: Validar compliance com protocolo MCP

**Steps**:
1. Validar tool registration
2. Validar input/output schemas
3. Validar JSON-RPC 2.0 compliance
4. Validar todos os c√≥digos de erro (-32602, -32000, -32001)
5. Validar examples funcionam (se dispon√≠veis)
6. Validar lat√™ncia dentro de limites

**Acceptance Criteria**:
- ‚úÖ 100% MCP compliance
- ‚úÖ Todos os error codes validados
- ‚úÖ Schemas v√°lidos
- ‚úÖ Performance dentro de limites

**Parallel**: ‚úÖ [P] (independente de testes de integra√ß√£o)

---

### T039: Escrever testes de performance para call-id

**User Story**: US3  
**File**: `tests/integration/test_call_id_performance.py`  
**Description**: Validar m√©tricas de performance (<200ms, <10ms validation)

**Steps**:
1. Testar valida√ß√£o √© <10ms (95th percentile)
2. Testar opera√ß√£o b√°sica √© <200ms
3. Testar concorr√™ncia (m√∫ltiplas requisi√ß√µes simult√¢neas)
4. Testar uso de mem√≥ria √© <1GB
5. Testar rate limiting funciona corretamente
6. Gerar relat√≥rio de performance

**Acceptance Criteria**:
- ‚úÖ Valida√ß√£o <10ms confirmada
- ‚úÖ Opera√ß√£o b√°sica <200ms confirmada
- ‚úÖ Concorr√™ncia funcional
- ‚úÖ Uso de mem√≥ria <1GB

**Parallel**: ‚úÖ [P] (independente de outros testes)

---

‚ö†Ô∏è **CHECKPOINT US3**: Todas as tasks T027-T039 devem estar completas e testes passando antes de iniciar User Story 4.

---

## Phase 6: User Story 4 - Receber Feedback Claro de Erros (P2)

**Goal**: Padronizar e melhorar mensagens de erro em todas as ferramentas  
**Duration**: 1 dia  
**Prerequisites**: US1, US2, US3 completas  
**Priority**: P2 (Importante para experi√™ncia do desenvolvedor)

üõ°Ô∏è **User Story**: Como desenvolvedor, preciso receber mensagens de erro padronizadas e descritivas quando algo falha, para que eu possa identificar e corrigir problemas rapidamente.

**Independent Test Criteria**: Provocar diferentes tipos de erro (valida√ß√£o, conex√£o, opera√ß√£o inv√°lida) e verificar se mensagens claras s√£o retornadas.

‚ö†Ô∏è **TDD CHECKPOINT US4**: Escrever testes de error scenarios (T047) ANTES de implementar melhorias (T044-T046). Para cada tipo de erro: escrever teste ‚Üí implementar mensagem ‚Üí validar. Red ‚Üí Green ‚Üí Refactor.

### T043: Padronizar estrutura de erros JSON-RPC 2.0

**User Story**: US4  
**File**: `src/mcp_server/utils/errors.py`  
**Description**: Criar classes de erro padronizadas para todo o sistema

**Steps**:
1. Criar `utils/errors.py` com classes de erro
2. Definir c√≥digos de erro conforme data-model.md
3. Implementar formata√ß√£o JSON-RPC 2.0 autom√°tica
4. Adicionar campo `data` com detalhes extras
5. Criar helper functions para erro comum patterns
6. Documentar cada c√≥digo de erro

**Acceptance Criteria**:
- ‚úÖ Classes de erro para cada c√≥digo (-32700 a -32002)
- ‚úÖ Formata√ß√£o JSON-RPC 2.0 autom√°tica
- ‚úÖ Campo `data` com detalhes √∫teis
- ‚úÖ Documenta√ß√£o completa

**Parallel**: ‚ùå (primeira task da US4)

---

### T044: Melhorar mensagens de erro de valida√ß√£o

**User Story**: US4  
**File**: `src/mcp_server/openapi/validator.py`, todas as tools  
**Description**: Erros de valida√ß√£o devem listar especificamente o que est√° errado

**Steps**:
1. Atualizar validator.py para gerar erros detalhados
2. Listar campos missing explicitamente
3. Listar campos invalid com raz√£o (ex: "pageSize: must be <= 200")
4. Incluir expected_schema no erro quando √∫til
5. Evitar jarg√£o t√©cnico desnecess√°rio
6. Aplicar em search-ids, get-id, call-id

**Acceptance Criteria**:
- ‚úÖ Erros listam campos missing/invalid especificamente
- ‚úÖ Mensagens s√£o claras e acion√°veis
- ‚úÖ Expected schema inclu√≠do quando √∫til
- ‚úÖ Consistente em todas as ferramentas

**Parallel**: ‚úÖ [P] (pode rodar em paralelo com T045)

---

### T045: Adicionar resolu√ß√£o sugerida aos erros

**User Story**: US4  
**File**: Todas as tools e `operations/executor.py`  
**Description**: Erros devem incluir sugest√µes de como resolver

**Steps**:
1. Adicionar campo `resolution` aos erros
2. Para timeout: "Try with more specific filters"
3. Para conex√£o: "Check if RabbitMQ is running and credentials are correct"
4. Para valida√ß√£o: "Provide the 'vhost' parameter (e.g., '/' for default)"
5. Para rate limit: "Wait {retry_after} seconds before retrying"
6. Para opera√ß√£o n√£o encontrada: "Use search-ids to find available operations"

**Acceptance Criteria**:
- ‚úÖ Todos os erros incluem resolu√ß√£o sugerida
- ‚úÖ Sugest√µes s√£o pr√°ticas e acion√°veis
- ‚úÖ Sugest√µes contextuais (n√£o gen√©ricas)
- ‚úÖ Consist√™ncia em todas as ferramentas

**Parallel**: ‚úÖ [P] (pode rodar em paralelo com T044)

---

### T046: Garantir seguran√ßa de mensagens de erro

**User Story**: US4  
**File**: `src/mcp_server/utils/errors.py`, `utils/logging.py`  
**Description**: Erros n√£o devem expor informa√ß√µes sens√≠veis

**Steps**:
1. Nunca incluir stack traces em erros retornados ao cliente
2. Redatar credenciais e tokens em logs
3. Erros internos (n√£o esperados) devem retornar mensagem gen√©rica
4. Stack traces completos apenas em logs (n√£o no response)
5. Validar que dados sens√≠veis n√£o aparecem em erros
6. Adicionar testes de seguran√ßa

**Acceptance Criteria**:
- ‚úÖ Stack traces n√£o expostos ao cliente
- ‚úÖ Credenciais redatadas em logs
- ‚úÖ Erros internos retornam mensagem segura
- ‚úÖ Testes de seguran√ßa passando

**Parallel**: ‚úÖ [P] (pode rodar em paralelo com T047)

---

### T047: Escrever testes de error scenarios

**User Story**: US4  
**File**: `tests/unit/test_error_handling.py`, `tests/integration/test_error_scenarios.py`  
**Description**: Validar todos os cen√°rios de erro documentados

**Steps**:
1. Testar cada c√≥digo de erro (-32700 a -32002)
2. Validar formato JSON-RPC 2.0
3. Validar mensagens s√£o descritivas
4. Validar detalhes (data field) s√£o √∫teis
5. Validar sugest√µes de resolu√ß√£o presentes
6. Validar seguran√ßa (sem dados sens√≠veis)
7. Testar error scenarios de cada acceptance criteria das US
8. **Testar erros internos n√£o-capturados retornam mensagem gen√©rica segura sem stack traces**
9. **Testar que exce√ß√µes inesperadas (ex: KeyError, AttributeError) s√£o capturadas e sanitizadas**
10. Atingir cobertura completa de error paths

**Acceptance Criteria**:
- ‚úÖ Todos os c√≥digos de erro testados
- ‚úÖ Formato JSON-RPC validado
- ‚úÖ Mensagens validadas
- ‚úÖ Seguran√ßa validada
- ‚úÖ Erros internos retornam mensagem gen√©rica (ex: "Internal server error") sem detalhes sens√≠veis
- ‚úÖ Stack traces nunca expostos ao cliente (apenas em logs)

**Parallel**: ‚úÖ [P] (independente de outras tasks)

---

‚ö†Ô∏è **CHECKPOINT US4**: Todas as tasks T043-T047 devem estar completas antes de prosseguir para console client.

---

## Phase 6.5: Console Client & Multilingual Support (Constitution ¬ßVIII)

**Goal**: Implementar console client built-in + suporte a 20 idiomas conforme constitution  
**Duration**: 2-3 semanas  
**Prerequisites**: US1-US4 completas (ferramentas MCP funcionais)  
**Constitution**: ¬ßVIII linha 71 (console client obrigat√≥rio) + linhas 604-624 (20 idiomas)

üñ•Ô∏è **Constitution Requirement**: "Every MCP server MUST include a built-in console client" + "MUST be available in the 20 most spoken languages worldwide"

**Architectural Decision**: ADR-002 (supersedes ADR-001) - Console simplificado em MVP para constitution compliance

‚ö†Ô∏è **TDD CHECKPOINT Phase 6.5**: Escrever testes (T067-T068) em paralelo com implementa√ß√£o (T057-T066).

### T057: Implementar CLI framework base com Click

**User Story**: Console Client  
**File**: `cli/main.py`, `cli/__init__.py`  
**Description**: Setup b√°sico do console client usando Click framework

**Steps**:
1. Criar estrutura `cli/` com `main.py`
2. Configurar Click framework para CLI
3. Implementar entrypoint principal (`rabbitmq-mcp` command)
4. Adicionar global options: `--host`, `--user`, `--password`, `--vhost`, `--lang`
5. Implementar help system b√°sico
6. Configurar Rich console para output formatado
7. Adicionar version command (`rabbitmq-mcp --version`)

**Acceptance Criteria**:
- ‚úÖ CLI execut√°vel via `rabbitmq-mcp`
- ‚úÖ Global options funcionais
- ‚úÖ Help text gerado automaticamente
- ‚úÖ Version command funcional

**Parallel**: ‚ùå (primeira task da Phase 6.5)

---

### T058: Implementar comando search

**User Story**: Console Client  
**File**: `cli/commands/search.py`  
**Description**: Comando para busca sem√¢ntica de opera√ß√µes (wraps search-ids)

**Steps**:
1. Criar `cli/commands/search.py`
2. Implementar `rabbitmq-mcp search "<query>"`
3. Integrar com search-ids MCP tool
4. Formatar resultados em Rich table (operation_id, description, similarity_score)
5. Adicionar pagination support (`--page`, `--page-size`)
6. Adicionar exemplo no help text
7. Implementar error handling com mensagens i18n-ready

**Acceptance Criteria**:
- ‚úÖ Comando funcional: `rabbitmq-mcp search "list queues"`
- ‚úÖ Resultados formatados em table
- ‚úÖ Pagination funcional
- ‚úÖ Error handling claro

**Parallel**: ‚ùå (depende de T057)

---

### T059: Implementar comando describe

**User Story**: Console Client  
**File**: `cli/commands/describe.py`  
**Description**: Comando para obter detalhes de opera√ß√£o (wraps get-id)

**Steps**:
1. Criar `cli/commands/describe.py`
2. Implementar `rabbitmq-mcp describe <operation-id>`
3. Integrar com get-id MCP tool
4. Formatar output: description, parameters (required/optional), examples
5. Syntax highlighting para JSON schemas (pygments)
6. Adicionar exemplo no help text

**Acceptance Criteria**:
- ‚úÖ Comando funcional: `rabbitmq-mcp describe queues.list`
- ‚úÖ Output formatado e leg√≠vel
- ‚úÖ JSON highlighting funcional
- ‚úÖ Examples displayed quando dispon√≠veis

**Parallel**: ‚úÖ [P] (pode rodar em paralelo com T060)

---

### T060: Implementar comando execute

**User Story**: Console Client  
**File**: `cli/commands/execute.py`  
**Description**: Comando para executar opera√ß√µes RabbitMQ (wraps call-id)

**Steps**:
1. Criar `cli/commands/execute.py`
2. Implementar `rabbitmq-mcp execute <operation-id> --params '{"vhost": "/"}'`
3. Integrar com call-id MCP tool
4. Parse JSON params de string ou file (`--params-file params.json`)
5. Formatar resultado com Rich (success/error color-coded)
6. Adicionar dry-run mode (`--dry-run` para validar params sem executar)
7. Progress indicator para opera√ß√µes longas

**Acceptance Criteria**:
- ‚úÖ Comando funcional: `rabbitmq-mcp execute queues.list --params '{"vhost": "/"}'`
- ‚úÖ Params via JSON string ou file
- ‚úÖ Dry-run mode funcional
- ‚úÖ Progress indicators para >5s operations

**Parallel**: ‚úÖ [P] (pode rodar em paralelo com T059)

---

### T061: Implementar comando connect (test connection)

**User Story**: Console Client  
**File**: `cli/commands/connect.py`  
**Description**: Comando para testar conectividade com RabbitMQ

**Steps**:
1. Criar `cli/commands/connect.py`
2. Implementar `rabbitmq-mcp connect --host localhost --user guest --password guest`
3. Testar HTTP API connection (Management API health check)
4. Testar AMQP connection (via pika)
5. Exibir status: HTTP API (‚úì/‚úó), AMQP (‚úì/‚úó), version, uptime
6. Adicionar verbose mode para troubleshooting

**Acceptance Criteria**:
- ‚úÖ Comando testa HTTP + AMQP
- ‚úÖ Status claro (success/failure)
- ‚úÖ Version info displayed
- ‚úÖ Verbose mode para debugging

**Parallel**: ‚úÖ [P] (independente de search/describe/execute)

---

### T062: Implementar framework i18n com gettext

**User Story**: Console Client (i18n)  
**File**: `cli/i18n/`, `setup.py` (i18n config)  
**Description**: Setup gettext para suporte multilingual

**Steps**:
1. Criar estrutura `cli/i18n/`
2. Configurar gettext com babel (extract, init, compile)
3. Criar `messages.pot` template com strings extra√≠das
4. Implementar wrapper `_()` para strings traduz√≠veis
5. Configurar locale detection via `locale.getdefaultlocale()`
6. Implementar fallback para English quando tradu√ß√£o ausente
7. Adicionar `--lang` flag para override manual

**Acceptance Criteria**:
- ‚úÖ gettext configurado e funcional
- ‚úÖ Locale detection autom√°tica
- ‚úÖ Fallback para English funcional
- ‚úÖ `--lang` override funcional

**Parallel**: ‚úÖ [P] (pode rodar em paralelo com T058-T061)

---

### T063: Criar translation templates (.pot files)

**User Story**: Console Client (i18n)  
**File**: `cli/i18n/messages.pot`  
**Description**: Extrair strings traduz√≠veis e criar template

**Steps**:
1. Executar `pybabel extract` para coletar strings `_()`
2. Gerar `messages.pot` com ~50-100 strings
3. Categorizar strings: commands, errors, help text, status messages
4. Adicionar contexto para tradutores (comments)
5. Validar que todas as strings user-facing t√™m `_()` wrapper
6. Documentar processo de atualiza√ß√£o de translations

**Acceptance Criteria**:
- ‚úÖ messages.pot gerado com todas as strings
- ‚úÖ ~50-100 strings extra√≠das
- ‚úÖ Context comments adicionados
- ‚úÖ Processo documentado

**Parallel**: ‚ùå (depende de T062)

---

### T064: Gerar tradu√ß√µes para 20 idiomas

**User Story**: Console Client (i18n)  
**File**: `cli/i18n/*/LC_MESSAGES/messages.po` (20 idiomas)  
**Description**: Criar arquivos .po para os 20 idiomas obrigat√≥rios

**Steps**:
1. Executar `pybabel init` para cada um dos 20 idiomas (constitution linhas 604-624):
   - en (English - base), zh_CN (Mandarin), hi (Hindi), es (Spanish), fr (French)
   - ar (Arabic), bn (Bengali), ru (Russian), pt (Portuguese), id (Indonesian)
   - ur (Urdu), de (German), ja (Japanese), sw (Swahili), mr (Marathi)
   - te (Telugu), tr (Turkish), ta (Tamil), vi (Vietnamese), it (Italian)
2. Usar machine translation (DeepL API ou Google Translate) para gerar tradu√ß√µes iniciais
3. Marcar tradu√ß√µes como fuzzy para revis√£o futura
4. Compilar .po ‚Üí .mo files (`pybabel compile`)
5. Testar que cada idioma carrega sem erros
6. Adicionar README em i18n/ explicando processo de contribui√ß√£o de tradu√ß√µes

**Acceptance Criteria**:
- ‚úÖ 20 idiomas com .po files completos
- ‚úÖ Machine translation aplicada (fuzzy OK para MVP)
- ‚úÖ .mo files compilados e funcionais
- ‚úÖ Todos os idiomas testados (loadable)

**Parallel**: ‚ùå (depende de T063)

---

### T065: Implementar locale detection e fallback

**User Story**: Console Client (i18n)  
**File**: `cli/i18n/loader.py`  
**Description**: Sistema robusto de detec√ß√£o e fallback de idiomas

**Steps**:
1. Criar `cli/i18n/loader.py` com fun√ß√£o `load_translations()`
2. Detectar locale via `locale.getdefaultlocale()` ou `LANG` env var
3. Mapear locale para idioma suportado (ex: pt_BR ‚Üí pt)
4. Fallback hierarchy: locale espec√≠fico ‚Üí idioma base ‚Üí English
5. Testar com todas as 20 locales suportadas
6. Implementar `--lang` override (highest priority)
7. Log de idioma selecionado em debug mode

**Acceptance Criteria**:
- ‚úÖ Locale detection funcional
- ‚úÖ Fallback hierarchy implementada
- ‚úÖ `--lang` override funciona
- ‚úÖ Testado com 20 idiomas

**Parallel**: ‚úÖ [P] (pode rodar em paralelo com T066)

---

### T066: Implementar Rich formatting para console output

**User Story**: Console Client  
**File**: `cli/formatter.py`  
**Description**: Formata√ß√£o consistente de output usando Rich

**Steps**:
1. Criar `cli/formatter.py` com classes de formata√ß√£o
2. Implementar table formatter (para search results)
3. Implementar JSON formatter com syntax highlighting
4. Implementar status messages (success: green, error: red, warning: yellow)
5. Implementar progress bars/spinners para long operations
6. Adicionar fallback para ambientes sem color support
7. Configurar via env var: `NO_COLOR` (respeitando standard)

**Acceptance Criteria**:
- ‚úÖ Tables formatadas com Rich
- ‚úÖ JSON syntax highlighting funcional
- ‚úÖ Color-coded messages
- ‚úÖ NO_COLOR respeitado

**Parallel**: ‚úÖ [P] (pode rodar em paralelo com T065)

---

### T067: Escrever testes de console CLI

**User Story**: Console Client  
**File**: `tests/unit/test_cli_commands.py`, `tests/integration/test_cli_e2e.py`  
**Description**: Cobertura completa de testes para comandos CLI

**Steps**:
1. Criar fixtures para CLI testing (Click CliRunner)
2. Testar search command: query v√°lida, pagination, errors
3. Testar describe command: operation v√°lido, operation inexistente
4. Testar execute command: params v√°lidos, params inv√°lidos, dry-run
5. Testar connect command: connection success, connection failure
6. Testar global options: --host, --user, --lang
7. Testar help text de todos os comandos
8. Testes de integra√ß√£o end-to-end com RabbitMQ mock
9. Atingir cobertura >80% para CLI

**Acceptance Criteria**:
- ‚úÖ Todos os 4 comandos testados (search, describe, execute, connect)
- ‚úÖ Global options testados
- ‚úÖ Error scenarios cobertos
- ‚úÖ Cobertura >80% para cli/

**Parallel**: ‚úÖ [P] (pode rodar em paralelo com T068)

---

### T068: Escrever testes de i18n coverage

**User Story**: Console Client (i18n)  
**File**: `tests/unit/test_i18n.py`  
**Description**: Validar que todos os 20 idiomas est√£o funcionais

**Steps**:
1. Criar teste que valida presen√ßa de 20 .po files
2. Testar que cada idioma carrega sem erros
3. Testar locale detection com diferentes env vars (LANG, LC_ALL)
4. Testar fallback hierarchy (specific locale ‚Üí base lang ‚Üí English)
5. Testar `--lang` override para todos os idiomas
6. Validar que strings n√£o traduzidas usam English (no crashes)
7. Testar que todos os 20 idiomas t√™m mesmo n√∫mero de strings

**Acceptance Criteria**:
- ‚úÖ 20 idiomas validados (loadable)
- ‚úÖ Locale detection testado
- ‚úÖ Fallback hierarchy testado
- ‚úÖ Sem crashes para idiomas incompletos

**Parallel**: ‚úÖ [P] (pode rodar em paralelo com T067)

---

‚ö†Ô∏è **CHECKPOINT Phase 6.5**: Todas as tasks T057-T068 devem estar completas antes de prosseguir para Phase 7 (Polish).

**Constitution Compliance**: ‚úÖ Console client + 20 idiomas implementados conforme ¬ßVIII

---

## Phase 7: Polish & Integration

**Goal**: Finalizar integra√ß√£o, documenta√ß√£o e CI/CD  
**Duration**: 2-3 dias  
**Prerequisites**: Todas as User Stories completas

### T048: Configurar CI/CD pipeline

**User Story**: Polish  
**File**: `.github/workflows/ci.yml` (ou similar)  
**Description**: Pipeline autom√°tico para testes, linting e valida√ß√£o

**Steps**:
1. Criar workflow de CI
2. Executar testes (unit, integration, contract) em cada PR
3. Executar linting (black, ruff, mypy)
4. Validar cobertura de testes (m√≠nimo 80%)
5. Validar sync OpenAPI ‚Üí schemas ‚Üí embeddings
6. Executar scripts de gera√ß√£o em CI para valida√ß√£o
7. Falhar build se qualquer valida√ß√£o falhar

**Acceptance Criteria**:
- ‚úÖ CI executa em cada PR
- ‚úÖ Todos os testes executados
- ‚úÖ Linting validado
- ‚úÖ Cobertura m√≠nima enforced

**Parallel**: ‚ùå (requer c√≥digo completo)

---

### T049: Criar documenta√ß√£o de deployment

**User Story**: Polish  
**File**: `docs/DEPLOYMENT.md`, `docs/API.md`, `docs/ARCHITECTURE.md`, `docs/EXAMPLES.md`, README atualizado  
**Description**: Guia completo de deployment, API, arquitetura e exemplos (constitution ¬ßVIII)

**Steps**:
1. Criar `docs/DEPLOYMENT.md` com vari√°veis de ambiente, processo de build (gera√ß√£o schemas/embeddings), deployment em diferentes ambientes, configura√ß√£o OpenTelemetry, troubleshooting
2. Criar `docs/API.md` com TypeScript interfaces para todas as 3 ferramentas MCP (search-ids, get-id, call-id), lista completa de operation IDs auto-gerados do OpenAPI, schemas de request/response, c√≥digos de erro
3. Criar `docs/ARCHITECTURE.md` com diagramas (semantic discovery pattern, OpenAPI generation flow, ChromaDB integration), decis√µes arquiteturais (ADRs), justificativa de escolhas t√©cnicas (ChromaDB vs sqlite-vec, threshold 0.7)
4. Criar `docs/EXAMPLES.md` com exemplos TESTADOS: debugging em dev environment, command-line usage (bash, PowerShell), MCP client configuration (Cursor, VS Code), exemplos de queries sem√¢nticas comuns
5. Atualizar README principal com overview, quick start, uvx usage examples, link para docs/
6. Validar que TODOS os exemplos em EXAMPLES.md s√£o funcionais e testados

**Acceptance Criteria**:
- ‚úÖ Documenta√ß√£o completa e testada
- ‚úÖ Vari√°veis de ambiente documentadas
- ‚úÖ Processo de build claro
- ‚úÖ Troubleshooting √∫til

**Parallel**: ‚úÖ [P] (pode rodar em paralelo com CI/CD)

---

### T050: Validar compliance constitucional final

**User Story**: Polish  
**File**: `tests/contract/test_constitution_compliance.py`  
**Description**: Teste final validando todas as regras da constitution

**Steps**:
1. Criar teste de compliance constitucional
2. Validar apenas 3 tools p√∫blicas registradas
3. Validar performance targets (<200ms, <10ms, <100ms, <1GB)
4. Validar rate limiting funcional (100 req/min)
5. Validar embeddings pr√©-computados (n√£o gerados em runtime)
6. Validar OpenAPI como source of truth
7. Validar MCP protocol compliance completo
8. Validar structured logging e OpenTelemetry

**Acceptance Criteria**:
- ‚úÖ 100% compliance com constitution
- ‚úÖ Todas as m√©tricas de performance atingidas
- ‚úÖ MCP protocol compliance validado
- ‚úÖ Teste documenta compliance

**Parallel**: ‚úÖ [P] (independente de documenta√ß√£o)

---

### T050a: Teste de integra√ß√£o OpenTelemetry end-to-end

**User Story**: Polish  
**File**: `tests/integration/test_opentelemetry_e2e.py`  
**Description**: Validar instrumenta√ß√£o completa de traces, m√©tricas e logs correlacionados

**Steps**:
1. Criar fixture com OTLP collector mock ou real (Jaeger in-memory)
2. Executar opera√ß√£o completa: search-ids ‚Üí get-id ‚Üí call-id
3. Validar que trace completo √© gerado com spans para cada opera√ß√£o
4. Validar que m√©tricas s√£o exportadas (lat√™ncia p50/p95/p99, error rate, cache hits/misses ratio)
5. Validar que logs incluem trace_id correlacionado
6. Testar que erros s√£o traceable (100% dos erros t√™m trace)
7. Validar 95% das opera√ß√µes geram traces completos: executar 100 opera√ß√µes aleat√≥rias, count traces completos (span com operation_id, duration_ms, status), assert ‚â•95 traces completos. M√©trica: (operations_with_complete_trace / total_operations) ‚â• 0.95
8. Medir overhead de instrumenta√ß√£o (<5% latency increase)

**Acceptance Criteria**:
- ‚úÖ Traces completos gerados para opera√ß√µes
- ‚úÖ M√©tricas exportadas corretamente (lat√™ncia p50/p95/p99, cache ratio)
- ‚úÖ Logs correlacionados com trace IDs
- ‚úÖ 100% dos erros s√£o traceable
- ‚úÖ 95%+ das opera√ß√µes t√™m traces completos
- ‚úÖ Overhead de instrumenta√ß√£o <5%

**Parallel**: ‚úÖ [P] (independente de outras tasks de teste)

---

### T051: Teste de autentica√ß√£o RabbitMQ (FR-013)

**User Story**: Polish  
**File**: `tests/integration/test_rabbitmq_authentication.py`  
**Description**: Validar autentica√ß√£o com credenciais via vari√°veis de ambiente

**Steps**:
1. Criar fixture com RabbitMQ container e credenciais customizadas
2. Testar autentica√ß√£o bem-sucedida com credenciais corretas
3. Testar falha de autentica√ß√£o com credenciais inv√°lidas
4. Testar erro descritivo quando RABBITMQ_USERNAME ausente
5. Testar erro descritivo quando RABBITMQ_PASSWORD ausente
6. Validar que credenciais s√£o carregadas de env vars corretamente
7. Testar autentica√ß√£o tanto HTTP API quanto AMQP

**Acceptance Criteria**:
- ‚úÖ Autentica√ß√£o validada para HTTP e AMQP
- ‚úÖ Credenciais carregadas de env vars
- ‚úÖ Erros descritivos para credenciais faltantes/inv√°lidas
- ‚úÖ Cobertura completa de cen√°rios de auth

**Parallel**: ‚úÖ [P] (independente de outras tasks de teste)

---

### T052: Teste de thread-safety do cache (FR-017)

**User Story**: Polish  
**File**: `tests/unit/test_cache_thread_safety.py`  
**Description**: Validar acesso concorrente ao cache com asyncio.Lock

**Steps**:
1. Criar fixtures de cache com asyncio.Lock
2. Testar m√∫ltiplas requisi√ß√µes simult√¢neas (50+ concurrent)
3. Testar cache hits/misses sob concorr√™ncia
4. Testar invalida√ß√£o de cache durante leitura concorrente
5. Testar que n√£o h√° condi√ß√µes de corrida (race conditions)
6. Testar que dados n√£o s√£o corrompidos sob concorr√™ncia
7. Validar que asyncio.Lock √© usado corretamente
8. Medir overhead de locks (deve ser <1ms)

**Acceptance Criteria**:
- ‚úÖ Cache funciona corretamente sob alta concorr√™ncia
- ‚úÖ Sem race conditions detectadas
- ‚úÖ Dados √≠ntegros ap√≥s 1000+ opera√ß√µes concorrentes
- ‚úÖ asyncio.Lock implementado e testado
- ‚úÖ Overhead de locks <1ms

**Parallel**: ‚úÖ [P] (independente de outras tasks de teste)

---

### T053: Teste de multi-vers√£o OpenAPI (FR-020)

**User Story**: Polish  
**File**: `tests/integration/test_openapi_versioning.py`  
**Description**: Validar suporte a vers√µes configur√°veis de OpenAPI via RABBITMQ_API_VERSION

**Steps**:
1. Criar fixtures com m√∫ltiplas vers√µes de OpenAPI (ex: 3.12, 3.13)
2. Testar carregamento de schemas da vers√£o correta
3. Testar que RABBITMQ_API_VERSION seleciona vers√£o correta
4. Testar erro quando vers√£o n√£o suportada √© especificada
5. Testar que embeddings s√£o carregados da vers√£o correta
6. Testar que operation registry usa vers√£o correta
7. Validar que uma vers√£o por vez √© ativa
8. Documentar vers√µes suportadas no README

**Acceptance Criteria**:
- ‚úÖ M√∫ltiplas vers√µes de OpenAPI suportadas
- ‚úÖ RABBITMQ_API_VERSION seleciona vers√£o corretamente
- ‚úÖ Erro claro para vers√µes n√£o suportadas
- ‚úÖ Apenas uma vers√£o ativa por deploy
- ‚úÖ Documenta√ß√£o de vers√µes suportadas completa

**Parallel**: ‚úÖ [P] (independente de outras tasks de teste)

---

### T054: Teste de identifica√ß√£o de cliente para rate limiting

**User Story**: Polish  
**File**: `tests/unit/test_rate_limit_client_identification.py`  
**Description**: Validar identifica√ß√£o de cliente via connection ID do MCP

**Steps**:
1. Criar fixtures de m√∫ltiplos clients MCP
2. Testar que cada client tem rate limit independente
3. Testar extra√ß√£o de connection ID do contexto MCP
4. Testar fallback quando connection ID n√£o dispon√≠vel
5. Testar que rate limit n√£o afeta clients diferentes
6. Testar que rate limit persiste por client
7. Validar m√©tricas por client

**Acceptance Criteria**:
- ‚úÖ Connection ID extra√≠do corretamente do MCP
- ‚úÖ Rate limit independente por client
- ‚úÖ Fallback funcional
- ‚úÖ M√©tricas por client funcionais

**Parallel**: ‚úÖ [P] (independente de outras tasks de teste)

---

### T055: Teste de performance com carga realista

**User Story**: Polish  
**File**: `tests/performance/test_realistic_load.py`  
**Description**: Validar performance com cen√°rios realistas de uso

**Steps**:
1. Criar cen√°rio: 10 clients fazendo buscas concorrentes
2. Testar throughput: m√≠nimo 500 req/min mantido
3. Testar lat√™ncia p95 <200ms para opera√ß√µes b√°sicas
4. Testar lat√™ncia p99 <500ms
5. Testar uso de mem√≥ria est√°vel <1GB ap√≥s 1h
6. Testar sem memory leaks (valgrind ou similar)
7. Gerar relat√≥rio de performance

**Acceptance Criteria**:
- ‚úÖ 500+ req/min sustentado
- ‚úÖ p95 latency <200ms
- ‚úÖ Mem√≥ria <1GB est√°vel
- ‚úÖ Sem memory leaks detectados

**Parallel**: ‚úÖ [P] (independente de outras tasks)

---

### T056: Valida√ß√£o final de cobertura de requisitos

**User Story**: Polish  
**File**: `tests/contract/test_requirements_coverage.py`  
**Description**: Teste automatizado validando que todos os FR-001 a FR-021 t√™m testes

**Steps**:
1. Criar mapeamento de FR-XXX ‚Üí tests
2. Para cada FR, validar que existe teste correspondente
3. Validar que teste cobre acceptance criteria
4. Gerar relat√≥rio de cobertura de requisitos
5. Falhar se qualquer FR n√£o tem teste
6. Documentar coverage em README

**Acceptance Criteria**:
- ‚úÖ 100% dos requisitos funcionais t√™m testes
- ‚úÖ Relat√≥rio de coverage gerado
- ‚úÖ Build falha se coverage <100%
- ‚úÖ Documenta√ß√£o atualizada

**Parallel**: ‚úÖ [P] (independente de outras tasks)

---

## Dependencies Graph

```
Phase 1 (Setup)
‚îú‚îÄ T001 ‚Üí T002
‚îú‚îÄ T003 [P]
‚îú‚îÄ T004 [P] ‚Üí T004a [P] (logging validation tests)
‚îú‚îÄ T005 [P]
‚îî‚îÄ T006 [P]

Phase 2 (Foundational + AMQP) - BLOCKS ALL USER STORIES
‚îú‚îÄ T007 ‚Üí T008 ‚Üí T008a [P] (multi-version schemas) ‚Üí T011 ‚Üí T012
‚îú‚îÄ T007 ‚Üí T009 [P]
‚îú‚îÄ T007 ‚Üí T010 [P]
‚îú‚îÄ T013 [P]
‚îú‚îÄ T013a [P] (AMQP client)
‚îú‚îÄ T013b [P] (AMQP schemas)
‚îú‚îÄ T008 + T013b ‚Üí T013c ‚Üí T013d (AMQP registry + embeddings)
‚îú‚îÄ T013a + T013c ‚Üí T013e (AMQP executors)
‚îî‚îÄ T013f [P] (AMQP integration tests)

Phase 3 (US1) - Descobrir Opera√ß√µes
‚îú‚îÄ T014 ‚Üí T015
‚îú‚îÄ T016 [P] ‚îê
‚îú‚îÄ T017 [P] ‚îú‚îÄ can run parallel
‚îú‚îÄ T018 [P] ‚îÇ
‚îú‚îÄ T019 [P] ‚îÇ
‚îú‚îÄ T020 [P] ‚îÇ
‚îî‚îÄ T021 [P] ‚îò

Phase 4 (US2) - Obter Detalhes
‚îú‚îÄ T022 ‚Üí T023
‚îú‚îÄ T024 [P] ‚îê
‚îú‚îÄ T025 [P] ‚îú‚îÄ can run parallel
‚îî‚îÄ T026 [P] ‚îò

Phase 5 (US3) - Executar Opera√ß√µes
‚îú‚îÄ T027 ‚Üí T028 ‚Üí T030
‚îú‚îÄ T027 ‚Üí T029 ‚Üí T030
‚îú‚îÄ T031 [P] ‚îê
‚îú‚îÄ T032 [P] ‚îÇ
‚îú‚îÄ T033 [P] ‚îÇ
‚îú‚îÄ T034 [P] ‚îú‚îÄ can run parallel after T027
‚îú‚îÄ T035 [P] ‚îÇ
‚îú‚îÄ T036 [P] ‚îÇ
‚îú‚îÄ T037      ‚îÇ  (requires infrastructure)
‚îú‚îÄ T038 [P] ‚îÇ
‚îî‚îÄ T039 [P] ‚îò

Phase 6 (US4) - Feedback de Erros
‚îú‚îÄ T043 ‚Üí T044 [P]
‚îú‚îÄ         T045 [P]
‚îú‚îÄ         T046 [P]
‚îî‚îÄ         T047 [P]

Phase 7 (Polish + Additional Tests)
‚îú‚îÄ T048
‚îú‚îÄ T049 [P]
‚îú‚îÄ T050 [P]
‚îú‚îÄ T050a [P] (OpenTelemetry e2e tests)
‚îú‚îÄ T051 [P] (Auth tests)
‚îú‚îÄ T052 [P] (Thread-safety tests)
‚îú‚îÄ T053 [P] (Multi-version tests)
‚îú‚îÄ T054 [P] (Rate limit client ID tests)
‚îú‚îÄ T055 [P] (Performance tests)
‚îî‚îÄ T056 [P] (Requirements coverage validation)
```

## Parallel Execution Examples

### Maximum Parallelization Opportunities

**During Setup (Phase 1)**:
- Run T003, T004, T005, T006 in parallel after T002
- **Speedup**: 4 tasks ‚Üí ~1 day instead of 2-3 days

**During Foundational (Phase 2)**:
- Run T009, T010, T013 in parallel with T008
- **Speedup**: 3 tasks concurrently

**During US1 (Phase 3)**:
- After T015, run T016-T021 (6 tasks) in parallel
- **Speedup**: 6 tasks ‚Üí ~1 day instead of 3 days

**During US3 (Phase 5)**:
- After T027, run T031-T039 (9 tasks) in parallel
- **Speedup**: 9 tasks ‚Üí ~1-2 days instead of 4+ days

**During US4 (Phase 6)**:
- After T040, run T041-T044 (4 tasks) in parallel
- **Speedup**: 4 tasks ‚Üí few hours instead of 1+ day

## Independent Testing Strategy

Cada User Story pode ser testada independentemente:

### US1 - Descobrir Opera√ß√µes
**Test**: Enviar query "list queues" ‚Üí verificar resultados relevantes retornados
**Success**: Opera√ß√µes de filas retornadas com similarity_score >= 0.7

### US2 - Obter Detalhes
**Test**: Solicitar detalhes de "queues.list" ‚Üí verificar schema completo retornado
**Success**: Request/response schemas, examples e documenta√ß√£o presentes

### US3 - Executar Opera√ß√µes
**Test**: Executar "queues.create" com params v√°lidos ‚Üí verificar fila criada no RabbitMQ
**Success**: Opera√ß√£o executada, resultado retornado, fila verific√°vel no RabbitMQ

### US4 - Feedback de Erros
**Test**: Executar opera√ß√£o sem param obrigat√≥rio ‚Üí verificar erro detalhado
**Success**: Erro lista especificamente "missing: ['vhost']" com sugest√£o de resolu√ß√£o

## Implementation Strategy

### MVP Scope (Recommended First Delivery)
**Focus**: User Story 1 apenas (T001-T021)
- Setup completo (Phase 1)
- Foundational completo (Phase 2)
- US1: Descobrir Opera√ß√µes (Phase 3)

**Rationale**: US1 √© a porta de entrada do sistema. Entregar busca sem√¢ntica funcional primeiro permite validar a proposta de valor do padr√£o de descoberta sem√¢ntica.

**Timeline**: ~1 semana

### Incremental Delivery
1. **Week 1**: MVP (US1 apenas)
2. **Week 2**: US2 (Obter Detalhes) + US4 (Error Handling)
3. **Week 3**: US3 (Executar Opera√ß√µes) - funcionalidade principal
4. **Week 4**: Polish, integration, CI/CD

## Success Metrics

Ap√≥s implementa√ß√£o completa, validar:

- ‚úÖ **SC-001**: Desenvolvedores descobrem opera√ß√µes em <5s via busca sem√¢ntica
- ‚úÖ **SC-002**: Resposta b√°sica em <200ms (95th percentile)
- ‚úÖ **SC-003**: Valida√ß√£o adiciona <10ms
- ‚úÖ **SC-004**: Uso de mem√≥ria <1GB
- ‚úÖ **SC-005**: 100% MCP compliance (validado por contract tests)
- ‚úÖ **SC-006**: Desenvolvedores executam opera√ß√µes com sucesso na primeira tentativa
- ‚úÖ **SC-007**: Erros permitem identificar problema em 90% dos casos
- ‚úÖ **SC-008**: Timeouts >30s abortados com mensagem clara
- ‚úÖ **SC-009**: Logs JSON permitem an√°lise automatizada
- ‚úÖ **SC-010**: Integridade de cache sob concorr√™ncia
- ‚úÖ **SC-011**: OpenTelemetry traces/metrics/logs completos
- ‚úÖ **SC-012**: Rate limiting protege RabbitMQ de sobrecarga

---

**Generated**: 2025-10-09  
**Version**: 1.0.0  
**Ready for**: Immediate implementation
